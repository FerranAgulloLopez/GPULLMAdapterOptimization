INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.982208503875881,
    "estimated_duration": 3600.028474806175,
    "input_throughput": 4816.9693993694455,
    "output_throughput": 4248.886948268802,
    "total_throughput": 9065.856347638248,
    "itl": 38.188782782961844,
    "ttft": 8667.487543186837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 69453,
    "finished_requests": 69287,
    "scheduler_time": 45.048548227565455
}
#Debug simulation 
Total elapsed time: 4.982347186654806. Arrivals time: 0.18624316342175007 Scheduler time: 4.518799133133143 Scheduler overhead time: 0.10100443521514535 Adapter cache time: 0.02770003955811262 Engine time: 0.10134523315355182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.949634830001742,
    "estimated_duration": 3600.02649931622,
    "input_throughput": 4816.9720426485055,
    "output_throughput": 4248.889279816497,
    "total_throughput": 9065.861322465003,
    "itl": 38.188814876122834,
    "ttft": 8667.507176215444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 69453,
    "finished_requests": 69287,
    "scheduler_time": 45.04848355161153
}
#Debug simulation 
Total elapsed time: 4.949750576168299. Arrivals time: 0.17829206259921193 Scheduler time: 4.4977284534834325 Scheduler overhead time: 0.10023683216422796 Adapter cache time: 0.027650534640997648 Engine time: 0.09922391921281815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.96910501178354,
    "estimated_duration": 3600.033282667072,
    "input_throughput": 4816.9632440600135,
    "output_throughput": 4248.90905138184,
    "total_throughput": 9065.872295441854,
    "itl": 38.188536879682445,
    "ttft": 8615.695589526616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 69453,
    "finished_requests": 69288,
    "scheduler_time": 45.048415418986366
}
#Debug simulation 
Total elapsed time: 4.969299261923879. Arrivals time: 0.18205677857622504 Scheduler time: 4.511158959474415 Scheduler overhead time: 0.10150939878076315 Adapter cache time: 0.02767395507544279 Engine time: 0.10005097324028611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.968007430899888,
    "estimated_duration": 3600.0322708229614,
    "input_throughput": 4816.964320165892,
    "output_throughput": 4248.8824680739135,
    "total_throughput": 9065.846788239805,
    "itl": 38.18881590880759,
    "ttft": 8667.435264070495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 69453,
    "finished_requests": 69287,
    "scheduler_time": 45.04861678442747
}
#Debug simulation 
Total elapsed time: 4.968137273099273. Arrivals time: 0.1879364657215774 Scheduler time: 4.5052948044613 Scheduler overhead time: 0.10010558553040028 Adapter cache time: 0.027778726536780596 Engine time: 0.10034396359696984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.952120521105826,
    "estimated_duration": 3600.029450012889,
    "input_throughput": 4816.968094507648,
    "output_throughput": 4248.8857972940295,
    "total_throughput": 9065.853891801677,
    "itl": 38.18856723954671,
    "ttft": 8667.575534799467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 69453,
    "finished_requests": 69287,
    "scheduler_time": 45.04838322442163
}
#Debug simulation 
Total elapsed time: 4.952214506920427. Arrivals time: 0.17806642269715667 Scheduler time: 4.500760048627853 Scheduler overhead time: 0.10016820952296257 Adapter cache time: 0.027730821631848812 Engine time: 0.09885642025619745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 540, 540, 1080, 540, 17280, 1080, 540, 540, 540, 17280, 17280, 540, 540, 1080, 1080, 1080, 17280, 17280, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 207360 . Total input tokens: 46296826 . Total output tokens: 41478695
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 5.004321780055761,
    "estimated_duration": 3600.0262442130265,
    "input_throughput": 4816.972383986281,
    "output_throughput": 4248.8895808990865,
    "total_throughput": 9065.861964885367,
    "itl": 38.18880490871074,
    "ttft": 8667.465790664604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 69453,
    "finished_requests": 69287,
    "scheduler_time": 45.048483592586585
}
#Debug simulation 
Total elapsed time: 5.004426495172083. Arrivals time: 0.20652049453929067 Scheduler time: 4.5214243535883725 Scheduler overhead time: 0.1009867237880826 Adapter cache time: 0.02768895262852311 Engine time: 0.10108805447816849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.879991516005248,
    "estimated_duration": 3599.984979643388,
    "input_throughput": 4737.536710969684,
    "output_throughput": 4187.935528968087,
    "total_throughput": 8925.47223993777,
    "itl": 36.61678065159407,
    "ttft": 10670.592248163175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.43753485590985
}
#Debug simulation 
Total elapsed time: 4.880156068596989. Arrivals time: 0.18377617001533508 Scheduler time: 4.418125652242452 Scheduler overhead time: 0.10267274221405387 Adapter cache time: 0.026372624095529318 Engine time: 0.10114999674260616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.921304564923048,
    "estimated_duration": 3599.9559340151563,
    "input_throughput": 4737.574934973689,
    "output_throughput": 4187.9693186090335,
    "total_throughput": 8925.544253582722,
    "itl": 36.61677312751074,
    "ttft": 10670.691819552037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.4371822465488
}
#Debug simulation 
Total elapsed time: 4.9214154882356524. Arrivals time: 0.17527510598301888 Scheduler time: 4.465928981546313 Scheduler overhead time: 0.1030437839217484 Adapter cache time: 0.02651259582489729 Engine time: 0.1024017003364861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.994492670986801,
    "estimated_duration": 3599.9535074650016,
    "input_throughput": 4737.578128338038,
    "output_throughput": 4187.972141511489,
    "total_throughput": 8925.550269849527,
    "itl": 36.61678698721971,
    "ttft": 10670.678497853034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.437113484812066
}
#Debug simulation 
Total elapsed time: 4.9945971430279315. Arrivals time: 0.16138427425175905 Scheduler time: 4.552950740791857 Scheduler overhead time: 0.10320238955318928 Adapter cache time: 0.02651353506371379 Engine time: 0.10246313456445932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.987922691740096,
    "estimated_duration": 3599.984832581186,
    "input_throughput": 4737.5369045017715,
    "output_throughput": 4187.935700048536,
    "total_throughput": 8925.472604550308,
    "itl": 36.61674563757588,
    "ttft": 10670.622937194052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.43751463186963
}
#Debug simulation 
Total elapsed time: 4.988040870986879. Arrivals time: 0.18053683545440435 Scheduler time: 4.525797116104513 Scheduler overhead time: 0.10434863390401006 Adapter cache time: 0.026340223383158445 Engine time: 0.10258277179673314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.939717683941126,
    "estimated_duration": 3599.955994325354,
    "input_throughput": 4737.574855604918,
    "output_throughput": 4187.969248447826,
    "total_throughput": 8925.544104052746,
    "itl": 36.61669881111931,
    "ttft": 10670.719211629126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.43718625038188
}
#Debug simulation 
Total elapsed time: 4.939815633930266. Arrivals time: 0.1763473772443831 Scheduler time: 4.484910600353032 Scheduler overhead time: 0.10322247724980116 Adapter cache time: 0.02617064630612731 Engine time: 0.10092253424227238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.9862768850289285,
    "estimated_duration": 3599.9810380159975,
    "input_throughput": 4737.541898109356,
    "output_throughput": 4187.940114348181,
    "total_throughput": 8925.482012457538,
    "itl": 36.61675416197202,
    "ttft": 10670.516201218104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.4374621313148
}
#Debug simulation 
Total elapsed time: 4.9864057009108365. Arrivals time: 0.18718665651977062 Scheduler time: 4.518633637577295 Scheduler overhead time: 0.10413049254566431 Adapter cache time: 0.02616741554811597 Engine time: 0.10208753356710076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 270, 270, 1080, 270, 17280, 1080, 270, 270, 270, 17280, 17280, 270, 270, 1080, 1080, 1080, 17280, 17280, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 204660 . Total input tokens: 45688111 . Total output tokens: 40931793
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.993504453916103,
    "estimated_duration": 3599.9592904527094,
    "input_throughput": 4737.570517875289,
    "output_throughput": 4187.965413937797,
    "total_throughput": 8925.535931813087,
    "itl": 36.616608509860924,
    "ttft": 10670.58320281373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 68538,
    "finished_requests": 68336,
    "scheduler_time": 43.43721060117983
}
#Debug simulation 
Total elapsed time: 4.9936202727258205. Arrivals time: 0.18833539867773652 Scheduler time: 4.526578883174807 Scheduler overhead time: 0.10236566653475165 Adapter cache time: 0.026046403218060732 Engine time: 0.10256758378818631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.858684255741537,
    "estimated_duration": 3600.0047428180246,
    "input_throughput": 4741.789308487833,
    "output_throughput": 4121.233459372129,
    "total_throughput": 8863.022767859962,
    "itl": 35.44367418243045,
    "ttft": 9150.624354741069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.93212136329647
}
#Debug simulation 
Total elapsed time: 4.858899029903114. Arrivals time: 0.18202206725254655 Scheduler time: 4.394199810456485 Scheduler overhead time: 0.10481931455433369 Adapter cache time: 0.025406942702829838 Engine time: 0.1031458918005228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.804980495944619,
    "estimated_duration": 3600.026545211808,
    "input_throughput": 4741.760591377989,
    "output_throughput": 4121.208500457626,
    "total_throughput": 8862.969091835614,
    "itl": 35.443876668076726,
    "ttft": 9203.305129520779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.932485682844934
}
#Debug simulation 
Total elapsed time: 4.805086904205382. Arrivals time: 0.1750808502547443 Scheduler time: 4.34933875547722 Scheduler overhead time: 0.10442718863487244 Adapter cache time: 0.02535896748304367 Engine time: 0.10214888677001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.822296354919672,
    "estimated_duration": 3600.026590179428,
    "input_throughput": 4741.760532149068,
    "output_throughput": 4121.208448979967,
    "total_throughput": 8862.968981129035,
    "itl": 35.44386171033214,
    "ttft": 9203.302730118123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.93249377246104
}
#Debug simulation 
Total elapsed time: 4.822400152217597. Arrivals time: 0.17442667670547962 Scheduler time: 4.366227670107037 Scheduler overhead time: 0.104443424846977 Adapter cache time: 0.025188653264194727 Engine time: 0.10313801933079958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.868399900849909,
    "estimated_duration": 3600.0047639475706,
    "input_throughput": 4741.789280656799,
    "output_throughput": 4121.233435183331,
    "total_throughput": 8863.022715840129,
    "itl": 35.4436594539528,
    "ttft": 9150.572783347709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.93210926984732
}
#Debug simulation 
Total elapsed time: 4.8685072511434555. Arrivals time: 0.17713937815278769 Scheduler time: 4.410287680104375 Scheduler overhead time: 0.10497952299192548 Adapter cache time: 0.02524597616866231 Engine time: 0.10229447670280933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.841588080860674,
    "estimated_duration": 3600.0265844129453,
    "input_throughput": 4741.760539744368,
    "output_throughput": 4121.2084555812735,
    "total_throughput": 8862.96899532564,
    "itl": 35.44388726740682,
    "ttft": 9203.306390436259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.9324735484208
}
#Debug simulation 
Total elapsed time: 4.84168007504195. Arrivals time: 0.1794347744435072 Scheduler time: 4.382181892637163 Scheduler overhead time: 0.1035636137239635 Adapter cache time: 0.025255438406020403 Engine time: 0.10252676159143448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.853685466106981,
    "estimated_duration": 3600.0038826015816,
    "input_throughput": 4741.790441532481,
    "output_throughput": 4121.23444413573,
    "total_throughput": 8863.024885668212,
    "itl": 35.44365700346065,
    "ttft": 9150.60041659373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.93208900483211
}
#Debug simulation 
Total elapsed time: 4.853812779299915. Arrivals time: 0.18554541328921914 Scheduler time: 4.3850099691189826 Scheduler overhead time: 0.10531563684344292 Adapter cache time: 0.02543361857533455 Engine time: 0.10354093788191676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 135, 135, 1080, 135, 17280, 1080, 135, 135, 135, 17280, 17280, 135, 135, 1080, 1080, 1080, 17280, 17280, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 203310 . Total input tokens: 45377207 . Total output tokens: 40662412
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.882414466235787,
    "estimated_duration": 3600.0266254872167,
    "input_throughput": 4741.760485643556,
    "output_throughput": 4121.208408560611,
    "total_throughput": 8862.968894204168,
    "itl": 35.443863437849956,
    "ttft": 9203.300847110731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 68105,
    "finished_requests": 67932,
    "scheduler_time": 41.93246545880476
}
#Debug simulation 
Total elapsed time: 4.882536823861301. Arrivals time: 0.18194056069478393 Scheduler time: 4.417772497981787 Scheduler overhead time: 0.1052003693766892 Adapter cache time: 0.025517988484352827 Engine time: 0.10272050136700273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.927682643290609,
    "estimated_duration": 3599.955043729176,
    "input_throughput": 4709.2793643440245,
    "output_throughput": 4134.911080606214,
    "total_throughput": 8844.19044495024,
    "itl": 35.351129228428626,
    "ttft": 8596.14688362347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.05241933517133
}
#Debug simulation 
Total elapsed time: 4.927824160084128. Arrivals time: 0.1801444790326059 Scheduler time: 4.466356833931059 Scheduler overhead time: 0.10415417654439807 Adapter cache time: 0.024246935732662678 Engine time: 0.10395009769126773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.895747332833707,
    "estimated_duration": 3599.9548427044497,
    "input_throughput": 4709.279627314433,
    "output_throughput": 4134.91131150338,
    "total_throughput": 8844.190938817814,
    "itl": 35.35155015134664,
    "ttft": 8596.115252198466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.05260856618825
}
#Debug simulation 
Total elapsed time: 4.8958534128032625. Arrivals time: 0.17280564596876502 Scheduler time: 4.446494687348604 Scheduler overhead time: 0.1034235735423863 Adapter cache time: 0.023872157093137503 Engine time: 0.10041997442021966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.883111373055726,
    "estimated_duration": 3599.954848929839,
    "input_throughput": 4709.279619170692,
    "output_throughput": 4134.911304352892,
    "total_throughput": 8844.190923523585,
    "itl": 35.35156961607215,
    "ttft": 8596.118938488029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.0526045213802
}
#Debug simulation 
Total elapsed time: 4.883262749761343. Arrivals time: 0.17386409966275096 Scheduler time: 4.429935556370765 Scheduler overhead time: 0.10393992764875293 Adapter cache time: 0.024047108832746744 Engine time: 0.10252800630405545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.888709402177483,
    "estimated_duration": 3599.955417836803,
    "input_throughput": 4709.278874955373,
    "output_throughput": 4134.910650905957,
    "total_throughput": 8844.18952586133,
    "itl": 35.35120183589315,
    "ttft": 8596.150002273373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.052398988206285
}
#Debug simulation 
Total elapsed time: 4.888801922090352. Arrivals time: 0.1738055977039039 Scheduler time: 4.434674725867808 Scheduler overhead time: 0.10530226491391659 Adapter cache time: 0.02403868455439806 Engine time: 0.10169578436762094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.956436868291348,
    "estimated_duration": 3599.9548446723816,
    "input_throughput": 4709.279624740084,
    "output_throughput": 4134.911309243012,
    "total_throughput": 8844.190933983096,
    "itl": 35.351574678141176,
    "ttft": 8596.101241468772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.0526045213802
}
#Debug simulation 
Total elapsed time: 4.956530323252082. Arrivals time: 0.18324984796345234 Scheduler time: 4.493480797391385 Scheduler overhead time: 0.10403749439865351 Adapter cache time: 0.02434433437883854 Engine time: 0.10231974255293608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.925750439055264,
    "estimated_duration": 3599.9555069994644,
    "input_throughput": 4709.27875831731,
    "output_throughput": 4134.91054849368,
    "total_throughput": 8844.18930681099,
    "itl": 35.35120855429184,
    "ttft": 8596.138510691555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.052419417121015
}
#Debug simulation 
Total elapsed time: 4.925847533158958. Arrivals time: 0.18055784236639738 Scheduler time: 4.466398897115141 Scheduler overhead time: 0.10434697708114982 Adapter cache time: 0.024211648385971785 Engine time: 0.10169735411182046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 66, 66, 1080, 66, 17280, 1080, 66, 66, 66, 17280, 17280, 66, 66, 1080, 1080, 1080, 17280, 17280, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202620 . Total input tokens: 45215902 . Total output tokens: 40517626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.921614145860076,
    "estimated_duration": 3599.9550499095585,
    "input_throughput": 4709.2793562591605,
    "output_throughput": 4134.911073507423,
    "total_throughput": 8844.190429766582,
    "itl": 35.35154201919065,
    "ttft": 8596.135766555979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 67887,
    "finished_requests": 67726,
    "scheduler_time": 42.05257208096602
}
#Debug simulation 
Total elapsed time: 4.921715356875211. Arrivals time: 0.17858492117375135 Scheduler time: 4.463160007726401 Scheduler overhead time: 0.10432459460571408 Adapter cache time: 0.02425378281623125 Engine time: 0.10242209769785404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.948782007209957,
    "estimated_duration": 3600.0027144084083,
    "input_throughput": 4674.240920055873,
    "output_throughput": 4156.635476998253,
    "total_throughput": 8830.876397054126,
    "itl": 35.50065234560379,
    "ttft": 8770.279602781495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 67772,
    "finished_requests": 67607,
    "scheduler_time": 42.42239734021165
}
#Debug simulation 
Total elapsed time: 4.948910844977945. Arrivals time: 0.1717618885450065 Scheduler time: 4.501806921791285 Scheduler overhead time: 0.10293391346931458 Adapter cache time: 0.023049157578498125 Engine time: 0.1011374774388969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.916242563165724,
    "estimated_duration": 3600.0153176332433,
    "input_throughput": 4674.32622232924,
    "output_throughput": 4156.62148066573,
    "total_throughput": 8830.94770299497,
    "itl": 35.50038935076392,
    "ttft": 8770.17004896724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 67772,
    "finished_requests": 67608,
    "scheduler_time": 42.422579397548645
}
#Debug simulation 
Total elapsed time: 4.9163242992945015. Arrivals time: 0.17393459472805262 Scheduler time: 4.467408312950283 Scheduler overhead time: 0.10343914106488228 Adapter cache time: 0.023189658764749765 Engine time: 0.10004012705758214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.918519098777324,
    "estimated_duration": 3600.0160880155504,
    "input_throughput": 4674.325222050872,
    "output_throughput": 4156.620591173137,
    "total_throughput": 8830.945813224009,
    "itl": 35.50043891718765,
    "ttft": 8770.169328368207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 67772,
    "finished_requests": 67608,
    "scheduler_time": 42.42259153197282
}
#Debug simulation 
Total elapsed time: 4.918699319008738. Arrivals time: 0.17502917489036918 Scheduler time: 4.466757213231176 Scheduler overhead time: 0.10312180779874325 Adapter cache time: 0.02318563312292099 Engine time: 0.10171058680862188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.8970018438994884,
    "estimated_duration": 3600.0085784950998,
    "input_throughput": 4674.233306142358,
    "output_throughput": 4156.628706216948,
    "total_throughput": 8830.862012359306,
    "itl": 35.50065538022046,
    "ttft": 8770.239058918472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 67772,
    "finished_requests": 67607,
    "scheduler_time": 42.422514762569435
}
#Debug simulation 
Total elapsed time: 4.89708906179294. Arrivals time: 0.1812953930348158 Scheduler time: 4.43978372681886 Scheduler overhead time: 0.10323709715157747 Adapter cache time: 0.023253439459949732 Engine time: 0.10092503437772393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.924591368995607,
    "estimated_duration": 3600.0160636806468,
    "input_throughput": 4674.325253647746,
    "output_throughput": 4156.6206192705,
    "total_throughput": 8830.945872918246,
    "itl": 35.50043956787849,
    "ttft": 8770.18525037816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 67772,
    "finished_requests": 67608,
    "scheduler_time": 42.422591531972856
}
#Debug simulation 
Total elapsed time: 4.924682708922774. Arrivals time: 0.18509336607530713 Scheduler time: 4.461808651220053 Scheduler overhead time: 0.1037599197588861 Adapter cache time: 0.0233107665553689 Engine time: 0.10183513211086392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.891967969015241,
    "estimated_duration": 3600.0014244758986,
    "input_throughput": 4674.242594903911,
    "output_throughput": 4156.636966380784,
    "total_throughput": 8830.879561284695,
    "itl": 35.50065740904045,
    "ttft": 8770.337029772245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 67772,
    "finished_requests": 67607,
    "scheduler_time": 42.42236910850516
}
#Debug simulation 
Total elapsed time: 4.892080697230995. Arrivals time: 0.17853787913918495 Scheduler time: 4.438810071442276 Scheduler overhead time: 0.10345581453293562 Adapter cache time: 0.023161379154771566 Engine time: 0.09968095971271396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 1080, 33, 33, 1080, 33, 17280, 1080, 33, 33, 33, 17280, 17280, 33, 33, 1080, 1080, 1080, 17280, 17280, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 1080, 1080, 17280]
Prompts retrieved: 202290 . Total input tokens: 45146373 . Total output tokens: 40445837
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.909859488718212,
    "estimated_duration": 3600.016018266588,
    "input_throughput": 4674.325312614173,
    "output_throughput": 4156.620671706104,
    "total_throughput": 8830.945984320277,
    "itl": 35.500438732784374,
    "ttft": 8770.199350767192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 67772,
    "finished_requests": 67608,
    "scheduler_time": 42.42257535274069
}
#Debug simulation 
Total elapsed time: 4.909956695977598. Arrivals time: 0.17293195752426982 Scheduler time: 4.459189131855965 Scheduler overhead time: 0.10298875533044338 Adapter cache time: 0.02304972568526864 Engine time: 0.10306375101208687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.796069893985987,
    "estimated_duration": 3599.9647760007656,
    "input_throughput": 4610.6270568677555,
    "output_throughput": 4054.3041135569424,
    "total_throughput": 8664.931170424697,
    "itl": 34.287593218774205,
    "ttft": 6812.930761169124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.27529436188837
}
#Debug simulation 
Total elapsed time: 4.796179044991732. Arrivals time: 0.1711118989624083 Scheduler time: 4.334390262607485 Scheduler overhead time: 0.1070276452228427 Adapter cache time: 0.025216237176209688 Engine time: 0.1082604443654418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.831398203969002,
    "estimated_duration": 3599.9384520355525,
    "input_throughput": 4610.6607713292315,
    "output_throughput": 4054.333759997255,
    "total_throughput": 8664.994531326487,
    "itl": 34.28770955738747,
    "ttft": 6812.974415471101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.27503457823765
}
#Debug simulation 
Total elapsed time: 4.831486126873642. Arrivals time: 0.1720923907123506 Scheduler time: 4.372195945121348 Scheduler overhead time: 0.10664451168850064 Adapter cache time: 0.025512085761874914 Engine time: 0.10507776215672493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.821201012004167,
    "estimated_duration": 3599.9384790457093,
    "input_throughput": 4610.660736735676,
    "output_throughput": 4054.3337295777933,
    "total_throughput": 8664.99446631347,
    "itl": 34.287700176721636,
    "ttft": 6812.980593658878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.27503457823767
}
#Debug simulation 
Total elapsed time: 4.821297901216894. Arrivals time: 0.17702999338507652 Scheduler time: 4.358794336672872 Scheduler overhead time: 0.10625956626608968 Adapter cache time: 0.02529112482443452 Engine time: 0.10403340589255095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.762124634813517,
    "estimated_duration": 3599.933643443384,
    "input_throughput": 4610.666929994772,
    "output_throughput": 4054.3391755519565,
    "total_throughput": 8665.006105546729,
    "itl": 34.287627881634194,
    "ttft": 6812.94419062406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.27502248478843
}
#Debug simulation 
Total elapsed time: 4.762215060647577. Arrivals time: 0.1802794965915382 Scheduler time: 4.2984468303620815 Scheduler overhead time: 0.10549152223393321 Adapter cache time: 0.02524231467396021 Engine time: 0.10298987478017807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.814142657909542,
    "estimated_duration": 3599.9432991770877,
    "input_throughput": 4610.654563307751,
    "output_throughput": 4054.3283010419514,
    "total_throughput": 8664.982864349702,
    "itl": 34.2876668408322,
    "ttft": 6812.975468737544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.27515183669618
}
#Debug simulation 
Total elapsed time: 4.814254778902978. Arrivals time: 0.17893508356064558 Scheduler time: 4.350872568786144 Scheduler overhead time: 0.10636038333177567 Adapter cache time: 0.02532921778038144 Engine time: 0.10259276442229748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.797046923078597,
    "estimated_duration": 3599.9645754064622,
    "input_throughput": 4610.627313777373,
    "output_throughput": 4054.3043394675847,
    "total_throughput": 8664.931653244957,
    "itl": 34.28768427765723,
    "ttft": 6812.946303672118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.275314585928605
}
#Debug simulation 
Total elapsed time: 4.797140018083155. Arrivals time: 0.17409563437104225 Scheduler time: 4.337524933274835 Scheduler overhead time: 0.10624715685844421 Adapter cache time: 0.025353566277772188 Engine time: 0.10392497759312391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 270, 270, 540, 270, 17280, 540, 270, 270, 270, 17280, 17280, 270, 270, 540, 540, 540, 17280, 17280, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 540, 540, 17280]
Prompts retrieved: 198720 . Total input tokens: 44354450 . Total output tokens: 39727035
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.834034711122513,
    "estimated_duration": 3599.9461976042935,
    "input_throughput": 4610.65085112821,
    "output_throughput": 4054.325036777764,
    "total_throughput": 8664.975887905974,
    "itl": 34.287675408444855,
    "ttft": 6813.0060150873915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 66605,
    "finished_requests": 66480,
    "scheduler_time": 40.275184154185595
}
#Debug simulation 
Total elapsed time: 4.834183398168534. Arrivals time: 0.16796086123213172 Scheduler time: 4.378732057288289 Scheduler overhead time: 0.10751300444826484 Adapter cache time: 0.02542828395962715 Engine time: 0.10429303627461195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.808399325702339,
    "estimated_duration": 3600.0191485039654,
    "input_throughput": 4560.838518545984,
    "output_throughput": 4065.2764322328103,
    "total_throughput": 8626.114950778794,
    "itl": 33.903639124508736,
    "ttft": 7893.036829148114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.21221083348952
}
#Debug simulation 
Total elapsed time: 4.808517592027783. Arrivals time: 0.169058034196496 Scheduler time: 4.353934406768531 Scheduler overhead time: 0.1074284347705543 Adapter cache time: 0.023901421576738358 Engine time: 0.10353510454297066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.835320075973868,
    "estimated_duration": 3600.0018463592182,
    "input_throughput": 4560.860438614802,
    "output_throughput": 4065.295970556475,
    "total_throughput": 8626.156409171277,
    "itl": 33.9038432733975,
    "ttft": 7784.482945180811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.21217272127036
}
#Debug simulation 
Total elapsed time: 4.83540114434436. Arrivals time: 0.17047057440504432 Scheduler time: 4.377785116434097 Scheduler overhead time: 0.10774433426558971 Adapter cache time: 0.024079424794763327 Engine time: 0.10467771673575044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.836661422159523,
    "estimated_duration": 3600.001861567798,
    "input_throughput": 4560.8604193469755,
    "output_throughput": 4065.295953382212,
    "total_throughput": 8626.156372729187,
    "itl": 33.90383230256956,
    "ttft": 7784.497296249563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.21216867646235
}
#Debug simulation 
Total elapsed time: 4.8367558480240405. Arrivals time: 0.1780323786661029 Scheduler time: 4.371626745443791 Scheduler overhead time: 0.10744942259043455 Adapter cache time: 0.023812368512153625 Engine time: 0.10530114034190774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.850690929219127,
    "estimated_duration": 3600.0203598338076,
    "input_throughput": 4560.836983921385,
    "output_throughput": 4065.275064354252,
    "total_throughput": 8626.112048275636,
    "itl": 33.90365936083515,
    "ttft": 7893.028646769036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.21221800716982
}
#Debug simulation 
Total elapsed time: 4.850784032139927. Arrivals time: 0.17835450312122703 Scheduler time: 4.383888196200132 Scheduler overhead time: 0.10820222459733486 Adapter cache time: 0.02404460357502103 Engine time: 0.10590517800301313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.834141922183335,
    "estimated_duration": 3600.0018553171535,
    "input_throughput": 4560.860427265949,
    "output_throughput": 4065.295960440742,
    "total_throughput": 8626.156387706691,
    "itl": 33.90379483383947,
    "ttft": 7784.491708258999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.212160627821156
}
#Debug simulation 
Total elapsed time: 4.83424985408783. Arrivals time: 0.17184720328077674 Scheduler time: 4.378134123980999 Scheduler overhead time: 0.10727758752182126 Adapter cache time: 0.02382394950836897 Engine time: 0.10282150888815522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.821106086950749,
    "estimated_duration": 3600.0215787295883,
    "input_throughput": 4560.835439712597,
    "output_throughput": 4065.273687932885,
    "total_throughput": 8626.109127645483,
    "itl": 33.90373848348462,
    "ttft": 7893.059738181475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.21223902422091
}
#Debug simulation 
Total elapsed time: 4.821212561801076. Arrivals time: 0.16521231830120087 Scheduler time: 4.3708725911565125 Scheduler overhead time: 0.10763709712773561 Adapter cache time: 0.023788990452885628 Engine time: 0.10320750204846263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 135, 135, 540, 135, 17280, 540, 135, 135, 135, 17280, 17280, 135, 135, 540, 540, 540, 17280, 17280, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 540, 540, 17280]
Prompts retrieved: 197370 . Total input tokens: 44032375 . Total output tokens: 39454431
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.814029419794679,
    "estimated_duration": 3600.002455775322,
    "input_throughput": 4560.859666542607,
    "output_throughput": 4065.2952823744918,
    "total_throughput": 8626.1549489171,
    "itl": 33.903770206412815,
    "ttft": 7784.4778863934225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 66148,
    "finished_requests": 66003,
    "scheduler_time": 40.21214040378084
}
#Debug simulation 
Total elapsed time: 4.814111846033484. Arrivals time: 0.1704997126944363 Scheduler time: 4.357318559195846 Scheduler overhead time: 0.10669483803212643 Adapter cache time: 0.02376540843397379 Engine time: 0.10485584661364555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.769346907734871,
    "estimated_duration": 3600.030089404736,
    "input_throughput": 4524.18968606262,
    "output_throughput": 4060.2118974002515,
    "total_throughput": 8584.401583462872,
    "itl": 33.61324942689696,
    "ttft": 8356.194685375127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.97733663107464
}
#Debug simulation 
Total elapsed time: 4.769531985744834. Arrivals time: 0.17110984632745385 Scheduler time: 4.312857123091817 Scheduler overhead time: 0.1070389705710113 Adapter cache time: 0.022714901715517044 Engine time: 0.10533197177574039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.808418862055987,
    "estimated_duration": 3600.0361115821734,
    "input_throughput": 4524.182117951578,
    "output_throughput": 4060.2051054360263,
    "total_throughput": 8584.387223387605,
    "itl": 33.61304711360032,
    "ttft": 8356.20122128862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.97738525072092
}
#Debug simulation 
Total elapsed time: 4.8085009371861815. Arrivals time: 0.1756519959308207 Scheduler time: 4.346058499533683 Scheduler overhead time: 0.10847428208217025 Adapter cache time: 0.022914183791726828 Engine time: 0.10460237320512533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.783375284168869,
    "estimated_duration": 3600.0352821860215,
    "input_throughput": 4524.183160257818,
    "output_throughput": 4060.2060408486614,
    "total_throughput": 8584.38920110648,
    "itl": 33.61304468340656,
    "ttft": 8356.224378709354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.97737311629679
}
#Debug simulation 
Total elapsed time: 4.783476530108601. Arrivals time: 0.1771284518763423 Scheduler time: 4.321493474300951 Scheduler overhead time: 0.10754960076883435 Adapter cache time: 0.02273387275636196 Engine time: 0.104002695530653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.8629952552728355,
    "estimated_duration": 3600.0312197139942,
    "input_throughput": 4524.188265593414,
    "output_throughput": 4060.210622607113,
    "total_throughput": 8584.398888200527,
    "itl": 33.61318798311955,
    "ttft": 8356.190407966118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.97732049281753
}
#Debug simulation 
Total elapsed time: 4.863093322142959. Arrivals time: 0.17414689483121037 Scheduler time: 4.397900566458702 Scheduler overhead time: 0.1093626981601119 Adapter cache time: 0.022841925732791424 Engine time: 0.10749313421547413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.775802408810705,
    "estimated_duration": 3600.0036758593074,
    "input_throughput": 4524.073158373215,
    "output_throughput": 4060.1386320837832,
    "total_throughput": 8584.211790456999,
    "itl": 33.61303525550345,
    "ttft": 8410.947815641804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 65922,
    "finished_requests": 65768,
    "scheduler_time": 39.9770283507023
}
#Debug simulation 
Total elapsed time: 4.775888526812196. Arrivals time: 0.16919156117364764 Scheduler time: 4.318494724109769 Scheduler overhead time: 0.10799530008807778 Adapter cache time: 0.022927456069737673 Engine time: 0.10670282365754247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.78928542137146,
    "estimated_duration": 3600.0215823420726,
    "input_throughput": 4524.20037698885,
    "output_throughput": 4060.2214919196863,
    "total_throughput": 8584.421868908536,
    "itl": 33.61318039227013,
    "ttft": 8301.659229191768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 65922,
    "finished_requests": 65770,
    "scheduler_time": 39.97717075296971
}
#Debug simulation 
Total elapsed time: 4.789368940982968. Arrivals time: 0.16918943682685494 Scheduler time: 4.336132009513676 Scheduler overhead time: 0.10664412658661604 Adapter cache time: 0.022666598670184612 Engine time: 0.10419625230133533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 66, 66, 540, 66, 17280, 540, 66, 66, 66, 17280, 17280, 66, 66, 540, 540, 540, 17280, 17280, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 540, 540, 17280]
Prompts retrieved: 196680 . Total input tokens: 43870822 . Total output tokens: 39320436
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.787920123897493,
    "estimated_duration": 3600.008077880436,
    "input_throughput": 4524.067626422952,
    "output_throughput": 4060.1336674238005,
    "total_throughput": 8584.201293846752,
    "itl": 33.61315872911778,
    "ttft": 8410.974095724923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 65922,
    "finished_requests": 65768,
    "scheduler_time": 39.97710512010511
}
#Debug simulation 
Total elapsed time: 4.788030283059925. Arrivals time: 0.1778451162390411 Scheduler time: 4.323973401915282 Scheduler overhead time: 0.10745959961786866 Adapter cache time: 0.022746555972844362 Engine time: 0.10521338460966945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.784225543960929,
    "estimated_duration": 3599.9571970946486,
    "input_throughput": 4556.941125088797,
    "output_throughput": 4029.4604090590296,
    "total_throughput": 8586.401534147826,
    "itl": 33.23235807931275,
    "ttft": 7985.747997475841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.334049572003245
}
#Debug simulation 
Total elapsed time: 4.784349963068962. Arrivals time: 0.17785696452483535 Scheduler time: 4.317155265714973 Scheduler overhead time: 0.10973445698618889 Adapter cache time: 0.02261503553017974 Engine time: 0.10551863443106413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.772634105756879,
    "estimated_duration": 3599.962189317242,
    "input_throughput": 4556.934805782303,
    "output_throughput": 4029.454821232759,
    "total_throughput": 8586.389627015062,
    "itl": 33.23247516386006,
    "ttft": 7985.791668500062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.334098902710906
}
#Debug simulation 
Total elapsed time: 4.772720030974597. Arrivals time: 0.1712245950475335 Scheduler time: 4.31067134346813 Scheduler overhead time: 0.10994379920884967 Adapter cache time: 0.022721126675605774 Engine time: 0.10717024747282267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.711611095350236,
    "estimated_duration": 3599.9620424511454,
    "input_throughput": 4556.9349916896035,
    "output_throughput": 4029.4549856206872,
    "total_throughput": 8586.389977310291,
    "itl": 33.23245848710318,
    "ttft": 7985.791615826619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.33409890271095
}
#Debug simulation 
Total elapsed time: 4.711702182423323. Arrivals time: 0.1633848175406456 Scheduler time: 4.263140671420842 Scheduler overhead time: 0.10789038147777319 Adapter cache time: 0.022364774253219366 Engine time: 0.1038148207589984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.749396026134491,
    "estimated_duration": 3599.959688363449,
    "input_throughput": 4556.937971563138,
    "output_throughput": 4029.457620564194,
    "total_throughput": 8586.395592127332,
    "itl": 33.23237951269163,
    "ttft": 7985.757037759725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.33410607639124
}
#Debug simulation 
Total elapsed time: 4.749527081847191. Arrivals time: 0.16945391986519098 Scheduler time: 4.293438309803605 Scheduler overhead time: 0.10703214490786195 Adapter cache time: 0.02241466846317053 Engine time: 0.10606360668316483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.72891202615574,
    "estimated_duration": 3599.9634497375805,
    "input_throughput": 4556.933210306851,
    "output_throughput": 4029.4534104387662,
    "total_throughput": 8586.386620745618,
    "itl": 33.23242603208115,
    "ttft": 7985.821812319072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.33412725734171
}
#Debug simulation 
Total elapsed time: 4.7289942391216755. Arrivals time: 0.16791200125589967 Scheduler time: 4.275929952971637 Scheduler overhead time: 0.10789090767502785 Adapter cache time: 0.022491201758384705 Engine time: 0.10389711009338498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.789009524974972,
    "estimated_duration": 3599.9552405263235,
    "input_throughput": 4556.943601776997,
    "output_throughput": 4029.4625990625373,
    "total_throughput": 8586.406200839534,
    "itl": 33.23235333054849,
    "ttft": 7985.777948380124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.33403735562945
}
#Debug simulation 
Total elapsed time: 4.789089919999242. Arrivals time: 0.17637416534125805 Scheduler time: 4.321847137529403 Scheduler overhead time: 0.11017216229811311 Adapter cache time: 0.022764195688068867 Engine time: 0.10677602747455239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 540, 33, 33, 540, 33, 17280, 540, 33, 33, 33, 17280, 17280, 33, 33, 540, 540, 540, 17280, 17280, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 540, 540, 17280]
Prompts retrieved: 196350 . Total input tokens: 43796335 . Total output tokens: 39251512
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.763788423966616,
    "estimated_duration": 3599.965521273708,
    "input_throughput": 4556.9305881006885,
    "output_throughput": 4029.451091761472,
    "total_throughput": 8586.381679862161,
    "itl": 33.232443281807484,
    "ttft": 7985.834983507003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 65819,
    "finished_requests": 65674,
    "scheduler_time": 39.334131220200064
}
#Debug simulation 
Total elapsed time: 4.76399609586224. Arrivals time: 0.17744002118706703 Scheduler time: 4.297804237343371 Scheduler overhead time: 0.10927904583513737 Adapter cache time: 0.02258360292762518 Engine time: 0.10574246430769563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.725360478274524,
    "estimated_duration": 3600.004163046635,
    "input_throughput": 4463.863726868648,
    "output_throughput": 4014.0236915089386,
    "total_throughput": 8477.887418377586,
    "itl": 32.71003011963295,
    "ttft": 8893.725718394371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.79420519008154
}
#Debug simulation 
Total elapsed time: 4.725503440015018. Arrivals time: 0.17089427541941404 Scheduler time: 4.261183610651642 Scheduler overhead time: 0.11139829782769084 Adapter cache time: 0.022118539549410343 Engine time: 0.1079003126360476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.699528046883643,
    "estimated_duration": 3599.9800785570947,
    "input_throughput": 4463.893590889252,
    "output_throughput": 4014.050546021881,
    "total_throughput": 8477.944136911134,
    "itl": 32.709923483130794,
    "ttft": 8893.750631436482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.79396979820405
}
#Debug simulation 
Total elapsed time: 4.69961834512651. Arrivals time: 0.16204725159332156 Scheduler time: 4.248341275844723 Scheduler overhead time: 0.1096544899046421 Adapter cache time: 0.021815655287355185 Engine time: 0.10600223438814282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.721157995052636,
    "estimated_duration": 3599.980114541532,
    "input_throughput": 4463.893546269366,
    "output_throughput": 4014.0505058985063,
    "total_throughput": 8477.944052167873,
    "itl": 32.70992826017256,
    "ttft": 8893.766289277923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.7939778878201
}
#Debug simulation 
Total elapsed time: 4.7212475491687655. Arrivals time: 0.1698232269845903 Scheduler time: 4.26041200524196 Scheduler overhead time: 0.11007226165384054 Adapter cache time: 0.02192510385066271 Engine time: 0.1073030298575759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.675618308130652,
    "estimated_duration": 3599.975602895977,
    "input_throughput": 4463.899140614356,
    "output_throughput": 4014.0555364806883,
    "total_throughput": 8477.954677095044,
    "itl": 32.7100723076732,
    "ttft": 8893.71107257499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.79390095451732
}
#Debug simulation 
Total elapsed time: 4.675726761110127. Arrivals time: 0.16834470489993691 Scheduler time: 4.219898619223386 Scheduler overhead time: 0.10881336592137814 Adapter cache time: 0.02175967814400792 Engine time: 0.10538580175489187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.678897496778518,
    "estimated_duration": 3599.9845622236808,
    "input_throughput": 4463.888031251372,
    "output_throughput": 4014.045546649246,
    "total_throughput": 8477.933577900618,
    "itl": 32.709950742658144,
    "ttft": 8893.80943379519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.79403451513297
}
#Debug simulation 
Total elapsed time: 4.679022348951548. Arrivals time: 0.1760609312914312 Scheduler time: 4.213197536300868 Scheduler overhead time: 0.10960417008027434 Adapter cache time: 0.02185245929285884 Engine time: 0.10656529013067484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.714207699056715,
    "estimated_duration": 3599.9981248577183,
    "input_throughput": 4463.871213998237,
    "output_throughput": 4014.0304241328245,
    "total_throughput": 8477.901638131061,
    "itl": 32.70990627815825,
    "ttft": 8893.776464255818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.794074922238295
}
#Debug simulation 
Total elapsed time: 4.71431493293494. Arrivals time: 0.17168239364400506 Scheduler time: 4.251491913571954 Scheduler overhead time: 0.1105846306309104 Adapter cache time: 0.02192966314032674 Engine time: 0.1069818502292037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 135, 135, 270, 135, 17280, 270, 135, 135, 135, 17280, 17280, 135, 135, 270, 270, 270, 17280, 17280, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 270, 270, 17280]
Prompts retrieved: 194400 . Total input tokens: 43353626 . Total output tokens: 38858598
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.680990363005549,
    "estimated_duration": 3599.9875392507706,
    "input_throughput": 4463.884339817597,
    "output_throughput": 4014.0422272148858,
    "total_throughput": 8477.926567032482,
    "itl": 32.70985977890709,
    "ttft": 8893.784799114906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 65160,
    "finished_requests": 65000,
    "scheduler_time": 38.79403851896621
}
#Debug simulation 
Total elapsed time: 4.681078508030623. Arrivals time: 0.16743271285668015 Scheduler time: 4.226058738771826 Scheduler overhead time: 0.10923783294856548 Adapter cache time: 0.02172511164098978 Engine time: 0.10525034973397851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.638387307990342,
    "estimated_duration": 3600.011183802759,
    "input_throughput": 4484.453568543279,
    "output_throughput": 3970.564887218183,
    "total_throughput": 8455.018455761463,
    "itl": 32.27641196105581,
    "ttft": 7036.30916003615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.87736513624486
}
#Debug simulation 
Total elapsed time: 4.638489529956132. Arrivals time: 0.16589340567588806 Scheduler time: 4.182009224779904 Scheduler overhead time: 0.10990242706611753 Adapter cache time: 0.021210158243775368 Engine time: 0.1073623071424663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.637162336148322,
    "estimated_duration": 3600.022141839153,
    "input_throughput": 4484.43991840351,
    "output_throughput": 3970.552801294035,
    "total_throughput": 8454.992719697544,
    "itl": 32.27650413332291,
    "ttft": 7036.4749549557855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.87752759865234
}
#Debug simulation 
Total elapsed time: 4.6372723979875445. Arrivals time: 0.16728810733184218 Scheduler time: 4.181589021347463 Scheduler overhead time: 0.10984828229993582 Adapter cache time: 0.02108126226812601 Engine time: 0.10512642655521631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.648004307877272,
    "estimated_duration": 3600.0221652142554,
    "input_throughput": 4484.439889285844,
    "output_throughput": 3970.5527755130606,
    "total_throughput": 8454.992664798905,
    "itl": 32.27649228445286,
    "ttft": 7036.467841422047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.8775235538443
}
#Debug simulation 
Total elapsed time: 4.648079902864993. Arrivals time: 0.17358457809314132 Scheduler time: 4.182638630736619 Scheduler overhead time: 0.1111006522551179 Adapter cache time: 0.02136881183832884 Engine time: 0.10756024392321706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.640407505910844,
    "estimated_duration": 3600.017424707141,
    "input_throughput": 4484.445794401484,
    "output_throughput": 3970.5580039415545,
    "total_throughput": 8455.00379834304,
    "itl": 32.276448807868725,
    "ttft": 7036.393330621562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.87745812585438
}
#Debug simulation 
Total elapsed time: 4.640494416002184. Arrivals time: 0.17292635049670935 Scheduler time: 4.177492738701403 Scheduler overhead time: 0.11041646869853139 Adapter cache time: 0.021199191454797983 Engine time: 0.1065385197289288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.635988395195454,
    "estimated_duration": 3600.022777240051,
    "input_throughput": 4484.439126903753,
    "output_throughput": 3970.552100494909,
    "total_throughput": 8454.991227398663,
    "itl": 32.276506296221676,
    "ttft": 7036.459560884152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.877535729243476
}
#Debug simulation 
Total elapsed time: 4.636075654067099. Arrivals time: 0.16809630580246449 Scheduler time: 4.176185593474656 Scheduler overhead time: 0.11064981808885932 Adapter cache time: 0.021349315531551838 Engine time: 0.10760133434087038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.632647005841136,
    "estimated_duration": 3600.002205434365,
    "input_throughput": 4484.464752724257,
    "output_throughput": 3970.5747897660863,
    "total_throughput": 8455.039542490344,
    "itl": 32.276223717404434,
    "ttft": 7036.389513522809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.87721535542265
}
#Debug simulation 
Total elapsed time: 4.632736695930362. Arrivals time: 0.16529430728405714 Scheduler time: 4.177734178490937 Scheduler overhead time: 0.11031561065465212 Adapter cache time: 0.021278955973684788 Engine time: 0.10632390063256025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 66, 66, 270, 66, 17280, 270, 66, 66, 66, 17280, 17280, 66, 66, 270, 270, 270, 17280, 17280, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 270, 270, 17280]
Prompts retrieved: 193710 . Total input tokens: 43205196 . Total output tokens: 38713514
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.654261615127325,
    "estimated_duration": 3600.0244361094,
    "input_throughput": 4484.437060501497,
    "output_throughput": 3970.5502708886675,
    "total_throughput": 8454.987331390164,
    "itl": 32.27649230045415,
    "ttft": 7036.458700039266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 64957,
    "finished_requests": 64831,
    "scheduler_time": 37.87753977405164
}
#Debug simulation 
Total elapsed time: 4.654349710326642. Arrivals time: 0.16756171779707074 Scheduler time: 4.1935902470722795 Scheduler overhead time: 0.11095927050337195 Adapter cache time: 0.021231075283139944 Engine time: 0.10880902828648686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.623242810368538,
    "estimated_duration": 3599.9976449346655,
    "input_throughput": 4463.931531347334,
    "output_throughput": 3961.943147398601,
    "total_throughput": 8425.874678745937,
    "itl": 32.11935054145283,
    "ttft": 6383.295163406363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.65558060300379
}
#Debug simulation 
Total elapsed time: 4.6233659172430634. Arrivals time: 0.1657747095450759 Scheduler time: 4.16675168229267 Scheduler overhead time: 0.11127984104678035 Adapter cache time: 0.020976949017494917 Engine time: 0.10633639898151159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.6369328228756785,
    "estimated_duration": 3600.0031903345366,
    "input_throughput": 4463.924655163057,
    "output_throughput": 3961.937044470949,
    "total_throughput": 8425.861699634006,
    "itl": 32.11925993441332,
    "ttft": 6383.202950323413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.65562513686714
}
#Debug simulation 
Total elapsed time: 4.637036869768053. Arrivals time: 0.17302545113489032 Scheduler time: 4.1721812705509365 Scheduler overhead time: 0.11022360948845744 Adapter cache time: 0.02102626021951437 Engine time: 0.10826059803366661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.624707358889282,
    "estimated_duration": 3600.0031320354205,
    "input_throughput": 4463.924727452678,
    "output_throughput": 3961.9371086312894,
    "total_throughput": 8425.861836083966,
    "itl": 32.11925168510125,
    "ttft": 6383.206099679503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.655629181675216
}
#Debug simulation 
Total elapsed time: 4.62485648971051. Arrivals time: 0.17205538041889668 Scheduler time: 4.160601974930614 Scheduler overhead time: 0.11077375104650855 Adapter cache time: 0.021104860119521618 Engine time: 0.10781044000759721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.616780921351165,
    "estimated_duration": 3599.999272390547,
    "input_throughput": 4463.929513332587,
    "output_throughput": 3961.9413563183284,
    "total_throughput": 8425.870869650915,
    "itl": 32.1193452179941,
    "ttft": 6383.2659570470905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.65558468878651
}
#Debug simulation 
Total elapsed time: 4.616872490383685. Arrivals time: 0.16658607544377446 Scheduler time: 4.158268078230321 Scheduler overhead time: 0.11135159339755774 Adapter cache time: 0.021121157333254814 Engine time: 0.10722726583480835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.632035919930786,
    "estimated_duration": 3600.0048010819255,
    "input_throughput": 4463.922657872669,
    "output_throughput": 3961.9352717844936,
    "total_throughput": 8425.857929657162,
    "itl": 32.119321233156725,
    "ttft": 6383.155870252206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.65562918167526
}
#Debug simulation 
Total elapsed time: 4.63213637471199. Arrivals time: 0.16029766015708447 Scheduler time: 4.181423062458634 Scheduler overhead time: 0.11081829760223627 Adapter cache time: 0.020796214696019888 Engine time: 0.10679573519155383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.624400699976832,
    "estimated_duration": 3599.988578896197,
    "input_throughput": 4463.9427730982725,
    "output_throughput": 3961.953124966084,
    "total_throughput": 8425.895898064357,
    "itl": 32.11943974525969,
    "ttft": 6383.2563351546205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.655451292071135
}
#Debug simulation 
Total elapsed time: 4.624544771388173. Arrivals time: 0.16543026268482208 Scheduler time: 4.165862085763365 Scheduler overhead time: 0.11094342870637774 Adapter cache time: 0.021062734071165323 Engine time: 0.10900170914828777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 270, 33, 33, 270, 33, 17280, 270, 33, 33, 33, 17280, 17280, 33, 33, 270, 270, 270, 17280, 17280, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 270, 270, 17280]
Prompts retrieved: 193380 . Total input tokens: 43129627 . Total output tokens: 38646207
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.61950733885169,
    "estimated_duration": 3600.0065295261415,
    "input_throughput": 4463.920514642863,
    "output_throughput": 3961.9333695701366,
    "total_throughput": 8425.853884213,
    "itl": 32.11930583946955,
    "ttft": 6383.172960885845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 64833,
    "finished_requests": 64719,
    "scheduler_time": 37.65565741338157
}
#Debug simulation 
Total elapsed time: 4.619583162944764. Arrivals time: 0.1707175956107676 Scheduler time: 4.158530915621668 Scheduler overhead time: 0.11046640481799841 Adapter cache time: 0.020931062288582325 Engine time: 0.10649629402905703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.6341707850806415,
    "estimated_duration": 3600.0307162092126,
    "input_throughput": 4438.500185027702,
    "output_throughput": 3924.167906788219,
    "total_throughput": 8362.668091815922,
    "itl": 31.592067788797063,
    "ttft": 8432.957210557044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 64433,
    "finished_requests": 64283,
    "scheduler_time": 36.79406451824117
}
#Debug simulation 
Total elapsed time: 4.634301537182182. Arrivals time: 0.17269563069567084 Scheduler time: 4.165298992302269 Scheduler overhead time: 0.11289458302780986 Adapter cache time: 0.020354354288429022 Engine time: 0.10995058622211218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.6305140112526715,
    "estimated_duration": 3600.004316199887,
    "input_throughput": 4438.3407897872185,
    "output_throughput": 3924.037239741919,
    "total_throughput": 8362.378029529138,
    "itl": 31.591760116004384,
    "ttft": 8544.860754286949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 64433,
    "finished_requests": 64280,
    "scheduler_time": 36.793780547692435
}
#Debug simulation 
Total elapsed time: 4.6305964342318475. Arrivals time: 0.17196214338764548 Scheduler time: 4.163157718256116 Scheduler overhead time: 0.11337839113548398 Adapter cache time: 0.020229804329574108 Engine time: 0.10890511190518737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.616508868057281,
    "estimated_duration": 3600.004559174909,
    "input_throughput": 4438.340490230389,
    "output_throughput": 3924.0369748969674,
    "total_throughput": 8362.377465127356,
    "itl": 31.591758130443925,
    "ttft": 8544.867630224931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 64433,
    "finished_requests": 64280,
    "scheduler_time": 36.79378459250047
}
#Debug simulation 
Total elapsed time: 4.6165975839830935. Arrivals time: 0.16858831886202097 Scheduler time: 4.155816215090454 Scheduler overhead time: 0.11138186603784561 Adapter cache time: 0.020091832149773836 Engine time: 0.10776953212916851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.623016437981278,
    "estimated_duration": 3600.0340417509146,
    "input_throughput": 4438.496084950511,
    "output_throughput": 3924.164281826936,
    "total_throughput": 8362.660366777447,
    "itl": 31.59202452455149,
    "ttft": 8433.01084103886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 64433,
    "finished_requests": 64283,
    "scheduler_time": 36.794092913847216
}
#Debug simulation 
Total elapsed time: 4.623104602098465. Arrivals time: 0.1667534257285297 Scheduler time: 4.161792271770537 Scheduler overhead time: 0.11204706598073244 Adapter cache time: 0.02012574439868331 Engine time: 0.10923604061827064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.586657505016774,
    "estimated_duration": 3600.0058738267026,
    "input_throughput": 4438.338869435176,
    "output_throughput": 3924.035541915348,
    "total_throughput": 8362.374411350524,
    "itl": 31.591753849406093,
    "ttft": 8544.862240603585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089383,
    "arrivals": 64433,
    "finished_requests": 64280,
    "scheduler_time": 36.793784551525555
}
#Debug simulation 
Total elapsed time: 4.586759061086923. Arrivals time: 0.15962004102766514 Scheduler time: 4.1356006329879165 Scheduler overhead time: 0.11164375953376293 Adapter cache time: 0.019997214898467064 Engine time: 0.1074906256981194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.628322312608361,
    "estimated_duration": 3600.024044447275,
    "input_throughput": 4438.447577772565,
    "output_throughput": 3924.096568685264,
    "total_throughput": 8362.544146457829,
    "itl": 31.59192288313631,
    "ttft": 8488.913091470627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 64433,
    "finished_requests": 64282,
    "scheduler_time": 36.79391894612701
}
#Debug simulation 
Total elapsed time: 4.628423180896789. Arrivals time: 0.1641413839533925 Scheduler time: 4.168205100111663 Scheduler overhead time: 0.11383700557053089 Adapter cache time: 0.020240481477230787 Engine time: 0.10895767668262124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 66, 66, 135, 66, 17280, 135, 66, 66, 66, 17280, 17280, 66, 66, 135, 135, 135, 17280, 17280, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 135, 135, 17280]
Prompts retrieved: 192225 . Total input tokens: 42866645 . Total output tokens: 38418482
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.635356830898672,
    "estimated_duration": 3600.010379394001,
    "input_throughput": 4438.333314663839,
    "output_throughput": 3924.0306308166696,
    "total_throughput": 8362.363945480509,
    "itl": 31.591864694996314,
    "ttft": 8544.895902319016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145729,
    "arrivals": 64433,
    "finished_requests": 64280,
    "scheduler_time": 36.793861361903616
}
#Debug simulation 
Total elapsed time: 4.63548130216077. Arrivals time: 0.16376284882426262 Scheduler time: 4.175356627907604 Scheduler overhead time: 0.11376466508954763 Adapter cache time: 0.02017059735953808 Engine time: 0.10897901887074113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.586527087725699,
    "estimated_duration": 3600.0015725572816,
    "input_throughput": 4398.040301063806,
    "output_throughput": 3934.9163366996286,
    "total_throughput": 8332.956637763435,
    "itl": 31.581647990044726,
    "ttft": 7829.660166676932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.910286032404706
}
#Debug simulation 
Total elapsed time: 4.586679945699871. Arrivals time: 0.16583926044404507 Scheduler time: 4.128696206025779 Scheduler overhead time: 0.11122850654646754 Adapter cache time: 0.019354942720383406 Engine time: 0.10857285698875785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.601604409981519,
    "estimated_duration": 3600.013632290502,
    "input_throughput": 4398.0255680105065,
    "output_throughput": 3934.903155071415,
    "total_throughput": 8332.92872308192,
    "itl": 31.58165436466978,
    "ttft": 7829.666123966338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.9104559553172
}
#Debug simulation 
Total elapsed time: 4.601691109128296. Arrivals time: 0.17145834118127823 Scheduler time: 4.13632892863825 Scheduler overhead time: 0.1123835383914411 Adapter cache time: 0.01954623544588685 Engine time: 0.10901329992339015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.626940125133842,
    "estimated_duration": 3600.015295694066,
    "input_throughput": 4398.0235358826385,
    "output_throughput": 3934.9013369313807,
    "total_throughput": 8332.92487281402,
    "itl": 31.581686527054696,
    "ttft": 7829.6382087999955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.91049235858948
}
#Debug simulation 
Total elapsed time: 4.62703056121245. Arrivals time: 0.17341437144204974 Scheduler time: 4.159069415181875 Scheduler overhead time: 0.11320525081828237 Adapter cache time: 0.019664605148136616 Engine time: 0.10871534375473857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.617409250233322,
    "estimated_duration": 3600.0035402675185,
    "input_throughput": 4398.037897158136,
    "output_throughput": 3934.9141859308666,
    "total_throughput": 8332.952083089001,
    "itl": 31.581669295582238,
    "ttft": 7829.685186185574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.91029003623738
}
#Debug simulation 
Total elapsed time: 4.6175561072304845. Arrivals time: 0.16836911858990788 Scheduler time: 4.155586255248636 Scheduler overhead time: 0.11234076600521803 Adapter cache time: 0.019770896527916193 Engine time: 0.10822173859924078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.6123968926258385,
    "estimated_duration": 3600.0179941530923,
    "input_throughput": 4398.020239264031,
    "output_throughput": 3934.8983874544483,
    "total_throughput": 8332.91862671848,
    "itl": 31.5817506653565,
    "ttft": 7829.620757080361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 64340,
    "finished_requests": 64200,
    "scheduler_time": 36.910524717053775
}
#Debug simulation 
Total elapsed time: 4.612489087041467. Arrivals time: 0.16605449467897415 Scheduler time: 4.152587633114308 Scheduler overhead time: 0.11171298567205667 Adapter cache time: 0.019412255380302668 Engine time: 0.10950913978740573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.653514137957245,
    "estimated_duration": 3600.034909390407,
    "input_throughput": 4398.174017340598,
    "output_throughput": 3934.8987875227817,
    "total_throughput": 8333.07280486338,
    "itl": 31.581426565160818,
    "ttft": 7773.60203799377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 64340,
    "finished_requests": 64202,
    "scheduler_time": 36.91064276852325
}
#Debug simulation 
Total elapsed time: 4.6536043039523065. Arrivals time: 0.16526795737445354 Scheduler time: 4.19084588624537 Scheduler overhead time: 0.11381853371858597 Adapter cache time: 0.019627969712018967 Engine time: 0.11041514156386256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 135, 33, 33, 135, 33, 17280, 135, 33, 33, 33, 17280, 17280, 33, 33, 135, 135, 135, 17280, 17280, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 135, 135, 17280]
Prompts retrieved: 191895 . Total input tokens: 42783320 . Total output tokens: 38357461
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.629616680089384,
    "estimated_duration": 3600.018988751829,
    "input_throughput": 4398.070135038244,
    "output_throughput": 3934.9156335732127,
    "total_throughput": 8332.985768611457,
    "itl": 31.581786818826806,
    "ttft": 7773.692517277252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 64340,
    "finished_requests": 64201,
    "scheduler_time": 36.91054093726091
}
#Debug simulation 
Total elapsed time: 4.629702560137957. Arrivals time: 0.1609548511914909 Scheduler time: 4.172836981713772 Scheduler overhead time: 0.11301778303459287 Adapter cache time: 0.019575573038309813 Engine time: 0.11013170890510082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.5601574829779565,
    "estimated_duration": 3600.014965939668,
    "input_throughput": 4397.328108292453,
    "output_throughput": 3892.3138188517273,
    "total_throughput": 8289.641927144181,
    "itl": 31.05927552924374,
    "ttft": 7973.6687680662935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 64071,
    "finished_requests": 63930,
    "scheduler_time": 35.983046945527704
}
#Debug simulation 
Total elapsed time: 4.560310740023851. Arrivals time: 0.16120264865458012 Scheduler time: 4.102984924335033 Scheduler overhead time: 0.11420139344409108 Adapter cache time: 0.019166430924087763 Engine time: 0.10910360049456358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.602253803983331,
    "estimated_duration": 3599.9907710073708,
    "input_throughput": 4397.3571064378675,
    "output_throughput": 3892.2802560627206,
    "total_throughput": 8289.637362500589,
    "itl": 31.059257333133505,
    "ttft": 8030.002700935729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.98283252972686
}
#Debug simulation 
Total elapsed time: 4.602363219019026. Arrivals time: 0.16478897770866752 Scheduler time: 4.140131848398596 Scheduler overhead time: 0.11286455113440752 Adapter cache time: 0.01913434499874711 Engine time: 0.11165442410856485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.599626324139535,
    "estimated_duration": 3599.9910392986417,
    "input_throughput": 4397.356778722461,
    "output_throughput": 3892.2799659884386,
    "total_throughput": 8289.636744710899,
    "itl": 31.05926670004557,
    "ttft": 8029.987284337709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.982836574534886
}
#Debug simulation 
Total elapsed time: 4.599705146159977. Arrivals time: 0.16970382118597627 Scheduler time: 4.132848781067878 Scheduler overhead time: 0.11362467613071203 Adapter cache time: 0.01929018646478653 Engine time: 0.1103569190017879 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 4.594099543057382,
    "estimated_duration": 3600.017958031188,
    "input_throughput": 4397.324453530645,
    "output_throughput": 3892.3105838236506,
    "total_throughput": 8289.635037354295,
    "itl": 31.05929839238742,
    "ttft": 7973.717005470822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 64071,
    "finished_requests": 63930,
    "scheduler_time": 35.98306800355415
}
#Debug simulation 
Total elapsed time: 4.594260661862791. Arrivals time: 0.17112838895991445 Scheduler time: 4.1259909314103425 Scheduler overhead time: 0.11382162058725953 Adapter cache time: 0.01927930675446987 Engine time: 0.11049073468893766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 4.577765163965523,
    "estimated_duration": 3599.992597351198,
    "input_throughput": 4397.354875576056,
    "output_throughput": 3892.278281435877,
    "total_throughput": 8289.633157011933,
    "itl": 31.059262927142207,
    "ttft": 8030.011386455877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.98283657453481
}
#Debug simulation 
Total elapsed time: 4.577904129866511. Arrivals time: 0.16745097376406193 Scheduler time: 4.113131542224437 Scheduler overhead time: 0.11373826069757342 Adapter cache time: 0.019197681918740273 Engine time: 0.11074578994885087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 4.579110851045698,
    "estimated_duration": 3600.009361487287,
    "input_throughput": 4397.334954001314,
    "output_throughput": 3892.3198783602616,
    "total_throughput": 8289.654832361575,
    "itl": 31.059290075694854,
    "ttft": 7973.66438860962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 64071,
    "finished_requests": 63930,
    "scheduler_time": 35.982953873967865
}
#Debug simulation 
Total elapsed time: 4.579206550028175. Arrivals time: 0.16401572013273835 Scheduler time: 4.121002742089331 Scheduler overhead time: 0.11235867766663432 Adapter cache time: 0.019040812738239765 Engine time: 0.10952970152720809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [10 11 11]
Adapter prompts. [17280, 66, 33, 33, 66, 33, 17280, 66, 33, 33, 33, 17280, 17280, 33, 33, 66, 66, 66, 17280, 17280, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 66, 66, 17280]
Prompts retrieved: 191136 . Total input tokens: 42607616 . Total output tokens: 38213099
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 4.578296942170709,
    "estimated_duration": 3599.9959653122955,
    "input_throughput": 4397.350761649181,
    "output_throughput": 3892.2746400312867,
    "total_throughput": 8289.625401680467,
    "itl": 31.059277820481828,
    "ttft": 8029.988685115134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 64071,
    "finished_requests": 63929,
    "scheduler_time": 35.982877022615206
}
#Debug simulation 
Total elapsed time: 4.578416381031275. Arrivals time: 0.16069611348211765 Scheduler time: 4.119731209240854 Scheduler overhead time: 0.1137032420374453 Adapter cache time: 0.019038957078009844 Engine time: 0.11151350568979979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.829401179216802,
    "estimated_duration": 3600.0370071247316,
    "input_throughput": 3527.224018772439,
    "output_throughput": 3155.025344884314,
    "total_throughput": 6682.249363656753,
    "itl": 33.288977946738804,
    "ttft": 9453.694147189557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 51326,
    "finished_requests": 51192,
    "scheduler_time": 26.636077230423336
}
#Debug simulation 
Total elapsed time: 3.8295344160869718. Arrivals time: 0.14036810863763094 Scheduler time: 3.4019409525208175 Scheduler overhead time: 0.10662192013114691 Adapter cache time: 0.02712784195318818 Engine time: 0.1034315126016736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.8393059568479657,
    "estimated_duration": 3600.004947726294,
    "input_throughput": 3527.192930115221,
    "output_throughput": 3154.973441681929,
    "total_throughput": 6682.16637179715,
    "itl": 33.288932228635886,
    "ttft": 9453.897616786246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 51326,
    "finished_requests": 51191,
    "scheduler_time": 26.635768238989794
}
#Debug simulation 
Total elapsed time: 3.8393855607137084. Arrivals time: 0.14297197479754686 Scheduler time: 3.4120457908138633 Scheduler overhead time: 0.10544529417529702 Adapter cache time: 0.02727968618273735 Engine time: 0.10196151258423924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.862161469180137,
    "estimated_duration": 3600.0049526868156,
    "input_throughput": 3527.1929252550285,
    "output_throughput": 3154.973437334626,
    "total_throughput": 6682.166362589654,
    "itl": 33.28889721812266,
    "ttft": 9453.906148468684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 51326,
    "finished_requests": 51191,
    "scheduler_time": 26.635768238989794
}
#Debug simulation 
Total elapsed time: 3.8623122172430158. Arrivals time: 0.15046838484704494 Scheduler time: 3.426580733153969 Scheduler overhead time: 0.10508165042847395 Adapter cache time: 0.02731675887480378 Engine time: 0.10287189623340964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.8651260351762176,
    "estimated_duration": 3600.001590120379,
    "input_throughput": 3527.196219814836,
    "output_throughput": 3154.9763842243765,
    "total_throughput": 6682.172604039212,
    "itl": 33.288927802539405,
    "ttft": 9453.864861839354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 51326,
    "finished_requests": 51191,
    "scheduler_time": 26.635752893743778
}
#Debug simulation 
Total elapsed time: 3.865235671866685. Arrivals time: 0.14521603286266327 Scheduler time: 3.4339440846815705 Scheduler overhead time: 0.10590088879689574 Adapter cache time: 0.027618794701993465 Engine time: 0.10279476037248969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.8283611577935517,
    "estimated_duration": 3600.00481379983,
    "input_throughput": 3527.1930613329555,
    "output_throughput": 3154.973559052449,
    "total_throughput": 6682.166620385405,
    "itl": 33.28885695796226,
    "ttft": 9453.870742804329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 51326,
    "finished_requests": 51191,
    "scheduler_time": 26.635756104565683
}
#Debug simulation 
Total elapsed time: 3.8284624167717993. Arrivals time: 0.1408847630955279 Scheduler time: 3.4023003154434264 Scheduler overhead time: 0.10527962353080511 Adapter cache time: 0.027232902590185404 Engine time: 0.10314575349912047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.8676161938346922,
    "estimated_duration": 3600.022400579423,
    "input_throughput": 3527.2383299493463,
    "output_throughput": 3155.038145921508,
    "total_throughput": 6682.2764758708545,
    "itl": 33.28902172817489,
    "ttft": 9453.681452451736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 51326,
    "finished_requests": 51192,
    "scheduler_time": 26.635891169253366
}
#Debug simulation 
Total elapsed time: 3.867706375196576. Arrivals time: 0.14007498882710934 Scheduler time: 3.4416553657501936 Scheduler overhead time: 0.10670410422608256 Adapter cache time: 0.027154188137501478 Engine time: 0.10195258306339383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 1080, 1080, 4320, 1080, 8640, 4320, 1080, 1080, 1080, 8640, 8640, 1080, 1080, 4320, 4320, 4320, 8640, 8640, 1080, 8640, 8640, 8640, 8640, 4320, 1080, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 153360 . Total input tokens: 34149491 . Total output tokens: 30670757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.8275835323147476,
    "estimated_duration": 3600.0047749514165,
    "input_throughput": 3527.1930993956425,
    "output_throughput": 3154.973593098437,
    "total_throughput": 6682.166692494079,
    "itl": 33.28885946107337,
    "ttft": 9453.932046800712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 51326,
    "finished_requests": 51191,
    "scheduler_time": 26.635743970141565
}
#Debug simulation 
Total elapsed time: 3.8276675674133003. Arrivals time: 0.14250651886686683 Scheduler time: 3.40243029454723 Scheduler overhead time: 0.10429581301286817 Adapter cache time: 0.02718554111197591 Engine time: 0.10172539250925183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.7165783350355923,
    "estimated_duration": 3599.9951122542748,
    "input_throughput": 3423.2632589001,
    "output_throughput": 3019.133543543631,
    "total_throughput": 6442.396802443731,
    "itl": 31.603731235618596,
    "ttft": 7745.9011305746935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598612561004835
}
#Debug simulation 
Total elapsed time: 3.7167621520347893. Arrivals time: 0.14419781602919102 Scheduler time: 3.278641862794757 Scheduler overhead time: 0.10997142316773534 Adapter cache time: 0.026610099244862795 Engine time: 0.10566709795966744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.702939069829881,
    "estimated_duration": 3599.9704681525936,
    "input_throughput": 3423.2866933278488,
    "output_throughput": 3019.1542114448525,
    "total_throughput": 6442.440904772701,
    "itl": 31.604080883062608,
    "ttft": 7745.902892976132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598667520345195
}
#Debug simulation 
Total elapsed time: 3.7030367208644748. Arrivals time: 0.13941631885245442 Scheduler time: 3.2706025005318224 Scheduler overhead time: 0.10907538840547204 Adapter cache time: 0.026489889714866877 Engine time: 0.10586063237860799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7048127837479115,
    "estimated_duration": 3599.9705323603525,
    "input_throughput": 3423.2866322713585,
    "output_throughput": 3019.154157596321,
    "total_throughput": 6442.440789867679,
    "itl": 31.60409942116097,
    "ttft": 7745.892042022965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598663475537176
}
#Debug simulation 
Total elapsed time: 3.7049124320037663. Arrivals time: 0.1368451095186174 Scheduler time: 3.273504823911935 Scheduler overhead time: 0.11034081038087606 Adapter cache time: 0.026349143125116825 Engine time: 0.10570768499746919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.722478765062988,
    "estimated_duration": 3599.998014765158,
    "input_throughput": 3423.2604988822263,
    "output_throughput": 3019.131109356742,
    "total_throughput": 6442.391608238968,
    "itl": 31.603813358900634,
    "ttft": 7745.945858556939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598616646787598
}
#Debug simulation 
Total elapsed time: 3.722558829933405. Arrivals time: 0.13388017192482948 Scheduler time: 3.2958109453320503 Scheduler overhead time: 0.10999440914019942 Adapter cache time: 0.026523010339587927 Engine time: 0.10448117041960359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7165180523879826,
    "estimated_duration": 3599.9706718338543,
    "input_throughput": 3423.286499643118,
    "output_throughput": 3019.1540406253675,
    "total_throughput": 6442.440540268486,
    "itl": 31.604119858300596,
    "ttft": 7745.902649561813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598663475537187
}
#Debug simulation 
Total elapsed time: 3.7166067673824728. Arrivals time: 0.1435995572246611 Scheduler time: 3.2776734973303974 Scheduler overhead time: 0.10960953077301383 Adapter cache time: 0.026710684411227703 Engine time: 0.10726768709719181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.7054399820044637,
    "estimated_duration": 3599.9942010682203,
    "input_throughput": 3423.264125354202,
    "output_throughput": 3019.1343077094125,
    "total_throughput": 6442.398433063614,
    "itl": 31.603749262158114,
    "ttft": 7745.861364336737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598623902417753
}
#Debug simulation 
Total elapsed time: 3.7055571847595274. Arrivals time: 0.1455157627351582 Scheduler time: 3.2659515626728535 Scheduler overhead time: 0.10971113247796893 Adapter cache time: 0.026601615827530622 Engine time: 0.10570782283321023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 540, 540, 4320, 540, 8640, 4320, 540, 540, 540, 8640, 8640, 540, 540, 4320, 4320, 4320, 8640, 8640, 540, 8640, 8640, 8640, 8640, 4320, 540, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 147960 . Total input tokens: 32950313 . Total output tokens: 29601434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7084520026110113,
    "estimated_duration": 3599.979529909267,
    "input_throughput": 3423.2780763368964,
    "output_throughput": 3019.1466117236328,
    "total_throughput": 6442.424688060529,
    "itl": 31.604177911683358,
    "ttft": 7745.901264584912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 49599,
    "finished_requests": 49493,
    "scheduler_time": 23.598756547097274
}
#Debug simulation 
Total elapsed time: 3.708599649835378. Arrivals time: 0.13499725982546806 Scheduler time: 3.278434068430215 Scheduler overhead time: 0.11078365333378315 Adapter cache time: 0.026532601565122604 Engine time: 0.10583202447742224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.6379594490863383,
    "estimated_duration": 3600.005753948647,
    "input_throughput": 3370.786834629348,
    "output_throughput": 2977.656351866184,
    "total_throughput": 6348.443186495532,
    "itl": 30.844333468877394,
    "ttft": 7069.435045862535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 48729,
    "finished_requests": 48634,
    "scheduler_time": 22.485509838471806
}
#Debug simulation 
Total elapsed time: 3.63808477204293. Arrivals time: 0.13210028829053044 Scheduler time: 3.2107229945249856 Scheduler overhead time: 0.11115796491503716 Adapter cache time: 0.024792722892016172 Engine time: 0.10653328895568848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.657259003724903,
    "estimated_duration": 3600.006024564635,
    "input_throughput": 3370.786581243992,
    "output_throughput": 2977.6561280328324,
    "total_throughput": 6348.442709276824,
    "itl": 30.85773325770115,
    "ttft": 7069.485308309907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 48729,
    "finished_requests": 48634,
    "scheduler_time": 22.49514498797806
}
#Debug simulation 
Total elapsed time: 3.657345645595342. Arrivals time: 0.13622478768229485 Scheduler time: 3.223254403565079 Scheduler overhead time: 0.11131283128634095 Adapter cache time: 0.024666049052029848 Engine time: 0.10905845323577523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6360131460241973,
    "estimated_duration": 3600.009491545989,
    "input_throughput": 3370.783335015266,
    "output_throughput": 2977.6532604075387,
    "total_throughput": 6348.436595422804,
    "itl": 30.857741232390193,
    "ttft": 7069.471644736528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 48729,
    "finished_requests": 48634,
    "scheduler_time": 22.495181391250448
}
#Debug simulation 
Total elapsed time: 3.63610479189083. Arrivals time: 0.14224036689847708 Scheduler time: 3.1970721459947526 Scheduler overhead time: 0.11122559383511543 Adapter cache time: 0.024591140914708376 Engine time: 0.10838764859363437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.6660227850079536,
    "estimated_duration": 3600.011657077263,
    "input_throughput": 3370.78130737274,
    "output_throughput": 2977.6514692463224,
    "total_throughput": 6348.432776619063,
    "itl": 30.84438598131491,
    "ttft": 7069.422033989439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 48729,
    "finished_requests": 48634,
    "scheduler_time": 22.48555516534632
}
#Debug simulation 
Total elapsed time: 3.666172561701387. Arrivals time: 0.13389349775388837 Scheduler time: 3.232783594634384 Scheduler overhead time: 0.11286215670406818 Adapter cache time: 0.025036004837602377 Engine time: 0.10823187790811062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.683860160410404,
    "estimated_duration": 3600.0234907557056,
    "input_throughput": 3370.7868937968174,
    "output_throughput": 2977.64862577321,
    "total_throughput": 6348.435519570027,
    "itl": 30.84451319316178,
    "ttft": 6995.511014252177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 48729,
    "finished_requests": 48635,
    "scheduler_time": 22.485648195931244
}
#Debug simulation 
Total elapsed time: 3.683946304023266. Arrivals time: 0.13319206424057484 Scheduler time: 3.251378889195621 Scheduler overhead time: 0.1125416406430304 Adapter cache time: 0.02466298406943679 Engine time: 0.10925015760585666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.6755806799046695,
    "estimated_duration": 3600.001335717575,
    "input_throughput": 3370.7909715486826,
    "output_throughput": 2977.660006301999,
    "total_throughput": 6348.450977850682,
    "itl": 30.84431183372817,
    "ttft": 7069.340201399852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 48729,
    "finished_requests": 48634,
    "scheduler_time": 22.485473435199435
}
#Debug simulation 
Total elapsed time: 3.6756609650328755. Arrivals time: 0.13778935000300407 Scheduler time: 3.2413504594005644 Scheduler overhead time: 0.11144499527290463 Adapter cache time: 0.025042513385415077 Engine time: 0.10732798418030143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 270, 270, 4320, 270, 8640, 4320, 270, 270, 270, 8640, 8640, 270, 270, 4320, 4320, 4320, 8640, 8640, 270, 8640, 8640, 8640, 8640, 4320, 270, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 145260 . Total input tokens: 32362507 . Total output tokens: 29046899
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6797723690979183,
    "estimated_duration": 3600.0263657271776,
    "input_throughput": 3370.7842018953775,
    "output_throughput": 2977.646247830944,
    "total_throughput": 6348.430449726321,
    "itl": 30.844582484440796,
    "ttft": 6995.490311669981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 48729,
    "finished_requests": 48635,
    "scheduler_time": 22.485668419971393
}
#Debug simulation 
Total elapsed time: 3.679865083191544. Arrivals time: 0.1429941295646131 Scheduler time: 3.236122307833284 Scheduler overhead time: 0.11347046308219433 Adapter cache time: 0.02496257796883583 Engine time: 0.10931646404787898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.6038692160509527,
    "estimated_duration": 3599.9725993940283,
    "input_throughput": 3336.8753978910986,
    "output_throughput": 2930.9134191121484,
    "total_throughput": 6267.788817003247,
    "itl": 30.23915097835154,
    "ttft": 6993.069916883378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.39186389231871
}
#Debug simulation 
Total elapsed time: 3.604098131414503. Arrivals time: 0.13005399517714977 Scheduler time: 3.1746784755960107 Scheduler overhead time: 0.11324220290407538 Adapter cache time: 0.023796703200787306 Engine time: 0.10845553642138839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.5971058779396117,
    "estimated_duration": 3599.9879582301505,
    "input_throughput": 3336.861161587258,
    "output_throughput": 2930.9009147872966,
    "total_throughput": 6267.762076374554,
    "itl": 30.23919452548895,
    "ttft": 6992.9438131796405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.391982025737885
}
#Debug simulation 
Total elapsed time: 3.5971891307272017. Arrivals time: 0.12949138274416327 Scheduler time: 3.1730493120849133 Scheduler overhead time: 0.11193628702312708 Adapter cache time: 0.02361796284094453 Engine time: 0.10586547013372183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6192692490294576,
    "estimated_duration": 3599.9881118215544,
    "input_throughput": 3336.8610192220126,
    "output_throughput": 2930.9007897421097,
    "total_throughput": 6267.761808964122,
    "itl": 30.239217030687975,
    "ttft": 6992.955224912449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.391982025737903
}
#Debug simulation 
Total elapsed time: 3.6193651789799333. Arrivals time: 0.1377510754391551 Scheduler time: 3.1816327148117125 Scheduler overhead time: 0.11331730103120208 Adapter cache time: 0.023918259888887405 Engine time: 0.10917558055371046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.60919598210603,
    "estimated_duration": 3599.9807176733807,
    "input_throughput": 3336.8678729378366,
    "output_throughput": 2930.906809639554,
    "total_throughput": 6267.77468257739,
    "itl": 30.239219651523722,
    "ttft": 6992.947954641598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.391937532849322
}
#Debug simulation 
Total elapsed time: 3.609282243065536. Arrivals time: 0.14084133552387357 Scheduler time: 3.1687459722161293 Scheduler overhead time: 0.11275990772992373 Adapter cache time: 0.023751243483275175 Engine time: 0.10970387374982238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6046795072034,
    "estimated_duration": 3599.987964096309,
    "input_throughput": 3336.861156149863,
    "output_throughput": 2930.9009100114113,
    "total_throughput": 6267.762066161274,
    "itl": 30.239243373181537,
    "ttft": 6992.969481325347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.391961801697747
}
#Debug simulation 
Total elapsed time: 3.60479266801849. Arrivals time: 0.1315495283342898 Scheduler time: 3.1737372749485075 Scheduler overhead time: 0.11309500550851226 Adapter cache time: 0.02391741005703807 Engine time: 0.10875397734344006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.5909591279923916,
    "estimated_duration": 3599.966687493444,
    "input_throughput": 3336.8808777405875,
    "output_throughput": 2930.9182322868965,
    "total_throughput": 6267.799110027484,
    "itl": 30.23919677212637,
    "ttft": 6993.067162850583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.391787040965962
}
#Debug simulation 
Total elapsed time: 3.591045846696943. Arrivals time: 0.12942300317808986 Scheduler time: 3.1634652079083025 Scheduler overhead time: 0.11346981814131141 Adapter cache time: 0.023746117018163204 Engine time: 0.10752047738060355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 135, 135, 4320, 135, 8640, 4320, 135, 135, 135, 8640, 8640, 135, 135, 4320, 4320, 4320, 8640, 8640, 135, 8640, 8640, 8640, 8640, 4320, 135, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143910 . Total input tokens: 32059061 . Total output tokens: 28791111
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.61143451416865,
    "estimated_duration": 3599.988204427908,
    "input_throughput": 3336.8609333843615,
    "output_throughput": 2930.9007143474087,
    "total_throughput": 6267.76164773177,
    "itl": 30.239165246071487,
    "ttft": 6993.06495849452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 48221,
    "finished_requests": 48128,
    "scheduler_time": 21.391961801697686
}
#Debug simulation 
Total elapsed time: 3.611519327852875. Arrivals time: 0.13190406747162342 Scheduler time: 3.1813338100910187 Scheduler overhead time: 0.11278140358626842 Adapter cache time: 0.023569473531097174 Engine time: 0.10860842186957598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.6325948950834572,
    "estimated_duration": 3599.9827371757106,
    "input_throughput": 3300.4591597907083,
    "output_throughput": 2954.290277609434,
    "total_throughput": 6254.749437400143,
    "itl": 30.265992093750953,
    "ttft": 9418.708224929887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.77092971012183
}
#Debug simulation 
Total elapsed time: 3.632859716191888. Arrivals time: 0.138886162545532 Scheduler time: 3.1949863573536277 Scheduler overhead time: 0.11282416945323348 Adapter cache time: 0.02266231970861554 Engine time: 0.10981710581108928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.635140767786652,
    "estimated_duration": 3599.9751060750536,
    "input_throughput": 3300.4661559879933,
    "output_throughput": 2954.2965400100934,
    "total_throughput": 6254.762695998086,
    "itl": 30.293020503523497,
    "ttft": 9418.76149056189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.790500074768524
}
#Debug simulation 
Total elapsed time: 3.6352389780804515. Arrivals time: 0.13243280909955502 Scheduler time: 3.2048118570819497 Scheduler overhead time: 0.11213833000510931 Adapter cache time: 0.021935399156063795 Engine time: 0.11029647383838892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6254418469034135,
    "estimated_duration": 3599.974387325068,
    "input_throughput": 3300.466814939904,
    "output_throughput": 2954.2971298477887,
    "total_throughput": 6254.763944787693,
    "itl": 30.29305127718947,
    "ttft": 9418.765414904952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.790496029960444
}
#Debug simulation 
Total elapsed time: 3.6255320529453456. Arrivals time: 0.12914215680211782 Scheduler time: 3.200186293106526 Scheduler overhead time: 0.11305853351950645 Adapter cache time: 0.022163982968777418 Engine time: 0.10770831815898418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.6160666570067406,
    "estimated_duration": 3599.973191428929,
    "input_throughput": 3300.467911341269,
    "output_throughput": 2954.2981112530224,
    "total_throughput": 6254.766022594291,
    "itl": 30.267002316534132,
    "ttft": 9418.636695455058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.771585759838256
}
#Debug simulation 
Total elapsed time: 3.6161544620990753. Arrivals time: 0.13317447528243065 Scheduler time: 3.1849360410124063 Scheduler overhead time: 0.1128226425498724 Adapter cache time: 0.022619263734668493 Engine time: 0.10916833952069283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6220857137814164,
    "estimated_duration": 3599.977899028506,
    "input_throughput": 3300.4635954032888,
    "output_throughput": 2954.294247992489,
    "total_throughput": 6254.757843395778,
    "itl": 30.29304574285881,
    "ttft": 9418.730358968118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.790532474207698
}
#Debug simulation 
Total elapsed time: 3.622173785697669. Arrivals time: 0.1387634458951652 Scheduler time: 3.1891915551386774 Scheduler overhead time: 0.11209071334451437 Adapter cache time: 0.022056154906749725 Engine time: 0.10673552146181464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.651289517991245,
    "estimated_duration": 3599.981829902684,
    "input_throughput": 3300.4599915775652,
    "output_throughput": 2954.29102215427,
    "total_throughput": 6254.751013731836,
    "itl": 30.265999790115824,
    "ttft": 9418.698125217894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.770921620505785
}
#Debug simulation 
Total elapsed time: 3.651391663122922. Arrivals time: 0.13318747049197555 Scheduler time: 3.218990746419877 Scheduler overhead time: 0.11287402361631393 Adapter cache time: 0.022772797383368015 Engine time: 0.11010174453258514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 66, 66, 4320, 66, 8640, 4320, 66, 66, 66, 8640, 8640, 66, 66, 4320, 4320, 4320, 8640, 8640, 66, 8640, 8640, 8640, 8640, 4320, 66, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 143220 . Total input tokens: 31901592 . Total output tokens: 28646650
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6307219471782446,
    "estimated_duration": 3599.969704948717,
    "input_throughput": 3300.4711077615184,
    "output_throughput": 2954.3009724165177,
    "total_throughput": 6254.772080178036,
    "itl": 30.266101306477218,
    "ttft": 9418.776765163957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 48032,
    "finished_requests": 47907,
    "scheduler_time": 21.77089259578817
}
#Debug simulation 
Total elapsed time: 3.6308266362175345. Arrivals time: 0.12970720324665308 Scheduler time: 3.205010031349957 Scheduler overhead time: 0.11260727187618613 Adapter cache time: 0.02238586451858282 Engine time: 0.1075124409981072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.641908848658204,
    "estimated_duration": 3599.9911671076934,
    "input_throughput": 3281.7569409460098,
    "output_throughput": 2949.4566811758964,
    "total_throughput": 6231.213622121906,
    "itl": 30.14482766830091,
    "ttft": 7039.341987334604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.581266494125842
}
#Debug simulation 
Total elapsed time: 3.6420104140415788. Arrivals time: 0.13203266263008118 Scheduler time: 3.2096209707669914 Scheduler overhead time: 0.11481890361756086 Adapter cache time: 0.02233665995299816 Engine time: 0.10948229860514402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.656535340938717,
    "estimated_duration": 3599.963865107489,
    "input_throughput": 3281.781829676017,
    "output_throughput": 2949.479049752341,
    "total_throughput": 6231.260879428358,
    "itl": 30.144950319385185,
    "ttft": 7039.270616141597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.58109902999895
}
#Debug simulation 
Total elapsed time: 3.6566336881369352. Arrivals time: 0.1390400854870677 Scheduler time: 3.217721947003156 Scheduler overhead time: 0.11417329404503107 Adapter cache time: 0.022165699396282434 Engine time: 0.10972829349339008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.62828485481441,
    "estimated_duration": 3599.9706906671668,
    "input_throughput": 3281.775607403767,
    "output_throughput": 2949.4734575275693,
    "total_throughput": 6231.249064931337,
    "itl": 30.14498833925522,
    "ttft": 7039.331203028253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.58118397096778
}
#Debug simulation 
Total elapsed time: 3.6284004100598395. Arrivals time: 0.1299878265708685 Scheduler time: 3.1994389817118645 Scheduler overhead time: 0.11303633125498891 Adapter cache time: 0.022304516285657883 Engine time: 0.10993222938850522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 3.6455253208987415,
    "estimated_duration": 3599.9911611861194,
    "input_throughput": 3281.756946344125,
    "output_throughput": 2949.456686027416,
    "total_throughput": 6231.213632371541,
    "itl": 30.144878182259568,
    "ttft": 7039.318562360036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.5812543597017
}
#Debug simulation 
Total elapsed time: 3.645624016877264. Arrivals time: 0.12916821287944913 Scheduler time: 3.2175288992002606 Scheduler overhead time: 0.1128861322067678 Adapter cache time: 0.02205445757135749 Engine time: 0.1103271204046905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 3.683861871715635,
    "estimated_duration": 3599.9702465025503,
    "input_throughput": 3281.7760123095036,
    "output_throughput": 2949.47382143384,
    "total_throughput": 6231.2498337433435,
    "itl": 30.144938011096166,
    "ttft": 7039.3253814062555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.58116374692757
}
#Debug simulation 
Total elapsed time: 3.6839456567540765. Arrivals time: 0.13986328151077032 Scheduler time: 3.2362058544531465 Scheduler overhead time: 0.11768546095117927 Adapter cache time: 0.022470990661531687 Engine time: 0.1133289197459817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 3.653229701332748,
    "estimated_duration": 3599.991126186523,
    "input_throughput": 3281.756978249806,
    "output_throughput": 2949.456714702429,
    "total_throughput": 6231.213692952235,
    "itl": 30.14486791498261,
    "ttft": 7039.34677996711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.58127946253598
}
#Debug simulation 
Total elapsed time: 3.653364266268909. Arrivals time: 0.1399337504990399 Scheduler time: 3.2150785848498344 Scheduler overhead time: 0.1139061520807445 Adapter cache time: 0.022223758976906538 Engine time: 0.108483144082129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 4320, 33, 33, 4320, 33, 8640, 4320, 33, 33, 33, 8640, 8640, 33, 33, 4320, 4320, 4320, 8640, 8640, 33, 8640, 8640, 8640, 8640, 4320, 33, 4320, 4320, 4320, 4320, 8640]
Prompts retrieved: 142890 . Total input tokens: 31830453 . Total output tokens: 28573619
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 3.631135798059404,
    "estimated_duration": 3599.9702866851558,
    "input_throughput": 3281.7759756785595,
    "output_throughput": 2949.4737885120285,
    "total_throughput": 6231.2497641905875,
    "itl": 30.144984203981238,
    "ttft": 7039.314658565735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 47900,
    "finished_requests": 47807,
    "scheduler_time": 21.581171836543685
}
#Debug simulation 
Total elapsed time: 3.6312126517295837. Arrivals time: 0.1340478858910501 Scheduler time: 3.200392329134047 Scheduler overhead time: 0.11331104766577482 Adapter cache time: 0.022369487676769495 Engine time: 0.10757298022508621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.9765565237030387,
    "estimated_duration": 3599.9838815235225,
    "input_throughput": 2598.101354843215,
    "output_throughput": 2313.9289713915823,
    "total_throughput": 4912.030326234797,
    "itl": 26.693266879364966,
    "ttft": 9209.675481341705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.555375968972648
}
#Debug simulation 
Total elapsed time: 2.976716181728989. Arrivals time: 0.11404070956632495 Scheduler time: 2.522642742842436 Scheduler overhead time: 0.125943036749959 Adapter cache time: 0.03422809299081564 Engine time: 0.12050371803343296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.9622144321911037,
    "estimated_duration": 3599.9664253603682,
    "input_throughput": 2598.113952983248,
    "output_throughput": 2313.940191585573,
    "total_throughput": 4912.054144568821,
    "itl": 26.693307251387424,
    "ttft": 9209.64917138875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.555440478829315
}
#Debug simulation 
Total elapsed time: 2.962303026113659. Arrivals time: 0.10673105902969837 Scheduler time: 2.520439966581762 Scheduler overhead time: 0.12446739803999662 Adapter cache time: 0.034225833136588335 Engine time: 0.11777646886184812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.939305442851037,
    "estimated_duration": 3599.9666841779285,
    "input_throughput": 2598.113766193321,
    "output_throughput": 2313.9400252261566,
    "total_throughput": 4912.053791419478,
    "itl": 26.6933042783882,
    "ttft": 9209.676774044026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.555443689651343
}
#Debug simulation 
Total elapsed time: 2.9393915347754955. Arrivals time: 0.10418117931112647 Scheduler time: 2.5034424499608576 Scheduler overhead time: 0.12278706021606922 Adapter cache time: 0.034045904874801636 Engine time: 0.11646044906228781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.957110937219113,
    "estimated_duration": 3599.9902288543217,
    "input_throughput": 2598.096773995018,
    "output_throughput": 2313.924891582557,
    "total_throughput": 4912.021665577575,
    "itl": 26.693372215083617,
    "ttft": 9209.654665975771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.555535843078275
}
#Debug simulation 
Total elapsed time: 2.957203954923898. Arrivals time: 0.11242443509399891 Scheduler time: 2.5109719280153513 Scheduler overhead time: 0.12332405522465706 Adapter cache time: 0.034145215060561895 Engine time: 0.11777326185256243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.977780920919031,
    "estimated_duration": 3599.9701500469528,
    "input_throughput": 2598.111264860908,
    "output_throughput": 2313.937797481836,
    "total_throughput": 4912.049062342743,
    "itl": 26.69322305435085,
    "ttft": 9209.68114727283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.555472878268578
}
#Debug simulation 
Total elapsed time: 2.97787123080343. Arrivals time: 0.10533040948212147 Scheduler time: 2.53184031881392 Scheduler overhead time: 0.12681883852928877 Adapter cache time: 0.034482153598219156 Engine time: 0.12001711968332529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.9569016960449517,
    "estimated_duration": 3599.983730081669,
    "input_throughput": 2598.1014641385104,
    "output_throughput": 2313.9290687324924,
    "total_throughput": 4912.030532871003,
    "itl": 26.693264967510867,
    "ttft": 9209.684803163771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.55538893738276
}
#Debug simulation 
Total elapsed time: 2.9569936618208885. Arrivals time: 0.10416363319382071 Scheduler time: 2.5185476881451905 Scheduler overhead time: 0.12304748222231865 Adapter cache time: 0.03385920822620392 Engine time: 0.11894119950011373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 540, 540, 1080, 540, 8640, 1080, 540, 540, 540, 8640, 8640, 540, 540, 1080, 1080, 1080, 8640, 8640, 540, 8640, 8640, 8640, 8640, 1080, 540, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 112320 . Total input tokens: 25085478 . Total output tokens: 22474251
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.965829936787486,
    "estimated_duration": 3599.9701502515713,
    "input_throughput": 2598.1112647132336,
    "output_throughput": 2313.937797350314,
    "total_throughput": 4912.049062063547,
    "itl": 26.693196753541446,
    "ttft": 9209.63385443686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 37706,
    "finished_requests": 37610,
    "scheduler_time": 9.555491559458769
}
#Debug simulation 
Total elapsed time: 2.9659181688912213. Arrivals time: 0.11050024535506964 Scheduler time: 2.516160409897566 Scheduler overhead time: 0.12451985711231828 Adapter cache time: 0.03404775960370898 Engine time: 0.12231045914813876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.8910941719077528,
    "estimated_duration": 3600.0210655755914,
    "input_throughput": 2526.452994114854,
    "output_throughput": 2236.858299803444,
    "total_throughput": 4763.311293918298,
    "itl": 25.978405122308644,
    "ttft": 6312.173561947083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 36751,
    "finished_requests": 36687,
    "scheduler_time": 7.834186302185961
}
#Debug simulation 
Total elapsed time: 2.891216308809817. Arrivals time: 0.10481028305366635 Scheduler time: 2.4484906001016498 Scheduler overhead time: 0.12714635767042637 Adapter cache time: 0.03190798172727227 Engine time: 0.11881309235468507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.847076199017465,
    "estimated_duration": 3600.007429064647,
    "input_throughput": 2526.4625640961895,
    "output_throughput": 2236.8667728255937,
    "total_throughput": 4763.329336921784,
    "itl": 25.97856375133347,
    "ttft": 6214.287750217917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 36751,
    "finished_requests": 36687,
    "scheduler_time": 7.834199854338124
}
#Debug simulation 
Total elapsed time: 2.847187293227762. Arrivals time: 0.09890647465363145 Scheduler time: 2.4151890710927546 Scheduler overhead time: 0.12467067176476121 Adapter cache time: 0.031660801731050014 Engine time: 0.11705825105309486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8716589002870023,
    "estimated_duration": 3600.007391113504,
    "input_throughput": 2526.4625907300633,
    "output_throughput": 2236.8667964065594,
    "total_throughput": 4763.329387136623,
    "itl": 25.978585215282564,
    "ttft": 6214.313369082065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 36751,
    "finished_requests": 36687,
    "scheduler_time": 7.834178921433905
}
#Debug simulation 
Total elapsed time: 2.871745465323329. Arrivals time: 0.10522917564958334 Scheduler time: 2.4253886374644935 Scheduler overhead time: 0.12464386085048318 Adapter cache time: 0.031862637493759394 Engine time: 0.12501648906618357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8804871882312,
    "estimated_duration": 3600.001142403334,
    "input_throughput": 2526.420309391393,
    "output_throughput": 2236.796790187747,
    "total_throughput": 4763.21709957914,
    "itl": 25.97844495722131,
    "ttft": 6312.317157283237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 36751,
    "finished_requests": 36686,
    "scheduler_time": 7.834219119270324
}
#Debug simulation 
Total elapsed time: 2.8805773188360035. Arrivals time: 0.10755106434226036 Scheduler time: 2.4366178126074374 Scheduler overhead time: 0.1259789583273232 Adapter cache time: 0.031995588447898626 Engine time: 0.11856550676748157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.89079545205459,
    "estimated_duration": 3600.0074328320766,
    "input_throughput": 2526.4625614522315,
    "output_throughput": 2236.8667704846994,
    "total_throughput": 4763.32933193693,
    "itl": 25.978612815494877,
    "ttft": 6214.29511367191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 36751,
    "finished_requests": 36687,
    "scheduler_time": 7.834140850189524
}
#Debug simulation 
Total elapsed time: 2.890882942825556. Arrivals time: 0.10243079997599125 Scheduler time: 2.452863941900432 Scheduler overhead time: 0.1248253807425499 Adapter cache time: 0.031689888797700405 Engine time: 0.11936456337571144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.893952311016619,
    "estimated_duration": 3600.012485900612,
    "input_throughput": 2526.45901524551,
    "output_throughput": 2236.8636307619513,
    "total_throughput": 4763.322646007461,
    "itl": 25.978368997498237,
    "ttft": 6312.1094927266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 36751,
    "finished_requests": 36687,
    "scheduler_time": 7.834031181752395
}
#Debug simulation 
Total elapsed time: 2.8940618564374745. Arrivals time: 0.10697692353278399 Scheduler time: 2.439682499039918 Scheduler overhead time: 0.12601229641586542 Adapter cache time: 0.032124404795467854 Engine time: 0.12926378473639488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 270, 270, 1080, 270, 8640, 1080, 270, 270, 270, 8640, 8640, 270, 270, 1080, 1080, 1080, 8640, 8640, 270, 8640, 8640, 8640, 8640, 1080, 270, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 109620 . Total input tokens: 24475272 . Total output tokens: 21937825
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.898025556001812,
    "estimated_duration": 3600.0082586330823,
    "input_throughput": 2526.4619819104155,
    "output_throughput": 2236.8662573728684,
    "total_throughput": 4763.328239283283,
    "itl": 25.978591383232068,
    "ttft": 6214.31039851489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 36751,
    "finished_requests": 36687,
    "scheduler_time": 7.83410778286118
}
#Debug simulation 
Total elapsed time: 2.8981971708126366. Arrivals time: 0.10469919769093394 Scheduler time: 2.448871991597116 Scheduler overhead time: 0.1263464828953147 Adapter cache time: 0.031964629888534546 Engine time: 0.12627572426572442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.886039533186704,
    "estimated_duration": 3599.9071859776345,
    "input_throughput": 2492.1684189376037,
    "output_throughput": 2225.5296000983553,
    "total_throughput": 4717.698019035959,
    "itl": 25.734513562226056,
    "ttft": 6285.892212752745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.465532992373065
}
#Debug simulation 
Total elapsed time: 2.8861480550840497. Arrivals time: 0.10104808630421758 Scheduler time: 2.437144245021045 Scheduler overhead time: 0.12660676334053278 Adapter cache time: 0.030959696043282747 Engine time: 0.12989922892302275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8706924659200013,
    "estimated_duration": 3599.919934443945,
    "input_throughput": 2492.1595933732283,
    "output_throughput": 2225.521718787202,
    "total_throughput": 4717.68131216043,
    "itl": 25.7345273276376,
    "ttft": 6285.801610807537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.4654904177006465
}
#Debug simulation 
Total elapsed time: 2.8707829392515123. Arrivals time: 0.10512426309287548 Scheduler time: 2.4269908033311367 Scheduler overhead time: 0.12668949039652944 Adapter cache time: 0.03096061944961548 Engine time: 0.12085697241127491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8917163820005953,
    "estimated_duration": 3599.919979895509,
    "input_throughput": 2492.159561907931,
    "output_throughput": 2225.521690688399,
    "total_throughput": 4717.68125259633,
    "itl": 25.73452999313294,
    "ttft": 6285.832277176163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.465448426770228
}
#Debug simulation 
Total elapsed time: 2.8918046969920397. Arrivals time: 0.10562875401228666 Scheduler time: 2.4504842278547585 Scheduler overhead time: 0.12665225565433502 Adapter cache time: 0.031000351067632437 Engine time: 0.11798428697511554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.8905319538898766,
    "estimated_duration": 3599.907199337377,
    "input_throughput": 2492.16840968883,
    "output_throughput": 2225.529591839114,
    "total_throughput": 4717.698001527944,
    "itl": 25.734423387029878,
    "ttft": 6285.894753772471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.465529656429033
}
#Debug simulation 
Total elapsed time: 2.8906085789203644. Arrivals time: 0.10199420526623726 Scheduler time: 2.442894611507654 Scheduler overhead time: 0.1270659207366407 Adapter cache time: 0.03243786096572876 Engine time: 0.12234263168647885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8949056956917048,
    "estimated_duration": 3599.9198371277903,
    "input_throughput": 2492.159660743447,
    "output_throughput": 2225.521778949435,
    "total_throughput": 4717.681439692882,
    "itl": 25.734516973200392,
    "ttft": 6285.820861482084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.465472695618479
}
#Debug simulation 
Total elapsed time: 2.894987855106592. Arrivals time: 0.10513185290619731 Scheduler time: 2.4491350944153965 Scheduler overhead time: 0.12601742381229997 Adapter cache time: 0.030871632043272257 Engine time: 0.12336226273328066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.8980705570429564,
    "estimated_duration": 3599.9052865270705,
    "input_throughput": 2492.169733902952,
    "output_throughput": 2225.5307743746534,
    "total_throughput": 4717.700508277606,
    "itl": 25.7345063888792,
    "ttft": 6285.852447261299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.465499091058728
}
#Debug simulation 
Total elapsed time: 2.898165616672486. Arrivals time: 0.10662932600826025 Scheduler time: 2.4536901083774865 Scheduler overhead time: 0.12693873699754477 Adapter cache time: 0.030954064335674047 Engine time: 0.11954530607908964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 135, 135, 1080, 135, 8640, 1080, 135, 135, 135, 8640, 8640, 135, 135, 1080, 1080, 1080, 8640, 8640, 135, 8640, 8640, 8640, 8640, 1080, 135, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 108270 . Total input tokens: 24167479 . Total output tokens: 21679601
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.893867479171604,
    "estimated_duration": 3599.9198632120992,
    "input_throughput": 2492.15964268575,
    "output_throughput": 2225.5217628237433,
    "total_throughput": 4717.681405509494,
    "itl": 25.73449676950023,
    "ttft": 6285.797562078851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 36327,
    "finished_requests": 36264,
    "scheduler_time": 7.465566184823403
}
#Debug simulation 
Total elapsed time: 2.8939578142017126. Arrivals time: 0.10306109394878149 Scheduler time: 2.4505828111432493 Scheduler overhead time: 0.12757081724703312 Adapter cache time: 0.031053881626576185 Engine time: 0.12117031309753656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.863610665779561,
    "estimated_duration": 3600.003649496704,
    "input_throughput": 2476.3255451828013,
    "output_throughput": 2229.214962357595,
    "total_throughput": 4705.540507540397,
    "itl": 25.647028176751714,
    "ttft": 6227.984405115869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.465957978242037
}
#Debug simulation 
Total elapsed time: 2.863717367872596. Arrivals time: 0.10171147622168064 Scheduler time: 2.4218043670989573 Scheduler overhead time: 0.12733250856399536 Adapter cache time: 0.030375296249985695 Engine time: 0.12215621257200837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8903284780681133,
    "estimated_duration": 3600.0113965549044,
    "input_throughput": 2476.3202162446373,
    "output_throughput": 2229.2101651899884,
    "total_throughput": 4705.530381434626,
    "itl": 25.644818613684823,
    "ttft": 6228.035741942472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.463686714338894
}
#Debug simulation 
Total elapsed time: 2.8904182389378548. Arrivals time: 0.10707100387662649 Scheduler time: 2.4425432472489774 Scheduler overhead time: 0.12772684171795845 Adapter cache time: 0.029808082152158022 Engine time: 0.12281682109460235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8541023158468306,
    "estimated_duration": 3599.985725784552,
    "input_throughput": 2476.3378743834282,
    "output_throughput": 2229.226061236967,
    "total_throughput": 4705.563935620395,
    "itl": 25.644815241917186,
    "ttft": 6228.016550350176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.463632588984344
}
#Debug simulation 
Total elapsed time: 2.8541818619705737. Arrivals time: 0.09963533701375127 Scheduler time: 2.418152714148164 Scheduler overhead time: 0.12671847408637404 Adapter cache time: 0.029538383707404137 Engine time: 0.11995300278067589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.849949029274285,
    "estimated_duration": 3599.9931975462587,
    "input_throughput": 2476.332734760799,
    "output_throughput": 2229.2214344932463,
    "total_throughput": 4705.5541692540455,
    "itl": 25.64477634441317,
    "ttft": 6227.941824586631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.463670743482724
}
#Debug simulation 
Total elapsed time: 2.850032094400376. Arrivals time: 0.10355145204812288 Scheduler time: 2.409684309735894 Scheduler overhead time: 0.12596158729866147 Adapter cache time: 0.029640809632837772 Engine time: 0.12087154574692249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.875264761969447,
    "estimated_duration": 3599.985375217639,
    "input_throughput": 2476.338115529442,
    "output_throughput": 2229.2262783192095,
    "total_throughput": 4705.564393848652,
    "itl": 25.644800521562754,
    "ttft": 6228.011176445754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.463632463862341
}
#Debug simulation 
Total elapsed time: 2.875371651723981. Arrivals time: 0.10572567535564303 Scheduler time: 2.433961483184248 Scheduler overhead time: 0.1271547032520175 Adapter cache time: 0.030002876184880733 Engine time: 0.1181986415758729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.864001623354852,
    "estimated_duration": 3600.0037489686993,
    "input_throughput": 2476.32547675925,
    "output_throughput": 2229.214900761976,
    "total_throughput": 4705.540377521225,
    "itl": 25.64696427557093,
    "ttft": 6227.959977971106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.465936920215791
}
#Debug simulation 
Total elapsed time: 2.86412742594257. Arrivals time: 0.09870293037965894 Scheduler time: 2.4271819768473506 Scheduler overhead time: 0.12699780939146876 Adapter cache time: 0.029851760249584913 Engine time: 0.1206986689940095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 66, 66, 1080, 66, 8640, 1080, 66, 66, 66, 8640, 8640, 66, 66, 1080, 1080, 1080, 8640, 8640, 66, 8640, 8640, 8640, 8640, 1080, 66, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107580 . Total input tokens: 24012937 . Total output tokens: 21541985
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.865118072833866,
    "estimated_duration": 3599.986871732323,
    "input_throughput": 2476.3370861155904,
    "output_throughput": 2229.225351629758,
    "total_throughput": 4705.562437745349,
    "itl": 25.644822582076795,
    "ttft": 6228.005087332725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 36084,
    "finished_requests": 36022,
    "scheduler_time": 7.46370431129906
}
#Debug simulation 
Total elapsed time: 2.865201434120536. Arrivals time: 0.09880756074562669 Scheduler time: 2.424620491452515 Scheduler overhead time: 0.12738502444699407 Adapter cache time: 0.030006099492311478 Engine time: 0.12374064000323415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.840207310859114,
    "estimated_duration": 3599.649342733218,
    "input_throughput": 2491.97078546237,
    "output_throughput": 2195.427178470506,
    "total_throughput": 4687.397963932875,
    "itl": 25.42310174190973,
    "ttft": 7343.497525772261,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.772968188911148
}
#Debug simulation 
Total elapsed time: 2.8403247566893697. Arrivals time: 0.10431842040270567 Scheduler time: 2.397873235400766 Scheduler overhead time: 0.12729999888688326 Adapter cache time: 0.029068152885884047 Engine time: 0.121267756447196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8631746256724,
    "estimated_duration": 3599.6515253187845,
    "input_throughput": 2491.969274499592,
    "output_throughput": 2195.425847311743,
    "total_throughput": 4687.395121811334,
    "itl": 25.42302034685553,
    "ttft": 7343.390820309778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.773013515785589
}
#Debug simulation 
Total elapsed time: 2.8632703428156674. Arrivals time: 0.09772482514381409 Scheduler time: 2.424038726836443 Scheduler overhead time: 0.12856499757617712 Adapter cache time: 0.029025784693658352 Engine time: 0.12289284076541662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8216612469404936,
    "estimated_duration": 3599.6545275694016,
    "input_throughput": 2491.967196101169,
    "output_throughput": 2195.4240162419683,
    "total_throughput": 4687.391212343137,
    "itl": 25.423035056112283,
    "ttft": 7343.412092221444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.772980448457253
}
#Debug simulation 
Total elapsed time: 2.8217857922427356. Arrivals time: 0.0969659979455173 Scheduler time: 2.387099150568247 Scheduler overhead time: 0.12649355363100767 Adapter cache time: 0.029134522657841444 Engine time: 0.1215223427861929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.861133382190019,
    "estimated_duration": 3599.6493703071437,
    "input_throughput": 2491.9707663734503,
    "output_throughput": 2195.427161653161,
    "total_throughput": 4687.397928026611,
    "itl": 25.423114440976544,
    "ttft": 7343.46948763694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.7730933277164205
}
#Debug simulation 
Total elapsed time: 2.8613432832062244. Arrivals time: 0.10436981869861484 Scheduler time: 2.4164684480056167 Scheduler overhead time: 0.12811054335907102 Adapter cache time: 0.02939622336998582 Engine time: 0.12162795197218657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8198553039692342,
    "estimated_duration": 3599.654480190317,
    "input_throughput": 2491.967228900741,
    "output_throughput": 2195.4240451384026,
    "total_throughput": 4687.391274039143,
    "itl": 25.42302788072853,
    "ttft": 7343.471460280703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1061953396908939,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.773002924211471
}
#Debug simulation 
Total elapsed time: 2.819942515809089. Arrivals time: 0.0972984116524458 Scheduler time: 2.3851442453451455 Scheduler overhead time: 0.12696558935567737 Adapter cache time: 0.02914029313251376 Engine time: 0.12067599594593048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.840325869154185,
    "estimated_duration": 3599.6493775550202,
    "input_throughput": 2491.970761355879,
    "output_throughput": 2195.427157232679,
    "total_throughput": 4687.397918588558,
    "itl": 25.423145276724124,
    "ttft": 7343.492025323745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.772936789554831
}
#Debug simulation 
Total elapsed time: 2.8404210512526333. Arrivals time: 0.1034385897219181 Scheduler time: 2.398213212378323 Scheduler overhead time: 0.12769318232312799 Adapter cache time: 0.029153934679925442 Engine time: 0.1211414160206914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 1080, 33, 33, 1080, 33, 8640, 1080, 33, 33, 33, 8640, 8640, 33, 33, 1080, 1080, 1080, 8640, 8640, 33, 8640, 8640, 8640, 8640, 1080, 33, 1080, 1080, 1080, 1080, 8640]
Prompts retrieved: 107250 . Total input tokens: 23940134 . Total output tokens: 21478222
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8324565230868757,
    "estimated_duration": 3599.6374252128853,
    "input_throughput": 2491.9790357689967,
    "output_throughput": 2195.4344469936786,
    "total_throughput": 4687.413482762675,
    "itl": 25.42315634675613,
    "ttft": 7343.417178936118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 35993,
    "finished_requests": 35920,
    "scheduler_time": 6.773083445006326
}
#Debug simulation 
Total elapsed time: 2.8325499701313674. Arrivals time: 0.10148137342184782 Scheduler time: 2.3941766624338925 Scheduler overhead time: 0.12692149775102735 Adapter cache time: 0.029369506519287825 Engine time: 0.11977499816566706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7469760309904814,
    "estimated_duration": 3599.9661865765956,
    "input_throughput": 2413.3501676752894,
    "output_throughput": 2122.530769453221,
    "total_throughput": 4535.880937128511,
    "itl": 24.921696989689572,
    "ttft": 4597.672915389498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.307439724175404
}
#Debug simulation 
Total elapsed time: 2.747104302048683. Arrivals time: 0.09649433940649033 Scheduler time: 2.3085689204744995 Scheduler overhead time: 0.12975705228745937 Adapter cache time: 0.02947829756885767 Engine time: 0.12100377446040511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.755915797315538,
    "estimated_duration": 3599.9559056940016,
    "input_throughput": 2413.357059806855,
    "output_throughput": 2122.5368310523672,
    "total_throughput": 4535.893890859223,
    "itl": 24.922480824046445,
    "ttft": 4597.63017502826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.308114039634321
}
#Debug simulation 
Total elapsed time: 2.7559958193451166. Arrivals time: 0.09991403250023723 Scheduler time: 2.3076460254378617 Scheduler overhead time: 0.13206433318555355 Adapter cache time: 0.029456012416630983 Engine time: 0.1246507577598095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7779464437626302,
    "estimated_duration": 3599.960256027404,
    "input_throughput": 2413.354143411372,
    "output_throughput": 2122.534266095474,
    "total_throughput": 4535.888409506846,
    "itl": 24.922479110183186,
    "ttft": 4597.675871557574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.308106909126238
}
#Debug simulation 
Total elapsed time: 2.7780386419035494. Arrivals time: 0.10276920208707452 Scheduler time: 2.3287269044667482 Scheduler overhead time: 0.12949174595996737 Adapter cache time: 0.029385162517428398 Engine time: 0.12574487924575806 
