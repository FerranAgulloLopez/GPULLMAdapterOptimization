INFO 06-01 00:47:27 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:28 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.700577611103654,
    "estimated_duration": 3600.3195771510223,
    "input_throughput": 3314.488545887058,
    "output_throughput": 2870.430465558225,
    "total_throughput": 6184.919011445283,
    "itl": 290.52256932219603,
    "ttft": 2368118.4984759595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 354,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0834126613521964,
    "arrivals": 1847695,
    "finished_requests": 48031,
    "scheduler_time": 28.842600813121273
}
#Debug simulation 
Total elapsed time: 3.7006944697350264. Arrivals time: 0.21023548860102892 Scheduler time: 3.3579147276468575 Scheduler overhead time: 0.019938939716666937 Adapter cache time: 0.08302378980442882 Engine time: 0.020354653242975473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9679279308766127,
    "estimated_duration": 3600.003517871624,
    "input_throughput": 3122.2302823318573,
    "output_throughput": 2724.1592824326003,
    "total_throughput": 5846.389564764458,
    "itl": 122.86269563089255,
    "ttft": 2412112.3669859776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1437632890045701,
    "arrivals": 1847695,
    "finished_requests": 45247,
    "scheduler_time": 7.313968226921495
}
#Debug simulation 
Total elapsed time: 3.968033619225025. Arrivals time: 0.31687902193516493 Scheduler time: 3.290611643809825 Scheduler overhead time: 0.04214644804596901 Adapter cache time: 0.2545718578621745 Engine time: 0.043818975798785686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.838146640919149,
    "estimated_duration": 3600.041166732273,
    "input_throughput": 3117.176021124803,
    "output_throughput": 2719.060573655925,
    "total_throughput": 5836.236594780728,
    "itl": 122.71932170980521,
    "ttft": 2413163.811404157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0947318507917247,
    "arrivals": 1847695,
    "finished_requests": 45167,
    "scheduler_time": 7.202892787438143
}
#Debug simulation 
Total elapsed time: 3.838241337798536. Arrivals time: 0.1990793701261282 Scheduler time: 3.281300208065659 Scheduler overhead time: 0.041928963735699654 Adapter cache time: 0.25219731265679 Engine time: 0.04369001928716898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.8789566112682223,
    "estimated_duration": 3600.1321281471023,
    "input_throughput": 3117.097262142893,
    "output_throughput": 2718.9918735116016,
    "total_throughput": 5836.089135654495,
    "itl": 122.71756661631338,
    "ttft": 2413137.1726370025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0465176032157613,
    "arrivals": 1847695,
    "finished_requests": 45167,
    "scheduler_time": 7.203408218993858
}
#Debug simulation 
Total elapsed time: 3.87904662406072. Arrivals time: 0.21227743895724416 Scheduler time: 3.308215310331434 Scheduler overhead time: 0.04203724581748247 Adapter cache time: 0.25229791551828384 Engine time: 0.04420390445739031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.8289892058819532,
    "estimated_duration": 3600.3087556066866,
    "input_throughput": 3290.7874863647694,
    "output_throughput": 2901.1025745318166,
    "total_throughput": 6191.890060896586,
    "itl": 290.7943287677745,
    "ttft": 2372002.292757733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9579326638509507,
    "arrivals": 1844823,
    "finished_requests": 48022,
    "scheduler_time": 29.21991146570983
}
#Debug simulation 
Total elapsed time: 3.8290851577185094. Arrivals time: 0.33122486947104335 Scheduler time: 3.3732382874004543 Scheduler overhead time: 0.02006000466644764 Adapter cache time: 0.07497763959690928 Engine time: 0.020408700685948133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.926174547057599,
    "estimated_duration": 3600.1273376614213,
    "input_throughput": 3090.816784060788,
    "output_throughput": 2735.5996264280516,
    "total_throughput": 5826.41641048884,
    "itl": 122.90761968599223,
    "ttft": 2416105.80832703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0123120129737124,
    "arrivals": 1844823,
    "finished_requests": 45012,
    "scheduler_time": 7.424219512420739
}
#Debug simulation 
Total elapsed time: 3.9262642841786146. Arrivals time: 0.21111999358981848 Scheduler time: 3.374976433813572 Scheduler overhead time: 0.042388553731143475 Adapter cache time: 0.23343990370631218 Engine time: 0.04418213199824095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.84057032270357,
    "estimated_duration": 3600.085454759719,
    "input_throughput": 3090.8527422004413,
    "output_throughput": 2735.6314520198853,
    "total_throughput": 5826.484194220327,
    "itl": 122.90605106315346,
    "ttft": 2416081.6432362865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9702266951743544,
    "arrivals": 1844823,
    "finished_requests": 45012,
    "scheduler_time": 7.424421928515342
}
#Debug simulation 
Total elapsed time: 3.8406616719439626. Arrivals time: 0.19860738515853882 Scheduler time: 3.301652896683663 Scheduler overhead time: 0.0420434819534421 Adapter cache time: 0.23434337694197893 Engine time: 0.043926962185651064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.886124925687909,
    "estimated_duration": 3600.0423908986213,
    "input_throughput": 3090.889715113177,
    "output_throughput": 2735.664175760351,
    "total_throughput": 5826.553890873528,
    "itl": 122.90446093396935,
    "ttft": 2416056.19148052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9269155914196757,
    "arrivals": 1844823,
    "finished_requests": 45012,
    "scheduler_time": 7.424669171170167
}
#Debug simulation 
Total elapsed time: 3.8862158097326756. Arrivals time: 0.21759710041806102 Scheduler time: 3.329172587953508 Scheduler overhead time: 0.042337183840572834 Adapter cache time: 0.23287509428337216 Engine time: 0.04406566871330142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.86009055795148,
    "estimated_duration": 3600.09564204263,
    "input_throughput": 3290.8172943089025,
    "output_throughput": 2898.813819868073,
    "total_throughput": 6189.631114176976,
    "itl": 290.1913105645738,
    "ttft": 2370698.086091498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8875414457404974,
    "arrivals": 1843393,
    "finished_requests": 48021,
    "scheduler_time": 29.19943361218208
}
#Debug simulation 
Total elapsed time: 3.8601841549389064. Arrivals time: 0.3450323371216655 Scheduler time: 3.3907022112980485 Scheduler overhead time: 0.01992913568392396 Adapter cache time: 0.07480623479932547 Engine time: 0.02053541038185358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.895593752153218,
    "estimated_duration": 3600.073984326562,
    "input_throughput": 3085.556032559684,
    "output_throughput": 2741.976704638905,
    "total_throughput": 5827.5327371985895,
    "itl": 123.3644855623441,
    "ttft": 2413702.4753840463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9370033310959163,
    "arrivals": 1843393,
    "finished_requests": 45006,
    "scheduler_time": 7.657756709812292
}
#Debug simulation 
Total elapsed time: 3.8956878152675927. Arrivals time: 0.21366781182587147 Scheduler time: 3.344553603325039 Scheduler overhead time: 0.042381631676107645 Adapter cache time: 0.23099640291184187 Engine time: 0.044020370580255985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.988723746035248,
    "estimated_duration": 3600.0370098954186,
    "input_throughput": 3085.5877229780745,
    "output_throughput": 2742.00486630185,
    "total_throughput": 5827.592589279925,
    "itl": 123.36311907337267,
    "ttft": 2413679.8154205573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8998211571178429,
    "arrivals": 1843393,
    "finished_requests": 45006,
    "scheduler_time": 7.657964452646227
}
#Debug simulation 
Total elapsed time: 3.9888197337277234. Arrivals time: 0.3355907341465354 Scheduler time: 3.315922182518989 Scheduler overhead time: 0.04206892102956772 Adapter cache time: 0.23144717048853636 Engine time: 0.04372149659320712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.880219796206802,
    "estimated_duration": 3600.129692375187,
    "input_throughput": 3085.5082869726675,
    "output_throughput": 2741.934275564221,
    "total_throughput": 5827.4425625368885,
    "itl": 123.36162363056407,
    "ttft": 2413671.847039472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8581444346369256,
    "arrivals": 1843393,
    "finished_requests": 45006,
    "scheduler_time": 7.658476205098562
}
#Debug simulation 
Total elapsed time: 3.880314564332366. Arrivals time: 0.21406040200963616 Scheduler time: 3.3299842085689306 Scheduler overhead time: 0.04195776814594865 Adapter cache time: 0.2304450822994113 Engine time: 0.04380823019891977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.8450293140485883,
    "estimated_duration": 3600.202738108976,
    "input_throughput": 3384.6002257085,
    "output_throughput": 2974.70886476389,
    "total_throughput": 6359.3090904723895,
    "itl": 282.27145925177393,
    "ttft": 2357927.7883172613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1703822,
    "finished_requests": 49170,
    "scheduler_time": 29.87887198011145
}
#Debug simulation 
Total elapsed time: 3.84512592619285. Arrivals time: 0.21090552490204573 Scheduler time: 3.4686157796531916 Scheduler overhead time: 0.020708910655230284 Adapter cache time: 0.1141616078093648 Engine time: 0.02121717296540737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.012663116212934,
    "estimated_duration": 3600.0787077599225,
    "input_throughput": 3222.666486427743,
    "output_throughput": 2852.532356546697,
    "total_throughput": 6075.198842974441,
    "itl": 118.00036291203011,
    "ttft": 2394256.663640674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631698,
    "arrivals": 1703822,
    "finished_requests": 46792,
    "scheduler_time": 7.811598828591845
}
#Debug simulation 
Total elapsed time: 4.012751534115523. Arrivals time: 0.21037606382742524 Scheduler time: 3.4436175217851996 Scheduler overhead time: 0.04401976615190506 Adapter cache time: 0.24801963241770864 Engine time: 0.045785000547766685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.991757954005152,
    "estimated_duration": 3600.0266114913293,
    "input_throughput": 3222.71312188825,
    "output_throughput": 2852.5736357670626,
    "total_throughput": 6075.286757655313,
    "itl": 117.99847515382089,
    "ttft": 2394224.7178228702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027993,
    "arrivals": 1703822,
    "finished_requests": 46792,
    "scheduler_time": 7.811802760758411
}
#Debug simulation 
Total elapsed time: 3.9918564902618527. Arrivals time: 0.20181328430771828 Scheduler time: 3.430959729477763 Scheduler overhead time: 0.04369903029873967 Adapter cache time: 0.24887018091976643 Engine time: 0.04562298767268658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.980953123420477,
    "estimated_duration": 3600.095687616365,
    "input_throughput": 3222.860170053458,
    "output_throughput": 2852.6955645447815,
    "total_throughput": 6075.55573459824,
    "itl": 117.99689600393701,
    "ttft": 2394187.4200226986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 1703822,
    "finished_requests": 46795,
    "scheduler_time": 7.812235153760739
}
#Debug simulation 
Total elapsed time: 3.9810436703264713. Arrivals time: 0.20132708363234997 Scheduler time: 3.4209422026760876 Scheduler overhead time: 0.04366760700941086 Adapter cache time: 0.2484193779528141 Engine time: 0.04587969044223428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.036346320994198,
    "estimated_duration": 3600.1919243924403,
    "input_throughput": 3465.073324418736,
    "output_throughput": 3050.0257293513796,
    "total_throughput": 6515.0990537701155,
    "itl": 275.56084276205314,
    "ttft": 2343642.291509214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1680953,
    "finished_requests": 50387,
    "scheduler_time": 30.64514787274145
}
#Debug simulation 
Total elapsed time: 4.0364666930399835. Arrivals time: 0.33663122775033116 Scheduler time: 3.5456348937004805 Scheduler overhead time: 0.021148223895579576 Adapter cache time: 0.1016559824347496 Engine time: 0.021630785893648863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.150044803041965,
    "estimated_duration": 3600.002940469752,
    "input_throughput": 3257.659839152717,
    "output_throughput": 2887.8543078754888,
    "total_throughput": 6145.514147028205,
    "itl": 116.18850473467282,
    "ttft": 2386365.4142354936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2497896644682673,
    "arrivals": 1680953,
    "finished_requests": 47377,
    "scheduler_time": 7.807952711500452
}
#Debug simulation 
Total elapsed time: 4.1501401187852025. Arrivals time: 0.3273211158812046 Scheduler time: 3.4683865695260465 Scheduler overhead time: 0.0443692822009325 Adapter cache time: 0.2423190250992775 Engine time: 0.04659896157681942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.0302135408855975,
    "estimated_duration": 3600.1199138105103,
    "input_throughput": 3259.5208717866185,
    "output_throughput": 2889.8306859418662,
    "total_throughput": 6149.351557728485,
    "itl": 116.54648131150259,
    "ttft": 2385883.8374809357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1974894637078974,
    "arrivals": 1680953,
    "finished_requests": 47407,
    "scheduler_time": 7.949308930552729
}
#Debug simulation 
Total elapsed time: 4.030306212604046. Arrivals time: 0.2046092231757939 Scheduler time: 3.4738076459616423 Scheduler overhead time: 0.044104546308517456 Adapter cache time: 0.23959106160327792 Engine time: 0.04705058876425028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.054372201208025,
    "estimated_duration": 3600.067823155481,
    "input_throughput": 3259.568034947323,
    "output_throughput": 2889.872499924477,
    "total_throughput": 6149.4405348718,
    "itl": 116.54480181273982,
    "ttft": 2385852.077240703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1451892629475295,
    "arrivals": 1680953,
    "finished_requests": 47407,
    "scheduler_time": 7.949518476283052
}
#Debug simulation 
Total elapsed time: 4.054461562074721. Arrivals time: 0.21472963318228722 Scheduler time: 3.4900053087621927 Scheduler overhead time: 0.04410972446203232 Adapter cache time: 0.23787159379571676 Engine time: 0.04662851057946682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.105538250412792,
    "estimated_duration": 3600.2544637157707,
    "input_throughput": 3540.366418112794,
    "output_throughput": 3119.3172908143088,
    "total_throughput": 6659.683708927102,
    "itl": 270.3182873761447,
    "ttft": 2338156.3829637663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1538038794626522,
    "arrivals": 1669342,
    "finished_requests": 51578,
    "scheduler_time": 31.372298095783034
}
#Debug simulation 
Total elapsed time: 4.105633662082255. Arrivals time: 0.21579229645431042 Scheduler time: 3.7435268838889897 Scheduler overhead time: 0.021546856965869665 Adapter cache time: 0.09275028808042407 Engine time: 0.022012225352227688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.505510958842933,
    "estimated_duration": 3600.0554341638504,
    "input_throughput": 3295.4673107014264,
    "output_throughput": 2921.421125961841,
    "total_throughput": 6216.888436663267,
    "itl": 115.46083120220113,
    "ttft": 2384357.0123648187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2226004995615272,
    "arrivals": 1669342,
    "finished_requests": 48017,
    "scheduler_time": 8.090095453075218
}
#Debug simulation 
Total elapsed time: 4.505575329065323. Arrivals time: 0.6634037466719747 Scheduler time: 3.503842956852168 Scheduler overhead time: 0.044639311730861664 Adapter cache time: 0.22609449410811067 Engine time: 0.046351329889148474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.167213486973196,
    "estimated_duration": 3600.005387550763,
    "input_throughput": 3295.5131236821544,
    "output_throughput": 2921.461739021272,
    "total_throughput": 6216.974862703427,
    "itl": 115.45916802569076,
    "ttft": 2384327.8500488764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1723432753933596,
    "arrivals": 1669342,
    "finished_requests": 48017,
    "scheduler_time": 8.090306064153408
}
#Debug simulation 
Total elapsed time: 4.16728052822873. Arrivals time: 0.32737884065136313 Scheduler time: 3.501721733249724 Scheduler overhead time: 0.04464136669412255 Adapter cache time: 0.2258352697826922 Engine time: 0.046442754566669464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.502932740841061,
    "estimated_duration": 3600.0960608329797,
    "input_throughput": 3298.514761645667,
    "output_throughput": 2923.9700336119345,
    "total_throughput": 6222.484795257601,
    "itl": 115.84583410969762,
    "ttft": 2384073.5409033047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.121268860588313,
    "arrivals": 1669342,
    "finished_requests": 48059,
    "scheduler_time": 8.241274231378164
}
#Debug simulation 
Total elapsed time: 4.502998211886734. Arrivals time: 0.6626946213655174 Scheduler time: 3.501592578366399 Scheduler overhead time: 0.04450342897325754 Adapter cache time: 0.22656930470839143 Engine time: 0.04649160895496607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.0263659888878465,
    "estimated_duration": 3600.279993680391,
    "input_throughput": 3584.276507008129,
    "output_throughput": 3157.5880264742527,
    "total_throughput": 6741.864533482381,
    "itl": 267.07556807846146,
    "ttft": 2325897.449579554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.089533636840062,
    "arrivals": 1663594,
    "finished_requests": 52465,
    "scheduler_time": 31.784520912318232
}
#Debug simulation 
Total elapsed time: 4.026435200124979. Arrivals time: 0.2181400111876428 Scheduler time: 3.665056847501546 Scheduler overhead time: 0.021886100992560387 Adapter cache time: 0.08894896181300282 Engine time: 0.02233097516000271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.054881075862795,
    "estimated_duration": 3600.0106908313082,
    "input_throughput": 3315.9254305557197,
    "output_throughput": 2942.032652007004,
    "total_throughput": 6257.958082562724,
    "itl": 115.20927950857191,
    "ttft": 2374100.4275202993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1621121860924228,
    "arrivals": 1663594,
    "finished_requests": 48484,
    "scheduler_time": 8.3278432133291
}
#Debug simulation 
Total elapsed time: 4.054972110781819. Arrivals time: 0.20679430617019534 Scheduler time: 3.520022570155561 Scheduler overhead time: 0.04471847368404269 Adapter cache time: 0.21544722048565745 Engine time: 0.0466790902428329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.085027160122991,
    "estimated_duration": 3600.029505416515,
    "input_throughput": 3316.567539803705,
    "output_throughput": 2942.6853263454927,
    "total_throughput": 6259.252866149198,
    "itl": 115.19281115290347,
    "ttft": 2374135.2114522425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1130807478795768,
    "arrivals": 1663594,
    "finished_requests": 48495,
    "scheduler_time": 8.335245203921845
}
#Debug simulation 
Total elapsed time: 4.085120207164437. Arrivals time: 0.2082783905789256 Scheduler time: 3.545899766497314 Scheduler overhead time: 0.04460841650143266 Adapter cache time: 0.21841063164174557 Engine time: 0.04659410333260894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.552241970784962,
    "estimated_duration": 3600.050960175063,
    "input_throughput": 3315.703341993676,
    "output_throughput": 2941.770024134604,
    "total_throughput": 6257.47336612828,
    "itl": 115.01087911325384,
    "ttft": 2374188.7366609075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0644579049851737,
    "arrivals": 1663594,
    "finished_requests": 48479,
    "scheduler_time": 8.265532568499856
}
#Debug simulation 
Total elapsed time: 4.552309030666947. Arrivals time: 0.6697178855538368 Scheduler time: 3.5493408762849867 Scheduler overhead time: 0.04486206220462918 Adapter cache time: 0.21995574794709682 Engine time: 0.04701153002679348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.054576084017754,
    "estimated_duration": 3600.2446858247686,
    "input_throughput": 3605.6904829584214,
    "output_throughput": 3162.5064387510274,
    "total_throughput": 6768.196921709448,
    "itl": 266.14593758177494,
    "ttft": 2323075.1770056738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9609931515948834,
    "arrivals": 1660646,
    "finished_requests": 52411,
    "scheduler_time": 31.84206163537236
}
#Debug simulation 
Total elapsed time: 4.054647846147418. Arrivals time: 0.2205625087954104 Scheduler time: 3.6954963579773903 Scheduler overhead time: 0.02182910544797778 Adapter cache time: 0.08430750202387571 Engine time: 0.022426852956414223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.169076413847506,
    "estimated_duration": 3600.0813615028424,
    "input_throughput": 3315.1411875363465,
    "output_throughput": 2921.66480248913,
    "total_throughput": 6236.805990025477,
    "itl": 115.29958478737758,
    "ttft": 2377220.77931854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0055147217470277,
    "arrivals": 1660646,
    "finished_requests": 48095,
    "scheduler_time": 8.045764818938949
}
#Debug simulation 
Total elapsed time: 4.169168669264764. Arrivals time: 0.33586349757388234 Scheduler time: 3.5191147858276963 Scheduler overhead time: 0.044887982308864594 Adapter cache time: 0.20104034850373864 Engine time: 0.04694032948464155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.162264897953719,
    "estimated_duration": 3600.054877870483,
    "input_throughput": 3324.533210193632,
    "output_throughput": 2930.170888461525,
    "total_throughput": 6254.704098655157,
    "itl": 114.30888427579532,
    "ttft": 2375838.218445404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9634294039476691,
    "arrivals": 1660646,
    "finished_requests": 48222,
    "scheduler_time": 7.858658486640332
}
#Debug simulation 
Total elapsed time: 4.162384744733572. Arrivals time: 0.33024534210562706 Scheduler time: 3.5097210709936917 Scheduler overhead time: 0.04517062846571207 Adapter cache time: 0.20853182021528482 Engine time: 0.04718527337536216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.49524201778695,
    "estimated_duration": 3600.0126225133386,
    "input_throughput": 3324.5722320951822,
    "output_throughput": 2930.2052815124302,
    "total_throughput": 6254.7775136076125,
    "itl": 114.30733168250876,
    "ttft": 2375812.2629233208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9209354908298714,
    "arrivals": 1660646,
    "finished_requests": 48222,
    "scheduler_time": 7.858897042612554
}
#Debug simulation 
Total elapsed time: 4.495304660871625. Arrivals time: 0.6616772105917335 Scheduler time: 3.511536207050085 Scheduler overhead time: 0.04494789848104119 Adapter cache time: 0.20880458503961563 Engine time: 0.046931416261941195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.041438022162765,
    "estimated_duration": 3600.2102502566454,
    "input_throughput": 3645.523479931316,
    "output_throughput": 3186.793604396333,
    "total_throughput": 6832.317084327649,
    "itl": 264.2547181082471,
    "ttft": 2323411.608768544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9120253476919594,
    "arrivals": 1659330,
    "finished_requests": 53118,
    "scheduler_time": 32.00575937633498
}
#Debug simulation 
Total elapsed time: 4.041505238972604. Arrivals time: 0.222158954013139 Scheduler time: 3.6847681873477995 Scheduler overhead time: 0.022018348332494497 Adapter cache time: 0.08003022707998753 Engine time: 0.02245149901136756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.045842200983316,
    "estimated_duration": 3600.0302727734734,
    "input_throughput": 3333.7702993130324,
    "output_throughput": 2934.075049280744,
    "total_throughput": 6267.845348593777,
    "itl": 115.03604416497748,
    "ttft": 2375513.205642891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9629667100473358,
    "arrivals": 1659330,
    "finished_requests": 48548,
    "scheduler_time": 8.18327998820986
}
#Debug simulation 
Total elapsed time: 4.045936333015561. Arrivals time: 0.20897243358194828 Scheduler time: 3.527939551975578 Scheduler overhead time: 0.04498067731037736 Adapter cache time: 0.19585950346663594 Engine time: 0.046845872420817614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.028152896091342,
    "estimated_duration": 3600.1095272969033,
    "input_throughput": 3333.6969081080447,
    "output_throughput": 2934.010457157095,
    "total_throughput": 6267.70736526514,
    "itl": 115.0347102853297,
    "ttft": 2375456.0718112295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9221071782032987,
    "arrivals": 1659330,
    "finished_requests": 48548,
    "scheduler_time": 8.183756411655706
}
#Debug simulation 
Total elapsed time: 4.028244421817362. Arrivals time: 0.20604058681055903 Scheduler time: 3.512756352312863 Scheduler overhead time: 0.04479435505345464 Adapter cache time: 0.19624545658007264 Engine time: 0.047142538242042065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.483639775309712,
    "estimated_duration": 3600.069705113931,
    "input_throughput": 3333.73378380744,
    "output_throughput": 2934.042911723489,
    "total_throughput": 6267.776695530929,
    "itl": 115.03336882449429,
    "ttft": 2375431.0747124343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.882064836996143,
    "arrivals": 1659330,
    "finished_requests": 48548,
    "scheduler_time": 8.183976569889774
}
#Debug simulation 
Total elapsed time: 4.483730881009251. Arrivals time: 0.6576685216277838 Scheduler time: 3.5160850337706506 Scheduler overhead time: 0.044820275623351336 Adapter cache time: 0.19707662891596556 Engine time: 0.04672449408099055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.478739632293582,
    "estimated_duration": 3600.080661654689,
    "input_throughput": 4061.232615071442,
    "output_throughput": 3561.85547078999,
    "total_throughput": 7623.088085861432,
    "itl": 237.16854540523772,
    "ttft": 2269650.776016995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1542191,
    "finished_requests": 59216,
    "scheduler_time": 35.75964284046868
}
#Debug simulation 
Total elapsed time: 4.478805752936751. Arrivals time: 0.23752284003421664 Scheduler time: 4.106111281085759 Scheduler overhead time: 0.02424642350524664 Adapter cache time: 0.0748602356761694 Engine time: 0.024876270443201065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.2527085822075605,
    "estimated_duration": 3600.1031212573284,
    "input_throughput": 3582.0471152215746,
    "output_throughput": 3155.9612648073035,
    "total_throughput": 6738.0083800288785,
    "itl": 106.97383542251971,
    "ttft": 2337945.4864712083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631696,
    "arrivals": 1542191,
    "finished_requests": 52160,
    "scheduler_time": 8.776300089449064
}
#Debug simulation 
Total elapsed time: 4.252800429239869. Arrivals time: 0.21206707786768675 Scheduler time: 3.7463173186406493 Scheduler overhead time: 0.04765605367720127 Adapter cache time: 0.17418229160830379 Engine time: 0.04976276634261012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.274902040138841,
    "estimated_duration": 3600.0376899102907,
    "input_throughput": 3578.5528124070916,
    "output_throughput": 3152.967823590439,
    "total_throughput": 6731.52063599753,
    "itl": 106.83732771228848,
    "ttft": 2337997.0572445854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 1542191,
    "finished_requests": 52109,
    "scheduler_time": 8.683235533901522
}
#Debug simulation 
Total elapsed time: 4.2749916589818895. Arrivals time: 0.21892362413927913 Scheduler time: 3.763861325569451 Scheduler overhead time: 0.04769898997619748 Adapter cache time: 0.1722012278623879 Engine time: 0.04957283893600106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.251873796805739,
    "estimated_duration": 3600.0352522829426,
    "input_throughput": 3581.5738170406726,
    "output_throughput": 3155.6271547051892,
    "total_throughput": 6737.200971745862,
    "itl": 106.98696798413685,
    "ttft": 2337942.0404426083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 1542191,
    "finished_requests": 52153,
    "scheduler_time": 8.775507057889383
}
#Debug simulation 
Total elapsed time: 4.251966712996364. Arrivals time: 0.2135887141339481 Scheduler time: 3.7457288377918303 Scheduler overhead time: 0.04765273351222277 Adapter cache time: 0.17246419424191117 Engine time: 0.04971830639988184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.70404111687094,
    "estimated_duration": 3600.2414586943346,
    "input_throughput": 4146.481332230955,
    "output_throughput": 3639.704211603695,
    "total_throughput": 7786.185543834649,
    "itl": 231.98533071834413,
    "ttft": 2271192.0657245447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1660458304383836,
    "arrivals": 1530695,
    "finished_requests": 60332,
    "scheduler_time": 36.553117367792936
}
#Debug simulation 
Total elapsed time: 4.704138020053506. Arrivals time: 0.36346520856022835 Scheduler time: 4.216230870690197 Scheduler overhead time: 0.02466457849368453 Adapter cache time: 0.06300095934420824 Engine time: 0.025328618939965963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.280366299208254,
    "estimated_duration": 3600.0419760008735,
    "input_throughput": 3616.277834199576,
    "output_throughput": 3188.0031056607922,
    "total_throughput": 6804.280939860368,
    "itl": 106.19719912619371,
    "ttft": 2338902.871576302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.23959372762824,
    "arrivals": 1530695,
    "finished_requests": 52432,
    "scheduler_time": 9.01098935247945
}
#Debug simulation 
Total elapsed time: 4.280482691247016. Arrivals time: 0.21275464724749327 Scheduler time: 3.7881395728327334 Scheduler overhead time: 0.04782767640426755 Adapter cache time: 0.15884814271703362 Engine time: 0.049917851109057665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.271319326944649,
    "estimated_duration": 3600.1085213462684,
    "input_throughput": 3616.619033231548,
    "output_throughput": 3188.1591712985037,
    "total_throughput": 6804.778204530052,
    "itl": 106.19661104413518,
    "ttft": 2338913.469602255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.188110717504751,
    "arrivals": 1530695,
    "finished_requests": 52436,
    "scheduler_time": 9.011486895553277
}
#Debug simulation 
Total elapsed time: 4.27141106268391. Arrivals time: 0.21364356949925423 Scheduler time: 3.7790961060673 Scheduler overhead time: 0.047873706091195345 Adapter cache time: 0.15796099742874503 Engine time: 0.04992903536185622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.281699272338301,
    "estimated_duration": 3600.0568536687556,
    "input_throughput": 3616.670938607905,
    "output_throughput": 3188.2049274592027,
    "total_throughput": 6804.875866067107,
    "itl": 106.19503530192704,
    "ttft": 2338882.173245139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1362191120628233,
    "arrivals": 1530695,
    "finished_requests": 52436,
    "scheduler_time": 9.011710823479795
}
#Debug simulation 
Total elapsed time: 4.281791307032108. Arrivals time: 0.21446283487603068 Scheduler time: 3.7869667410850525 Scheduler overhead time: 0.048204426653683186 Adapter cache time: 0.15894984593614936 Engine time: 0.05013102013617754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.6116310567595065,
    "estimated_duration": 3600.226123065528,
    "input_throughput": 4229.393232399158,
    "output_throughput": 3698.837113225852,
    "total_throughput": 7928.230345625009,
    "itl": 227.20287635511042,
    "ttft": 2260468.050295584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1262594897672564,
    "arrivals": 1525074,
    "finished_requests": 61000,
    "scheduler_time": 36.98659792620755
}
#Debug simulation 
Total elapsed time: 4.61172154173255. Arrivals time: 0.23772492446005344 Scheduler time: 4.254140235949308 Scheduler overhead time: 0.025213790591806173 Adapter cache time: 0.057090910617262125 Engine time: 0.025822527706623077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.148922980763018,
    "estimated_duration": 3600.025131571545,
    "input_throughput": 3517.2443350339868,
    "output_throughput": 3094.5117305714016,
    "total_throughput": 6611.756065605388,
    "itl": 99.75231576611016,
    "ttft": 2349931.0648623845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1850855147489403,
    "arrivals": 1525074,
    "finished_requests": 50679,
    "scheduler_time": 5.143979464914316
}
#Debug simulation 
Total elapsed time: 4.149017069954425. Arrivals time: 0.20952356234192848 Scheduler time: 3.6762440581806004 Scheduler overhead time: 0.05040905624628067 Adapter cache time: 0.1363570000976324 Engine time: 0.05236667627468705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.290021107997745,
    "estimated_duration": 3600.08963633256,
    "input_throughput": 3640.7229608183125,
    "output_throughput": 3202.8866402744334,
    "total_throughput": 6843.609601092746,
    "itl": 104.79198407990225,
    "ttft": 2338158.213583395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.142442772444338,
    "arrivals": 1525074,
    "finished_requests": 52496,
    "scheduler_time": 8.709463361405378
}
#Debug simulation 
Total elapsed time: 4.290107890032232. Arrivals time: 0.21299180388450623 Scheduler time: 3.8085641297511756 Scheduler overhead time: 0.048393326345831156 Adapter cache time: 0.14653847692534328 Engine time: 0.050390610471367836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.269766187295318,
    "estimated_duration": 3600.0068680451254,
    "input_throughput": 3627.9466897495618,
    "output_throughput": 3191.706133116181,
    "total_throughput": 6819.652822865743,
    "itl": 105.11162806653782,
    "ttft": 2340018.1042931215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0913683576392923,
    "arrivals": 1525074,
    "finished_requests": 52312,
    "scheduler_time": 8.656569570974815
}
#Debug simulation 
Total elapsed time: 4.2698548920452595. Arrivals time: 0.21285726269707084 Scheduler time: 3.7884021662175655 Scheduler overhead time: 0.048305935226380825 Adapter cache time: 0.1468445141799748 Engine time: 0.050288927275687456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.6300066518597305,
    "estimated_duration": 3600.0561734102125,
    "input_throughput": 4205.803262691125,
    "output_throughput": 3696.1720481698117,
    "total_throughput": 7901.9753108609375,
    "itl": 228.69695808610723,
    "ttft": 2260352.104476393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0191424187296063,
    "arrivals": 1522091,
    "finished_requests": 61079,
    "scheduler_time": 37.07503868837133
}
#Debug simulation 
Total elapsed time: 4.630104340147227. Arrivals time: 0.2475697067566216 Scheduler time: 4.266376669984311 Scheduler overhead time: 0.02509200619533658 Adapter cache time: 0.05357179185375571 Engine time: 0.025840274058282375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.395657547283918,
    "estimated_duration": 3600.006578842627,
    "input_throughput": 3622.2336583041124,
    "output_throughput": 3205.9449746090395,
    "total_throughput": 6828.178632913152,
    "itl": 105.6109565706404,
    "ttft": 2335389.0841533095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0592057439894473,
    "arrivals": 1522091,
    "finished_requests": 52662,
    "scheduler_time": 8.964927163568685
}
#Debug simulation 
Total elapsed time: 4.395749012008309. Arrivals time: 0.3307723398320377 Scheduler time: 3.8039489085786045 Scheduler overhead time: 0.04830310819670558 Adapter cache time: 0.139548494014889 Engine time: 0.050079628359526396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.336242514662445,
    "estimated_duration": 3600.0767673660803,
    "input_throughput": 3622.163037801132,
    "output_throughput": 3205.8824702352213,
    "total_throughput": 6828.045508036354,
    "itl": 105.609732703992,
    "ttft": 2335364.274616141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0158946402347677,
    "arrivals": 1522091,
    "finished_requests": 52662,
    "scheduler_time": 8.96535909411407
}
#Debug simulation 
Total elapsed time: 4.336339094676077. Arrivals time: 0.21785643743351102 Scheduler time: 3.8574552815407515 Scheduler overhead time: 0.04837260069325566 Adapter cache time: 0.13921230705454946 Engine time: 0.05025483202189207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.322288389783353,
    "estimated_duration": 3600.032836161046,
    "input_throughput": 3622.2072390610433,
    "output_throughput": 3205.921591622866,
    "total_throughput": 6828.12883068391,
    "itl": 105.60843463493775,
    "ttft": 2335337.8620217657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9717663458432084,
    "arrivals": 1522091,
    "finished_requests": 52662,
    "scheduler_time": 8.965556183469344
}
#Debug simulation 
Total elapsed time: 4.322379895020276. Arrivals time: 0.21411858592182398 Scheduler time: 3.8474161233752966 Scheduler overhead time: 0.04842298710718751 Adapter cache time: 0.1391861652955413 Engine time: 0.050127805676311255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.63492345996201,
    "estimated_duration": 3600.071549053006,
    "input_throughput": 4226.352113474614,
    "output_throughput": 3718.3630429570953,
    "total_throughput": 7944.71515643171,
    "itl": 227.8403537275744,
    "ttft": 2257054.2988586896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9334487618994887,
    "arrivals": 1520700,
    "finished_requests": 61629,
    "scheduler_time": 37.38677485598627
}
#Debug simulation 
Total elapsed time: 4.635016317944974. Arrivals time: 0.2397169810719788 Scheduler time: 4.282583258114755 Scheduler overhead time: 0.02525384398177266 Adapter cache time: 0.04997667018324137 Engine time: 0.02577769197523594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.280879468191415,
    "estimated_duration": 3600.1024739706227,
    "input_throughput": 3646.0953805914114,
    "output_throughput": 3216.1015092523394,
    "total_throughput": 6862.196889843751,
    "itl": 105.02349147962498,
    "ttft": 2333930.048289509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9799599381140488,
    "arrivals": 1520700,
    "finished_requests": 53026,
    "scheduler_time": 8.957258057384664
}
#Debug simulation 
Total elapsed time: 4.280974340159446. Arrivals time: 0.21415785374119878 Scheduler time: 3.810414530336857 Scheduler overhead time: 0.04859551880508661 Adapter cache time: 0.13372007897123694 Engine time: 0.05091837514191866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.289950096979737,
    "estimated_duration": 3600.060967908677,
    "input_throughput": 3646.1374173963645,
    "output_throughput": 3216.1385885434,
    "total_throughput": 6862.276005939765,
    "itl": 105.02233267667283,
    "ttft": 2333905.414156639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9382832156331307,
    "arrivals": 1520700,
    "finished_requests": 53026,
    "scheduler_time": 8.957428717917868
}
#Debug simulation 
Total elapsed time: 4.290046670939773. Arrivals time: 0.21390744112432003 Scheduler time: 3.8200324731878936 Scheduler overhead time: 0.04844496678560972 Adapter cache time: 0.13394965091720223 Engine time: 0.05048430152237415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.718640123028308,
    "estimated_duration": 3600.019898878642,
    "input_throughput": 3646.17901253509,
    "output_throughput": 3216.1752782551243,
    "total_throughput": 6862.354290790214,
    "itl": 105.02106185271974,
    "ttft": 2333879.761889085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8970150884706539,
    "arrivals": 1520700,
    "finished_requests": 53026,
    "scheduler_time": 8.957627815044116
}
#Debug simulation 
Total elapsed time: 4.718705071136355. Arrivals time: 0.21552387718111277 Scheduler time: 4.247031315229833 Scheduler overhead time: 0.04856177978217602 Adapter cache time: 0.13395703164860606 Engine time: 0.05043920176103711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.733723675832152,
    "estimated_duration": 3600.1263218823246,
    "input_throughput": 4316.534646449539,
    "output_throughput": 3819.341259339689,
    "total_throughput": 8135.875905789228,
    "itl": 222.2129421351934,
    "ttft": 2248476.3225029795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1629853426944508,
    "arrivals": 1507762,
    "finished_requests": 62946,
    "scheduler_time": 38.38698585099595
}
#Debug simulation 
Total elapsed time: 4.733788530807942. Arrivals time: 0.24293662747368217 Scheduler time: 4.378804027568549 Scheduler overhead time: 0.0255155093036592 Adapter cache time: 0.048454056959599257 Engine time: 0.026227792259305716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.33302519377321,
    "estimated_duration": 3600.0800976091436,
    "input_throughput": 3675.5110000990308,
    "output_throughput": 3260.026077695953,
    "total_throughput": 6935.537077794984,
    "itl": 104.04041384787168,
    "ttft": 2331396.087587327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.235786486696457,
    "arrivals": 1507762,
    "finished_requests": 53465,
    "scheduler_time": 9.206242154746988
}
#Debug simulation 
Total elapsed time: 4.3331164750270545. Arrivals time: 0.21716829389333725 Scheduler time: 3.858130445703864 Scheduler overhead time: 0.04888322809711099 Adapter cache time: 0.13483648328110576 Engine time: 0.050781162455677986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.325936350040138,
    "estimated_duration": 3600.0292012713367,
    "input_throughput": 3675.5629635801624,
    "output_throughput": 3260.0721671522415,
    "total_throughput": 6935.635130732404,
    "itl": 104.03897833054441,
    "ttft": 2331366.9778008847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1847120718914081,
    "arrivals": 1507762,
    "finished_requests": 53465,
    "scheduler_time": 9.206420231740339
}
#Debug simulation 
Total elapsed time: 4.326026210095733. Arrivals time: 0.21446761209517717 Scheduler time: 3.8528517531231046 Scheduler overhead time: 0.04892801959067583 Adapter cache time: 0.13579819351434708 Engine time: 0.050625698640942574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.7996437670663,
    "estimated_duration": 3600.0303584451694,
    "input_throughput": 3676.827604786323,
    "output_throughput": 3261.524440330308,
    "total_throughput": 6938.352045116631,
    "itl": 104.1019422329653,
    "ttft": 2330936.4921495235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1332290617679213,
    "arrivals": 1507762,
    "finished_requests": 53490,
    "scheduler_time": 9.259170238321952
}
#Debug simulation 
Total elapsed time: 4.7997101987712085. Arrivals time: 0.6564908041618764 Scheduler time: 3.882037597708404 Scheduler overhead time: 0.048777771182358265 Adapter cache time: 0.1382284020073712 Engine time: 0.050823938101530075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.783569249324501,
    "estimated_duration": 3600.117553046755,
    "input_throughput": 4344.360640880684,
    "output_throughput": 3865.498221918552,
    "total_throughput": 8209.858862799236,
    "itl": 219.50835953603675,
    "ttft": 2237122.0759771657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1231990020233236,
    "arrivals": 1502157,
    "finished_requests": 63484,
    "scheduler_time": 38.83177007508343
}
#Debug simulation 
Total elapsed time: 4.7836395050399005. Arrivals time: 0.24547524889931083 Scheduler time: 4.433640029281378 Scheduler overhead time: 0.025983698666095734 Adapter cache time: 0.04004324972629547 Engine time: 0.02646703226491809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.321616819128394,
    "estimated_duration": 3600.041892684706,
    "input_throughput": 3669.1836911234723,
    "output_throughput": 3270.437220167968,
    "total_throughput": 6939.62091129144,
    "itl": 103.32686641648708,
    "ttft": 2324582.1297748447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1680922866822276,
    "arrivals": 1502157,
    "finished_requests": 53500,
    "scheduler_time": 9.15885264635276
}
#Debug simulation 
Total elapsed time: 4.321707648225129. Arrivals time: 0.21334836818277836 Scheduler time: 3.8624946302734315 Scheduler overhead time: 0.049076505936682224 Adapter cache time: 0.12239513313397765 Engine time: 0.05090000480413437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.326963190920651,
    "estimated_duration": 3600.1011450744827,
    "input_throughput": 3669.206632728289,
    "output_throughput": 3270.5422779882483,
    "total_throughput": 6939.7489107165375,
    "itl": 103.32577711026867,
    "ttft": 2324554.433757534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1211038250615832,
    "arrivals": 1502157,
    "finished_requests": 53501,
    "scheduler_time": 9.159221013115602
}
#Debug simulation 
Total elapsed time: 4.327076603192836. Arrivals time: 0.2134881243109703 Scheduler time: 3.867536515928805 Scheduler overhead time: 0.049034975934773684 Adapter cache time: 0.12275991775095463 Engine time: 0.05074281198903918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.347400696948171,
    "estimated_duration": 3600.0506698293448,
    "input_throughput": 3669.2580775887186,
    "output_throughput": 3270.58813329373,
    "total_throughput": 6939.846210882449,
    "itl": 103.3243568178854,
    "ttft": 2324526.14070435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0704380055749778,
    "arrivals": 1502157,
    "finished_requests": 53501,
    "scheduler_time": 9.159411587458921
}
#Debug simulation 
Total elapsed time: 4.347490807063878. Arrivals time: 0.2173782642930746 Scheduler time: 3.8839388503693044 Scheduler overhead time: 0.04897892102599144 Adapter cache time: 0.12253675423562527 Engine time: 0.05119779799133539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.800835469271988,
    "estimated_duration": 3600.0693074158044,
    "input_throughput": 4361.451310855691,
    "output_throughput": 3873.435983933797,
    "total_throughput": 8234.887294789489,
    "itl": 219.74843285154637,
    "ttft": 2237913.3141438127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0619892471446664,
    "arrivals": 1499241,
    "finished_requests": 63609,
    "scheduler_time": 38.93939529287869
}
#Debug simulation 
Total elapsed time: 4.8009634031914175. Arrivals time: 0.24710656981915236 Scheduler time: 4.451395239215344 Scheduler overhead time: 0.026133158709853888 Adapter cache time: 0.037571368739008904 Engine time: 0.0266036968678236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.323324361350387,
    "estimated_duration": 3600.096929047429,
    "input_throughput": 3672.440842724271,
    "output_throughput": 3284.200462660441,
    "total_throughput": 6956.641305384712,
    "itl": 103.87750342437268,
    "ttft": 2324434.1865901276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1067867825762425,
    "arrivals": 1499241,
    "finished_requests": 53644,
    "scheduler_time": 9.47746532221537
}
#Debug simulation 
Total elapsed time: 4.32340590422973. Arrivals time: 0.21366064436733723 Scheduler time: 3.8664525700733066 Scheduler overhead time: 0.04884295677766204 Adapter cache time: 0.12050977349281311 Engine time: 0.05057193525135517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.337114098947495,
    "estimated_duration": 3600.035359808178,
    "input_throughput": 3669.615067531979,
    "output_throughput": 3282.3333159232147,
    "total_throughput": 6951.948383455194,
    "itl": 103.69051082170053,
    "ttft": 2324479.7124399743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0618412975478013,
    "arrivals": 1499241,
    "finished_requests": 53606,
    "scheduler_time": 9.384791223437807
}
#Debug simulation 
Total elapsed time: 4.337207950185984. Arrivals time: 0.21235368214547634 Scheduler time: 3.8787295683287084 Scheduler overhead time: 0.04921045573428273 Adapter cache time: 0.12231665570288897 Engine time: 0.05106450943276286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.338934225961566,
    "estimated_duration": 3600.10024160809,
    "input_throughput": 3669.5492106905986,
    "output_throughput": 3282.2969381324147,
    "total_throughput": 6951.846148823013,
    "itl": 103.6892786622805,
    "ttft": 2324451.01886416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0136270499718385,
    "arrivals": 1499241,
    "finished_requests": 53607,
    "scheduler_time": 9.385217007757507
}
#Debug simulation 
Total elapsed time: 4.339024538174272. Arrivals time: 0.2113028997555375 Scheduler time: 3.881136881187558 Scheduler overhead time: 0.04916540067642927 Adapter cache time: 0.1229011956602335 Engine time: 0.05103684216737747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.830618518870324,
    "estimated_duration": 3600.0326524839925,
    "input_throughput": 4417.867707123725,
    "output_throughput": 3913.325616721651,
    "total_throughput": 8331.193323845377,
    "itl": 216.65625807832345,
    "ttft": 2234007.6697530863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9456907128752197,
    "arrivals": 1497804,
    "finished_requests": 64309,
    "scheduler_time": 39.31210034867135
}
#Debug simulation 
Total elapsed time: 4.830707943998277. Arrivals time: 0.242808751296252 Scheduler time: 4.489133045542985 Scheduler overhead time: 0.026406151242554188 Adapter cache time: 0.03317344933748245 Engine time: 0.026984735392034054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.453849294222891,
    "estimated_duration": 3600.0261241674752,
    "input_throughput": 3700.8367552002246,
    "output_throughput": 3293.306101422183,
    "total_throughput": 6994.142856622408,
    "itl": 102.70553645887699,
    "ttft": 2321820.747449146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9945015942701192,
    "arrivals": 1497804,
    "finished_requests": 53798,
    "scheduler_time": 9.19010551368989
}
#Debug simulation 
Total elapsed time: 4.453940666280687. Arrivals time: 0.319873655680567 Scheduler time: 3.8941875686869025 Scheduler overhead time: 0.04958474729210138 Adapter cache time: 0.11526490561664104 Engine time: 0.05140266474336386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.344154718331993,
    "estimated_duration": 3600.0708086152617,
    "input_throughput": 3698.508087156615,
    "output_throughput": 3291.413594322537,
    "total_throughput": 6989.921681479152,
    "itl": 102.60781449461808,
    "ttft": 2321613.303087654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9532334671076418,
    "arrivals": 1497804,
    "finished_requests": 53764,
    "scheduler_time": 9.123552912942843
}
#Debug simulation 
Total elapsed time: 4.344274279195815. Arrivals time: 0.21254965662956238 Scheduler time: 3.8913113796152174 Scheduler overhead time: 0.04981096461415291 Adapter cache time: 0.11558064119890332 Engine time: 0.051371349953114986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.353629750665277,
    "estimated_duration": 3600.0340251097477,
    "input_throughput": 3695.2500746418514,
    "output_throughput": 3288.4964190412325,
    "total_throughput": 6983.746493683084,
    "itl": 102.34504595728063,
    "ttft": 2322320.505841241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9119653399451648,
    "arrivals": 1497804,
    "finished_requests": 53715,
    "scheduler_time": 8.974854474114169
}
#Debug simulation 
Total elapsed time: 4.35372150503099. Arrivals time: 0.21748247183859348 Scheduler time: 3.8971937517635524 Scheduler overhead time: 0.04968490032479167 Adapter cache time: 0.11363566620275378 Engine time: 0.052012473810464144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.887769998982549,
    "estimated_duration": 3600.238321291632,
    "input_throughput": 4512.58848724531,
    "output_throughput": 3965.0891763405716,
    "total_throughput": 8477.677663585882,
    "itl": 213.24857275238264,
    "ttft": 2223578.306117951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1017755878157935,
    "arrivals": 1490652,
    "finished_requests": 65678,
    "scheduler_time": 39.75873963297662
}
#Debug simulation 
Total elapsed time: 4.887884873896837. Arrivals time: 0.2505888449959457 Scheduler time: 4.5413390239700675 Scheduler overhead time: 0.026722722686827183 Adapter cache time: 0.029664800968021154 Engine time: 0.027208078186959028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.369651652406901,
    "estimated_duration": 3600.047458919375,
    "input_throughput": 3758.0979568700172,
    "output_throughput": 3312.1724466319165,
    "total_throughput": 7070.270403501933,
    "itl": 101.79685260609837,
    "ttft": 2317317.8053776436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1263614656194163,
    "arrivals": 1490652,
    "finished_requests": 54640,
    "scheduler_time": 9.206351512452901
}
#Debug simulation 
Total elapsed time: 4.369743753224611. Arrivals time: 0.21624089078977704 Scheduler time: 3.9146935832686722 Scheduler overhead time: 0.049836351070553064 Adapter cache time: 0.1136500439606607 Engine time: 0.0514477682299912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.468917842954397,
    "estimated_duration": 3600.0006349310815,
    "input_throughput": 3758.146837176601,
    "output_throughput": 3312.2155269365035,
    "total_throughput": 7070.362364113104,
    "itl": 101.79556241354982,
    "ttft": 2317293.288464421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0793730039987728,
    "arrivals": 1490652,
    "finished_requests": 54640,
    "scheduler_time": 9.206515985773496
}
#Debug simulation 
Total elapsed time: 4.469009121879935. Arrivals time: 0.3233852004632354 Scheduler time: 3.906087134499103 Scheduler overhead time: 0.04966508550569415 Adapter cache time: 0.11435704538598657 Engine time: 0.05172565532848239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.371586457826197,
    "estimated_duration": 3600.041545178773,
    "input_throughput": 3760.50299145304,
    "output_throughput": 3315.0397989108096,
    "total_throughput": 7075.542790363849,
    "itl": 102.00164112263383,
    "ttft": 2317232.4934603637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.031567351741251,
    "arrivals": 1490652,
    "finished_requests": 54684,
    "scheduler_time": 9.330888533421385
}
#Debug simulation 
Total elapsed time: 4.371677658054978. Arrivals time: 0.21706218970939517 Scheduler time: 3.9158224924467504 Scheduler overhead time: 0.049515862949192524 Adapter cache time: 0.11380199063569307 Engine time: 0.05169522622600198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.894785321783274,
    "estimated_duration": 3600.1175694711296,
    "input_throughput": 4516.085846159858,
    "output_throughput": 3976.412915343486,
    "total_throughput": 8492.498761503344,
    "itl": 212.49347086500254,
    "ttft": 2221896.1843835292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0069004677538749,
    "arrivals": 1487737,
    "finished_requests": 65631,
    "scheduler_time": 39.91746949878309
}
#Debug simulation 
Total elapsed time: 4.894911854062229. Arrivals time: 0.2463231743313372 Scheduler time: 4.555588401854038 Scheduler overhead time: 0.026853775139898062 Adapter cache time: 0.026500731706619263 Engine time: 0.02719819825142622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.473149188794196,
    "estimated_duration": 3600.099671788138,
    "input_throughput": 3761.1578107432038,
    "output_throughput": 3317.455650906446,
    "total_throughput": 7078.61346164965,
    "itl": 101.82156851810913,
    "ttft": 2315178.402207567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0404482515831528,
    "arrivals": 1487737,
    "finished_requests": 54572,
    "scheduler_time": 9.284761155405429
}
#Debug simulation 
Total elapsed time: 4.473240579944104. Arrivals time: 0.2137741232290864 Scheduler time: 4.02835246315226 Scheduler overhead time: 0.04991353861987591 Adapter cache time: 0.10606366069987416 Engine time: 0.05133597971871495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.47939517814666,
    "estimated_duration": 3600.0581638823232,
    "input_throughput": 3761.201176093722,
    "output_throughput": 3317.493900465324,
    "total_throughput": 7078.695076559045,
    "itl": 101.82040593552608,
    "ttft": 2315154.571226278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9987715291022358,
    "arrivals": 1487737,
    "finished_requests": 54572,
    "scheduler_time": 9.284929972067326
}
#Debug simulation 
Total elapsed time: 4.47949011111632. Arrivals time: 0.3236737875267863 Scheduler time: 3.9245736803859472 Scheduler overhead time: 0.049610578920692205 Adapter cache time: 0.10640611499547958 Engine time: 0.05141653912141919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.793334700167179,
    "estimated_duration": 3600.0134138886324,
    "input_throughput": 3761.247929733098,
    "output_throughput": 3317.535138598088,
    "total_throughput": 7078.783068331186,
    "itl": 101.81914073612926,
    "ttft": 2315129.417638226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 319,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9538260440737953,
    "arrivals": 1487737,
    "finished_requests": 54572,
    "scheduler_time": 9.285125463400796
}
#Debug simulation 
Total elapsed time: 4.793398081790656. Arrivals time: 0.6430618576705456 Scheduler time: 3.918803201057017 Scheduler overhead time: 0.04993024002760649 Adapter cache time: 0.10630470747128129 Engine time: 0.0514777353964746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.959258411079645,
    "estimated_duration": 3600.1932069017835,
    "input_throughput": 4565.06749929223,
    "output_throughput": 4023.634890546914,
    "total_throughput": 8588.702389839144,
    "itl": 210.1216690096696,
    "ttft": 2224652.930673406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9028438844601612,
    "arrivals": 1486263,
    "finished_requests": 66437,
    "scheduler_time": 40.315066525500335
}
#Debug simulation 
Total elapsed time: 4.959354512859136. Arrivals time: 0.24973850138485432 Scheduler time: 4.619189660064876 Scheduler overhead time: 0.027204192709177732 Adapter cache time: 0.02307622181251645 Engine time: 0.0274995150975883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.362382214982063,
    "estimated_duration": 3600.0658245486366,
    "input_throughput": 3748.535348431289,
    "output_throughput": 3326.896391262968,
    "total_throughput": 7075.431739694257,
    "itl": 101.32503710298009,
    "ttft": 2317870.6419979087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9493721275939657,
    "arrivals": 1486263,
    "finished_requests": 54604,
    "scheduler_time": 9.208624042895956
}
#Debug simulation 
Total elapsed time: 4.362466946709901. Arrivals time: 0.21655758656561375 Scheduler time: 3.922345775179565 Scheduler overhead time: 0.04995372937992215 Adapter cache time: 0.09807463129982352 Engine time: 0.0516856387257576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.4716550703160465,
    "estimated_duration": 3600.027991624143,
    "input_throughput": 3748.5747420290973,
    "output_throughput": 3326.9313538299984,
    "total_throughput": 7075.506095859096,
    "itl": 101.32394920133471,
    "ttft": 2317849.627564107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9113727629790115,
    "arrivals": 1486263,
    "finished_requests": 54604,
    "scheduler_time": 9.20879048301261
}
#Debug simulation 
Total elapsed time: 4.471747813280672. Arrivals time: 0.3260097927413881 Scheduler time: 3.9225676525384188 Scheduler overhead time: 0.04993869969621301 Adapter cache time: 0.09759917575865984 Engine time: 0.051728556863963604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.437317450996488,
    "estimated_duration": 3600.0964090409966,
    "input_throughput": 3748.572389925217,
    "output_throughput": 3326.9761803936194,
    "total_throughput": 7075.548570318836,
    "itl": 101.32303475395544,
    "ttft": 2317824.6068034302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8701046358165343,
    "arrivals": 1486263,
    "finished_requests": 54605,
    "scheduler_time": 9.209226159844784
}
#Debug simulation 
Total elapsed time: 4.437408175319433. Arrivals time: 0.22309248615056276 Scheduler time: 3.9874859135597944 Scheduler overhead time: 0.050149509217590094 Adapter cache time: 0.10083896946161985 Engine time: 0.051919770892709494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.959835640154779,
    "estimated_duration": 3600.102904370835,
    "input_throughput": 4591.096543360767,
    "output_throughput": 4040.75116362328,
    "total_throughput": 8631.847706984046,
    "itl": 208.62662127106745,
    "ttft": 2221244.8229926894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9701746148266817,
    "arrivals": 1482016,
    "finished_requests": 66829,
    "scheduler_time": 40.49931261377404
}
#Debug simulation 
Total elapsed time: 4.959954951424152. Arrivals time: 0.24937315843999386 Scheduler time: 4.624779475387186 Scheduler overhead time: 0.027200777549296618 Adapter cache time: 0.01835771184414625 Engine time: 0.027608624193817377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.799631561152637,
    "estimated_duration": 3600.0894556279477,
    "input_throughput": 3752.5548091258725,
    "output_throughput": 3323.0538150372977,
    "total_throughput": 7075.60862416317,
    "itl": 100.61627308085681,
    "ttft": 2317715.874822341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9693554059555806,
    "arrivals": 1482016,
    "finished_requests": 54682,
    "scheduler_time": 8.922633167431316
}
#Debug simulation 
Total elapsed time: 4.799696673173457. Arrivals time: 0.21857774397358298 Scheduler time: 4.359432214405388 Scheduler overhead time: 0.050346811302006245 Adapter cache time: 0.09565630089491606 Engine time: 0.05159446829929948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.37714031431824,
    "estimated_duration": 3600.051212714988,
    "input_throughput": 3752.594672066276,
    "output_throughput": 3323.0891154400697,
    "total_throughput": 7075.683787506346,
    "itl": 100.61526166656674,
    "ttft": 2317694.6609530076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.930947446022186,
    "arrivals": 1482016,
    "finished_requests": 54682,
    "scheduler_time": 8.92279821440076
}
#Debug simulation 
Total elapsed time: 4.377207402139902. Arrivals time: 0.21383985690772533 Scheduler time: 3.9408676773309708 Scheduler overhead time: 0.0505072339437902 Adapter cache time: 0.09574063122272491 Engine time: 0.052179081831127405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.818016293924302,
    "estimated_duration": 3600.0812436852134,
    "input_throughput": 3760.6856855655487,
    "output_throughput": 3330.336508663621,
    "total_throughput": 7091.02219422917,
    "itl": 100.88771852573859,
    "ttft": 2317544.648251667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8880449375859474,
    "arrivals": 1482016,
    "finished_requests": 54805,
    "scheduler_time": 9.127585905854518
}
#Debug simulation 
Total elapsed time: 4.8180821649730206. Arrivals time: 0.648821510374546 Scheduler time: 3.9490237291902304 Scheduler overhead time: 0.04993820749223232 Adapter cache time: 0.09442122653126717 Engine time: 0.051890353206545115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.995514248032123,
    "estimated_duration": 3600.0945463256758,
    "input_throughput": 4631.708358053651,
    "output_throughput": 4068.8389739514573,
    "total_throughput": 8700.547332005108,
    "itl": 208.09191568972776,
    "ttft": 2221585.2395221666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9059043722040939,
    "arrivals": 1480643,
    "finished_requests": 67333,
    "scheduler_time": 40.75541900160158
}
#Debug simulation 
Total elapsed time: 4.99558588815853. Arrivals time: 0.25166700268164277 Scheduler time: 4.65849254000932 Scheduler overhead time: 0.02741574589163065 Adapter cache time: 0.01740709552541375 Engine time: 0.027932041324675083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.377996527124196,
    "estimated_duration": 3600.016984886724,
    "input_throughput": 3778.1918966218373,
    "output_throughput": 3342.419230385552,
    "total_throughput": 7120.61112700739,
    "itl": 101.24921995838912,
    "ttft": 2320410.525201613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9390463076881181,
    "arrivals": 1480643,
    "finished_requests": 54940,
    "scheduler_time": 9.359309124682245
}
#Debug simulation 
Total elapsed time: 4.3780614151619375. Arrivals time: 0.2157729919999838 Scheduler time: 3.9469996420666575 Scheduler overhead time: 0.05030694464221597 Adapter cache time: 0.0893378066830337 Engine time: 0.05176370544359088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.381041046697646,
    "estimated_duration": 3600.094171620272,
    "input_throughput": 3778.310052894564,
    "output_throughput": 3342.456732064959,
    "total_throughput": 7120.766784959523,
    "itl": 101.24769576528044,
    "ttft": 2320430.804533753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8977781805256407,
    "arrivals": 1480643,
    "finished_requests": 54943,
    "scheduler_time": 9.359870928100213
}
#Debug simulation 
Total elapsed time: 4.38110514357686. Arrivals time: 0.21525175916031003 Scheduler time: 3.950455404818058 Scheduler overhead time: 0.05015223054215312 Adapter cache time: 0.08953021466732025 Engine time: 0.05185955623164773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.384032282046974,
    "estimated_duration": 3600.0791409948915,
    "input_throughput": 3778.9644247210467,
    "output_throughput": 3342.797068809515,
    "total_throughput": 7121.761493530562,
    "itl": 101.28684921059893,
    "ttft": 2320526.847060371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8581444346369256,
    "arrivals": 1480643,
    "finished_requests": 54951,
    "scheduler_time": 9.385156590885611
}
#Debug simulation 
Total elapsed time: 4.384099722839892. Arrivals time: 0.22077505057677627 Scheduler time: 3.9461315628141165 Scheduler overhead time: 0.050249235704541206 Adapter cache time: 0.09113025525584817 Engine time: 0.05194417666643858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.025149787776172,
    "estimated_duration": 3600.0996903524856,
    "input_throughput": 4654.926652422562,
    "output_throughput": 4105.891856164886,
    "total_throughput": 8760.818508587448,
    "itl": 206.47385938214737,
    "ttft": 2217711.7879506336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8232712031179097,
    "arrivals": 1477777,
    "finished_requests": 67817,
    "scheduler_time": 41.19922097795414
}
#Debug simulation 
Total elapsed time: 5.025216781999916. Arrivals time: 0.2526378119364381 Scheduler time: 4.6916964133270085 Scheduler overhead time: 0.027467066887766123 Adapter cache time: 0.012836729176342487 Engine time: 0.027928097173571587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.809134297072887,
    "estimated_duration": 3600.0160375931487,
    "input_throughput": 3785.081471223147,
    "output_throughput": 3362.330298976287,
    "total_throughput": 7147.411770199435,
    "itl": 100.8550526801003,
    "ttft": 2314757.788583262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7998506667278744,
    "arrivals": 1477777,
    "finished_requests": 55135,
    "scheduler_time": 9.538755099168764
}
#Debug simulation 
Total elapsed time: 4.809250690974295. Arrivals time: 0.6401327946223319 Scheduler time: 3.962118296418339 Scheduler overhead time: 0.05004841275513172 Adapter cache time: 0.08103642286732793 Engine time: 0.0518750031478703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.378202906809747,
    "estimated_duration": 3600.088300108195,
    "input_throughput": 3785.1068818480007,
    "output_throughput": 3362.315585325008,
    "total_throughput": 7147.422467173009,
    "itl": 100.85427433386941,
    "ttft": 2314753.0375027177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7663458506157643,
    "arrivals": 1477777,
    "finished_requests": 55137,
    "scheduler_time": 9.539119450389649
}
#Debug simulation 
Total elapsed time: 4.378270528744906. Arrivals time: 0.2150328354910016 Scheduler time: 3.956108897458762 Scheduler overhead time: 0.05026764236390591 Adapter cache time: 0.08098094584420323 Engine time: 0.05191981792449951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.806220056023449,
    "estimated_duration": 3600.051715300987,
    "input_throughput": 3785.145347241413,
    "output_throughput": 3362.349754186233,
    "total_throughput": 7147.495101427647,
    "itl": 100.85332925214831,
    "ttft": 2314733.264668348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 244,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7295722719561318,
    "arrivals": 1477777,
    "finished_requests": 55137,
    "scheduler_time": 9.53930822183658
}
#Debug simulation 
Total elapsed time: 4.806282201781869. Arrivals time: 0.640720043797046 Scheduler time: 3.9585584281012416 Scheduler overhead time: 0.05005383212119341 Adapter cache time: 0.0810373998247087 Engine time: 0.052051210310310125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.1542065320536494,
    "estimated_duration": 3600.3493189621818,
    "input_throughput": 2568.96322567559,
    "output_throughput": 2258.668334533741,
    "total_throughput": 4827.631560209331,
    "itl": 370.4503890568808,
    "ttft": 2457894.689221847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1289312,
    "finished_requests": 37598,
    "scheduler_time": 22.880299230633426
}
#Debug simulation 
Total elapsed time: 3.1542973197065294. Arrivals time: 0.18618510058149695 Scheduler time: 2.7867251308634877 Scheduler overhead time: 0.016332293394953012 Adapter cache time: 0.14078442519530654 Engine time: 0.01685854373499751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.529967409092933,
    "estimated_duration": 3600.106882389639,
    "input_throughput": 2639.147200455724,
    "output_throughput": 2343.554865348817,
    "total_throughput": 4982.702065804541,
    "itl": 144.30370296152012,
    "ttft": 2465836.32915244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631692,
    "arrivals": 1289312,
    "finished_requests": 38574,
    "scheduler_time": 6.654176302299535
}
#Debug simulation 
Total elapsed time: 3.530061034951359. Arrivals time: 0.18672637455165386 Scheduler time: 2.898872333113104 Scheduler overhead time: 0.036417022347450256 Adapter cache time: 0.3521995823830366 Engine time: 0.0385488192550838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.519467373844236,
    "estimated_duration": 3600.0548452478515,
    "input_throughput": 2639.1853481181824,
    "output_throughput": 2343.588740359631,
    "total_throughput": 4982.774088477814,
    "itl": 144.30120706281323,
    "ttft": 2465805.581278923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027997,
    "arrivals": 1289312,
    "finished_requests": 38574,
    "scheduler_time": 6.654439361272683
}
#Debug simulation 
Total elapsed time: 3.5195594360120595. Arrivals time: 0.18581138225272298 Scheduler time: 2.890189934987575 Scheduler overhead time: 0.03636897774413228 Adapter cache time: 0.3515350418165326 Engine time: 0.03835624875500798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.526752178091556,
    "estimated_duration": 3600.021736384629,
    "input_throughput": 2635.004367925433,
    "output_throughput": 2339.8197613271404,
    "total_throughput": 4974.824129252574,
    "itl": 144.2073515266915,
    "ttft": 2466294.1861159946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 1289312,
    "finished_requests": 38512,
    "scheduler_time": 6.5896857484253575
}
#Debug simulation 
Total elapsed time: 3.526841637212783. Arrivals time: 0.18631453858688474 Scheduler time: 2.892127452418208 Scheduler overhead time: 0.03650919208303094 Adapter cache time: 0.35593020264059305 Engine time: 0.038575093261897564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.3572505223564804,
    "estimated_duration": 3600.0602333150564,
    "input_throughput": 2896.698200629072,
    "output_throughput": 2545.282413667353,
    "total_throughput": 5441.980614296424,
    "itl": 329.6335781081621,
    "ttft": 2401784.0633489178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1150725,
    "finished_requests": 42381,
    "scheduler_time": 25.72567879419537
}
#Debug simulation 
Total elapsed time: 3.35733763827011. Arrivals time: 0.19684359896928072 Scheduler time: 3.013818471226841 Scheduler overhead time: 0.017726770136505365 Adapter cache time: 0.10239152936264873 Engine time: 0.018380674067884684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7111225011758506,
    "estimated_duration": 3600.1063331729088,
    "input_throughput": 2809.9822793523385,
    "output_throughput": 2493.899115498371,
    "total_throughput": 5303.8813948507095,
    "itl": 135.98019378180976,
    "ttft": 2432894.4407979334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631692,
    "arrivals": 1150725,
    "finished_requests": 41135,
    "scheduler_time": 7.150300463498499
}
#Debug simulation 
Total elapsed time: 3.711219046730548. Arrivals time: 0.19917145743966103 Scheduler time: 3.09340112330392 Scheduler overhead time: 0.03870842605829239 Adapter cache time: 0.3206306700594723 Engine time: 0.04081373242661357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.6720876512117684,
    "estimated_duration": 3600.0698646030523,
    "input_throughput": 2811.460160681077,
    "output_throughput": 2495.365183972764,
    "total_throughput": 5306.825344653841,
    "itl": 136.18342377765717,
    "ttft": 2432496.598999787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.200479514002799,
    "arrivals": 1150725,
    "finished_requests": 41156,
    "scheduler_time": 7.214707007512744
}
#Debug simulation 
Total elapsed time: 3.672175563406199. Arrivals time: 0.19320237915962934 Scheduler time: 3.0617761318571866 Scheduler overhead time: 0.038592747412621975 Adapter cache time: 0.31984103051945567 Engine time: 0.04043571650981903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6757684578187764,
    "estimated_duration": 3600.0178314358322,
    "input_throughput": 2811.50079636221,
    "output_throughput": 2495.401250947977,
    "total_throughput": 5306.902047310187,
    "itl": 136.1812880946054,
    "ttft": 2432465.394727652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 1150725,
    "finished_requests": 41156,
    "scheduler_time": 7.2149740410529315
}
#Debug simulation 
Total elapsed time: 3.675863384734839. Arrivals time: 0.19314521318301558 Scheduler time: 3.0666170646436512 Scheduler overhead time: 0.03854227950796485 Adapter cache time: 0.3186157727614045 Engine time: 0.04063962958753109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.854233972262591,
    "estimated_duration": 3600.3380656369745,
    "input_throughput": 3014.8285527958137,
    "output_throughput": 2635.2705848808673,
    "total_throughput": 5650.0991376766815,
    "itl": 317.53230712924244,
    "ttft": 2395657.154031165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1127715,
    "finished_requests": 43889,
    "scheduler_time": 26.583332148121983
}
#Debug simulation 
Total elapsed time: 3.854301759041846. Arrivals time: 0.5798836299218237 Scheduler time: 3.138006053864956 Scheduler overhead time: 0.018582137301564217 Adapter cache time: 0.09025807399302721 Engine time: 0.019099552650004625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.737620001193136,
    "estimated_duration": 3600.0518943209836,
    "input_throughput": 2867.5125534397575,
    "output_throughput": 2536.5673240447472,
    "total_throughput": 5404.079877484504,
    "itl": 133.3975335145428,
    "ttft": 2431144.428215485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.25277971476317,
    "arrivals": 1127715,
    "finished_requests": 41800,
    "scheduler_time": 7.22855363867968
}
#Debug simulation 
Total elapsed time: 3.7377255554310977. Arrivals time: 0.20572059834375978 Scheduler time: 3.1274993089027703 Scheduler overhead time: 0.03925687214359641 Adapter cache time: 0.30503438180312514 Engine time: 0.04148890357464552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7889920598827302,
    "estimated_duration": 3600.1434398890765,
    "input_throughput": 2867.439637437909,
    "output_throughput": 2536.5028234212127,
    "total_throughput": 5403.942460859122,
    "itl": 133.39524958517922,
    "ttft": 2431096.691509416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140028002,
    "arrivals": 1127715,
    "finished_requests": 41800,
    "scheduler_time": 7.229080537364002
}
#Debug simulation 
Total elapsed time: 3.789082694798708. Arrivals time: 0.27450534142553806 Scheduler time: 3.1101113143377006 Scheduler overhead time: 0.03906337637454271 Adapter cache time: 0.30549809942021966 Engine time: 0.04129308555275202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.725026131607592,
    "estimated_duration": 3600.0342298739965,
    "input_throughput": 2862.8119461966126,
    "output_throughput": 2532.234256094579,
    "total_throughput": 5395.046202291192,
    "itl": 133.5665127760785,
    "ttft": 2431600.221368484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 1127715,
    "finished_requests": 41731,
    "scheduler_time": 7.20174375571656
}
#Debug simulation 
Total elapsed time: 3.725117975845933. Arrivals time: 0.19236273923888803 Scheduler time: 3.1307301465421915 Scheduler overhead time: 0.03903230559080839 Adapter cache time: 0.30287146009504795 Engine time: 0.04149714205414057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5328109632246196,
    "estimated_duration": 3600.28049276745,
    "input_throughput": 3061.746167317861,
    "output_throughput": 2703.9901528663513,
    "total_throughput": 5765.736320184212,
    "itl": 311.4081344312998,
    "ttft": 2380854.285043583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1691063181823165,
    "arrivals": 1116080,
    "finished_requests": 44829,
    "scheduler_time": 27.318003610576618
}
#Debug simulation 
Total elapsed time: 3.532927374355495. Arrivals time: 0.2040560538880527 Scheduler time: 3.2060276377014816 Scheduler overhead time: 0.018904922995716333 Adapter cache time: 0.07583541376516223 Engine time: 0.019437007140368223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.757354207802564,
    "estimated_duration": 3600.009741376752,
    "input_throughput": 2873.6825017711344,
    "output_throughput": 2560.9005703618664,
    "total_throughput": 5434.583072133001,
    "itl": 131.4592588491818,
    "ttft": 2424638.6813721345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2463910188549252,
    "arrivals": 1116080,
    "finished_requests": 42038,
    "scheduler_time": 7.138462329649135
}
#Debug simulation 
Total elapsed time: 3.7574453051202. Arrivals time: 0.20448883343487978 Scheduler time: 3.1574821383692324 Scheduler overhead time: 0.03998394077643752 Adapter cache time: 0.2946318816393614 Engine time: 0.04188994225114584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.106402100995183,
    "estimated_duration": 3600.1099500218315,
    "input_throughput": 2873.7144541758403,
    "output_throughput": 2560.9112299317667,
    "total_throughput": 5434.625684107607,
    "itl": 131.45756930986772,
    "ttft": 2424590.085053487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1940908180945549,
    "arrivals": 1116080,
    "finished_requests": 42039,
    "scheduler_time": 7.139065383112637
}
#Debug simulation 
Total elapsed time: 4.10647297790274. Arrivals time: 0.5721935746259987 Scheduler time: 3.137457144446671 Scheduler overhead time: 0.0397241348400712 Adapter cache time: 0.29635319532826543 Engine time: 0.04187218006700277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7425725501962006,
    "estimated_duration": 3600.058308240467,
    "input_throughput": 2873.755676767488,
    "output_throughput": 2560.9479654528354,
    "total_throughput": 5434.703642220323,
    "itl": 131.45561240389785,
    "ttft": 2424561.0074977838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1421992126526275,
    "arrivals": 1116080,
    "finished_requests": 42039,
    "scheduler_time": 7.13931520718729
}
#Debug simulation 
Total elapsed time: 3.742660982068628. Arrivals time: 0.20013285148888826 Scheduler time: 3.146335213445127 Scheduler overhead time: 0.039866541512310505 Adapter cache time: 0.2954880427569151 Engine time: 0.04189526615664363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.915005635935813,
    "estimated_duration": 3600.316403245069,
    "input_throughput": 3107.7951898658102,
    "output_throughput": 2719.8004017574845,
    "total_throughput": 5827.595591623294,
    "itl": 308.2694005935346,
    "ttft": 2375448.8066364503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 373,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1415619284869207,
    "arrivals": 1110230,
    "finished_requests": 45193,
    "scheduler_time": 27.43774144829692
}
#Debug simulation 
Total elapsed time: 3.9150701337493956. Arrivals time: 0.5816616318188608 Scheduler time: 3.218637331854552 Scheduler overhead time: 0.01891927933320403 Adapter cache time: 0.0676371706649661 Engine time: 0.0195595882833004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7141383457928896,
    "estimated_duration": 3600.065636158293,
    "input_throughput": 2908.7125231345562,
    "output_throughput": 2558.3830771009384,
    "total_throughput": 5467.095600235495,
    "itl": 132.0028768402771,
    "ttft": 2422968.823339156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2144475393137022,
    "arrivals": 1110230,
    "finished_requests": 42207,
    "scheduler_time": 7.27472832659876
}
#Debug simulation 
Total elapsed time: 3.714228526689112. Arrivals time: 0.19568459130823612 Scheduler time: 3.135336714796722 Scheduler overhead time: 0.03957292577251792 Adapter cache time: 0.28309962851926684 Engine time: 0.0416362714022398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.709261141717434,
    "estimated_duration": 3600.015196028658,
    "input_throughput": 2908.7532773616217,
    "output_throughput": 2558.418922831314,
    "total_throughput": 5467.172200192936,
    "itl": 132.00094712270578,
    "ttft": 2422941.4118092423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.163781719827094,
    "arrivals": 1110230,
    "finished_requests": 42207,
    "scheduler_time": 7.274954016446751
}
#Debug simulation 
Total elapsed time: 3.7093797335401177. Arrivals time: 0.19233490200713277 Scheduler time: 3.136678444687277 Scheduler overhead time: 0.039585047867149115 Adapter cache time: 0.2799021992832422 Engine time: 0.042021299712359905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.075094647239894,
    "estimated_duration": 3600.1112271387824,
    "input_throughput": 2908.67568786822,
    "output_throughput": 2558.3506783261246,
    "total_throughput": 5467.0263661943445,
    "itl": 131.99883559603916,
    "ttft": 2422913.325583681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1122987097036068,
    "arrivals": 1110230,
    "finished_requests": 42207,
    "scheduler_time": 7.275493131505033
}
#Debug simulation 
Total elapsed time: 4.075156670995057. Arrivals time: 0.5716059482656419 Scheduler time: 3.124191134236753 Scheduler overhead time: 0.03944934345781803 Adapter cache time: 0.27956561418250203 Engine time: 0.04158036783337593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5815115817822516,
    "estimated_duration": 3600.187419665023,
    "input_throughput": 3133.2741007826685,
    "output_throughput": 2748.7180100531427,
    "total_throughput": 5881.992110835811,
    "itl": 306.3774571477931,
    "ttft": 2367668.5192169873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0069004677538749,
    "arrivals": 1107373,
    "finished_requests": 45755,
    "scheduler_time": 27.775307465352014
}
#Debug simulation 
Total elapsed time: 3.5816075978800654. Arrivals time: 0.20566483587026596 Scheduler time: 3.2670201496221125 Scheduler overhead time: 0.019173980690538883 Adapter cache time: 0.06129912938922644 Engine time: 0.01965828239917755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7059969450347126,
    "estimated_duration": 3600.0836964181512,
    "input_throughput": 2908.2315531766235,
    "output_throughput": 2568.321122422609,
    "total_throughput": 5476.552675599232,
    "itl": 131.31237696230068,
    "ttft": 2419092.308975793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0608401252632085,
    "arrivals": 1107373,
    "finished_requests": 42467,
    "scheduler_time": 7.234170893433334
}
#Debug simulation 
Total elapsed time: 3.70608913525939. Arrivals time: 0.19492807565256953 Scheduler time: 3.1446708948351443 Scheduler overhead time: 0.039711656514555216 Adapter cache time: 0.26585951168090105 Engine time: 0.04198167333379388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.109967016149312,
    "estimated_duration": 3600.1409745638302,
    "input_throughput": 2918.801534229668,
    "output_throughput": 2576.6863202138557,
    "total_throughput": 5495.487854443524,
    "itl": 131.54498574044618,
    "ttft": 2419067.518210907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0201104764849909,
    "arrivals": 1107373,
    "finished_requests": 42606,
    "scheduler_time": 7.395948121531524
}
#Debug simulation 
Total elapsed time: 4.110051390249282. Arrivals time: 0.5774485971778631 Scheduler time: 3.162967559415847 Scheduler overhead time: 0.039664680138230324 Adapter cache time: 0.26950021740049124 Engine time: 0.04162685573101044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.717449457384646,
    "estimated_duration": 3600.095875347475,
    "input_throughput": 2918.8380987175174,
    "output_throughput": 2576.718598946939,
    "total_throughput": 5495.556697664456,
    "itl": 131.54325507231286,
    "ttft": 2419041.8298294437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9747563961381106,
    "arrivals": 1107373,
    "finished_requests": 42606,
    "scheduler_time": 7.396202985521085
}
#Debug simulation 
Total elapsed time: 3.7175392010249197. Arrivals time: 0.1941871577873826 Scheduler time: 3.1524015381000936 Scheduler overhead time: 0.03979865461587906 Adapter cache time: 0.2704597585834563 Engine time: 0.041797255631536245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.640719556249678,
    "estimated_duration": 3600.3299108960564,
    "input_throughput": 3141.2212991295814,
    "output_throughput": 2757.8753185784544,
    "total_throughput": 5899.096617708035,
    "itl": 304.82290093456305,
    "ttft": 2370721.6160329813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9242672986676904,
    "arrivals": 1105887,
    "finished_requests": 45807,
    "scheduler_time": 27.864382049779287
}
#Debug simulation 
Total elapsed time: 3.6408108840696514. Arrivals time: 0.20325285336002707 Scheduler time: 3.331019056495279 Scheduler overhead time: 0.019190059043467045 Adapter cache time: 0.05871099140495062 Engine time: 0.01978015573695302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.720906164031476,
    "estimated_duration": 3600.081273646702,
    "input_throughput": 2917.1916414436587,
    "output_throughput": 2586.37327667002,
    "total_throughput": 5503.564918113679,
    "itl": 131.6347118984489,
    "ttft": 2419198.6869355813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.984714252748532,
    "arrivals": 1105887,
    "finished_requests": 42542,
    "scheduler_time": 7.494091148585621
}
#Debug simulation 
Total elapsed time: 3.720994775183499. Arrivals time: 0.19487573113292456 Scheduler time: 3.165550858248025 Scheduler overhead time: 0.040082062128931284 Adapter cache time: 0.2596260588616133 Engine time: 0.04190006339922547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7042026738636196,
    "estimated_duration": 3600.0418570269053,
    "input_throughput": 2917.2235815816825,
    "output_throughput": 2586.401594699684,
    "total_throughput": 5503.625176281366,
    "itl": 131.63306400944802,
    "ttft": 2419176.4509987454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9450805068598156,
    "arrivals": 1105887,
    "finished_requests": 42542,
    "scheduler_time": 7.494308274675763
}
#Debug simulation 
Total elapsed time: 3.7042998326942325. Arrivals time: 0.19243841106072068 Scheduler time: 3.1507912487722933 Scheduler overhead time: 0.03980112401768565 Adapter cache time: 0.260600907728076 Engine time: 0.041777235455811024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6990671269595623,
    "estimated_duration": 3600.048958277051,
    "input_throughput": 2908.6671101860475,
    "output_throughput": 2579.769083041807,
    "total_throughput": 5488.436193227854,
    "itl": 131.4589932587649,
    "ttft": 2420272.8487766827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9029951890604583,
    "arrivals": 1105887,
    "finished_requests": 42422,
    "scheduler_time": 7.348782033210866
}
#Debug simulation 
Total elapsed time: 3.6991865769959986. Arrivals time: 0.19216511445119977 Scheduler time: 3.1454726113006473 Scheduler overhead time: 0.03974182577803731 Adapter cache time: 0.2610682719387114 Engine time: 0.04170628963038325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5045143300667405,
    "estimated_duration": 3600.1171155197153,
    "input_throughput": 2952.0356307813563,
    "output_throughput": 2624.253794209174,
    "total_throughput": 5576.28942499053,
    "itl": 320.0815205118489,
    "ttft": 2388064.484839251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 966726,
    "finished_requests": 43180,
    "scheduler_time": 26.574059102295355
}
#Debug simulation 
Total elapsed time: 3.5046054357662797. Arrivals time: 0.19689703499898314 Scheduler time: 3.1372505892068148 Scheduler overhead time: 0.01840259926393628 Adapter cache time: 0.12442792160436511 Engine time: 0.01912908721715212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.843506339006126,
    "estimated_duration": 3600.0481441546017,
    "input_throughput": 2913.99353006805,
    "output_throughput": 2614.752254156453,
    "total_throughput": 5528.745784224503,
    "itl": 129.16105364695835,
    "ttft": 2411676.4773725043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631696,
    "arrivals": 966726,
    "finished_requests": 42626,
    "scheduler_time": 7.367608682188902
}
#Debug simulation 
Total elapsed time: 3.8436248251236975. Arrivals time: 0.25343547528609633 Scheduler time: 3.184398573823273 Scheduler overhead time: 0.04026582883670926 Adapter cache time: 0.30388301331549883 Engine time: 0.04236069368198514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.80167117388919,
    "estimated_duration": 3600.0646575483916,
    "input_throughput": 2911.172436313145,
    "output_throughput": 2612.000031800429,
    "total_throughput": 5523.172468113575,
    "itl": 128.48279962458878,
    "ttft": 2411635.422231518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 966726,
    "finished_requests": 42582,
    "scheduler_time": 7.171856859049378
}
#Debug simulation 
Total elapsed time: 3.8017593007534742. Arrivals time: 0.19594035437330604 Scheduler time: 3.1952681173570454 Scheduler overhead time: 0.04084996227174997 Adapter cache time: 0.30738941254094243 Engine time: 0.04296854371204972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7813782352022827,
    "estimated_duration": 3600.012618152984,
    "input_throughput": 2911.214518291622,
    "output_throughput": 2612.0377891409935,
    "total_throughput": 5523.252307432615,
    "itl": 128.48066797031402,
    "ttft": 2411603.9903939916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 966726,
    "finished_requests": 42582,
    "scheduler_time": 7.172117664402039
}
#Debug simulation 
Total elapsed time: 3.7814946291036904. Arrivals time: 0.1901703798212111 Scheduler time: 3.1851053894497454 Scheduler overhead time: 0.04065980017185211 Adapter cache time: 0.3035887577570975 Engine time: 0.042586362920701504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.61606282973662,
    "estimated_duration": 3600.2281732334613,
    "input_throughput": 3115.3169911246882,
    "output_throughput": 2748.1972041549275,
    "total_throughput": 5863.514195279616,
    "itl": 305.2284897313767,
    "ttft": 2362045.4385020128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 943309,
    "finished_requests": 45293,
    "scheduler_time": 27.778803587331787
}
#Debug simulation 
Total elapsed time: 3.6161533989943564. Arrivals time: 0.19863366521894932 Scheduler time: 3.262041042558849 Scheduler overhead time: 0.019226347096264362 Adapter cache time: 0.10768597573041916 Engine time: 0.019761153496801853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.176260631997138,
    "estimated_duration": 3600.0062405011386,
    "input_throughput": 3008.0170079073437,
    "output_throughput": 2674.628141383344,
    "total_throughput": 5682.645149290688,
    "itl": 125.81084644132373,
    "ttft": 2394870.9788248925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631696,
    "arrivals": 943309,
    "finished_requests": 43735,
    "scheduler_time": 7.5048161477662925
}
#Debug simulation 
Total elapsed time: 4.176376750692725. Arrivals time: 0.19619164522737265 Scheduler time: 3.5923512866720557 Scheduler overhead time: 0.04175472958013415 Adapter cache time: 0.2808793946169317 Engine time: 0.04555832454934716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.8384591350331903,
    "estimated_duration": 3600.0912916404104,
    "input_throughput": 3008.0348309905185,
    "output_throughput": 2674.69967285535,
    "total_throughput": 5682.734503845869,
    "itl": 125.80914713371905,
    "ttft": 2394871.1639050427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 943309,
    "finished_requests": 43736,
    "scheduler_time": 7.505326884787704
}
#Debug simulation 
Total elapsed time: 3.83854965493083. Arrivals time: 0.19337512087076902 Scheduler time: 3.258803572040051 Scheduler overhead time: 0.041215415112674236 Adapter cache time: 0.2826128317974508 Engine time: 0.04299743566662073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.81016001990065,
    "estimated_duration": 3600.1336855773493,
    "input_throughput": 3004.6550891526863,
    "output_throughput": 2672.153547669504,
    "total_throughput": 5676.80863682219,
    "itl": 125.38507594887277,
    "ttft": 2395161.430054866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 943309,
    "finished_requests": 43695,
    "scheduler_time": 7.358584107735531
}
#Debug simulation 
Total elapsed time: 3.810246468987316. Arrivals time: 0.19250513520091772 Scheduler time: 3.232178197707981 Scheduler overhead time: 0.04150123102590442 Adapter cache time: 0.2813849966041744 Engine time: 0.04307216918095946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6165369041264057,
    "estimated_duration": 3600.2370749131173,
    "input_throughput": 3225.236771464617,
    "output_throughput": 2808.9655735363067,
    "total_throughput": 6034.202345000924,
    "itl": 299.33381826048975,
    "ttft": 2354433.8965661675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1691063181823165,
    "arrivals": 931969,
    "finished_requests": 46965,
    "scheduler_time": 28.365598736748808
}
#Debug simulation 
Total elapsed time: 3.616629121825099. Arrivals time: 0.19858014304190874 Scheduler time: 3.2760376846417785 Scheduler overhead time: 0.01932269847020507 Adapter cache time: 0.09383777296170592 Engine time: 0.019903148990124464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7962658060714602,
    "estimated_duration": 3600.0827737975346,
    "input_throughput": 3069.4080370668303,
    "output_throughput": 2702.1012046727683,
    "total_throughput": 5771.509241739599,
    "itl": 125.12867664154237,
    "ttft": 2390231.7688710922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.246391018854925,
    "arrivals": 931969,
    "finished_requests": 44741,
    "scheduler_time": 7.727273487240222
}
#Debug simulation 
Total elapsed time: 3.7963528586551547. Arrivals time: 0.18399598635733128 Scheduler time: 3.2397726317867637 Scheduler overhead time: 0.041139775421470404 Adapter cache time: 0.26888438081368804 Engine time: 0.04296983499079943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.8008797741495073,
    "estimated_duration": 3600.020429174918,
    "input_throughput": 3070.3203544134517,
    "output_throughput": 2703.5443802274885,
    "total_throughput": 5773.86473464094,
    "itl": 125.31292850475886,
    "ttft": 2389615.9655756336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1944994134129954,
    "arrivals": 931969,
    "finished_requests": 44764,
    "scheduler_time": 7.7961545735732765
}
#Debug simulation 
Total elapsed time: 3.800979155115783. Arrivals time: 0.18514508893713355 Scheduler time: 3.247916477266699 Scheduler overhead time: 0.040824560448527336 Adapter cache time: 0.26454753475263715 Engine time: 0.04297440964728594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7802456729114056,
    "estimated_duration": 3600.0997391903265,
    "input_throughput": 3070.25271541113,
    "output_throughput": 2703.4848212813513,
    "total_throughput": 5773.737536692482,
    "itl": 125.31078679987722,
    "ttft": 2389585.1643172465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 382,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1421992126526275,
    "arrivals": 931969,
    "finished_requests": 44764,
    "scheduler_time": 7.796675841148596
}
#Debug simulation 
Total elapsed time: 3.78035706281662. Arrivals time: 0.17794776149094105 Scheduler time: 3.2351727238856256 Scheduler overhead time: 0.04081686632707715 Adapter cache time: 0.2642922019585967 Engine time: 0.04264824837446213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6309952759183943,
    "estimated_duration": 3600.0687004021133,
    "input_throughput": 3235.4946445046908,
    "output_throughput": 2868.506647899951,
    "total_throughput": 6104.001292404642,
    "itl": 294.3118284673221,
    "ttft": 2343120.7047429183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1538038794626522,
    "arrivals": 926257,
    "finished_requests": 47305,
    "scheduler_time": 28.988290838194605
}
#Debug simulation 
Total elapsed time: 3.6310801217332482. Arrivals time: 0.18425906356424093 Scheduler time: 3.312694882042706 Scheduler overhead time: 0.019528575241565704 Adapter cache time: 0.0854526087641716 Engine time: 0.020206560846418142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.810371983330697,
    "estimated_duration": 3600.025519381437,
    "input_throughput": 3061.6052415911195,
    "output_throughput": 2729.3648189716955,
    "total_throughput": 5790.970060562815,
    "itl": 123.21353185766425,
    "ttft": 2386105.5539855417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2242348808352899,
    "arrivals": 926257,
    "finished_requests": 44727,
    "scheduler_time": 7.605837185673364
}
#Debug simulation 
Total elapsed time: 3.8104656510986388. Arrivals time: 0.18000777391716838 Scheduler time: 3.2668614205904305 Scheduler overhead time: 0.04155688127502799 Adapter cache time: 0.2586329975165427 Engine time: 0.043575786985456944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.890391529072076,
    "estimated_duration": 3600.1158497298047,
    "input_throughput": 3061.6403638308584,
    "output_throughput": 2729.493274706006,
    "total_throughput": 5791.133638536865,
    "itl": 123.21227822430367,
    "ttft": 2386087.928947694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1723432753933596,
    "arrivals": 926257,
    "finished_requests": 44729,
    "scheduler_time": 7.606427466671303
}
#Debug simulation 
Total elapsed time: 3.8904922669753432. Arrivals time: 0.24724627239629626 Scheduler time: 3.2784341447986662 Scheduler overhead time: 0.04174010921269655 Adapter cache time: 0.2595252199098468 Engine time: 0.04362233728170395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.8047428089194,
    "estimated_duration": 3600.065027351723,
    "input_throughput": 3061.6835852290665,
    "output_throughput": 2729.5318071597603,
    "total_throughput": 5791.215392388826,
    "itl": 123.21045436990501,
    "ttft": 2386058.99938534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 375,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.121268860588313,
    "arrivals": 926257,
    "finished_requests": 44729,
    "scheduler_time": 7.606679503391526
}
#Debug simulation 
Total elapsed time: 3.804832666181028. Arrivals time: 0.18063250510022044 Scheduler time: 3.26077100681141 Scheduler overhead time: 0.04161622887477279 Adapter cache time: 0.2585047837346792 Engine time: 0.04341941326856613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.650866450276226,
    "estimated_duration": 3600.2619600107637,
    "input_throughput": 3320.234508703434,
    "output_throughput": 2894.6935294588516,
    "total_throughput": 6214.928038162286,
    "itl": 290.0443833603,
    "ttft": 2339742.8494815733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0528077839128678,
    "arrivals": 923309,
    "finished_requests": 48114,
    "scheduler_time": 29.205710536067155
}
#Debug simulation 
Total elapsed time: 3.6509566172026098. Arrivals time: 0.18628491088747978 Scheduler time: 3.3348064278252423 Scheduler overhead time: 0.01968499505892396 Adapter cache time: 0.08068586559966207 Engine time: 0.020383646711707115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8161043557338417,
    "estimated_duration": 3600.0895962577397,
    "input_throughput": 3121.6531421001405,
    "output_throughput": 2738.8023926541473,
    "total_throughput": 5860.455534754288,
    "itl": 123.48225663689476,
    "ttft": 2386575.189095976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1101854281895849,
    "arrivals": 923309,
    "finished_requests": 45177,
    "scheduler_time": 7.872832769666995
}
#Debug simulation 
Total elapsed time: 3.8161891126073897. Arrivals time: 0.18199431942775846 Scheduler time: 3.2785225436091423 Scheduler overhead time: 0.04165994515642524 Adapter cache time: 0.2512992941774428 Engine time: 0.04290569480508566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.8115559271536767,
    "estimated_duration": 3600.043250317248,
    "input_throughput": 3121.693329381432,
    "output_throughput": 2738.8376512229706,
    "total_throughput": 5860.530980604402,
    "itl": 123.48033907678243,
    "ttft": 2386549.688605582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0636055618873816,
    "arrivals": 923309,
    "finished_requests": 45177,
    "scheduler_time": 7.873066695473491
}
#Debug simulation 
Total elapsed time: 3.8116420470178127. Arrivals time: 0.1804044214077294 Scheduler time: 3.273906842805445 Scheduler overhead time: 0.041852961760014296 Adapter cache time: 0.25270910328254104 Engine time: 0.042850828263908625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.83691333187744,
    "estimated_duration": 3600.133971721371,
    "input_throughput": 3122.002983301723,
    "output_throughput": 2738.935572246295,
    "total_throughput": 5860.938555548018,
    "itl": 123.47976190885741,
    "ttft": 2386528.5563019887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0166171002667406,
    "arrivals": 923309,
    "finished_requests": 45181,
    "scheduler_time": 7.8736521063286204
}
#Debug simulation 
Total elapsed time: 3.83700449205935. Arrivals time: 0.19371485617011786 Scheduler time: 3.284453039057553 Scheduler overhead time: 0.041717715095728636 Adapter cache time: 0.2540202266536653 Engine time: 0.043184126261621714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6466602571308613,
    "estimated_duration": 3600.1257028339082,
    "input_throughput": 3284.836135219133,
    "output_throughput": 2892.838156123816,
    "total_throughput": 6177.674291342949,
    "itl": 290.87829504021624,
    "ttft": 2340431.0199092086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9671141270827489,
    "arrivals": 921853,
    "finished_requests": 47761,
    "scheduler_time": 29.207042316017898
}
#Debug simulation 
Total elapsed time: 3.6467477651312947. Arrivals time: 0.18523350544273853 Scheduler time: 3.3376951152458787 Scheduler overhead time: 0.019584951922297478 Adapter cache time: 0.07487933896481991 Engine time: 0.020311503671109676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8551445682533085,
    "estimated_duration": 3600.0190791603377,
    "input_throughput": 3071.097890564148,
    "output_throughput": 2726.838603946961,
    "total_throughput": 5797.936494511109,
    "itl": 123.08276210625834,
    "ttft": 2388272.3316959403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0280794550851045,
    "arrivals": 921853,
    "finished_requests": 44639,
    "scheduler_time": 7.551628183983665
}
#Debug simulation 
Total elapsed time: 3.8552307062782347. Arrivals time: 0.23741816636174917 Scheduler time: 3.2700970307923853 Scheduler overhead time: 0.042029733303934336 Adapter cache time: 0.241744015365839 Engine time: 0.04402116034179926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7884621927514672,
    "estimated_duration": 3600.0180787603886,
    "input_throughput": 3074.220394973916,
    "output_throughput": 2730.953507707195,
    "total_throughput": 5805.173902681111,
    "itl": 123.69021554958313,
    "ttft": 2387293.499430697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9868113279226272,
    "arrivals": 921853,
    "finished_requests": 44696,
    "scheduler_time": 7.7701374807445385
}
#Debug simulation 
Total elapsed time: 3.7885482851415873. Arrivals time: 0.1804228168912232 Scheduler time: 3.2584010967984796 Scheduler overhead time: 0.04164033243432641 Adapter cache time: 0.2454398493282497 Engine time: 0.04293560516089201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.812418027315289,
    "estimated_duration": 3600.1092703792583,
    "input_throughput": 3074.1425242445785,
    "output_throughput": 2730.8843320092587,
    "total_throughput": 5805.026856253837,
    "itl": 123.68854561958017,
    "ttft": 2387301.940568112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9418658428941866,
    "arrivals": 921853,
    "finished_requests": 44696,
    "scheduler_time": 7.770661540462694
}
#Debug simulation 
Total elapsed time: 3.812502895016223. Arrivals time: 0.18495506746694446 Scheduler time: 3.279001044575125 Scheduler overhead time: 0.04173526540398598 Adapter cache time: 0.24372766725718975 Engine time: 0.04328666813671589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.0560964196920395,
    "estimated_duration": 3600.063992840849,
    "input_throughput": 3670.0847613472124,
    "output_throughput": 3209.7276667800697,
    "total_throughput": 6879.812428127282,
    "itl": 262.12815552632424,
    "ttft": 2279527.605974267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 805539,
    "finished_requests": 53267,
    "scheduler_time": 32.39306719159452
}
#Debug simulation 
Total elapsed time: 4.0561923938803375. Arrivals time: 0.19936717115342617 Scheduler time: 3.700452947989106 Scheduler overhead time: 0.021808657329529524 Adapter cache time: 0.10179648408666253 Engine time: 0.022635384928435087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.057058573234826,
    "estimated_duration": 3600.049100751447,
    "input_throughput": 3404.303846145278,
    "output_throughput": 3001.438229757638,
    "total_throughput": 6405.742075902916,
    "itl": 112.12690463869787,
    "ttft": 2332655.6828661608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.252779714763169,
    "arrivals": 805539,
    "finished_requests": 49449,
    "scheduler_time": 8.433951626443783
}
#Debug simulation 
Total elapsed time: 4.057147543877363. Arrivals time: 0.18315674318000674 Scheduler time: 3.5426013679243624 Scheduler overhead time: 0.045231977943331 Adapter cache time: 0.21787660848349333 Engine time: 0.046539136208593845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.055936394259334,
    "estimated_duration": 3600.063697498333,
    "input_throughput": 3387.6414488095725,
    "output_throughput": 2986.133830762581,
    "total_throughput": 6373.7752795721535,
    "itl": 111.77683861466859,
    "ttft": 2333975.2215280267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 805539,
    "finished_requests": 49202,
    "scheduler_time": 8.104985972781828
}
#Debug simulation 
Total elapsed time: 4.056017212104052. Arrivals time: 0.1895537027157843 Scheduler time: 3.535570354666561 Scheduler overhead time: 0.045315053313970566 Adapter cache time: 0.216950218193233 Engine time: 0.04688568413257599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.068741229828447,
    "estimated_duration": 3600.0571712604897,
    "input_throughput": 3404.751207244952,
    "output_throughput": 3001.9056603526465,
    "total_throughput": 6406.656867597599,
    "itl": 112.15779015886926,
    "ttft": 2332584.6199195837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 805539,
    "finished_requests": 49456,
    "scheduler_time": 8.446936735375267
}
#Debug simulation 
Total elapsed time: 4.068842289969325. Arrivals time: 0.18715749634429812 Scheduler time: 3.5477149062789977 Scheduler overhead time: 0.045226074289530516 Adapter cache time: 0.22024490125477314 Engine time: 0.04683120595291257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.204430953133851,
    "estimated_duration": 3600.169001669495,
    "input_throughput": 3777.662657973337,
    "output_throughput": 3338.9860293851702,
    "total_throughput": 7116.648687358507,
    "itl": 253.67007139087832,
    "ttft": 2259976.8853079323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 794133,
    "finished_requests": 55181,
    "scheduler_time": 33.70296209275652
}
#Debug simulation 
Total elapsed time: 4.204512764234096. Arrivals time: 0.249748595058918 Scheduler time: 3.811625196132809 Scheduler overhead time: 0.022537814918905497 Adapter cache time: 0.0872242315672338 Engine time: 0.02298153657466173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.1047094441019,
    "estimated_duration": 3600.0682183261342,
    "input_throughput": 3423.2034652193292,
    "output_throughput": 3054.752113867788,
    "total_throughput": 6477.955579087117,
    "itl": 111.11661387145308,
    "ttft": 2319383.6319394936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631698,
    "arrivals": 794133,
    "finished_requests": 50003,
    "scheduler_time": 8.863198981251301
}
#Debug simulation 
Total elapsed time: 4.104792463127524. Arrivals time: 0.18885229201987386 Scheduler time: 3.6035219272598624 Scheduler overhead time: 0.0455112224444747 Adapter cache time: 0.19787532463669777 Engine time: 0.04720958787947893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.112637071404606,
    "estimated_duration": 3600.064492165125,
    "input_throughput": 3426.1458445656804,
    "output_throughput": 3057.289952430987,
    "total_throughput": 6483.435796996667,
    "itl": 111.32247666374076,
    "ttft": 2319489.800627265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027997,
    "arrivals": 794133,
    "finished_requests": 50046,
    "scheduler_time": 8.965359942751464
}
#Debug simulation 
Total elapsed time: 4.112722045276314. Arrivals time: 0.19125418458133936 Scheduler time: 3.605693634133786 Scheduler overhead time: 0.04574564332142472 Adapter cache time: 0.20116287237033248 Engine time: 0.04696540208533406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.165137188974768,
    "estimated_duration": 3600.0124631773488,
    "input_throughput": 3426.195360755441,
    "output_throughput": 3057.334137750674,
    "total_throughput": 6483.5294985061155,
    "itl": 111.32083182402413,
    "ttft": 2319458.216892672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 794133,
    "finished_requests": 50046,
    "scheduler_time": 8.965631155733282
}
#Debug simulation 
Total elapsed time: 4.165218255016953. Arrivals time: 0.23908713972195983 Scheduler time: 3.609291337430477 Scheduler overhead time: 0.04604714876040816 Adapter cache time: 0.20160946948453784 Engine time: 0.04723667539656162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.294240472838283,
    "estimated_duration": 3600.1969144218915,
    "input_throughput": 3842.2565011895304,
    "output_throughput": 3394.1846211382044,
    "total_throughput": 7236.441122327735,
    "itl": 249.2955914526127,
    "ttft": 2257500.3586572413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1660458304383836,
    "arrivals": 788332,
    "finished_requests": 56151,
    "scheduler_time": 34.30435923674766
}
#Debug simulation 
Total elapsed time: 4.294334138743579. Arrivals time: 0.26394728710874915 Scheduler time: 3.8963235304690897 Scheduler overhead time: 0.022667359560728073 Adapter cache time: 0.07723733363673091 Engine time: 0.023595125414431095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.143781973049045,
    "estimated_duration": 3600.070554393324,
    "input_throughput": 3438.906491677439,
    "output_throughput": 3066.243517513566,
    "total_throughput": 6505.150009191006,
    "itl": 109.37323461072437,
    "ttft": 2322896.9242029064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2395937276282398,
    "arrivals": 788332,
    "finished_requests": 50281,
    "scheduler_time": 8.530574095630246
}
#Debug simulation 
Total elapsed time: 4.143880684394389. Arrivals time: 0.242980167735368 Scheduler time: 3.6024021967314184 Scheduler overhead time: 0.04581279261037707 Adapter cache time: 0.18304175464436412 Engine time: 0.047518127132207155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.163527430035174,
    "estimated_duration": 3600.0189001965596,
    "input_throughput": 3438.955834182993,
    "output_throughput": 3066.287512934249,
    "total_throughput": 6505.243347117242,
    "itl": 109.37159560570514,
    "ttft": 2322866.275773613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1877021221863107,
    "arrivals": 788332,
    "finished_requests": 50281,
    "scheduler_time": 8.530811504304767
}
#Debug simulation 
Total elapsed time: 4.163607615046203. Arrivals time: 0.1849836972542107 Scheduler time: 3.678761426359415 Scheduler overhead time: 0.046187855303287506 Adapter cache time: 0.18407099368050694 Engine time: 0.04744368465617299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.147540321107954,
    "estimated_duration": 3600.084897684728,
    "input_throughput": 3439.166117433121,
    "output_throughput": 3066.263522590602,
    "total_throughput": 6505.429640023723,
    "itl": 109.36916659873516,
    "ttft": 2322863.467136111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1362191120628233,
    "arrivals": 788332,
    "finished_requests": 50283,
    "scheduler_time": 8.53128193372777
}
#Debug simulation 
Total elapsed time: 4.1476420178078115. Arrivals time: 0.23849167115986347 Scheduler time: 3.610268071293831 Scheduler overhead time: 0.04603751329705119 Adapter cache time: 0.18323380127549171 Engine time: 0.04755880776792765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.273300459608436,
    "estimated_duration": 3600.0962851876075,
    "input_throughput": 3916.463584046959,
    "output_throughput": 3450.91631329871,
    "total_throughput": 7367.379897345669,
    "itl": 245.0826256033615,
    "ttft": 2242688.5530942297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0956546123279278,
    "arrivals": 785377,
    "finished_requests": 57095,
    "scheduler_time": 34.79992379650571
}
#Debug simulation 
Total elapsed time: 4.27338435780257. Arrivals time: 0.20838792668655515 Scheduler time: 3.9360181661322713 Scheduler overhead time: 0.02307961694896221 Adapter cache time: 0.07126552471891046 Engine time: 0.02389297029003501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.128231666050851,
    "estimated_duration": 3600.0179478554314,
    "input_throughput": 3487.353447079026,
    "output_throughput": 3097.85233338727,
    "total_throughput": 6585.205780466296,
    "itl": 109.13161337206083,
    "ttft": 2310755.082561069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.142128907730808,
    "arrivals": 785377,
    "finished_requests": 50884,
    "scheduler_time": 8.959700565956823
}
#Debug simulation 
Total elapsed time: 4.128312050364912. Arrivals time: 0.19304807484149933 Scheduler time: 3.643741408828646 Scheduler overhead time: 0.04707947326824069 Adapter cache time: 0.17436579568311572 Engine time: 0.04781314358115196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.145638367161155,
    "estimated_duration": 3600.08157912179,
    "input_throughput": 3487.2918082769042,
    "output_throughput": 3097.7975789983393,
    "total_throughput": 6585.089387275243,
    "itl": 109.02770018230177,
    "ttft": 2310965.052067348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0951404461101646,
    "arrivals": 785377,
    "finished_requests": 50884,
    "scheduler_time": 8.925287594295684
}
#Debug simulation 
Total elapsed time: 4.145718060899526. Arrivals time: 0.19530879659578204 Scheduler time: 3.6585004022344947 Scheduler overhead time: 0.04652503691613674 Adapter cache time: 0.1752721113152802 Engine time: 0.04792838403955102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.2056826408952475,
    "estimated_duration": 3600.013500846209,
    "input_throughput": 3487.418865803952,
    "output_throughput": 3097.857548972682,
    "total_throughput": 6585.276414776634,
    "itl": 109.0233005824666,
    "ttft": 2310995.770436627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0465176032157613,
    "arrivals": 785377,
    "finished_requests": 50886,
    "scheduler_time": 8.926327988256794
}
#Debug simulation 
Total elapsed time: 4.205770215019584. Arrivals time: 0.2453972063958645 Scheduler time: 3.665612507145852 Scheduler overhead time: 0.04676788346841931 Adapter cache time: 0.1772229834459722 Engine time: 0.04855070170015097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.342137677129358,
    "estimated_duration": 3600.2216928890325,
    "input_throughput": 3942.0564094794036,
    "output_throughput": 3460.5274515754677,
    "total_throughput": 7402.583861054872,
    "itl": 242.85644993557918,
    "ttft": 2239196.0559809506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0099609554978077,
    "arrivals": 784050,
    "finished_requests": 57598,
    "scheduler_time": 34.89854289151424
}
#Debug simulation 
Total elapsed time: 4.342228919267654. Arrivals time: 0.2552024549804628 Scheduler time: 3.9600635352544487 Scheduler overhead time: 0.02331483969464898 Adapter cache time: 0.06885698204860091 Engine time: 0.024022941011935472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.126692812889814,
    "estimated_duration": 3600.0803401390776,
    "input_throughput": 3504.670953957816,
    "output_throughput": 3093.169581757114,
    "total_throughput": 6597.84053571493,
    "itl": 107.82771954038856,
    "ttft": 2309684.7876485568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0510527837416213,
    "arrivals": 784050,
    "finished_requests": 51116,
    "scheduler_time": 8.534868820695598
}
#Debug simulation 
Total elapsed time: 4.126776887103915. Arrivals time: 0.19402535678818822 Scheduler time: 3.6483793780207634 Scheduler overhead time: 0.04654483264312148 Adapter cache time: 0.16730905743315816 Engine time: 0.04803900374099612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.159382160753012,
    "estimated_duration": 3600.04763427092,
    "input_throughput": 3512.709354069713,
    "output_throughput": 3100.958135588905,
    "total_throughput": 6613.667489658617,
    "itl": 108.42730008697036,
    "ttft": 2308895.449100131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0089674659422632,
    "arrivals": 784050,
    "finished_requests": 51237,
    "scheduler_time": 8.858757120314424
}
#Debug simulation 
Total elapsed time: 4.159465442877263. Arrivals time: 0.2038195631466806 Scheduler time: 3.668639280833304 Scheduler overhead time: 0.046979060396552086 Adapter cache time: 0.16930356854572892 Engine time: 0.04830606747418642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.14273879211396,
    "estimated_duration": 3600.001716470781,
    "input_throughput": 3512.7541584611463,
    "output_throughput": 3100.99768811891,
    "total_throughput": 6613.751846580056,
    "itl": 108.42600726820882,
    "ttft": 2308867.8480952126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9627961949585019,
    "arrivals": 784050,
    "finished_requests": 51237,
    "scheduler_time": 8.859010591156776
}
#Debug simulation 
Total elapsed time: 4.142819835804403. Arrivals time: 0.19709305837750435 Scheduler time: 3.659228218719363 Scheduler overhead time: 0.0467448839917779 Adapter cache time: 0.1694160858169198 Engine time: 0.048015224281698465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.382456698920578,
    "estimated_duration": 3600.2258955673897,
    "input_throughput": 4090.030577839438,
    "output_throughput": 3549.123963507924,
    "total_throughput": 7639.154541347362,
    "itl": 237.0157775911161,
    "ttft": 2215471.579628593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 771112,
    "finished_requests": 59445,
    "scheduler_time": 35.77380303927588
}
#Debug simulation 
Total elapsed time: 4.3825343027710915. Arrivals time: 0.20896227471530437 Scheduler time: 4.041947642341256 Scheduler overhead time: 0.02403894579038024 Adapter cache time: 0.07146032294258475 Engine time: 0.025061294436454773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.198033368680626,
    "estimated_duration": 3600.0828510376004,
    "input_throughput": 3610.140526697633,
    "output_throughput": 3153.844639083117,
    "total_throughput": 6763.98516578075,
    "itl": 107.19154400477822,
    "ttft": 2289991.0525496216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631692,
    "arrivals": 771112,
    "finished_requests": 52500,
    "scheduler_time": 9.158201999522626
}
#Debug simulation 
Total elapsed time: 4.198119685985148. Arrivals time: 0.19958491250872612 Scheduler time: 3.7083283835090697 Scheduler overhead time: 0.0467668785713613 Adapter cache time: 0.17254281230270863 Engine time: 0.048350446857512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.187473725993186,
    "estimated_duration": 3600.06688557109,
    "input_throughput": 3597.6473248066945,
    "output_throughput": 3142.6802222329397,
    "total_throughput": 6740.327547039634,
    "itl": 107.46890305472819,
    "ttft": 2291189.2876983928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 771112,
    "finished_requests": 52319,
    "scheduler_time": 9.086211417701692
}
#Debug simulation 
Total elapsed time: 4.187559968791902. Arrivals time: 0.19570358004420996 Scheduler time: 3.704222810920328 Scheduler overhead time: 0.04713214375078678 Adapter cache time: 0.1697289147414267 Engine time: 0.04821937624365091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.191368155181408,
    "estimated_duration": 3600.1146957541137,
    "input_throughput": 3610.756628207113,
    "output_throughput": 3154.35728017028,
    "total_throughput": 6765.113908377392,
    "itl": 107.1413920351292,
    "ttft": 2290056.6256334772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 771112,
    "finished_requests": 52507,
    "scheduler_time": 9.141853859720795
}
#Debug simulation 
Total elapsed time: 4.191443643998355. Arrivals time: 0.1920130206272006 Scheduler time: 3.7114166049286723 Scheduler overhead time: 0.04702776437625289 Adapter cache time: 0.16986022051423788 Engine time: 0.048560271970927715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.478437012992799,
    "estimated_duration": 3600.096282619441,
    "input_throughput": 4116.599345286624,
    "output_throughput": 3650.3076496715903,
    "total_throughput": 7766.906994958214,
    "itl": 232.35285167763556,
    "ttft": 2220005.281833185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1660458304383836,
    "arrivals": 765327,
    "finished_requests": 59941,
    "scheduler_time": 36.82072878061932
}
#Debug simulation 
Total elapsed time: 4.478535638190806. Arrivals time: 0.20435714907944202 Scheduler time: 4.150710901711136 Scheduler overhead time: 0.024373013991862535 Adapter cache time: 0.06252373475581408 Engine time: 0.025247891433537006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.213821142911911,
    "estimated_duration": 3600.0870485586297,
    "input_throughput": 3569.9111789937315,
    "output_throughput": 3194.8338595326295,
    "total_throughput": 6764.745038526361,
    "itl": 106.120131489092,
    "ttft": 2299953.9165028264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2340222223568764,
    "arrivals": 765327,
    "finished_requests": 52090,
    "scheduler_time": 9.263654181265673
}
#Debug simulation 
Total elapsed time: 4.213898359797895. Arrivals time: 0.19398891925811768 Scheduler time: 3.745262840297073 Scheduler overhead time: 0.047653892543166876 Adapter cache time: 0.15387588180601597 Engine time: 0.05031352862715721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.221290085930377,
    "estimated_duration": 3600.0202084241173,
    "input_throughput": 3569.7521835927446,
    "output_throughput": 3194.777344051242,
    "total_throughput": 6764.5295276439865,
    "itl": 106.12053857375874,
    "ttft": 2299946.3626318267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1817220215965065,
    "arrivals": 765327,
    "finished_requests": 52088,
    "scheduler_time": 9.265766938554199
}
#Debug simulation 
Total elapsed time: 4.22136538522318. Arrivals time: 0.1968097253702581 Scheduler time: 3.749899490736425 Scheduler overhead time: 0.04781580716371536 Adapter cache time: 0.154910646378994 Engine time: 0.04915791703388095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.217167965136468,
    "estimated_duration": 3600.0737009239524,
    "input_throughput": 3570.150799052072,
    "output_throughput": 3195.1268100560983,
    "total_throughput": 6765.2776091081705,
    "itl": 106.11872546041621,
    "ttft": 2299901.8041190575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1302390114730192,
    "arrivals": 765327,
    "finished_requests": 52093,
    "scheduler_time": 9.264314927521717
}
#Debug simulation 
Total elapsed time: 4.217241133097559. Arrivals time: 0.19645776320248842 Scheduler time: 3.745653425808996 Scheduler overhead time: 0.047374862246215343 Adapter cache time: 0.15588473295792937 Engine time: 0.049077791161835194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.528038683347404,
    "estimated_duration": 3600.0191524427673,
    "input_throughput": 4197.821278185617,
    "output_throughput": 3693.9942363852238,
    "total_throughput": 7891.815514570841,
    "itl": 229.31722766622357,
    "ttft": 2202748.8345848406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1078965633036593,
    "arrivals": 762451,
    "finished_requests": 61325,
    "scheduler_time": 37.251043209963996
}
#Debug simulation 
Total elapsed time: 4.528115059249103. Arrivals time: 0.2114020180888474 Scheduler time: 4.199118281248957 Scheduler overhead time: 0.02467077225446701 Adapter cache time: 0.055897807236760855 Engine time: 0.0255852984264493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.2720957370474935,
    "estimated_duration": 3600.1053857896013,
    "input_throughput": 3629.407919994602,
    "output_throughput": 3206.0197586322943,
    "total_throughput": 6835.427678626896,
    "itl": 105.56730895633011,
    "ttft": 2289029.249733391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.157896349842199,
    "arrivals": 762451,
    "finished_requests": 53023,
    "scheduler_time": 9.284747575492124
}
#Debug simulation 
Total elapsed time: 4.2721789428032935. Arrivals time: 0.24567218637093902 Scheduler time: 3.759243421256542 Scheduler overhead time: 0.047888773027807474 Adapter cache time: 0.14714679028838873 Engine time: 0.04933051811531186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.2185937953181565,
    "estimated_duration": 3600.109684808827,
    "input_throughput": 3627.990295716108,
    "output_throughput": 3205.1084578587584,
    "total_throughput": 6833.098753574866,
    "itl": 105.38941373333626,
    "ttft": 2289314.6405487596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.109273506947794,
    "arrivals": 762451,
    "finished_requests": 53005,
    "scheduler_time": 9.200682323274927
}
#Debug simulation 
Total elapsed time: 4.21867332002148. Arrivals time: 0.19656422128900886 Scheduler time: 3.7551067853346467 Scheduler overhead time: 0.04769140714779496 Adapter cache time: 0.14696071622893214 Engine time: 0.049484115559607744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.232787975575775,
    "estimated_duration": 3600.0621094356106,
    "input_throughput": 3628.0382401645916,
    "output_throughput": 3205.1508138588624,
    "total_throughput": 6833.1890540234535,
    "itl": 105.387983956372,
    "ttft": 2289285.953758812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0614678546902716,
    "arrivals": 762451,
    "finished_requests": 53005,
    "scheduler_time": 9.200912602313728
}
#Debug simulation 
Total elapsed time: 4.232869046740234. Arrivals time: 0.199717216193676 Scheduler time: 3.762600233312696 Scheduler overhead time: 0.04945823363959789 Adapter cache time: 0.14829166186973453 Engine time: 0.049690136685967445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.538728374056518,
    "estimated_duration": 3600.201145102493,
    "input_throughput": 4221.0274891647405,
    "output_throughput": 3721.0470915559413,
    "total_throughput": 7942.074580720682,
    "itl": 226.58045841406772,
    "ttft": 2201672.762086403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0191424187296063,
    "arrivals": 761080,
    "finished_requests": 61721,
    "scheduler_time": 37.480574982166026
}
#Debug simulation 
Total elapsed time: 4.538807358127087. Arrivals time: 0.20695250714197755 Scheduler time: 4.218788182362914 Scheduler overhead time: 0.024918057024478912 Adapter cache time: 0.05081999767571688 Engine time: 0.025727770756930113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.243430177681148,
    "estimated_duration": 3600.038646607775,
    "input_throughput": 3625.4449691250747,
    "output_throughput": 3218.872111531119,
    "total_throughput": 6844.317080656194,
    "itl": 104.88938593450838,
    "ttft": 2287533.370117475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0638301755581105,
    "arrivals": 761080,
    "finished_requests": 53060,
    "scheduler_time": 9.316064922670076
}
#Debug simulation 
Total elapsed time: 4.2435053717345. Arrivals time: 0.20154330786317587 Scheduler time: 3.782384706661105 Scheduler overhead time: 0.04874575091525912 Adapter cache time: 0.137940872926265 Engine time: 0.049850073643028736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.2343257260508835,
    "estimated_duration": 3600.111082654422,
    "input_throughput": 3625.6359040943908,
    "output_throughput": 3218.956786037705,
    "total_throughput": 6844.592690132095,
    "itl": 104.88848278770598,
    "ttft": 2287535.228147982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0201104764849909,
    "arrivals": 761080,
    "finished_requests": 53062,
    "scheduler_time": 9.316543986067922
}
#Debug simulation 
Total elapsed time: 4.234404291026294. Arrivals time: 0.19767063856124878 Scheduler time: 3.7777562285773456 Scheduler overhead time: 0.04803982423618436 Adapter cache time: 0.13890195917338133 Engine time: 0.04907879652455449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_384_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.236023462377489,
    "estimated_duration": 3600.0659559029223,
    "input_throughput": 3625.681351364656,
    "output_throughput": 3218.9971355937273,
    "total_throughput": 6844.6784869583835,
    "itl": 104.88705408959868,
    "ttft": 2287508.5358967516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9747563961381106,
    "arrivals": 761080,
    "finished_requests": 53062,
    "scheduler_time": 9.31677131491263
}
#Debug simulation 
Total elapsed time: 4.236095893196762. Arrivals time: 0.1965700825676322 Scheduler time: 3.7816100446507335 Scheduler overhead time: 0.04804282449185848 Adapter cache time: 0.13761725835502148 Engine time: 0.049215779174119234 
