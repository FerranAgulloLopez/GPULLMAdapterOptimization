INFO 06-01 00:47:16 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:17 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.4568747720331885,
    "estimated_duration": 3600.1887025871365,
    "input_throughput": 3710.7193826812086,
    "output_throughput": 3221.271149388956,
    "total_throughput": 6931.990532070165,
    "itl": 260.72511506382307,
    "ttft": 2323407.985439303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5535029518464043,
    "arrivals": 1852456,
    "finished_requests": 53590,
    "scheduler_time": 66.04216006594912
}
#Debug simulation 
Total elapsed time: 4.457014736020938. Arrivals time: 0.2299543300177902 Scheduler time: 4.145430883858353 Scheduler overhead time: 0.023097788623999804 Adapter cache time: 0.024809699330944568 Engine time: 0.02325151872355491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.843849915021565,
    "estimated_duration": 3600.0452826558385,
    "input_throughput": 3069.6799990936297,
    "output_throughput": 2689.561447087399,
    "total_throughput": 5759.241446181029,
    "itl": 125.55097715042787,
    "ttft": 2416787.423729337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4064,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.668968198298527,
    "arrivals": 1852456,
    "finished_requests": 44408,
    "scheduler_time": 78.06377535773241
}
#Debug simulation 
Total elapsed time: 3.843995917995926. Arrivals time: 0.3181894486187957 Scheduler time: 3.2328962943865918 Scheduler overhead time: 0.0413869921467267 Adapter cache time: 0.1897751516662538 Engine time: 0.042251866252627224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.865789075032808,
    "estimated_duration": 3600.1591803239157,
    "input_throughput": 3666.431771167514,
    "output_throughput": 3230.9832475111375,
    "total_throughput": 6897.415018678652,
    "itl": 264.3513046530348,
    "ttft": 2325223.858222908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 814,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.491237023561312,
    "arrivals": 1850068,
    "finished_requests": 53557,
    "scheduler_time": 65.94421888735151
}
#Debug simulation 
Total elapsed time: 4.8658539520110935. Arrivals time: 0.6771445577032864 Scheduler time: 4.109203464642633 Scheduler overhead time: 0.02254500676644966 Adapter cache time: 0.02402523293858394 Engine time: 0.022681616013869643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.367744761984795,
    "estimated_duration": 3600.292852479591,
    "input_throughput": 3658.5393299126536,
    "output_throughput": 3224.611573473608,
    "total_throughput": 6883.150903386262,
    "itl": 262.12854612737783,
    "ttft": 2326492.232795562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7563718973426226,
    "arrivals": 1850068,
    "finished_requests": 53456,
    "scheduler_time": 66.00618694165509
}
#Debug simulation 
Total elapsed time: 4.367896715993993. Arrivals time: 0.22310527577064931 Scheduler time: 4.063398911384866 Scheduler overhead time: 0.02290724264457822 Adapter cache time: 0.025169917556922883 Engine time: 0.02294948644703254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.826060449006036,
    "estimated_duration": 3600.0883823724344,
    "input_throughput": 3038.5331797857916,
    "output_throughput": 2698.650690791549,
    "total_throughput": 5737.183870577341,
    "itl": 125.56516901347054,
    "ttft": 2419765.4684561724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.294119304194275,
    "arrivals": 1850068,
    "finished_requests": 44363,
    "scheduler_time": 78.1700626953481
}
#Debug simulation 
Total elapsed time: 3.8261519969673827. Arrivals time: 0.320933828887064 Scheduler time: 3.220396156248171 Scheduler overhead time: 0.04112893040291965 Adapter cache time: 0.18225877487566322 Engine time: 0.04205713659757748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.480247054016218,
    "estimated_duration": 3600.2745571069154,
    "input_throughput": 3658.3671025867443,
    "output_throughput": 3224.8504428867127,
    "total_throughput": 6883.217545473457,
    "itl": 262.0797736663434,
    "ttft": 2326373.6655281647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.630933134581402,
    "arrivals": 1850068,
    "finished_requests": 53453,
    "scheduler_time": 66.00955036055232
}
#Debug simulation 
Total elapsed time: 4.480379360029474. Arrivals time: 0.3494378076866269 Scheduler time: 4.049642207741272 Scheduler overhead time: 0.022940970142371953 Adapter cache time: 0.025114107585977763 Engine time: 0.022881338896695524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.167214554967359,
    "estimated_duration": 3600.1160729892263,
    "input_throughput": 3038.5098086343664,
    "output_throughput": 2698.6299338768777,
    "total_throughput": 5737.139742511244,
    "itl": 125.57126367050714,
    "ttft": 2419818.8837370803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.458227995465652,
    "arrivals": 1850068,
    "finished_requests": 44363,
    "scheduler_time": 78.16721141750368
}
#Debug simulation 
Total elapsed time: 4.167275470972527. Arrivals time: 0.6639080399181694 Scheduler time: 3.214790932717733 Scheduler overhead time: 0.04109025624347851 Adapter cache time: 0.18621874769451097 Engine time: 0.04194537713192403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.372860468982253,
    "estimated_duration": 3600.164006937267,
    "input_throughput": 3658.4794399977754,
    "output_throughput": 3224.9494683096837,
    "total_throughput": 6883.428908307459,
    "itl": 262.07293938567136,
    "ttft": 2326329.5018337932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5206123986024815,
    "arrivals": 1850068,
    "finished_requests": 53453,
    "scheduler_time": 66.00932092685774
}
#Debug simulation 
Total elapsed time: 4.37297943898011. Arrivals time: 0.22430119483033195 Scheduler time: 4.067067441297695 Scheduler overhead time: 0.022874556540045887 Adapter cache time: 0.025662889354862273 Engine time: 0.02269739133771509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8584510830114596,
    "estimated_duration": 3600.002505077332,
    "input_throughput": 3038.6056633493977,
    "output_throughput": 2698.7150665305726,
    "total_throughput": 5737.320729879971,
    "itl": 125.5772107684891,
    "ttft": 2419887.030229268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3754,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.61806105799895,
    "arrivals": 1850068,
    "finished_requests": 44363,
    "scheduler_time": 78.16140707572178
}
#Debug simulation 
Total elapsed time: 3.8585430340026505. Arrivals time: 0.338549880660139 Scheduler time: 3.233446892001666 Scheduler overhead time: 0.04121401335578412 Adapter cache time: 0.1839191365870647 Engine time: 0.04198918794281781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.3842904749908485,
    "estimated_duration": 3600.0102407945374,
    "input_throughput": 3649.5379516199114,
    "output_throughput": 3230.7935872518556,
    "total_throughput": 6880.331538871767,
    "itl": 265.03342254161777,
    "ttft": 2324512.89908766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.469813609353782,
    "arrivals": 1848950,
    "finished_requests": 53243,
    "scheduler_time": 65.92979076540486
}
#Debug simulation 
Total elapsed time: 4.38444689795142. Arrivals time: 0.2259035396273248 Scheduler time: 4.079261021572165 Scheduler overhead time: 0.022781048086471856 Adapter cache time: 0.02355232840636745 Engine time: 0.02261942980112508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.359546578023583,
    "estimated_duration": 3600.157324110858,
    "input_throughput": 3636.3649755870724,
    "output_throughput": 3220.8086914267715,
    "total_throughput": 6857.173667013843,
    "itl": 261.1929698862054,
    "ttft": 2326644.7087741494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6962921791919583,
    "arrivals": 1848950,
    "finished_requests": 53074,
    "scheduler_time": 66.03921412099153
}
#Debug simulation 
Total elapsed time: 4.359636363049503. Arrivals time: 0.23220155766466632 Scheduler time: 4.046972200972959 Scheduler overhead time: 0.02284457115456462 Adapter cache time: 0.02419747959356755 Engine time: 0.02298325503943488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.7244119319948368,
    "estimated_duration": 3600.0673615997207,
    "input_throughput": 3028.1172281053814,
    "output_throughput": 2700.2789180256636,
    "total_throughput": 5728.3961461310455,
    "itl": 125.15223922380386,
    "ttft": 2420718.9418939105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.017570959030852,
    "arrivals": 1848950,
    "finished_requests": 44204,
    "scheduler_time": 78.39286234708852
}
#Debug simulation 
Total elapsed time: 3.724553464038763. Arrivals time: 0.1962991171167232 Scheduler time: 3.2380690645659342 Scheduler overhead time: 0.041578818985726684 Adapter cache time: 0.1866730791516602 Engine time: 0.0423546364181675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.326841668982524,
    "estimated_duration": 3600.0271741638194,
    "input_throughput": 3636.49643923612,
    "output_throughput": 3220.9251316813393,
    "total_throughput": 6857.42157091746,
    "itl": 261.1845855245431,
    "ttft": 2326591.8714660094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5663588679278933,
    "arrivals": 1848950,
    "finished_requests": 53074,
    "scheduler_time": 66.038997485188
}
#Debug simulation 
Total elapsed time: 4.326932489988394. Arrivals time: 0.2230454096570611 Scheduler time: 4.023092243063729 Scheduler overhead time: 0.023046358895953745 Adapter cache time: 0.024488926108460873 Engine time: 0.022904293553438038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.201114454015624,
    "estimated_duration": 3600.0884964836914,
    "input_throughput": 3028.09945106842,
    "output_throughput": 2700.263065614903,
    "total_throughput": 5728.3625166833235,
    "itl": 125.15830049025296,
    "ttft": 2420688.1262363917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.18193115787505,
    "arrivals": 1848950,
    "finished_requests": 44204,
    "scheduler_time": 78.38988448660915
}
#Debug simulation 
Total elapsed time: 4.201261712005362. Arrivals time: 0.1995752095244825 Scheduler time: 3.7132679338683374 Scheduler overhead time: 0.04143537685740739 Adapter cache time: 0.18489112361567095 Engine time: 0.04252841335255653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.3338252429966815,
    "estimated_duration": 3600.212689791571,
    "input_throughput": 3636.8606880161924,
    "output_throughput": 3221.264408317889,
    "total_throughput": 6858.125096334082,
    "itl": 261.18196220315315,
    "ttft": 2326549.2675888357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4638014429993422,
    "arrivals": 1848950,
    "finished_requests": 53081,
    "scheduler_time": 66.04407526002124
}
#Debug simulation 
Total elapsed time: 4.333915614988655. Arrivals time: 0.22263862390536815 Scheduler time: 4.03039181913482 Scheduler overhead time: 0.02281641139416024 Adapter cache time: 0.02479317382676527 Engine time: 0.022879763680975884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.701325158996042,
    "estimated_duration": 3600.0898221528323,
    "input_throughput": 3027.9694503514606,
    "output_throughput": 2700.0356880504933,
    "total_throughput": 5728.005138401954,
    "itl": 125.1631037564728,
    "ttft": 2420724.840493739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.32794588979258,
    "arrivals": 1848950,
    "finished_requests": 44201,
    "scheduler_time": 78.38690045951286
}
#Debug simulation 
Total elapsed time: 3.701451133005321. Arrivals time: 0.1950298182782717 Scheduler time: 3.21749891579384 Scheduler overhead time: 0.04129540192661807 Adapter cache time: 0.1858210076461546 Engine time: 0.042310741264373064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.09926547203213,
    "estimated_duration": 3600.295853981723,
    "input_throughput": 3673.909738659813,
    "output_throughput": 3227.7575153019616,
    "total_throughput": 6901.667253961774,
    "itl": 264.2205428160608,
    "ttft": 2320086.4591542394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.00389746133019,
    "arrivals": 1692537,
    "finished_requests": 53325,
    "scheduler_time": 65.89543837419878
}
#Debug simulation 
Total elapsed time: 6.099364134017378. Arrivals time: 0.6891226735897362 Scheduler time: 5.309149411332328 Scheduler overhead time: 0.023196714115329087 Adapter cache time: 0.04408430907642469 Engine time: 0.0233566066599451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.603912862017751,
    "estimated_duration": 3600.2172121332455,
    "input_throughput": 3665.051640642967,
    "output_throughput": 3220.125430468314,
    "total_throughput": 6885.17707111128,
    "itl": 261.5449993727107,
    "ttft": 2321525.9263797486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.422187202959197,
    "arrivals": 1692537,
    "finished_requests": 53192,
    "scheduler_time": 65.96374635643141
}
#Debug simulation 
Total elapsed time: 5.604020635015331. Arrivals time: 0.24680273031117395 Scheduler time: 5.253445975249633 Scheduler overhead time: 0.02325656864559278 Adapter cache time: 0.04628553113434464 Engine time: 0.023687819368205965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.13465368503239,
    "estimated_duration": 3600.139235825199,
    "input_throughput": 2960.692712640832,
    "output_throughput": 2619.086480370177,
    "total_throughput": 5579.779193011009,
    "itl": 128.91728564774132,
    "ttft": 2427096.7199449437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.959350791238762,
    "arrivals": 1692537,
    "finished_requests": 42987,
    "scheduler_time": 76.03071106279654
}
#Debug simulation 
Total elapsed time: 4.134717683016788. Arrivals time: 0.6488912729546428 Scheduler time: 3.1621722588315606 Scheduler overhead time: 0.040568489697761834 Adapter cache time: 0.2227302070823498 Engine time: 0.04136449086945504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.567425424000248,
    "estimated_duration": 3600.279564821133,
    "input_throughput": 3665.286198588747,
    "output_throughput": 3220.3715826095904,
    "total_throughput": 6885.657781198338,
    "itl": 261.5269221595059,
    "ttft": 2321527.193197478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.190513657403521,
    "arrivals": 1692537,
    "finished_requests": 53198,
    "scheduler_time": 65.96892684303454
}
#Debug simulation 
Total elapsed time: 5.567560844996478. Arrivals time: 0.23348878900287673 Scheduler time: 5.231273494078778 Scheduler overhead time: 0.023274929320905358 Adapter cache time: 0.0452943894197233 Engine time: 0.023642009415198117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.133389135997277,
    "estimated_duration": 3600.021516521126,
    "input_throughput": 2960.7831372908545,
    "output_throughput": 2619.1110127340453,
    "total_throughput": 5579.8941500249,
    "itl": 128.9293210529062,
    "ttft": 2427083.936229623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7937,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.289609406142624,
    "arrivals": 1692537,
    "finished_requests": 42986,
    "scheduler_time": 76.02157291439623
}
#Debug simulation 
Total elapsed time: 4.133450207998976. Arrivals time: 0.19651618163334206 Scheduler time: 3.614292917540297 Scheduler overhead time: 0.040661008679308 Adapter cache time: 0.22157569194678217 Engine time: 0.0413341898820363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.57044882804621,
    "estimated_duration": 3600.0582675490537,
    "input_throughput": 3665.511505452375,
    "output_throughput": 3220.5695403628683,
    "total_throughput": 6886.081045815243,
    "itl": 261.51221632977644,
    "ttft": 2321446.8278160784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.969463590127276,
    "arrivals": 1692537,
    "finished_requests": 53198,
    "scheduler_time": 65.96867963817516
}
#Debug simulation 
Total elapsed time: 5.570601148006972. Arrivals time: 0.2328282956732437 Scheduler time: 5.235354632313829 Scheduler overhead time: 0.023171969514805824 Adapter cache time: 0.04517425276571885 Engine time: 0.023449685832019895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.1411245000199415,
    "estimated_duration": 3600.048802431431,
    "input_throughput": 2960.0387619198023,
    "output_throughput": 2618.896997627458,
    "total_throughput": 5578.93575954726,
    "itl": 128.94643963982105,
    "ttft": 2427080.703759605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.615340884735506,
    "arrivals": 1692537,
    "finished_requests": 42978,
    "scheduler_time": 76.01553715688564
}
#Debug simulation 
Total elapsed time: 4.141185917018447. Arrivals time: 0.1975255527650006 Scheduler time: 3.620536537258886 Scheduler overhead time: 0.04049756453605369 Adapter cache time: 0.22218037478160113 Engine time: 0.04137946123955771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.6020172770367935,
    "estimated_duration": 3600.0261248218058,
    "input_throughput": 3663.615635748431,
    "output_throughput": 3228.4987933456455,
    "total_throughput": 6892.1144290940765,
    "itl": 264.3817842027407,
    "ttft": 2318112.6004757797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.7016886669468825,
    "arrivals": 1577546,
    "finished_requests": 53616,
    "scheduler_time": 65.86015603792976
}
#Debug simulation 
Total elapsed time: 4.602119809016585. Arrivals time: 0.22858589002862573 Scheduler time: 4.267261016822886 Scheduler overhead time: 0.023027776391245425 Adapter cache time: 0.0498498392989859 Engine time: 0.022959333728067577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.746688521001488,
    "estimated_duration": 3600.0655711376935,
    "input_throughput": 3654.2226079072816,
    "output_throughput": 3221.557988549318,
    "total_throughput": 6875.7805964566,
    "itl": 261.99653015413753,
    "ttft": 2319327.592350873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.224879090795101,
    "arrivals": 1577546,
    "finished_requests": 53488,
    "scheduler_time": 65.92123574467769
}
#Debug simulation 
Total elapsed time: 4.746780322981067. Arrivals time: 0.22728050051955506 Scheduler time: 4.413497780449688 Scheduler overhead time: 0.023223011172376573 Adapter cache time: 0.04916275612777099 Engine time: 0.023107667511794716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.037898022972513,
    "estimated_duration": 3600.1145418736005,
    "input_throughput": 3137.6671127028267,
    "output_throughput": 2783.0706171880956,
    "total_throughput": 5920.737729890922,
    "itl": 121.89789703603779,
    "ttft": 2400075.756165107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.806285730599148,
    "arrivals": 1577546,
    "finished_requests": 45894,
    "scheduler_time": 80.5028558550528
}
#Debug simulation 
Total elapsed time: 4.038034463999793. Arrivals time: 0.20151641150005162 Scheduler time: 3.5386642673402093 Scheduler overhead time: 0.04265737161040306 Adapter cache time: 0.19154099823208526 Engine time: 0.043478412786498666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.78855850599939,
    "estimated_duration": 3600.08537544313,
    "input_throughput": 3654.2875037736226,
    "output_throughput": 3221.5980429554156,
    "total_throughput": 6875.885546729038,
    "itl": 261.97832819602957,
    "ttft": 2319291.0642319634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.95561477594293,
    "arrivals": 1577546,
    "finished_requests": 53489,
    "scheduler_time": 65.92633400891364
}
#Debug simulation 
Total elapsed time: 4.788650550006423. Arrivals time: 0.2405726364813745 Scheduler time: 4.441975511726923 Scheduler overhead time: 0.023250274010933936 Adapter cache time: 0.04935194121208042 Engine time: 0.022984282986726612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.026019387994893,
    "estimated_duration": 3600.0717084220946,
    "input_throughput": 3137.5136149581585,
    "output_throughput": 2782.912900474189,
    "total_throughput": 5920.4265154323475,
    "itl": 121.904769244976,
    "ttft": 2400145.3662369517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.004222190416227,
    "arrivals": 1577546,
    "finished_requests": 45891,
    "scheduler_time": 80.49712213181772
}
#Debug simulation 
Total elapsed time: 4.026150705001783. Arrivals time: 0.20190104033099487 Scheduler time: 3.5278599997982383 Scheduler overhead time: 0.04240788845345378 Adapter cache time: 0.19047262764070183 Engine time: 0.04337389476131648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.815250302024651,
    "estimated_duration": 3600.067145699043,
    "input_throughput": 3654.629890922564,
    "output_throughput": 3221.956016530829,
    "total_throughput": 6876.585907453393,
    "itl": 261.9077610029937,
    "ttft": 2319322.5758467694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.675115459724164,
    "arrivals": 1577546,
    "finished_requests": 53495,
    "scheduler_time": 65.93231932254523
}
#Debug simulation 
Total elapsed time: 4.815344898030162. Arrivals time: 0.4286189478589222 Scheduler time: 4.2808829102432355 Scheduler overhead time: 0.02319687866838649 Adapter cache time: 0.04881709913024679 Engine time: 0.02328685822430998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.029752405011095,
    "estimated_duration": 3600.0142360206755,
    "input_throughput": 3137.5631482183753,
    "output_throughput": 2782.8123288405973,
    "total_throughput": 5920.375477058973,
    "itl": 121.91113907907098,
    "ttft": 2400192.6207656767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.188577241300495,
    "arrivals": 1577546,
    "finished_requests": 45889,
    "scheduler_time": 80.49136188506237
}
#Debug simulation 
Total elapsed time: 4.029878815053962. Arrivals time: 0.3913667813758366 Scheduler time: 3.341476423724089 Scheduler overhead time: 0.0425421820837073 Adapter cache time: 0.19061068166047335 Engine time: 0.043702956463675946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.4310092379455455,
    "estimated_duration": 3600.0933206657023,
    "input_throughput": 3681.7506712712243,
    "output_throughput": 3226.2427569106135,
    "total_throughput": 6907.993428181838,
    "itl": 263.60607370571233,
    "ttft": 2314321.26262086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.628236961092494,
    "arrivals": 1558275,
    "finished_requests": 53627,
    "scheduler_time": 65.8805314355298
}
#Debug simulation 
Total elapsed time: 4.431101502967067. Arrivals time: 0.3491828489350155 Scheduler time: 3.9792012312682346 Scheduler overhead time: 0.022755237005185336 Adapter cache time: 0.04651614493923262 Engine time: 0.023075361095834523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.269819720997475,
    "estimated_duration": 3600.0297346747616,
    "input_throughput": 3674.0702090881337,
    "output_throughput": 3221.7339452191586,
    "total_throughput": 6895.804154307292,
    "itl": 261.60529369938536,
    "ttft": 2315209.587136132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.142662180745789,
    "arrivals": 1558275,
    "finished_requests": 53534,
    "scheduler_time": 65.92971343746899
}
#Debug simulation 
Total elapsed time: 4.269949520996306. Arrivals time: 0.22282809735042974 Scheduler time: 3.9423283988726325 Scheduler overhead time: 0.022964932024478912 Adapter cache time: 0.04837945458712056 Engine time: 0.02287667983910069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9119284960324876,
    "estimated_duration": 3600.018967214695,
    "input_throughput": 3211.468357608382,
    "output_throughput": 2835.4528387103474,
    "total_throughput": 6046.92119631873,
    "itl": 118.73242429818664,
    "ttft": 2389087.222050042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.354183346777553,
    "arrivals": 1558275,
    "finished_requests": 46830,
    "scheduler_time": 82.30494931210247
}
#Debug simulation 
Total elapsed time: 3.912021693016868. Arrivals time: 0.2185055603622459 Scheduler time: 3.4065825254656374 Scheduler overhead time: 0.043530354159884155 Adapter cache time: 0.17818418837850913 Engine time: 0.04461609455756843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.244241777982097,
    "estimated_duration": 3600.1684706050673,
    "input_throughput": 3675.0116301575104,
    "output_throughput": 3222.3264257548135,
    "total_throughput": 6897.338055912324,
    "itl": 261.5834503133299,
    "ttft": 2315171.9829435754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.875310959420001,
    "arrivals": 1558275,
    "finished_requests": 53544,
    "scheduler_time": 65.93697860338524
}
#Debug simulation 
Total elapsed time: 4.244380401971284. Arrivals time: 0.2272202066378668 Scheduler time: 3.912328337377403 Scheduler overhead time: 0.02289010788081214 Adapter cache time: 0.04837327415589243 Engine time: 0.023095652752090245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.887102466018405,
    "estimated_duration": 3600.0417935955943,
    "input_throughput": 3211.1960534918794,
    "output_throughput": 2835.102086358315,
    "total_throughput": 6046.298139850194,
    "itl": 118.7381881987694,
    "ttft": 2389147.8120878204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.512381610087404,
    "arrivals": 1558275,
    "finished_requests": 46826,
    "scheduler_time": 82.30199744478206
}
#Debug simulation 
Total elapsed time: 3.8871949129970744. Arrivals time: 0.2053559203632176 Scheduler time: 3.394021064043045 Scheduler overhead time: 0.04349933739285916 Adapter cache time: 0.1794929932220839 Engine time: 0.044327593699563295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.250177964975592,
    "estimated_duration": 3600.201018783754,
    "input_throughput": 3675.160062165056,
    "output_throughput": 3222.4558960652976,
    "total_throughput": 6897.6159582303535,
    "itl": 261.56683617317026,
    "ttft": 2315105.932447713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1879,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.618304504121025,
    "arrivals": 1558275,
    "finished_requests": 53546,
    "scheduler_time": 65.94207534224141
}
#Debug simulation 
Total elapsed time: 4.250339849968441. Arrivals time: 0.2251254101865925 Scheduler time: 3.9207720328704454 Scheduler overhead time: 0.022884659469127655 Adapter cache time: 0.048127297894097865 Engine time: 0.022915964014828205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0235796319902875,
    "estimated_duration": 3600.048526011636,
    "input_throughput": 3211.0408836090883,
    "output_throughput": 2835.0117856069733,
    "total_throughput": 6046.052669216061,
    "itl": 118.74281316111751,
    "ttft": 2389098.7859883294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.65448338873616,
    "arrivals": 1558275,
    "finished_requests": 46825,
    "scheduler_time": 82.29904809725369
}
#Debug simulation 
Total elapsed time: 4.023673971008975. Arrivals time: 0.20941035612486303 Scheduler time: 3.5259595759562217 Scheduler overhead time: 0.04411031003110111 Adapter cache time: 0.17883237433852628 Engine time: 0.04464404354803264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.180765948956832,
    "estimated_duration": 3600.1489550661418,
    "input_throughput": 3674.9193339298745,
    "output_throughput": 3226.4459457029875,
    "total_throughput": 6901.365279632862,
    "itl": 264.3550053080474,
    "ttft": 2317910.228056079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.508877939079112,
    "arrivals": 1548789,
    "finished_requests": 53431,
    "scheduler_time": 65.87055578946004
}
#Debug simulation 
Total elapsed time: 4.180939005978871. Arrivals time: 0.22131068666931242 Scheduler time: 3.856875784462318 Scheduler overhead time: 0.022515002347063273 Adapter cache time: 0.04703942668857053 Engine time: 0.022774774522986263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.179958752996754,
    "estimated_duration": 3600.004397358688,
    "input_throughput": 3666.050799738796,
    "output_throughput": 3218.4127354124435,
    "total_throughput": 6884.463535151239,
    "itl": 261.9032575718187,
    "ttft": 2319561.74203226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.004283730422439,
    "arrivals": 1548789,
    "finished_requests": 53294,
    "scheduler_time": 65.93022361256537
}
#Debug simulation 
Total elapsed time: 4.180053421994671. Arrivals time: 0.22168818721547723 Scheduler time: 3.854069355293177 Scheduler overhead time: 0.02291651739506051 Adapter cache time: 0.047544272732920945 Engine time: 0.023403344152029604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.879165960010141,
    "estimated_duration": 3600.0730396874205,
    "input_throughput": 3227.1653580141656,
    "output_throughput": 2848.7260916490886,
    "total_throughput": 6075.891449663254,
    "itl": 117.74416598380623,
    "ttft": 2392525.423982886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.329325475059193,
    "arrivals": 1548789,
    "finished_requests": 46895,
    "scheduler_time": 82.92026049433561
}
#Debug simulation 
Total elapsed time: 3.879303327004891. Arrivals time: 0.20122188853565603 Scheduler time: 3.3881968243513256 Scheduler overhead time: 0.043890347762499005 Adapter cache time: 0.18005617323797196 Engine time: 0.04516279185190797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.161350668990053,
    "estimated_duration": 3600.0297331891015,
    "input_throughput": 3666.2961081456983,
    "output_throughput": 3218.782304260297,
    "total_throughput": 6885.078412405996,
    "itl": 261.8876199113959,
    "ttft": 2319482.640587681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.734332107999206,
    "arrivals": 1548789,
    "finished_requests": 53299,
    "scheduler_time": 65.93544647085434
}
#Debug simulation 
Total elapsed time: 4.161440347030293. Arrivals time: 0.21983518643537536 Scheduler time: 3.8382777632796206 Scheduler overhead time: 0.022722843859810382 Adapter cache time: 0.047365667880512774 Engine time: 0.02280069194966927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.00822151300963,
    "estimated_duration": 3600.0673029087334,
    "input_throughput": 3227.0643914388297,
    "output_throughput": 2848.685076446747,
    "total_throughput": 6075.749467885576,
    "itl": 117.74826674072962,
    "ttft": 2392571.378424078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.458097352347885,
    "arrivals": 1548789,
    "finished_requests": 46894,
    "scheduler_time": 82.91727911953073
}
#Debug simulation 
Total elapsed time: 4.008362673979718. Arrivals time: 0.31623521738220006 Scheduler time: 3.4033340912428685 Scheduler overhead time: 0.04387702577514574 Adapter cache time: 0.179033299558796 Engine time: 0.045167234377004206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.160343088035006,
    "estimated_duration": 3600.08638598983,
    "input_throughput": 3666.436186466912,
    "output_throughput": 3218.9474800099247,
    "total_throughput": 6885.383666476837,
    "itl": 261.873084563359,
    "ttft": 2319436.506580353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.49571244203004,
    "arrivals": 1548789,
    "finished_requests": 53302,
    "scheduler_time": 65.94065434301184
}
#Debug simulation 
Total elapsed time: 4.160437365993857. Arrivals time: 0.2240985826938413 Scheduler time: 3.833235008060001 Scheduler overhead time: 0.02278489450691268 Adapter cache time: 0.046937501057982445 Engine time: 0.022933486266992986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.319386831019074,
    "estimated_duration": 3600.044757059132,
    "input_throughput": 3227.0662683345017,
    "output_throughput": 2848.6006958361704,
    "total_throughput": 6075.666964170672,
    "itl": 117.75189051302813,
    "ttft": 2392595.2121698987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2853,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.570269729829839,
    "arrivals": 1548789,
    "finished_requests": 46893,
    "scheduler_time": 82.9143041769478
}
#Debug simulation 
Total elapsed time: 4.319483163999394. Arrivals time: 0.6368090592441149 Scheduler time: 3.392895233875606 Scheduler overhead time: 0.043869177519809455 Adapter cache time: 0.17988381738541648 Engine time: 0.045392559841275215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.148082164989319,
    "estimated_duration": 3600.1605413194115,
    "input_throughput": 3679.286200705235,
    "output_throughput": 3224.9906265971435,
    "total_throughput": 6904.2768273023785,
    "itl": 263.81607053197393,
    "ttft": 2314345.8133035367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.028381363281653,
    "arrivals": 1544103,
    "finished_requests": 53482,
    "scheduler_time": 65.88170010526733
}
#Debug simulation 
Total elapsed time: 4.1481457100017. Arrivals time: 0.2229871196905151 Scheduler time: 3.824544531700667 Scheduler overhead time: 0.022538371791597456 Adapter cache time: 0.04489771381486207 Engine time: 0.022844261955469847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.154203907994088,
    "estimated_duration": 3600.0558187400197,
    "input_throughput": 3669.638934827314,
    "output_throughput": 3216.51790500647,
    "total_throughput": 6886.156839833784,
    "itl": 260.5247692514589,
    "ttft": 2316291.077086511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.642950338639642,
    "arrivals": 1544103,
    "finished_requests": 53339,
    "scheduler_time": 65.9648658782429
}
#Debug simulation 
Total elapsed time: 4.154351110977586. Arrivals time: 0.22154439485166222 Scheduler time: 3.830403698142618 Scheduler overhead time: 0.022759670100640506 Adapter cache time: 0.04587583354441449 Engine time: 0.023252992832567543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9950603499892168,
    "estimated_duration": 3600.004846357546,
    "input_throughput": 3215.542615647439,
    "output_throughput": 2843.3828388750344,
    "total_throughput": 6058.925454522473,
    "itl": 116.78651196402889,
    "ttft": 2385212.265415849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.097935951538332,
    "arrivals": 1544103,
    "finished_requests": 46760,
    "scheduler_time": 83.11444703988835
}
#Debug simulation 
Total elapsed time: 3.9951525059877895. Arrivals time: 0.20385714521398768 Scheduler time: 3.5111475452431478 Scheduler overhead time: 0.044085860485211015 Adapter cache time: 0.17012105538742617 Engine time: 0.04522296186769381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.138926799991168,
    "estimated_duration": 3600.108412381789,
    "input_throughput": 3669.63671276213,
    "output_throughput": 3216.610355447244,
    "total_throughput": 6886.247068209374,
    "itl": 260.5095070398983,
    "ttft": 2316229.611890974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.396567361620119,
    "arrivals": 1544103,
    "finished_requests": 53341,
    "scheduler_time": 65.97012135938867
}
#Debug simulation 
Total elapsed time: 4.139063529029954. Arrivals time: 0.21996500150999054 Scheduler time: 3.8167721435893327 Scheduler overhead time: 0.022862756450194865 Adapter cache time: 0.045698575384449214 Engine time: 0.023243056144565344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.8475277289981022,
    "estimated_duration": 3600.115489700672,
    "input_throughput": 3215.4437914886093,
    "output_throughput": 2843.2954524053557,
    "total_throughput": 6058.739243893965,
    "itl": 116.79028525498481,
    "ttft": 2385250.4806986763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.208473529796832,
    "arrivals": 1544103,
    "finished_requests": 46760,
    "scheduler_time": 83.11455280484293
}
#Debug simulation 
Total elapsed time: 3.847618466010317. Arrivals time: 0.20171020069392398 Scheduler time: 3.367801198735833 Scheduler overhead time: 0.044242975825909525 Adapter cache time: 0.16810202272608876 Engine time: 0.045067298342473805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.162429824005812,
    "estimated_duration": 3600.1811136970455,
    "input_throughput": 3669.921201945347,
    "output_throughput": 3216.744001000425,
    "total_throughput": 6886.665202945772,
    "itl": 260.495341361673,
    "ttft": 2316163.3778566797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.169796959885715,
    "arrivals": 1544103,
    "finished_requests": 53347,
    "scheduler_time": 65.97538439966802
}
#Debug simulation 
Total elapsed time: 4.162570749991573. Arrivals time: 0.22443286300403997 Scheduler time: 3.8375413049943745 Scheduler overhead time: 0.02290095022181049 Adapter cache time: 0.0441195085295476 Engine time: 0.02302108221920207 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.896067049005069,
    "estimated_duration": 3600.07056006517,
    "input_throughput": 3215.4836431290523,
    "output_throughput": 2843.3006601444786,
    "total_throughput": 6058.784303273531,
    "itl": 116.79332979636952,
    "ttft": 2385203.4049525135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.305192777439592,
    "arrivals": 1544103,
    "finished_requests": 46759,
    "scheduler_time": 83.11152488189356
}
#Debug simulation 
Total elapsed time: 3.8961551259853877. Arrivals time: 0.21466113673523068 Scheduler time: 3.4019989651278593 Scheduler overhead time: 0.04422917478950694 Adapter cache time: 0.1692577851936221 Engine time: 0.045207924500573426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.133962701016571,
    "estimated_duration": 3600.279624111019,
    "input_throughput": 3674.7206831932554,
    "output_throughput": 3228.895034193469,
    "total_throughput": 6903.615717386725,
    "itl": 263.70952062231044,
    "ttft": 2312321.1521525993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.371155990602134,
    "arrivals": 1541713,
    "finished_requests": 53812,
    "scheduler_time": 65.89316377590966
}
#Debug simulation 
Total elapsed time: 4.134095503017306. Arrivals time: 0.22443211695645005 Scheduler time: 3.808566684368998 Scheduler overhead time: 0.022715277038514614 Adapter cache time: 0.04529170470777899 Engine time: 0.022682535520289093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.150451836001594,
    "estimated_duration": 3600.10344920982,
    "input_throughput": 3667.6723839416672,
    "output_throughput": 3222.1476864910856,
    "total_throughput": 6889.820070432753,
    "itl": 261.60362852062497,
    "ttft": 2313652.487965984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.795610678987416,
    "arrivals": 1541713,
    "finished_requests": 53706,
    "scheduler_time": 65.94445127896525
}
#Debug simulation 
Total elapsed time: 4.150553612038493. Arrivals time: 0.23465644172392786 Scheduler time: 3.812665938748978 Scheduler overhead time: 0.02280651981709525 Adapter cache time: 0.047059990058187395 Engine time: 0.02289911441039294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.90421597805107,
    "estimated_duration": 3600.094748569703,
    "input_throughput": 3253.0991037535605,
    "output_throughput": 2868.7950516033584,
    "total_throughput": 6121.894155356918,
    "itl": 118.17122117144932,
    "ttft": 2382602.1192676863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.802443706896118,
    "arrivals": 1541713,
    "finished_requests": 47574,
    "scheduler_time": 82.97712132532098
}
#Debug simulation 
Total elapsed time: 3.904308180033695. Arrivals time: 0.2034668168053031 Scheduler time: 3.41589575575199 Scheduler overhead time: 0.04372119239997119 Adapter cache time: 0.17556169664021581 Engine time: 0.045065823826007545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.2612704270286486,
    "estimated_duration": 3600.1001439325096,
    "input_throughput": 3668.3848981973156,
    "output_throughput": 3222.775905152017,
    "total_throughput": 6891.160803349332,
    "itl": 261.5845851117678,
    "ttft": 2313545.4792974256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.545810110233576,
    "arrivals": 1541713,
    "finished_requests": 53715,
    "scheduler_time": 65.9495421154757
}
#Debug simulation 
Total elapsed time: 4.261363380996045. Arrivals time: 0.34004339698003605 Scheduler time: 3.8184850678080693 Scheduler overhead time: 0.022843859042041004 Adapter cache time: 0.046702805208042264 Engine time: 0.022851141402497888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9180535040213726,
    "estimated_duration": 3600.069091090312,
    "input_throughput": 3253.122288398382,
    "output_throughput": 2868.81549733594,
    "total_throughput": 6121.9377857343225,
    "itl": 118.17493164784592,
    "ttft": 2382655.429304501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.909082917775759,
    "arrivals": 1541713,
    "finished_requests": 47574,
    "scheduler_time": 82.97415009587323
}
#Debug simulation 
Total elapsed time: 3.9181475730147213. Arrivals time: 0.2071445134934038 Scheduler time: 3.4267755552427843 Scheduler overhead time: 0.043865881161764264 Adapter cache time: 0.1746439155540429 Engine time: 0.04507726134033874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.171438056975603,
    "estimated_duration": 3600.1676220008326,
    "input_throughput": 3668.397804394494,
    "output_throughput": 3222.9546560810986,
    "total_throughput": 6891.352460475592,
    "itl": 261.57059603733205,
    "ttft": 2313500.044314707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.313319374041014,
    "arrivals": 1541713,
    "finished_requests": 53718,
    "scheduler_time": 65.95481470419807
}
#Debug simulation 
Total elapsed time: 4.171532769978512. Arrivals time: 0.2371676404727623 Scheduler time: 3.8301412263535894 Scheduler overhead time: 0.023202713520731777 Adapter cache time: 0.04739523184252903 Engine time: 0.023113255156204104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.935852419002913,
    "estimated_duration": 3600.0315268994655,
    "input_throughput": 3253.156232797362,
    "output_throughput": 2868.8454317218034,
    "total_throughput": 6122.001664519165,
    "itl": 118.1781504194886,
    "ttft": 2382672.0629438497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.004027026518846,
    "arrivals": 1541713,
    "finished_requests": 47574,
    "scheduler_time": 82.97117999382212
}
#Debug simulation 
Total elapsed time: 3.9359684769879095. Arrivals time: 0.20463090896373615 Scheduler time: 3.4455531870480627 Scheduler overhead time: 0.043846664717420936 Adapter cache time: 0.17601504194317386 Engine time: 0.0451258507091552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.5582876760163344,
    "estimated_duration": 3600.240310812379,
    "input_throughput": 3670.1002875606623,
    "output_throughput": 3227.9570241736656,
    "total_throughput": 6898.057311734327,
    "itl": 264.4425770618526,
    "ttft": 2312623.9375020736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.107954044623908,
    "arrivals": 1540502,
    "finished_requests": 53364,
    "scheduler_time": 65.88221822762193
}
#Debug simulation 
Total elapsed time: 4.558356916997582. Arrivals time: 0.6564942059339955 Scheduler time: 3.8018809749628417 Scheduler overhead time: 0.022422921378165483 Adapter cache time: 0.044423308107070625 Engine time: 0.022855896095279604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.116556028020568,
    "estimated_duration": 3600.276152220494,
    "input_throughput": 3661.715502536988,
    "output_throughput": 3221.8681316559178,
    "total_throughput": 6883.583634192905,
    "itl": 261.9029337472792,
    "ttft": 2313158.321320184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.635335856776077,
    "arrivals": 1540502,
    "finished_requests": 53241,
    "scheduler_time": 65.95376114849475
}
#Debug simulation 
Total elapsed time: 4.11662264901679. Arrivals time: 0.22093986673280597 Scheduler time: 3.7928548322524875 Scheduler overhead time: 0.02272294508293271 Adapter cache time: 0.04673975973855704 Engine time: 0.02292490901891142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.044174722977914,
    "estimated_duration": 3600.082200070004,
    "input_throughput": 3233.760884619141,
    "output_throughput": 2868.829217232643,
    "total_throughput": 6102.590101851783,
    "itl": 117.84754093040615,
    "ttft": 2380774.089114366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.4764996909722425,
    "arrivals": 1540502,
    "finished_requests": 47090,
    "scheduler_time": 83.11205558546058
}
#Debug simulation 
Total elapsed time: 4.044273530016653. Arrivals time: 0.32332474150462076 Scheduler time: 3.4401915420312434 Scheduler overhead time: 0.04403529077535495 Adapter cache time: 0.17103086755378172 Engine time: 0.044991264410782605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.112496682966594,
    "estimated_duration": 3600.0287353507883,
    "input_throughput": 3661.9671589136424,
    "output_throughput": 3222.089558923959,
    "total_throughput": 6884.056717837601,
    "itl": 261.88598092239306,
    "ttft": 2313069.6255190345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.388135689119669,
    "arrivals": 1540502,
    "finished_requests": 53241,
    "scheduler_time": 65.9535444463809
}
#Debug simulation 
Total elapsed time: 4.112615001969971. Arrivals time: 0.2233161519980058 Scheduler time: 3.787300416151993 Scheduler overhead time: 0.022798335587140173 Adapter cache time: 0.04587071522837505 Engine time: 0.022944508760701865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.3442271270323545,
    "estimated_duration": 3600.0498914322025,
    "input_throughput": 3233.7899059972633,
    "output_throughput": 2868.8549635325244,
    "total_throughput": 6102.644869529788,
    "itl": 117.85102482265566,
    "ttft": 2380825.022912076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.5778572428224855,
    "arrivals": 1540502,
    "finished_requests": 47090,
    "scheduler_time": 83.10906552436803
}
#Debug simulation 
Total elapsed time: 4.344291184039321. Arrivals time: 0.6338587123318575 Scheduler time: 3.427975485450588 Scheduler overhead time: 0.04391020181355998 Adapter cache time: 0.1729679848649539 Engine time: 0.0448985708062537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.136528042028658,
    "estimated_duration": 3600.0900177959893,
    "input_throughput": 3662.3959219975172,
    "output_throughput": 3222.325259272833,
    "total_throughput": 6884.72118127035,
    "itl": 261.8707611749568,
    "ttft": 2313025.240406979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.163816859295911,
    "arrivals": 1540502,
    "finished_requests": 53246,
    "scheduler_time": 65.95858813892409
}
#Debug simulation 
Total elapsed time: 4.136595831019804. Arrivals time: 0.22324505890719593 Scheduler time: 3.8099895308259875 Scheduler overhead time: 0.02287684369366616 Adapter cache time: 0.046997869678307325 Engine time: 0.0230250564054586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.025454533053562,
    "estimated_duration": 3600.0091071803226,
    "input_throughput": 3233.7437638090073,
    "output_throughput": 2868.8760757300706,
    "total_throughput": 6102.619839539078,
    "itl": 117.85384408261083,
    "ttft": 2380874.6301207934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.671166552342179,
    "arrivals": 1540502,
    "finished_requests": 47089,
    "scheduler_time": 83.10607519827671
}
#Debug simulation 
Total elapsed time: 4.025546748016495. Arrivals time: 0.20932212786283344 Scheduler time: 3.5350550714647397 Scheduler overhead time: 0.04380536382086575 Adapter cache time: 0.17166984523646533 Engine time: 0.04506293433951214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.171374452009331,
    "estimated_duration": 3600.2939897441133,
    "input_throughput": 3656.4602883820717,
    "output_throughput": 3227.1253495122987,
    "total_throughput": 6883.58563789437,
    "itl": 264.96862498608357,
    "ttft": 2314729.482767999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.73847200119382,
    "arrivals": 1423678,
    "finished_requests": 53330,
    "scheduler_time": 65.85128534767338
}
#Debug simulation 
Total elapsed time: 4.171488044026773. Arrivals time: 0.21874053380452096 Scheduler time: 3.822476732020732 Scheduler overhead time: 0.022611057269386947 Adapter cache time: 0.07459705101791769 Engine time: 0.022692790429573506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.158127165981568,
    "estimated_duration": 3600.2837720820103,
    "input_throughput": 3649.6998103016995,
    "output_throughput": 3222.1835095213564,
    "total_throughput": 6871.883319823056,
    "itl": 262.3531042343648,
    "ttft": 2315626.6455893726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.574155030367066,
    "arrivals": 1423678,
    "finished_requests": 53228,
    "scheduler_time": 65.93911801569824
}
#Debug simulation 
Total elapsed time: 4.158218096010387. Arrivals time: 0.22046268358826637 Scheduler time: 3.804952576814685 Scheduler overhead time: 0.0227471090038307 Adapter cache time: 0.07674141263123602 Engine time: 0.022845526284072548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.027196534967516,
    "estimated_duration": 3600.023459304457,
    "input_throughput": 3355.4725785964392,
    "output_throughput": 2978.344202810158,
    "total_throughput": 6333.816781406597,
    "itl": 113.72435053083456,
    "ttft": 2366142.4493764276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.121618129666334,
    "arrivals": 1423678,
    "finished_requests": 48802,
    "scheduler_time": 86.27360835783223
}
#Debug simulation 
Total elapsed time: 4.027289129968267. Arrivals time: 0.20365272014169022 Scheduler time: 3.543049960921053 Scheduler overhead time: 0.04558156261919066 Adapter cache time: 0.1668539202073589 Engine time: 0.0467384738731198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.200204303022474,
    "estimated_duration": 3600.106444874163,
    "input_throughput": 3650.2781796106974,
    "output_throughput": 3222.591936557454,
    "total_throughput": 6872.870116168151,
    "itl": 262.3134534776507,
    "ttft": 2315544.2220516778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.111216534574204,
    "arrivals": 1423678,
    "finished_requests": 53236,
    "scheduler_time": 65.9441717210992
}
#Debug simulation 
Total elapsed time: 4.200296719034668. Arrivals time: 0.23320172692183405 Scheduler time: 3.8340668159071356 Scheduler overhead time: 0.022912071202881634 Adapter cache time: 0.0765023700078018 Engine time: 0.023086747445631772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.462967664992902,
    "estimated_duration": 3600.051601473735,
    "input_throughput": 3355.0771869646273,
    "output_throughput": 2977.9362039175526,
    "total_throughput": 6333.01339088218,
    "itl": 113.72975018234659,
    "ttft": 2366152.6888933205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.27151664307279,
    "arrivals": 1423678,
    "finished_requests": 48798,
    "scheduler_time": 86.27075316792167
}
#Debug simulation 
Total elapsed time: 4.463046834978741. Arrivals time: 0.6314165005460382 Scheduler time: 3.5514841261901893 Scheduler overhead time: 0.04548216669354588 Adapter cache time: 0.16662386804819107 Engine time: 0.046613152720965445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.166512494033668,
    "estimated_duration": 3600.2479358126034,
    "input_throughput": 3650.563581819967,
    "output_throughput": 3222.739713169557,
    "total_throughput": 6873.303294989524,
    "itl": 262.28335732021026,
    "ttft": 2315560.9652533056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.681782854893436,
    "arrivals": 1423678,
    "finished_requests": 53242,
    "scheduler_time": 65.95446871333809
}
#Debug simulation 
Total elapsed time: 4.16657646902604. Arrivals time: 0.22989874053746462 Scheduler time: 3.803037023637444 Scheduler overhead time: 0.0227636867784895 Adapter cache time: 0.07761723943985999 Engine time: 0.022802912979386747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.030064610007685,
    "estimated_duration": 3600.0672983283257,
    "input_throughput": 3354.8706174488048,
    "output_throughput": 2977.6190586708226,
    "total_throughput": 6332.489676119627,
    "itl": 113.73351438479176,
    "ttft": 2366208.2809166512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.408965531624187,
    "arrivals": 1423678,
    "finished_requests": 48793,
    "scheduler_time": 86.26790228818169
}
#Debug simulation 
Total elapsed time: 4.030176997999661. Arrivals time: 0.20505181478802115 Scheduler time: 3.5447362731210887 Scheduler overhead time: 0.04527999396668747 Adapter cache time: 0.16667397395940498 Engine time: 0.0470438227057457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.169887454016134,
    "estimated_duration": 3600.060492034592,
    "input_throughput": 3718.420295886343,
    "output_throughput": 3285.1031326187954,
    "total_throughput": 7003.523428505138,
    "itl": 260.4627690487863,
    "ttft": 2303934.456978093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2742,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.391857393863752,
    "arrivals": 1404624,
    "finished_requests": 54284,
    "scheduler_time": 66.98846710648095
}
#Debug simulation 
Total elapsed time: 4.169982713996433. Arrivals time: 0.22673061571549624 Scheduler time: 3.8175021656788886 Scheduler overhead time: 0.022545032610651106 Adapter cache time: 0.0700053067994304 Engine time: 0.022856007504742593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.55832971498603,
    "estimated_duration": 3600.124471868223,
    "input_throughput": 3716.8573210625914,
    "output_throughput": 3284.0820067158966,
    "total_throughput": 7000.939327778488,
    "itl": 257.5418692754541,
    "ttft": 2304119.9041043087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.968622425508036,
    "arrivals": 1404624,
    "finished_requests": 54257,
    "scheduler_time": 67.17063326105682
}
#Debug simulation 
Total elapsed time: 4.558391669008415. Arrivals time: 0.634369294042699 Scheduler time: 3.798027877113782 Scheduler overhead time: 0.022621065087150782 Adapter cache time: 0.0699011737597175 Engine time: 0.023045336245559156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.082300046982709,
    "estimated_duration": 3600.0237710985148,
    "input_throughput": 3395.721188882525,
    "output_throughput": 3020.1670020312954,
    "total_throughput": 6415.888190913821,
    "itl": 112.61350001954895,
    "ttft": 2360510.114974383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.437715406138361,
    "arrivals": 1404624,
    "finished_requests": 49581,
    "scheduler_time": 87.22738949943658
}
#Debug simulation 
Total elapsed time: 4.082362563989591. Arrivals time: 0.21016650961246341 Scheduler time: 3.6037215975811705 Scheduler overhead time: 0.04591310292016715 Adapter cache time: 0.1537437574006617 Engine time: 0.04712189402198419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.138747392978985,
    "estimated_duration": 3600.0197109193623,
    "input_throughput": 3717.194925186271,
    "output_throughput": 3284.456183430283,
    "total_throughput": 7001.651108616554,
    "itl": 257.51702070356674,
    "ttft": 2304051.801883028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.57718811044219,
    "arrivals": 1404624,
    "finished_requests": 54262,
    "scheduler_time": 67.17574531856613
}
#Debug simulation 
Total elapsed time: 4.138838266953826. Arrivals time: 0.2182484397199005 Scheduler time: 3.7932364650187083 Scheduler overhead time: 0.02263621467864141 Adapter cache time: 0.07133249525213614 Engine time: 0.022943684074562043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.061852764978539,
    "estimated_duration": 3600.010377290349,
    "input_throughput": 3395.6821561167594,
    "output_throughput": 3020.037683386693,
    "total_throughput": 6415.719839503452,
    "itl": 112.6169912082523,
    "ttft": 2360535.1694296086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.552528613134967,
    "arrivals": 1404624,
    "finished_requests": 49580,
    "scheduler_time": 87.22441170490376
}
#Debug simulation 
Total elapsed time: 4.061972618976142. Arrivals time: 0.20625762653071433 Scheduler time: 3.588728984061163 Scheduler overhead time: 0.045964682125486434 Adapter cache time: 0.15256047307047993 Engine time: 0.046894892351701856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.243687937036157,
    "estimated_duration": 3600.0088151145087,
    "input_throughput": 3717.2242311785412,
    "output_throughput": 3284.528624028909,
    "total_throughput": 7001.75285520745,
    "itl": 257.5365390705375,
    "ttft": 2303895.730175048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2749,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.21964826068589,
    "arrivals": 1404624,
    "finished_requests": 54263,
    "scheduler_time": 67.17909286542343
}
#Debug simulation 
Total elapsed time: 4.243778870033566. Arrivals time: 0.31531391898170114 Scheduler time: 3.802759575424716 Scheduler overhead time: 0.022620787320192903 Adapter cache time: 0.06969606841448694 Engine time: 0.022944355325307697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.069038960034959,
    "estimated_duration": 3600.1173730442533,
    "input_throughput": 3395.5812361925828,
    "output_throughput": 3019.947927643957,
    "total_throughput": 6415.52916383654,
    "itl": 112.62051941883306,
    "ttft": 2360571.470088557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.659419331587461,
    "arrivals": 1404624,
    "finished_requests": 49580,
    "scheduler_time": 87.22451674044486
}
#Debug simulation 
Total elapsed time: 4.069133959012106. Arrivals time: 0.20633020770037547 Scheduler time: 3.594419381057378 Scheduler overhead time: 0.04601463285507634 Adapter cache time: 0.15358191885752603 Engine time: 0.04718996142037213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.180393580987584,
    "estimated_duration": 3600.1120842541454,
    "input_throughput": 3824.5359249287226,
    "output_throughput": 3331.639882119092,
    "total_throughput": 7156.1758070478145,
    "itl": 254.68451142039788,
    "ttft": 2292247.8025663476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.075847663972737,
    "arrivals": 1395198,
    "finished_requests": 55542,
    "scheduler_time": 68.04501777791744
}
#Debug simulation 
Total elapsed time: 4.180498441972304. Arrivals time: 0.22324082168051973 Scheduler time: 3.834894584841095 Scheduler overhead time: 0.022591808112338185 Adapter cache time: 0.06622660893481225 Engine time: 0.023016282357275486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.198813101975247,
    "estimated_duration": 3600.0013243582257,
    "input_throughput": 3822.583038202975,
    "output_throughput": 3330.1796082359006,
    "total_throughput": 7152.762646438876,
    "itl": 251.6998354930796,
    "ttft": 2292475.957404258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.536401800808645,
    "arrivals": 1395198,
    "finished_requests": 55509,
    "scheduler_time": 68.24031722859615
}
#Debug simulation 
Total elapsed time: 4.198906555015128. Arrivals time: 0.22078106045955792 Scheduler time: 3.8543140488909557 Scheduler overhead time: 0.022862427693326026 Adapter cache time: 0.06685975065920502 Engine time: 0.02349467558087781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.086646651965566,
    "estimated_duration": 3600.056764007935,
    "input_throughput": 3465.99396008093,
    "output_throughput": 3038.1048736085686,
    "total_throughput": 6504.098833689499,
    "itl": 110.8126107644855,
    "ttft": 2348197.8569717174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8618166716955225,
    "arrivals": 1395198,
    "finished_requests": 50263,
    "scheduler_time": 88.16824762634899
}
#Debug simulation 
Total elapsed time: 4.086741078004707. Arrivals time: 0.20616723754210398 Scheduler time: 3.614383892097976 Scheduler overhead time: 0.04658312862738967 Adapter cache time: 0.14954526582732797 Engine time: 0.047980109113268554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.234595826012082,
    "estimated_duration": 3600.2246143883085,
    "input_throughput": 3822.9250877832937,
    "output_throughput": 3330.457758685485,
    "total_throughput": 7153.382846468779,
    "itl": 251.6798705066927,
    "ttft": 2292463.367052157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.190730161408176,
    "arrivals": 1395198,
    "finished_requests": 55515,
    "scheduler_time": 68.25086579562745
}
#Debug simulation 
Total elapsed time: 4.234690645011142. Arrivals time: 0.23220967192901298 Scheduler time: 3.878107036696747 Scheduler overhead time: 0.022909556631930172 Adapter cache time: 0.06745380064239725 Engine time: 0.023357053170911968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.080399493977893,
    "estimated_duration": 3600.0291952043435,
    "input_throughput": 3465.8438372169303,
    "output_throughput": 3038.076750757903,
    "total_throughput": 6503.920587974833,
    "itl": 110.8155523634569,
    "ttft": 2348167.7353193234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.957138041797888,
    "arrivals": 1395198,
    "finished_requests": 50262,
    "scheduler_time": 88.16531691104946
}
#Debug simulation 
Total elapsed time: 4.080491441010963. Arrivals time: 0.2072703099111095 Scheduler time: 3.606771591643337 Scheduler overhead time: 0.046844853030052036 Adapter cache time: 0.15008414338808507 Engine time: 0.047658481169492006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.196889295009896,
    "estimated_duration": 3600.2190639627925,
    "input_throughput": 3823.3862316280038,
    "output_throughput": 3330.63566048711,
    "total_throughput": 7154.021892115114,
    "itl": 251.6621607527532,
    "ttft": 2292412.4490687633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.901036080634013,
    "arrivals": 1395198,
    "finished_requests": 55520,
    "scheduler_time": 68.25605477055734
}
#Debug simulation 
Total elapsed time: 4.196983047993854. Arrivals time: 0.22304352483479306 Scheduler time: 3.8500921928789467 Scheduler overhead time: 0.023077261459548026 Adapter cache time: 0.06670669798040763 Engine time: 0.02340939757414162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.090480852988549,
    "estimated_duration": 3600.113922127353,
    "input_throughput": 3465.7622702747976,
    "output_throughput": 3038.005251105246,
    "total_throughput": 6503.767521380043,
    "itl": 110.81830379310428,
    "ttft": 2348197.538926165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2096,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.041770340054993,
    "arrivals": 1395198,
    "finished_requests": 50262,
    "scheduler_time": 88.1654115358709
}
#Debug simulation 
Total elapsed time: 4.090574198984541. Arrivals time: 0.20907042437465861 Scheduler time: 3.615431184938643 Scheduler overhead time: 0.04653073981171474 Adapter cache time: 0.15009484038455412 Engine time: 0.04754218878224492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.254323291999754,
    "estimated_duration": 3600.012901692089,
    "input_throughput": 3856.9431219187322,
    "output_throughput": 3389.8792402282843,
    "total_throughput": 7246.822362147016,
    "itl": 251.68266310568688,
    "ttft": 2295156.947648615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.664962814019688,
    "arrivals": 1390337,
    "finished_requests": 56175,
    "scheduler_time": 69.11315170385386
}
#Debug simulation 
Total elapsed time: 4.254448636027519. Arrivals time: 0.2246984500088729 Scheduler time: 3.9110867134295404 Scheduler overhead time: 0.0229371779714711 Adapter cache time: 0.06171097280457616 Engine time: 0.02338971762219444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.228023878997192,
    "estimated_duration": 3600.0021358186536,
    "input_throughput": 3854.8268796635675,
    "output_throughput": 3388.0057677316895,
    "total_throughput": 7242.8326473952575,
    "itl": 248.97654808159692,
    "ttft": 2295954.808813382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.045067477782548,
    "arrivals": 1390337,
    "finished_requests": 56144,
    "scheduler_time": 69.29199286948321
}
#Debug simulation 
Total elapsed time: 4.228115305013489. Arrivals time: 0.22369777137646452 Scheduler time: 3.8847857957007363 Scheduler overhead time: 0.023194451408926398 Adapter cache time: 0.06196739070583135 Engine time: 0.02363395522115752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.081100185983814,
    "estimated_duration": 3600.0663500837804,
    "input_throughput": 3456.6018483827124,
    "output_throughput": 3056.010620399806,
    "total_throughput": 6512.612468782519,
    "itl": 110.41489126927583,
    "ttft": 2358796.129894438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.494530290849451,
    "arrivals": 1390337,
    "finished_requests": 50329,
    "scheduler_time": 88.50588229821462
}
#Debug simulation 
Total elapsed time: 4.08118914795341. Arrivals time: 0.20594234496820718 Scheduler time: 3.6181898826616816 Scheduler overhead time: 0.0464065270498395 Adapter cache time: 0.14129780512303114 Engine time: 0.04754822142422199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.2662818530225195,
    "estimated_duration": 3600.2094370181,
    "input_throughput": 3855.352651788024,
    "output_throughput": 3388.3214889030555,
    "total_throughput": 7243.67414069108,
    "itl": 249.14260922416116,
    "ttft": 2295895.3770686635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.780018999180597,
    "arrivals": 1390337,
    "finished_requests": 56152,
    "scheduler_time": 69.28807584882742
}
#Debug simulation 
Total elapsed time: 4.266380254004616. Arrivals time: 0.23578996199648827 Scheduler time: 3.9115239460370503 Scheduler overhead time: 0.023080880870111287 Adapter cache time: 0.06175963504938409 Engine time: 0.023523061303421855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.063505786005408,
    "estimated_duration": 3600.0208103997984,
    "input_throughput": 3456.4266862163295,
    "output_throughput": 3055.875946111063,
    "total_throughput": 6512.3026323273925,
    "itl": 110.41672194186741,
    "ttft": 2358845.2206222373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.569353793766273,
    "arrivals": 1390337,
    "finished_requests": 50326,
    "scheduler_time": 88.50295145053697
}
#Debug simulation 
Total elapsed time: 4.063619530003052. Arrivals time: 0.20377362868748605 Scheduler time: 3.6037717675208114 Scheduler overhead time: 0.046212277142331004 Adapter cache time: 0.140827318537049 Engine time: 0.04727441392606124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.240874165960122,
    "estimated_duration": 3600.268451080716,
    "input_throughput": 3855.3302867827765,
    "output_throughput": 3388.3873288221366,
    "total_throughput": 7243.717615604914,
    "itl": 249.01406416367402,
    "ttft": 2295823.643061838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.528602995273963,
    "arrivals": 1390337,
    "finished_requests": 56154,
    "scheduler_time": 69.30148208639943
}
#Debug simulation 
Total elapsed time: 4.240965268982109. Arrivals time: 0.2210828991374001 Scheduler time: 3.9010556466528215 Scheduler overhead time: 0.023038940504193306 Adapter cache time: 0.06167459569405764 Engine time: 0.02344649232691154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.051397463015746,
    "estimated_duration": 3600.089447203946,
    "input_throughput": 3456.3607883865698,
    "output_throughput": 3055.8176849034217,
    "total_throughput": 6512.178473289991,
    "itl": 110.41888699685087,
    "ttft": 2358870.3858728018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1679,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.63788960736235,
    "arrivals": 1390337,
    "finished_requests": 50326,
    "scheduler_time": 88.50305244114878
}
#Debug simulation 
Total elapsed time: 4.051490181009285. Arrivals time: 0.19753618905087933 Scheduler time: 3.598219323263038 Scheduler overhead time: 0.04614906676579267 Adapter cache time: 0.14084580313647166 Engine time: 0.04707894887542352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.182456306996755,
    "estimated_duration": 3600.0285672159102,
    "input_throughput": 3861.575745981086,
    "output_throughput": 3396.4327703810345,
    "total_throughput": 7258.008516362121,
    "itl": 251.4950825362528,
    "ttft": 2290684.9833689597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.104893556879975,
    "arrivals": 1387991,
    "finished_requests": 56240,
    "scheduler_time": 69.20099482489408
}
#Debug simulation 
Total elapsed time: 4.182582933979575. Arrivals time: 0.20713135018013418 Scheduler time: 3.861250357935205 Scheduler overhead time: 0.022669330704957247 Adapter cache time: 0.05778688535792753 Engine time: 0.02314765559276566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.288608087983448,
    "estimated_duration": 3600.0157674171123,
    "input_throughput": 3860.796423670112,
    "output_throughput": 3396.0195704285866,
    "total_throughput": 7256.815994098698,
    "itl": 249.16306397014444,
    "ttft": 2291115.035991136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.481877271912399,
    "arrivals": 1387991,
    "finished_requests": 56221,
    "scheduler_time": 69.35644613782111
}
#Debug simulation 
Total elapsed time: 4.288695741968695. Arrivals time: 0.30203372781397775 Scheduler time: 3.871104796009604 Scheduler overhead time: 0.022820209269411862 Adapter cache time: 0.05894408735912293 Engine time: 0.023172917251940817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0667844849522226,
    "estimated_duration": 3600.0713890997645,
    "input_throughput": 3453.153189584013,
    "output_throughput": 3063.98340693969,
    "total_throughput": 6517.136596523704,
    "itl": 110.61929148505804,
    "ttft": 2350629.5876256744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.971819040626234,
    "arrivals": 1387991,
    "finished_requests": 50420,
    "scheduler_time": 88.61208252777082
}
#Debug simulation 
Total elapsed time: 4.066873184987344. Arrivals time: 0.19490705156931654 Scheduler time: 3.616438780154567 Scheduler overhead time: 0.046212565794121474 Adapter cache time: 0.1405009715235792 Engine time: 0.047104277822654694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.231792972015683,
    "estimated_duration": 3600.036750187376,
    "input_throughput": 3860.9689190746585,
    "output_throughput": 3396.1106089718805,
    "total_throughput": 7257.079528046539,
    "itl": 249.14711253871073,
    "ttft": 2291095.5526453364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.233451318300668,
    "arrivals": 1387991,
    "finished_requests": 56225,
    "scheduler_time": 69.3615054134099
}
#Debug simulation 
Total elapsed time: 4.231882820022292. Arrivals time: 0.2109163374407217 Scheduler time: 3.904740299039986 Scheduler overhead time: 0.022864406928420067 Adapter cache time: 0.05942704464541748 Engine time: 0.023281067376956344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.167433085036464,
    "estimated_duration": 3600.0211370817724,
    "input_throughput": 3453.2013914999475,
    "output_throughput": 3064.0261765078208,
    "total_throughput": 6517.227568007768,
    "itl": 110.62152003192506,
    "ttft": 2350638.1001329767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.041235130727247,
    "arrivals": 1387991,
    "finished_requests": 50420,
    "scheduler_time": 88.6092041962874
}
#Debug simulation 
Total elapsed time: 4.167543562012725. Arrivals time: 0.2908869525999762 Scheduler time: 3.621731104212813 Scheduler overhead time: 0.04618209012551233 Adapter cache time: 0.13956747215706855 Engine time: 0.047380032076034695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.186638520972338,
    "estimated_duration": 3600.0897687067836,
    "input_throughput": 3861.386768973155,
    "output_throughput": 3396.414474518034,
    "total_throughput": 7257.801243491189,
    "itl": 249.1298746519066,
    "ttft": 2291126.460370442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.017304394845709,
    "arrivals": 1387991,
    "finished_requests": 56231,
    "scheduler_time": 69.36655129443605
}
#Debug simulation 
Total elapsed time: 4.186760773009155. Arrivals time: 0.20637077977880836 Scheduler time: 3.8650835097650997 Scheduler overhead time: 0.022777234902605414 Adapter cache time: 0.05877352907555178 Engine time: 0.023127473308704793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.072191191022284,
    "estimated_duration": 3600.0818535856233,
    "input_throughput": 3453.143152180923,
    "output_throughput": 3063.9745007502374,
    "total_throughput": 6517.117652931161,
    "itl": 110.62348000841538,
    "ttft": 2350660.3450751025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.10184845577921,
    "arrivals": 1387991,
    "finished_requests": 50420,
    "scheduler_time": 88.60930737513965
}
#Debug simulation 
Total elapsed time: 4.072273053985555. Arrivals time: 0.19869947794359177 Scheduler time: 3.6188821304240264 Scheduler overhead time: 0.04611210071016103 Adapter cache time: 0.14022386848228052 Engine time: 0.04666012985398993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.175070439989213,
    "estimated_duration": 3600.2418756804536,
    "input_throughput": 3849.3519264954093,
    "output_throughput": 3408.339890408275,
    "total_throughput": 7257.691816903684,
    "itl": 251.6570953979716,
    "ttft": 2290195.920129244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.820268196694219,
    "arrivals": 1386791,
    "finished_requests": 56194,
    "scheduler_time": 69.39534595341291
}
#Debug simulation 
Total elapsed time: 4.175185750005767. Arrivals time: 0.20801417989423499 Scheduler time: 3.854061556921806 Scheduler overhead time: 0.022606558864936233 Adapter cache time: 0.05707793147303164 Engine time: 0.02286605047993362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.189884198014624,
    "estimated_duration": 3600.0507223216487,
    "input_throughput": 3847.7224540511306,
    "output_throughput": 3406.2145080255887,
    "total_throughput": 7253.936962076719,
    "itl": 248.47622724132424,
    "ttft": 2290648.544184759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.134287291769775,
    "arrivals": 1386791,
    "finished_requests": 56158,
    "scheduler_time": 69.6040878789974
}
#Debug simulation 
Total elapsed time: 4.189968362974469. Arrivals time: 0.20699017692822963 Scheduler time: 3.868037970736623 Scheduler overhead time: 0.023180651769507676 Adapter cache time: 0.05799766629934311 Engine time: 0.02316259650979191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.067222361045424,
    "estimated_duration": 3600.000027284864,
    "input_throughput": 3443.1163627930664,
    "output_throughput": 3075.3080322473998,
    "total_throughput": 6518.424395040466,
    "itl": 109.89833000806611,
    "ttft": 2351940.7711759936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.652990387678093,
    "arrivals": 1386791,
    "finished_requests": 50349,
    "scheduler_time": 89.06712351635052
}
#Debug simulation 
Total elapsed time: 4.06731736601796. Arrivals time: 0.1955498346942477 Scheduler time: 3.6183147717965767 Scheduler overhead time: 0.046377356746234 Adapter cache time: 0.13805675192270428 Engine time: 0.047245963593013585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.304909118975047,
    "estimated_duration": 3600.0925628862997,
    "input_throughput": 3848.060503448096,
    "output_throughput": 3406.456580151913,
    "total_throughput": 7254.517083600009,
    "itl": 248.46219906356654,
    "ttft": 2290571.7862296393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.903022341532525,
    "arrivals": 1386791,
    "finished_requests": 56161,
    "scheduler_time": 69.60924403104823
}
#Debug simulation 
Total elapsed time: 4.304992415010929. Arrivals time: 0.3029533438384533 Scheduler time: 3.886897206713911 Scheduler overhead time: 0.02292612212477252 Adapter cache time: 0.058501543069723994 Engine time: 0.023104525520466268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.160133320954628,
    "estimated_duration": 3600.06513482683,
    "input_throughput": 3443.0540936855114,
    "output_throughput": 3075.2524149906917,
    "total_throughput": 6518.3065086762035,
    "itl": 109.90042678413802,
    "ttft": 2351964.4718156857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.718005095254602,
    "arrivals": 1386791,
    "finished_requests": 50349,
    "scheduler_time": 89.06721635079342
}
#Debug simulation 
Total elapsed time: 4.160245562961791. Arrivals time: 0.19317425735061988 Scheduler time: 3.7138139195158146 Scheduler overhead time: 0.046488422667607665 Adapter cache time: 0.13797675835667178 Engine time: 0.047081328579224646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.572427242004778,
    "estimated_duration": 3600.1629967681306,
    "input_throughput": 3848.1616005821834,
    "output_throughput": 3406.5363182193364,
    "total_throughput": 7254.69791880152,
    "itl": 248.4457570131641,
    "ttft": 2290614.043356666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.70035906358609,
    "arrivals": 1386791,
    "finished_requests": 56165,
    "scheduler_time": 69.6143918279992
}
#Debug simulation 
Total elapsed time: 4.572490322985686. Arrivals time: 0.5701936995028518 Scheduler time: 3.8874996288795955 Scheduler overhead time: 0.022972458333242685 Adapter cache time: 0.058049456449225545 Engine time: 0.023122820246499032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.154282213014085,
    "estimated_duration": 3600.004665846544,
    "input_throughput": 3442.9397043810222,
    "output_throughput": 3075.211569870757,
    "total_throughput": 6518.151274251779,
    "itl": 109.9019700989249,
    "ttft": 2351989.159966006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1422,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.77421703778206,
    "arrivals": 1386791,
    "finished_requests": 50347,
    "scheduler_time": 89.0643500874238
}
#Debug simulation 
Total elapsed time: 4.154369472002145. Arrivals time: 0.290920601983089 Scheduler time: 3.610673408897128 Scheduler overhead time: 0.04647392174229026 Adapter cache time: 0.13748832826968282 Engine time: 0.04705034539802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.679027170990594,
    "estimated_duration": 3600.198348019,
    "input_throughput": 4328.139311705991,
    "output_throughput": 3829.869820252257,
    "total_throughput": 8158.009131958247,
    "itl": 224.36145173169533,
    "ttft": 2237564.7521279273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.319127698955275,
    "arrivals": 1289387,
    "finished_requests": 62939,
    "scheduler_time": 77.84662348816872
}
#Debug simulation 
Total elapsed time: 4.67910564498743. Arrivals time: 0.22341273358324543 Scheduler time: 4.341990117158275 Scheduler overhead time: 0.025135695992503315 Adapter cache time: 0.051492853614035994 Engine time: 0.02537426247727126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.676893466967158,
    "estimated_duration": 3600.076277070109,
    "input_throughput": 4324.398096550892,
    "output_throughput": 3826.58392205275,
    "total_throughput": 8150.982018603641,
    "itl": 221.19487345025632,
    "ttft": 2238486.9583187615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.663880690703953,
    "arrivals": 1289387,
    "finished_requests": 62881,
    "scheduler_time": 78.10087889950557
}
#Debug simulation 
Total elapsed time: 4.676977960974909. Arrivals time: 0.2199799559894018 Scheduler time: 4.341333114251029 Scheduler overhead time: 0.025641982443630695 Adapter cache time: 0.05212869151728228 Engine time: 0.02594546729233116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.29819675401086,
    "estimated_duration": 3600.0689393829625,
    "input_throughput": 3712.1730791884643,
    "output_throughput": 3306.9600056160366,
    "total_throughput": 7019.133084804501,
    "itl": 101.44047177759123,
    "ttft": 2314701.2704022327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.87344786057243,
    "arrivals": 1289387,
    "finished_requests": 54046,
    "scheduler_time": 96.1053642066513
}
#Debug simulation 
Total elapsed time: 4.29827514704084. Arrivals time: 0.19911911443341523 Scheduler time: 3.875187090365216 Scheduler overhead time: 0.049772628117352724 Adapter cache time: 0.10002546285977587 Engine time: 0.05065401381580159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.692415731027722,
    "estimated_duration": 3600.0807843768166,
    "input_throughput": 4324.510457532681,
    "output_throughput": 3826.652185079982,
    "total_throughput": 8151.162642612663,
    "itl": 221.17925543206493,
    "ttft": 2238436.424422291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.422530740571534,
    "arrivals": 1289387,
    "finished_requests": 62883,
    "scheduler_time": 78.10613378543484
}
#Debug simulation 
Total elapsed time: 4.6924985609948635. Arrivals time: 0.22117651824373752 Scheduler time: 4.355877512076404 Scheduler overhead time: 0.025602449488360435 Adapter cache time: 0.051874667522497475 Engine time: 0.025994914409238845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.28896007098956,
    "estimated_duration": 3600.0251597383767,
    "input_throughput": 3712.215444897391,
    "output_throughput": 3306.90633308384,
    "total_throughput": 7019.121777981231,
    "itl": 101.44220485960086,
    "ttft": 2314678.747030097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.939217090867411,
    "arrivals": 1289387,
    "finished_requests": 54045,
    "scheduler_time": 96.10245974914574
}
#Debug simulation 
Total elapsed time: 4.289059375994839. Arrivals time: 0.19905268150614575 Scheduler time: 3.8653561371029355 Scheduler overhead time: 0.04997904092306271 Adapter cache time: 0.10061647283146158 Engine time: 0.05059286765754223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.674785611976404,
    "estimated_duration": 3600.0826742282234,
    "input_throughput": 4325.190393950628,
    "output_throughput": 3826.9779465421784,
    "total_throughput": 8152.168340492806,
    "itl": 221.26546975008088,
    "ttft": 2238369.215070291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.193717362244931,
    "arrivals": 1289387,
    "finished_requests": 62891,
    "scheduler_time": 78.10245014914584
}
#Debug simulation 
Total elapsed time: 4.674864962988067. Arrivals time: 0.21875513182021677 Scheduler time: 4.340627450728789 Scheduler overhead time: 0.02553940308280289 Adapter cache time: 0.05208478192798793 Engine time: 0.025922275090124458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.294851900951471,
    "estimated_duration": 3600.0846146594367,
    "input_throughput": 3712.1541381505067,
    "output_throughput": 3306.8517199633075,
    "total_throughput": 7019.005858113815,
    "itl": 101.44390793092435,
    "ttft": 2314701.158257415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9985728780552385,
    "arrivals": 1289387,
    "finished_requests": 54045,
    "scheduler_time": 96.10255888306868
}
#Debug simulation 
Total elapsed time: 4.294928008981515. Arrivals time: 0.20090174622600898 Scheduler time: 3.869600045552943 Scheduler overhead time: 0.0498262036126107 Adapter cache time: 0.10039039980620146 Engine time: 0.05077955068554729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.886542856984306,
    "estimated_duration": 3600.149799568743,
    "input_throughput": 4419.789699280309,
    "output_throughput": 3924.781685943343,
    "total_throughput": 8344.571385223651,
    "itl": 219.29881363674224,
    "ttft": 2222604.631294209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.015359920039876,
    "arrivals": 1279697,
    "finished_requests": 65145,
    "scheduler_time": 79.67743220300453
}
#Debug simulation 
Total elapsed time: 4.886625075945631. Arrivals time: 0.3132452309364453 Scheduler time: 4.463125264563132 Scheduler overhead time: 0.02583821868756786 Adapter cache time: 0.0459826480364427 Engine time: 0.026375534012913704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.728731200040784,
    "estimated_duration": 3600.1344615111834,
    "input_throughput": 4416.2447736261065,
    "output_throughput": 3921.4318662070186,
    "total_throughput": 8337.676639833126,
    "itl": 216.7160338842895,
    "ttft": 2223469.8298690985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.306987694003599,
    "arrivals": 1279697,
    "finished_requests": 65090,
    "scheduler_time": 79.88164071169338
}
#Debug simulation 
Total elapsed time: 4.7288393240305595. Arrivals time: 0.2251066745375283 Scheduler time: 4.392756209883373 Scheduler overhead time: 0.0260926389019005 Adapter cache time: 0.04632445197785273 Engine time: 0.026397970970720053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.320425487996545,
    "estimated_duration": 3600.0428456726722,
    "input_throughput": 3743.070451563512,
    "output_throughput": 3358.229753996445,
    "total_throughput": 7101.300205559957,
    "itl": 101.24395071416426,
    "ttft": 2306204.8525889153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6900718522443854,
    "arrivals": 1279697,
    "finished_requests": 55304,
    "scheduler_time": 96.90222704044801
}
#Debug simulation 
Total elapsed time: 4.320503129973076. Arrivals time: 0.19984031637432054 Scheduler time: 3.9022768221329898 Scheduler overhead time: 0.04994863457977772 Adapter cache time: 0.09454122016904876 Engine time: 0.05052488943329081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.890297312987968,
    "estimated_duration": 3600.193093539502,
    "input_throughput": 4416.173129305391,
    "output_throughput": 3921.397167650307,
    "total_throughput": 8337.570296955699,
    "itl": 216.7090822690198,
    "ttft": 2223475.557225432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1173994662472415,
    "arrivals": 1279697,
    "finished_requests": 65091,
    "scheduler_time": 79.88649150352484
}
#Debug simulation 
Total elapsed time: 4.890396041970234. Arrivals time: 0.3239496469614096 Scheduler time: 4.455135988770053 Scheduler overhead time: 0.026176281040534377 Adapter cache time: 0.0464525586576201 Engine time: 0.026473676203750074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.340585875965189,
    "estimated_duration": 3600.0918477117852,
    "input_throughput": 3743.0195033954014,
    "output_throughput": 3358.1840440221677,
    "total_throughput": 7101.203547417569,
    "itl": 101.24540710128377,
    "ttft": 2306222.995732914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7389900751598164,
    "arrivals": 1279697,
    "finished_requests": 55304,
    "scheduler_time": 96.90231085668788
}
#Debug simulation 
Total elapsed time: 4.340669035969768. Arrivals time: 0.20105129986768588 Scheduler time: 3.920559899415821 Scheduler overhead time: 0.04990731319412589 Adapter cache time: 0.09493849298451096 Engine time: 0.05073714576428756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.7805814140010625,
    "estimated_duration": 3600.1082987673058,
    "input_throughput": 4416.389086251671,
    "output_throughput": 3921.7161897141473,
    "total_throughput": 8338.105275965818,
    "itl": 216.7771291276488,
    "ttft": 2223391.7342812256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9408862886809644,
    "arrivals": 1279697,
    "finished_requests": 65094,
    "scheduler_time": 79.88129718752772
}
#Debug simulation 
Total elapsed time: 4.7806600839830935. Arrivals time: 0.2251392110483721 Scheduler time: 4.444447202258743 Scheduler overhead time: 0.02612760872580111 Adapter cache time: 0.046356781211216 Engine time: 0.026434061757754534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.424250190029852,
    "estimated_duration": 3600.029846687036,
    "input_throughput": 3742.9695235444574,
    "output_throughput": 3358.1866025709624,
    "total_throughput": 7101.15612611542,
    "itl": 101.24656977236474,
    "ttft": 2306162.9698907677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.785896237492615,
    "arrivals": 1279697,
    "finished_requests": 55303,
    "scheduler_time": 96.8994603081357
}
#Debug simulation 
Total elapsed time: 4.424332008988131. Arrivals time: 0.29032032151008025 Scheduler time: 3.915218208974693 Scheduler overhead time: 0.05002286389935762 Adapter cache time: 0.09478427784051746 Engine time: 0.05058152333367616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.845929471950512,
    "estimated_duration": 3600.0024776276096,
    "input_throughput": 4554.356310000295,
    "output_throughput": 3993.2841961468953,
    "total_throughput": 8547.64050614719,
    "itl": 213.94121467373017,
    "ttft": 2216899.962399839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.170665302714407,
    "arrivals": 1274994,
    "finished_requests": 65998,
    "scheduler_time": 81.24712509910199
}
#Debug simulation 
Total elapsed time: 4.846029542968608. Arrivals time: 0.2313385182642378 Scheduler time: 4.507222246262245 Scheduler overhead time: 0.026235869445372373 Adapter cache time: 0.04218224307987839 Engine time: 0.026801649655681103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.973106069024652,
    "estimated_duration": 3600.0460394454444,
    "input_throughput": 4550.386250761238,
    "output_throughput": 3989.7875867755733,
    "total_throughput": 8540.173837536811,
    "itl": 211.9693896663766,
    "ttft": 2217574.2072458486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3857518050191073,
    "arrivals": 1274994,
    "finished_requests": 65941,
    "scheduler_time": 81.4023466855733
}
#Debug simulation 
Total elapsed time: 4.973191117984243. Arrivals time: 0.31606887630186975 Scheduler time: 4.5481393311638385 Scheduler overhead time: 0.026666096528060734 Adapter cache time: 0.04271582094952464 Engine time: 0.027132107818033546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.365745957009494,
    "estimated_duration": 3600.063742844967,
    "input_throughput": 3830.9524456089403,
    "output_throughput": 3380.6559742695404,
    "total_throughput": 7211.608419878481,
    "itl": 99.96178215279775,
    "ttft": 2301852.971851711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8590114955976387,
    "arrivals": 1274994,
    "finished_requests": 55549,
    "scheduler_time": 97.86643041329866
}
#Debug simulation 
Total elapsed time: 4.365826613968238. Arrivals time: 0.2043194065336138 Scheduler time: 3.9457899141707458 Scheduler overhead time: 0.0505889467895031 Adapter cache time: 0.08980400121072307 Engine time: 0.05159006390022114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.959252494969405,
    "estimated_duration": 3600.1344317819608,
    "input_throughput": 4550.454242868722,
    "output_throughput": 3990.00961552704,
    "total_throughput": 8540.463858395762,
    "itl": 211.96267747164833,
    "ttft": 2217564.654209867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2345715371961345,
    "arrivals": 1274994,
    "finished_requests": 65945,
    "scheduler_time": 81.40752372537379
}
#Debug simulation 
Total elapsed time: 4.959333955950569. Arrivals time: 0.3158218180760741 Scheduler time: 4.534888051392045 Scheduler overhead time: 0.026576880656648427 Adapter cache time: 0.04260419466299936 Engine time: 0.02706289367051795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.392682426958345,
    "estimated_duration": 3600.1031991343134,
    "input_throughput": 3830.9104592658255,
    "output_throughput": 3380.618923070471,
    "total_throughput": 7211.529382336296,
    "itl": 99.962947987007,
    "ttft": 2301868.228685198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8983724307455163,
    "arrivals": 1274994,
    "finished_requests": 55549,
    "scheduler_time": 97.86652576753357
}
#Debug simulation 
Total elapsed time: 4.392784508992918. Arrivals time: 0.20414566237013787 Scheduler time: 3.972323411318939 Scheduler overhead time: 0.050904928357340395 Adapter cache time: 0.08947483694646508 Engine time: 0.05174343986436725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.955994019983336,
    "estimated_duration": 3600.23712144017,
    "input_throughput": 4550.811084756011,
    "output_throughput": 3990.4029971929017,
    "total_throughput": 8541.214081948912,
    "itl": 211.95446808229303,
    "ttft": 2217611.159104614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.097692105518581,
    "arrivals": 1274994,
    "finished_requests": 65952,
    "scheduler_time": 81.41269725072752
}
#Debug simulation 
Total elapsed time: 4.956097738002427. Arrivals time: 0.3156252761837095 Scheduler time: 4.532110891013872 Scheduler overhead time: 0.026538939215242863 Adapter cache time: 0.04230220185127109 Engine time: 0.027110344381071627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.370572270010598,
    "estimated_duration": 3600.02841665653,
    "input_throughput": 3830.990037797757,
    "output_throughput": 3380.6891478104585,
    "total_throughput": 7211.679185608215,
    "itl": 99.96394512789828,
    "ttft": 2301882.423219969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9332062295824572,
    "arrivals": 1274994,
    "finished_requests": 55549,
    "scheduler_time": 97.86361726546248
}
#Debug simulation 
Total elapsed time: 4.370652975980192. Arrivals time: 0.20239254733314738 Scheduler time: 3.952326438506134 Scheduler overhead time: 0.050607269862666726 Adapter cache time: 0.09017761191353202 Engine time: 0.051282238855492324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.8977238640072756,
    "estimated_duration": 3600.0003698506866,
    "input_throughput": 4566.203697551785,
    "output_throughput": 4014.6798653244155,
    "total_throughput": 8580.8835628762,
    "itl": 213.63460706046143,
    "ttft": 2218011.0156276072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.534083851976372,
    "arrivals": 1272675,
    "finished_requests": 66382,
    "scheduler_time": 81.57091403385115
}
#Debug simulation 
Total elapsed time: 4.897809071990196. Arrivals time: 0.23315553361317143 Scheduler time: 4.559570049750619 Scheduler overhead time: 0.026478895160835236 Adapter cache time: 0.03927675151498988 Engine time: 0.02699931984534487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.882458156032953,
    "estimated_duration": 3600.1152324348996,
    "input_throughput": 4560.332361610561,
    "output_throughput": 4009.907480165927,
    "total_throughput": 8570.239841776489,
    "itl": 211.4586598733539,
    "ttft": 2219030.43387508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.70975687857951,
    "arrivals": 1272675,
    "finished_requests": 66305,
    "scheduler_time": 81.74174544887107
}
#Debug simulation 
Total elapsed time: 4.8825408080010675. Arrivals time: 0.23164884181460366 Scheduler time: 4.545223092078231 Scheduler overhead time: 0.02669090958079323 Adapter cache time: 0.03935773117700592 Engine time: 0.02720805665012449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.366452638991177,
    "estimated_duration": 3600.0154671048126,
    "input_throughput": 3823.4013508473795,
    "output_throughput": 3377.2288233466147,
    "total_throughput": 7200.630174193994,
    "itl": 99.99343573398053,
    "ttft": 2306599.1198233287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3903842154704,
    "arrivals": 1272675,
    "finished_requests": 55588,
    "scheduler_time": 97.7780724682575
}
#Debug simulation 
Total elapsed time: 4.366537356982008. Arrivals time: 0.2060828460380435 Scheduler time: 3.9480111788143404 Scheduler overhead time: 0.05039281863719225 Adapter cache time: 0.08675558195682243 Engine time: 0.05147349729668349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.8521406119689345,
    "estimated_duration": 3600.2215549316265,
    "input_throughput": 4560.3326766126775,
    "output_throughput": 4010.147925541818,
    "total_throughput": 8570.480602154496,
    "itl": 211.4515333926006,
    "ttft": 2219022.7757913936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.582683734544528,
    "arrivals": 1272675,
    "finished_requests": 66311,
    "scheduler_time": 81.74690803387139
}
#Debug simulation 
Total elapsed time: 4.852224025991745. Arrivals time: 0.2342900934163481 Scheduler time: 4.513187722535804 Scheduler overhead time: 0.02656023419694975 Adapter cache time: 0.03883117361692712 Engine time: 0.02696351776830852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.35922667599516,
    "estimated_duration": 3600.049378755879,
    "input_throughput": 3823.3653352712427,
    "output_throughput": 3377.1970106147937,
    "total_throughput": 7200.562345886036,
    "itl": 99.99442871146823,
    "ttft": 2306612.4717992614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4242119840160035,
    "arrivals": 1272675,
    "finished_requests": 55588,
    "scheduler_time": 97.77815635080769
}
#Debug simulation 
Total elapsed time: 4.359309758001473. Arrivals time: 0.20629438071046025 Scheduler time: 3.9401389757404104 Scheduler overhead time: 0.05064702546223998 Adapter cache time: 0.08684288361109793 Engine time: 0.05157005914952606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.869337604963221,
    "estimated_duration": 3600.1026674286554,
    "input_throughput": 4561.066868609077,
    "output_throughput": 4010.674509544703,
    "total_throughput": 8571.74137815378,
    "itl": 211.5846386698354,
    "ttft": 2218873.825499851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4727715938840484,
    "arrivals": 1272675,
    "finished_requests": 66317,
    "scheduler_time": 81.73576157025101
}
#Debug simulation 
Total elapsed time: 4.869423481984995. Arrivals time: 0.23045768961310387 Scheduler time: 4.533614409447182 Scheduler overhead time: 0.026629561209119856 Adapter cache time: 0.03912561584729701 Engine time: 0.027154700306709856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.337548789975699,
    "estimated_duration": 3600.079651769622,
    "input_throughput": 3823.333184651663,
    "output_throughput": 3377.16861181771,
    "total_throughput": 7200.501796469373,
    "itl": 99.99525023059202,
    "ttft": 2306624.655614313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.454392892755578,
    "arrivals": 1272675,
    "finished_requests": 55588,
    "scheduler_time": 97.77824845583712
}
#Debug simulation 
Total elapsed time: 4.337628829991445. Arrivals time: 0.2045568788307719 Scheduler time: 3.921051999728661 Scheduler overhead time: 0.050337519438471645 Adapter cache time: 0.08665666216984391 Engine time: 0.05126333161024377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.90538116695825,
    "estimated_duration": 3600.195893800068,
    "input_throughput": 4561.8201021458235,
    "output_throughput": 4021.264794210662,
    "total_throughput": 8583.084896356486,
    "itl": 212.84325655220314,
    "ttft": 2212245.901629149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.332091660876803,
    "arrivals": 1271499,
    "finished_requests": 66656,
    "scheduler_time": 81.76347092453308
}
#Debug simulation 
Total elapsed time: 4.905458626977634. Arrivals time: 0.23335438902722672 Scheduler time: 4.567466572159901 Scheduler overhead time: 0.02641927363583818 Adapter cache time: 0.03910201112739742 Engine time: 0.026833156938664615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8971231110044755,
    "estimated_duration": 3600.0033617884424,
    "input_throughput": 4556.7051892558775,
    "output_throughput": 4018.0670811412574,
    "total_throughput": 8574.772270397134,
    "itl": 210.94919952523205,
    "ttft": 2212673.406382811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5001367534417738,
    "arrivals": 1271499,
    "finished_requests": 66596,
    "scheduler_time": 81.90390607860378
}
#Debug simulation 
Total elapsed time: 4.897216282028239. Arrivals time: 0.2330683995387517 Scheduler time: 4.558575090777595 Scheduler overhead time: 0.026612984074745327 Adapter cache time: 0.03940731118200347 Engine time: 0.02705186343519017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.350414880027529,
    "estimated_duration": 3600.072231628535,
    "input_throughput": 3821.6024887301737,
    "output_throughput": 3393.1585851748655,
    "total_throughput": 7214.761073905039,
    "itl": 100.16698081931149,
    "ttft": 2299222.4068107395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.146960747353739,
    "arrivals": 1271499,
    "finished_requests": 55930,
    "scheduler_time": 97.80253028174994
}
#Debug simulation 
Total elapsed time: 4.3504984700120986. Arrivals time: 0.2048946424620226 Scheduler time: 3.9354040362522937 Scheduler overhead time: 0.050162211584392935 Adapter cache time: 0.08556911163032055 Engine time: 0.05089847155613825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.896366866014432,
    "estimated_duration": 3600.1259715911383,
    "input_throughput": 4556.8516572628205,
    "output_throughput": 4018.0677326706705,
    "total_throughput": 8574.919389933491,
    "itl": 210.94255280832851,
    "ttft": 2212709.000955617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3894074221444113,
    "arrivals": 1271499,
    "finished_requests": 66599,
    "scheduler_time": 81.9090412117394
}
#Debug simulation 
Total elapsed time: 4.896445880993269. Arrivals time: 0.2339519629604183 Scheduler time: 4.556514761527069 Scheduler overhead time: 0.026719429064542055 Adapter cache time: 0.039587015693541616 Engine time: 0.027187007770407945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.362293901038356,
    "estimated_duration": 3600.1009862470905,
    "input_throughput": 3821.571964941465,
    "output_throughput": 3393.131483440445,
    "total_throughput": 7214.70344838191,
    "itl": 100.16780144570875,
    "ttft": 2299234.3224810343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1756326106563226,
    "arrivals": 1271499,
    "finished_requests": 55930,
    "scheduler_time": 97.80261303702476
}
#Debug simulation 
Total elapsed time: 4.362373654032126. Arrivals time: 0.2052602075273171 Scheduler time: 3.9472133545787074 Scheduler overhead time: 0.05022640322567895 Adapter cache time: 0.08509570907335728 Engine time: 0.05100436368957162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.873734789027367,
    "estimated_duration": 3600.069596230031,
    "input_throughput": 4557.444671953404,
    "output_throughput": 4018.336483036051,
    "total_throughput": 8575.781154989456,
    "itl": 211.00555955231573,
    "ttft": 2212706.952589734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.281408375010316,
    "arrivals": 1271499,
    "finished_requests": 66604,
    "scheduler_time": 81.90467979488939
}
#Debug simulation 
Total elapsed time: 4.873821139975917. Arrivals time: 0.23011923977173865 Scheduler time: 4.538023964734748 Scheduler overhead time: 0.026507434085942805 Adapter cache time: 0.03971363144228235 Engine time: 0.027043759415391833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.359839296026621,
    "estimated_duration": 3600.0229998985046,
    "input_throughput": 3821.494473893046,
    "output_throughput": 3393.0988775195,
    "total_throughput": 7214.593351412546,
    "itl": 100.1681881845601,
    "ttft": 2299204.586818691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.203046936094763,
    "arrivals": 1271499,
    "finished_requests": 55927,
    "scheduler_time": 97.79974332527617
}
#Debug simulation 
Total elapsed time: 4.359938815003261. Arrivals time: 0.20417599566280842 Scheduler time: 3.9458799735293724 Scheduler overhead time: 0.050172066141385585 Adapter cache time: 0.08522235770942643 Engine time: 0.05082224862417206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.0085580429877155,
    "estimated_duration": 3600.050010606018,
    "input_throughput": 4612.638144214185,
    "output_throughput": 4105.93657211771,
    "total_throughput": 8718.574716331896,
    "itl": 209.96053222845856,
    "ttft": 2203388.9760826644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1027,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.143120913019011,
    "arrivals": 1260602,
    "finished_requests": 67592,
    "scheduler_time": 83.31222528836939
}
#Debug simulation 
Total elapsed time: 5.0086409009527415. Arrivals time: 0.24363770353375003 Scheduler time: 4.662784639280289 Scheduler overhead time: 0.02692275313893333 Adapter cache time: 0.03526055905967951 Engine time: 0.027441417041700333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.978018947993405,
    "estimated_duration": 3600.0873048182784,
    "input_throughput": 4604.195842088525,
    "output_throughput": 4099.030593021933,
    "total_throughput": 8703.226435110457,
    "itl": 207.06419712576403,
    "ttft": 2204481.6820400464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.34552548216424,
    "arrivals": 1260602,
    "finished_requests": 67471,
    "scheduler_time": 83.53963387831904
}
#Debug simulation 
Total elapsed time: 4.978128221002407. Arrivals time: 0.23239332693628967 Scheduler time: 4.643161363725085 Scheduler overhead time: 0.027117691875901073 Adapter cache time: 0.03522272012196481 Engine time: 0.02749583637341857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.420244360982906,
    "estimated_duration": 3600.027523988042,
    "input_throughput": 3829.5354433089587,
    "output_throughput": 3425.154090583269,
    "total_throughput": 7254.689533892228,
    "itl": 99.00005382583444,
    "ttft": 2296200.239513022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8454801388270945,
    "arrivals": 1260602,
    "finished_requests": 56199,
    "scheduler_time": 98.93611268682889
}
#Debug simulation 
Total elapsed time: 4.420324501988944. Arrivals time: 0.20809830725193024 Scheduler time: 4.0044950634473935 Scheduler overhead time: 0.051336399803403765 Adapter cache time: 0.08088276570197195 Engine time: 0.05161176930414513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.047314886003733,
    "estimated_duration": 3600.1784195591954,
    "input_throughput": 4604.3587478727295,
    "output_throughput": 4098.9593515220395,
    "total_throughput": 8703.31809939477,
    "itl": 207.05566624567118,
    "ttft": 2204518.375954048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.202776886841715,
    "arrivals": 1260602,
    "finished_requests": 67475,
    "scheduler_time": 83.54473877419292
}
#Debug simulation 
Total elapsed time: 5.047397541988175. Arrivals time: 0.2515541188768111 Scheduler time: 4.6925461437786 Scheduler overhead time: 0.027230785170104355 Adapter cache time: 0.03554106311639771 Engine time: 0.02767761459108442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.404776143026538,
    "estimated_duration": 3600.06546778382,
    "input_throughput": 3829.495080956639,
    "output_throughput": 3425.1179903099587,
    "total_throughput": 7254.613071266597,
    "itl": 99.0011676846536,
    "ttft": 2296215.056853021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8833320285379913,
    "arrivals": 1260602,
    "finished_requests": 56199,
    "scheduler_time": 98.93620459292735
}
#Debug simulation 
Total elapsed time: 4.404856576991733. Arrivals time: 0.20542751596076414 Scheduler time: 3.992305600491818 Scheduler overhead time: 0.05102154123596847 Adapter cache time: 0.08021948841633275 Engine time: 0.05185274651739746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.025606170005631,
    "estimated_duration": 3600.0372684391727,
    "input_throughput": 4604.539276668903,
    "output_throughput": 4099.120064498115,
    "total_throughput": 8703.659341167018,
    "itl": 207.04822257008414,
    "ttft": 2204461.1868328196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.061811501979756,
    "arrivals": 1260602,
    "finished_requests": 67475,
    "scheduler_time": 83.54455303899681
}
#Debug simulation 
Total elapsed time: 5.0256907130242325. Arrivals time: 0.24444829724961892 Scheduler time: 4.677734537341166 Scheduler overhead time: 0.027085548674222082 Adapter cache time: 0.03614795149769634 Engine time: 0.02758537040790543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.387306576012634,
    "estimated_duration": 3600.1025330934735,
    "input_throughput": 3829.455653907079,
    "output_throughput": 3425.082726575734,
    "total_throughput": 7254.5383804828125,
    "itl": 99.00221102026232,
    "ttft": 2296229.95605959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9203036417439843,
    "arrivals": 1260602,
    "finished_requests": 56199,
    "scheduler_time": 98.93629828940436
}
#Debug simulation 
Total elapsed time: 4.387389709998388. Arrivals time: 0.20434867893345654 Scheduler time: 3.976460479083471 Scheduler overhead time: 0.050847090082243085 Adapter cache time: 0.08019251242512837 Engine time: 0.05159884982276708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.050614686042536,
    "estimated_duration": 3600.0886654147143,
    "input_throughput": 4718.496842366845,
    "output_throughput": 4160.758079072054,
    "total_throughput": 8879.254921438898,
    "itl": 206.12743038032994,
    "ttft": 2197467.3973379335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3688175138039975,
    "arrivals": 1256018,
    "finished_requests": 68839,
    "scheduler_time": 84.56468667910124
}
#Debug simulation 
Total elapsed time: 5.050698354025371. Arrivals time: 0.2403329733060673 Scheduler time: 4.711754674266558 Scheduler overhead time: 0.027248674421571195 Adapter cache time: 0.030766056792344898 Engine time: 0.02777491870801896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.057640507002361,
    "estimated_duration": 3600.192658152537,
    "input_throughput": 4714.366871885578,
    "output_throughput": 4157.180579241623,
    "total_throughput": 8871.5474511272,
    "itl": 204.34927979043124,
    "ttft": 2198146.1265000384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 776,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5323399991146345,
    "arrivals": 1256018,
    "finished_requests": 68772,
    "scheduler_time": 84.70170479324915
}
#Debug simulation 
Total elapsed time: 5.057719651027583. Arrivals time: 0.24321889219572768 Scheduler time: 4.715248214371968 Scheduler overhead time: 0.027481696219183505 Adapter cache time: 0.03115897171664983 Engine time: 0.027786867052782327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.408200384990778,
    "estimated_duration": 3600.103501238441,
    "input_throughput": 3883.3719628312556,
    "output_throughput": 3445.6373256304387,
    "total_throughput": 7329.009288461694,
    "itl": 98.61747207638336,
    "ttft": 2291846.6509247855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1432427335158057,
    "arrivals": 1256018,
    "finished_requests": 56687,
    "scheduler_time": 99.42511006986318
}
#Debug simulation 
Total elapsed time: 4.408283333003055. Arrivals time: 0.20525870163692161 Scheduler time: 4.0030743345269 Scheduler overhead time: 0.05103134457021952 Adapter cache time: 0.07346286432584748 Engine time: 0.05146552843507379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.044331152981613,
    "estimated_duration": 3600.086258389702,
    "input_throughput": 4714.506203968502,
    "output_throughput": 4157.303443805398,
    "total_throughput": 8871.8096477739,
    "itl": 204.34379835596513,
    "ttft": 2198102.8651354713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 776,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4261052163201176,
    "arrivals": 1256018,
    "finished_requests": 68772,
    "scheduler_time": 84.70153981318205
}
#Debug simulation 
Total elapsed time: 5.044414990989026. Arrivals time: 0.24014257284579799 Scheduler time: 4.704692794766743 Scheduler overhead time: 0.02744341199286282 Adapter cache time: 0.03144081664504483 Engine time: 0.02788185578538105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.408974723017309,
    "estimated_duration": 3600.0264398402364,
    "input_throughput": 3883.401200970187,
    "output_throughput": 3445.617194008854,
    "total_throughput": 7329.018394979041,
    "itl": 98.61809860985402,
    "ttft": 2291860.26986784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1705313051678266,
    "arrivals": 1256018,
    "finished_requests": 56686,
    "scheduler_time": 99.42221900643524
}
#Debug simulation 
Total elapsed time: 4.409054935036693. Arrivals time: 0.20774847269058228 Scheduler time: 4.000714541820344 Scheduler overhead time: 0.05130180931882933 Adapter cache time: 0.07351100724190474 Engine time: 0.05177955835824832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.047805879032239,
    "estimated_duration": 3600.2073386145407,
    "input_throughput": 4714.55180315582,
    "output_throughput": 4157.551660832989,
    "total_throughput": 8872.10346398881,
    "itl": 204.33942783785662,
    "ttft": 2198090.645222769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 776,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.320279028844043,
    "arrivals": 1256018,
    "finished_requests": 68776,
    "scheduler_time": 84.70669404296125
}
#Debug simulation 
Total elapsed time: 5.04789907601662. Arrivals time: 0.23652157658943906 Scheduler time: 4.711741786159109 Scheduler overhead time: 0.027610986900981516 Adapter cache time: 0.03129200992407277 Engine time: 0.02785812661750242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.4021040219813585,
    "estimated_duration": 3600.0550728162434,
    "input_throughput": 3883.3703144056303,
    "output_throughput": 3445.589789351856,
    "total_throughput": 7328.960103757487,
    "itl": 98.61890863948598,
    "ttft": 2291871.978925925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1990774146839995,
    "arrivals": 1256018,
    "finished_requests": 56686,
    "scheduler_time": 99.42230587294966
}
#Debug simulation 
Total elapsed time: 4.4021842990187. Arrivals time: 0.20531481213402003 Scheduler time: 3.996656180534046 Scheduler overhead time: 0.0507726056384854 Adapter cache time: 0.07367869326844811 Engine time: 0.05177470203489065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.214784122013953,
    "estimated_duration": 3600.182704379756,
    "input_throughput": 4762.009988866275,
    "output_throughput": 4180.556998312941,
    "total_throughput": 8942.566987179216,
    "itl": 204.5139473114507,
    "ttft": 2193151.938148957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9770750825805916,
    "arrivals": 1253655,
    "finished_requests": 69334,
    "scheduler_time": 84.99891733939711
}
#Debug simulation 
Total elapsed time: 5.2148900250322185. Arrivals time: 0.38294129905989394 Scheduler time: 4.734730771393515 Scheduler overhead time: 0.027437937154900283 Adapter cache time: 0.02910615160362795 Engine time: 0.027883965231012553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.070100755954627,
    "estimated_duration": 3600.006835798509,
    "input_throughput": 4756.188468792765,
    "output_throughput": 4176.625402619527,
    "total_throughput": 8932.813871412292,
    "itl": 202.8982918439039,
    "ttft": 2193677.8260703916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.115570266870789,
    "arrivals": 1253655,
    "finished_requests": 69256,
    "scheduler_time": 85.113625964294
}
#Debug simulation 
Total elapsed time: 5.070175669970922. Arrivals time: 0.2409173939959146 Scheduler time: 4.731354244810063 Scheduler overhead time: 0.02760716568445787 Adapter cache time: 0.029294633539393544 Engine time: 0.02813555987086147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.573804508021567,
    "estimated_duration": 3600.0661965934905,
    "input_throughput": 3923.895903182777,
    "output_throughput": 3453.4542758586563,
    "total_throughput": 7377.350179041434,
    "itl": 98.09303924190125,
    "ttft": 2290636.278495907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8308300743624681,
    "arrivals": 1253655,
    "finished_requests": 57034,
    "scheduler_time": 99.71041698595864
}
#Debug simulation 
Total elapsed time: 4.57391005998943. Arrivals time: 0.209919715533033 Scheduler time: 4.163053494004998 Scheduler overhead time: 0.0511473894584924 Adapter cache time: 0.07357064500683919 Engine time: 0.051995755813550204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.188962151994929,
    "estimated_duration": 3600.1376708861344,
    "input_throughput": 4756.279499662938,
    "output_throughput": 4176.678053619795,
    "total_throughput": 8932.957553282733,
    "itl": 202.89281760708363,
    "ttft": 2193673.7949966434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0215933436294877,
    "arrivals": 1253655,
    "finished_requests": 69259,
    "scheduler_time": 85.11877389532067
}
#Debug simulation 
Total elapsed time: 5.1890509750228375. Arrivals time: 0.3798787235864438 Scheduler time: 4.71183871087851 Scheduler overhead time: 0.02754018147243187 Adapter cache time: 0.02908975345781073 Engine time: 0.02788687776774168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.653789835982025,
    "estimated_duration": 3600.0907995467173,
    "input_throughput": 3923.869087351525,
    "output_throughput": 3453.430675016691,
    "total_throughput": 7377.299762368217,
    "itl": 98.09374152450143,
    "ttft": 2290646.6273642755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8553520627133584,
    "arrivals": 1253655,
    "finished_requests": 57034,
    "scheduler_time": 99.71049795085491
}
#Debug simulation 
Total elapsed time: 4.653885701962281. Arrivals time: 0.2966645529959351 Scheduler time: 4.155772204336245 Scheduler overhead time: 0.05130133545026183 Adapter cache time: 0.07383534638211131 Engine time: 0.05222138552926481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.210024747007992,
    "estimated_duration": 3600.0504610454723,
    "input_throughput": 4756.394718708282,
    "output_throughput": 4176.779232042568,
    "total_throughput": 8933.17395075085,
    "itl": 202.88859925595716,
    "ttft": 2193634.71312004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9345625408016758,
    "arrivals": 1253655,
    "finished_requests": 69259,
    "scheduler_time": 85.11859485746652
}
#Debug simulation 
Total elapsed time: 5.210108410043176. Arrivals time: 0.3802527407533489 Scheduler time: 4.731934165407438 Scheduler overhead time: 0.027551118517294526 Adapter cache time: 0.02941706927958876 Engine time: 0.02801725926110521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.44472880102694,
    "estimated_duration": 3600.00742514942,
    "input_throughput": 3923.959962225267,
    "output_throughput": 3453.5106547687124,
    "total_throughput": 7377.470616993979,
    "itl": 98.0943701500651,
    "ttft": 2290593.660546269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8791195283457591,
    "arrivals": 1253655,
    "finished_requests": 57034,
    "scheduler_time": 99.70756743436507
}
#Debug simulation 
Total elapsed time: 4.444805412029382. Arrivals time: 0.21048361441353336 Scheduler time: 4.032720103976317 Scheduler overhead time: 0.05122176691656932 Adapter cache time: 0.0735943948966451 Engine time: 0.0525956223718822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.214652208960615,
    "estimated_duration": 3600.0102566058054,
    "input_throughput": 4830.6090150965365,
    "output_throughput": 4239.522643579845,
    "total_throughput": 9070.131658676382,
    "itl": 201.53912440009248,
    "ttft": 2183399.1507766168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 474,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4506711906241396,
    "arrivals": 1252442,
    "finished_requests": 69979,
    "scheduler_time": 86.21412202572627
}
#Debug simulation 
Total elapsed time: 5.214737403963227. Arrivals time: 0.32642146170837805 Scheduler time: 4.7940138836274855 Scheduler overhead time: 0.02783290925435722 Adapter cache time: 0.025466978549957275 Engine time: 0.0280554203200154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.09656969003845,
    "estimated_duration": 3600.2092296784235,
    "input_throughput": 4823.318838486247,
    "output_throughput": 4232.572616720138,
    "total_throughput": 9055.891455206385,
    "itl": 199.2532800969544,
    "ttft": 2184123.3718758295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394727861182826,
    "arrivals": 1252442,
    "finished_requests": 69877,
    "scheduler_time": 86.38329287482256
}
#Debug simulation 
Total elapsed time: 5.09665332804434. Arrivals time: 0.23903086862992495 Scheduler time: 4.762322538066655 Scheduler overhead time: 0.0280099815572612 Adapter cache time: 0.025726199382916093 Engine time: 0.028523598215542734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.42326170403976,
    "estimated_duration": 3600.049442382982,
    "input_throughput": 3936.274272561082,
    "output_throughput": 3465.216575398601,
    "total_throughput": 7401.4908479596825,
    "itl": 97.31843134862305,
    "ttft": 2284075.3846695325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3260426897369402,
    "arrivals": 1252442,
    "finished_requests": 57041,
    "scheduler_time": 100.32003115627847
}
#Debug simulation 
Total elapsed time: 4.423342071997467. Arrivals time: 0.20792701351456344 Scheduler time: 4.020515018724836 Scheduler overhead time: 0.05150671553565189 Adapter cache time: 0.06693272793199867 Engine time: 0.05235875956714153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.109038727998268,
    "estimated_duration": 3600.125628030586,
    "input_throughput": 4822.88864166617,
    "output_throughput": 4232.0398158812695,
    "total_throughput": 9054.92845754744,
    "itl": 199.01542403423224,
    "ttft": 2184180.5219921935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4728717492124945,
    "arrivals": 1252442,
    "finished_requests": 69867,
    "scheduler_time": 86.39997999127002
}
#Debug simulation 
Total elapsed time: 5.109136735030916. Arrivals time: 0.24193442275281996 Scheduler time: 4.771735749149229 Scheduler overhead time: 0.02802102017449215 Adapter cache time: 0.025841650494839996 Engine time: 0.02849939465522766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.428872307005804,
    "estimated_duration": 3600.067126557101,
    "input_throughput": 3936.254936877282,
    "output_throughput": 3465.199553634527,
    "total_throughput": 7401.454490511809,
    "itl": 97.31890010914807,
    "ttft": 2284083.259661349,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.343648219835017,
    "arrivals": 1252442,
    "finished_requests": 57041,
    "scheduler_time": 100.32010980031367
}
#Debug simulation 
Total elapsed time: 4.428978549025487. Arrivals time: 0.20735919807339087 Scheduler time: 4.026418042660225 Scheduler overhead time: 0.05164426099509001 Adapter cache time: 0.06691633322043344 Engine time: 0.05234126670984551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.140851182979532,
    "estimated_duration": 3600.0777447323353,
    "input_throughput": 4823.494999631203,
    "output_throughput": 4232.727202154617,
    "total_throughput": 9056.22220178582,
    "itl": 199.24710716568748,
    "ttft": 2184061.7382559315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 471,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4083136888989116,
    "arrivals": 1252442,
    "finished_requests": 69877,
    "scheduler_time": 86.382967025928
}
#Debug simulation 
Total elapsed time: 5.140928795968648. Arrivals time: 0.24320834001991898 Scheduler time: 4.802121987682767 Scheduler overhead time: 0.028048802574630827 Adapter cache time: 0.025820942770224065 Engine time: 0.028712336788885295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.516661766974721,
    "estimated_duration": 3600.084442023893,
    "input_throughput": 3936.236004518127,
    "output_throughput": 3465.182886928852,
    "total_throughput": 7401.418891446979,
    "itl": 97.31937434292603,
    "ttft": 2284091.4990461357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3608764885738507,
    "arrivals": 1252442,
    "finished_requests": 57041,
    "scheduler_time": 100.32019699837969
}
#Debug simulation 
Total elapsed time: 4.516743345011491. Arrivals time: 0.20891877048416063 Scheduler time: 4.111917032394558 Scheduler overhead time: 0.05119116883724928 Adapter cache time: 0.06808543117949739 Engine time: 0.05234423803631216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.15700124995783,
    "estimated_duration": 3600.0622316951312,
    "input_throughput": 4882.605596438077,
    "output_throughput": 4287.746990621245,
    "total_throughput": 9170.35258705932,
    "itl": 199.760972467985,
    "ttft": 2180768.647751929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8118087444082172,
    "arrivals": 1246365,
    "finished_requests": 70983,
    "scheduler_time": 87.1323090704592
}
#Debug simulation 
Total elapsed time: 5.157074918970466. Arrivals time: 0.23386300931451842 Scheduler time: 4.83002553076949 Scheduler overhead time: 0.028096227499190718 Adapter cache time: 0.023133312934078276 Engine time: 0.02886070846579969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.142858110019006,
    "estimated_duration": 3600.07136037068,
    "input_throughput": 4875.71529643031,
    "output_throughput": 4282.956490732559,
    "total_throughput": 9158.67178716287,
    "itl": 198.0663765562104,
    "ttft": 2181557.4771309257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9316348084318495,
    "arrivals": 1246365,
    "finished_requests": 70893,
    "scheduler_time": 87.24998371860356
}
#Debug simulation 
Total elapsed time: 5.142935772018973. Arrivals time: 0.23395986523246393 Scheduler time: 4.815524880192243 Scheduler overhead time: 0.028262259031180292 Adapter cache time: 0.023359583981800824 Engine time: 0.028722288378048688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.430017900012899,
    "estimated_duration": 3600.0935749337973,
    "input_throughput": 3948.776525971667,
    "output_throughput": 3479.6764970839304,
    "total_throughput": 7428.453023055597,
    "itl": 96.74085291253063,
    "ttft": 2283928.999961801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6002551766298807,
    "arrivals": 1246365,
    "finished_requests": 57296,
    "scheduler_time": 100.88535434417598
}
#Debug simulation 
Total elapsed time: 4.430089653993491. Arrivals time: 0.20335385884391144 Scheduler time: 4.034378488198854 Scheduler overhead time: 0.05191233241930604 Adapter cache time: 0.06325479387305677 Engine time: 0.05267273780191317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.250187890953384,
    "estimated_duration": 3600.2101476186613,
    "input_throughput": 4875.600390052357,
    "output_throughput": 4283.000260470704,
    "total_throughput": 9158.600650523062,
    "itl": 198.06291438347958,
    "ttft": 2181573.05859071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8486899587884416,
    "arrivals": 1246365,
    "finished_requests": 70895,
    "scheduler_time": 87.2552104902925
}
#Debug simulation 
Total elapsed time: 5.2502657089498825. Arrivals time: 0.32587120501557365 Scheduler time: 4.830373861652333 Scheduler overhead time: 0.028411685954779387 Adapter cache time: 0.02337766607524827 Engine time: 0.028959185758139938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.452852017013356,
    "estimated_duration": 3600.007129378424,
    "input_throughput": 3948.583569181527,
    "output_throughput": 3479.630886776287,
    "total_throughput": 7428.214455957814,
    "itl": 96.7419385175468,
    "ttft": 2283818.3259408004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6215075665339864,
    "arrivals": 1246365,
    "finished_requests": 57293,
    "scheduler_time": 100.88243715545346
}
#Debug simulation 
Total elapsed time: 4.4529250070336275. Arrivals time: 0.20612436888040975 Scheduler time: 4.053936492127832 Scheduler overhead time: 0.05244164512259886 Adapter cache time: 0.06308682472445071 Engine time: 0.05273577611660585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.125076768978033,
    "estimated_duration": 3600.1343886587006,
    "input_throughput": 4875.702989115297,
    "output_throughput": 4283.09038922986,
    "total_throughput": 9158.793378345157,
    "itl": 198.05939615188322,
    "ttft": 2181538.57634475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.773099824876964,
    "arrivals": 1246365,
    "finished_requests": 70895,
    "scheduler_time": 87.25504166422706
}
#Debug simulation 
Total elapsed time: 5.12515981902834. Arrivals time: 0.2369932484580204 Scheduler time: 4.794725805870257 Scheduler overhead time: 0.028233078541234136 Adapter cache time: 0.023303332331124693 Engine time: 0.028696622524876148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_320_slots_192_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.442594780004583,
    "estimated_duration": 3600.0265792777586,
    "input_throughput": 3948.562236129883,
    "output_throughput": 3479.612087339955,
    "total_throughput": 7428.174323469838,
    "itl": 96.74243930219076,
    "ttft": 2283827.133953101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6408736496418703,
    "arrivals": 1246365,
    "finished_requests": 57293,
    "scheduler_time": 100.88252097169332
}
#Debug simulation 
Total elapsed time: 4.442665231006686. Arrivals time: 0.20432279794476926 Scheduler time: 4.046750542824157 Scheduler overhead time: 0.05177282262593508 Adapter cache time: 0.06285602855496109 Engine time: 0.052565658872481436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.183998532011174,
    "estimated_duration": 3600.0189344888117,
    "input_throughput": 4898.188404251795,
    "output_throughput": 4310.886215436996,
    "total_throughput": 9209.07461968879,
    "itl": 198.86453739084962,
    "ttft": 2183697.457550993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5424858229421254,
    "arrivals": 1243986,
    "finished_requests": 70968,
    "scheduler_time": 87.63929513031518
}
#Debug simulation 
Total elapsed time: 5.184080355975311. Arrivals time: 0.23461702011991292 Scheduler time: 4.858525629271753 Scheduler overhead time: 0.028088379476685077 Adapter cache time: 0.021109032328240573 Engine time: 0.028641806449741125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1750638199737296,
    "estimated_duration": 3600.174089510455,
    "input_throughput": 4889.598270064123,
    "output_throughput": 4302.640265406259,
    "total_throughput": 9192.238535470382,
    "itl": 196.95422799719512,
    "ttft": 2183899.154768374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6418218037160162,
    "arrivals": 1243986,
    "finished_requests": 70847,
    "scheduler_time": 87.7742713119908
}
#Debug simulation 
Total elapsed time: 5.175137243990321. Arrivals time: 0.23517638980410993 Scheduler time: 4.848019031982403 Scheduler overhead time: 0.028389826708007604 Adapter cache time: 0.021351963048800826 Engine time: 0.02894647151697427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.455182696983684,
    "estimated_duration": 3600.041311980207,
    "input_throughput": 3956.6215400359033,
    "output_throughput": 3496.8259831094997,
    "total_throughput": 7453.447523145403,
    "itl": 96.85761515959378,
    "ttft": 2289491.8877239074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4382990568503822,
    "arrivals": 1243986,
    "finished_requests": 57310,
    "scheduler_time": 101.06836534265187
}
#Debug simulation 
Total elapsed time: 4.455261871975381. Arrivals time: 0.20253686828073114 Scheduler time: 4.0603677033795975 Scheduler overhead time: 0.0518878007424064 Adapter cache time: 0.0634164332295768 Engine time: 0.052629998594056815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.266739461047109,
    "estimated_duration": 3600.104881205031,
    "input_throughput": 4889.692267550764,
    "output_throughput": 4302.722979230285,
    "total_throughput": 9192.415246781049,
    "itl": 196.95102568916386,
    "ttft": 2183867.8576807333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.572769194899585,
    "arrivals": 1243986,
    "finished_requests": 70847,
    "scheduler_time": 87.774115615368
}
#Debug simulation 
Total elapsed time: 5.266836294031236. Arrivals time: 0.32245605275966227 Scheduler time: 4.852446961624082 Scheduler overhead time: 0.02841859933687374 Adapter cache time: 0.021506860619410872 Engine time: 0.028861043567303568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.813672140007839,
    "estimated_duration": 3600.060006494788,
    "input_throughput": 3956.6009939564105,
    "output_throughput": 3496.8078246720816,
    "total_throughput": 7453.408818628493,
    "itl": 96.85810720138859,
    "ttft": 2289500.044919778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4569106172397777,
    "arrivals": 1243986,
    "finished_requests": 57310,
    "scheduler_time": 101.06844829685764
}
#Debug simulation 
Total elapsed time: 4.813748065032996. Arrivals time: 0.5522342310287058 Scheduler time: 4.06888414977584 Scheduler overhead time: 0.05189776548650116 Adapter cache time: 0.06347690999973565 Engine time: 0.052716161182615906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.24975323601393,
    "estimated_duration": 3600.1035324557547,
    "input_throughput": 4888.6469073278795,
    "output_throughput": 4301.551291619784,
    "total_throughput": 9190.198198947664,
    "itl": 196.53797368308022,
    "ttft": 2183998.1442337655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.50698534863068,
    "arrivals": 1243986,
    "finished_requests": 70822,
    "scheduler_time": 87.80397080050619
}
#Debug simulation 
Total elapsed time: 5.249829881009646. Arrivals time: 0.3215008739498444 Scheduler time: 4.835584324609954 Scheduler overhead time: 0.028600896417628974 Adapter cache time: 0.021676696138456464 Engine time: 0.029162349877879024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 192,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_320_slots_192_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.483802575035952,
    "estimated_duration": 3600.078449700728,
    "input_throughput": 3956.580724285076,
    "output_throughput": 3496.7899105216698,
    "total_throughput": 7453.370634806745,
    "itl": 96.85857943128867,
    "ttft": 2289508.2845877986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4752706700563434,
    "arrivals": 1243986,
    "finished_requests": 57310,
    "scheduler_time": 101.06853144999434
}
#Debug simulation 
Total elapsed time: 4.483872145006899. Arrivals time: 0.20737283438211307 Scheduler time: 4.083596252196003 Scheduler overhead time: 0.051985995552968234 Adapter cache time: 0.06356396531919017 Engine time: 0.05287186155328527 
