INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 25.41613325383514,
    "estimated_duration": 3600.0833442182347,
    "input_throughput": 5329.214677991349,
    "output_throughput": 4716.078595032323,
    "total_throughput": 10045.293273023672,
    "itl": 181.45150934856488,
    "ttft": 1488464.291786015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 366,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.146250013376121,
    "arrivals": 142715,
    "finished_requests": 77408,
    "scheduler_time": 111.37254307274418
}
#Debug simulation 
Total elapsed time: 25.416351228952408. Arrivals time: 0.326316692866385 Scheduler time: 24.973186747170985 Scheduler overhead time: 0.042954349890351295 Adapter cache time: 0.01298027066513896 Engine time: 0.044369516894221306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 24.32973917108029,
    "estimated_duration": 3600.1324229285206,
    "input_throughput": 5313.091784673993,
    "output_throughput": 4699.722958034073,
    "total_throughput": 10012.814742708066,
    "itl": 178.97017552077975,
    "ttft": 1498522.5911654804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3182623162865685,
    "arrivals": 142715,
    "finished_requests": 77178,
    "scheduler_time": 111.7671912777329
}
#Debug simulation 
Total elapsed time: 24.329881319310516. Arrivals time: 0.33153283735737205 Scheduler time: 23.87765424931422 Scheduler overhead time: 0.043972163926810026 Adapter cache time: 0.01447915006428957 Engine time: 0.044935621321201324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 25.55352982878685,
    "estimated_duration": 3600.1742353006616,
    "input_throughput": 5328.379335617894,
    "output_throughput": 4716.838377846407,
    "total_throughput": 10045.2177134643,
    "itl": 181.472647826971,
    "ttft": 1488214.3677948406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 368,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1003385085239985,
    "arrivals": 142715,
    "finished_requests": 77407,
    "scheduler_time": 111.37123572901909
}
#Debug simulation 
Total elapsed time: 25.553652700968087. Arrivals time: 0.3285947232507169 Scheduler time: 25.105131454300135 Scheduler overhead time: 0.04458429478108883 Adapter cache time: 0.01339916605502367 Engine time: 0.04477688251063228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 24.325359748210758,
    "estimated_duration": 3600.0857581931105,
    "input_throughput": 5313.029823378446,
    "output_throughput": 4699.603880684127,
    "total_throughput": 10012.633704062573,
    "itl": 178.96224725996015,
    "ttft": 1498530.5457741586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3358678463846463,
    "arrivals": 142715,
    "finished_requests": 77180,
    "scheduler_time": 111.76767919408391
}
#Debug simulation 
Total elapsed time: 24.32553950417787. Arrivals time: 0.33838984882459044 Scheduler time: 23.86611823644489 Scheduler overhead time: 0.043928887229412794 Adapter cache time: 0.014165985863655806 Engine time: 0.04566494049504399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 22.247002370189875,
    "estimated_duration": 3600.024380800044,
    "input_throughput": 5361.262024484055,
    "output_throughput": 4716.882499619707,
    "total_throughput": 10078.144524103762,
    "itl": 181.0419782624042,
    "ttft": 1485339.6717349212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1629853426944508,
    "arrivals": 140795,
    "finished_requests": 77464,
    "scheduler_time": 111.22763746054726
}
#Debug simulation 
Total elapsed time: 22.24709859583527. Arrivals time: 0.32613092521205544 Scheduler time: 21.806763637810946 Scheduler overhead time: 0.04196511534973979 Adapter cache time: 0.012811832129955292 Engine time: 0.04282065900042653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 22.298614887986332,
    "estimated_duration": 3600.0384213996394,
    "input_throughput": 5361.756942720482,
    "output_throughput": 4716.241054282683,
    "total_throughput": 10077.997997003164,
    "itl": 181.03986439636898,
    "ttft": 1485308.9755148946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.244218159196904,
    "arrivals": 140795,
    "finished_requests": 77450,
    "scheduler_time": 111.22847379970439
}
#Debug simulation 
Total elapsed time: 22.29879081621766. Arrivals time: 0.3286577146500349 Scheduler time: 21.85590749932453 Scheduler overhead time: 0.041717701591551304 Adapter cache time: 0.013338225428014994 Engine time: 0.04250579420477152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 21.34328865399584,
    "estimated_duration": 3600.0825194058216,
    "input_throughput": 5343.885840476573,
    "output_throughput": 4700.512810132181,
    "total_throughput": 10044.398650608755,
    "itl": 178.70049317619095,
    "ttft": 1490878.7910946037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2787119609303845,
    "arrivals": 140795,
    "finished_requests": 77239,
    "scheduler_time": 111.63498016679648
}
#Debug simulation 
Total elapsed time: 21.343384460080415. Arrivals time: 0.32368340250104666 Scheduler time: 20.904026573058218 Scheduler overhead time: 0.04289113683626056 Adapter cache time: 0.013759137131273746 Engine time: 0.042044480331242085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 22.461146865971386,
    "estimated_duration": 3600.1329847388733,
    "input_throughput": 5361.779434767214,
    "output_throughput": 4716.427440868989,
    "total_throughput": 10078.206875636204,
    "itl": 181.03992743930834,
    "ttft": 1485294.168874248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1955953163024982,
    "arrivals": 140795,
    "finished_requests": 77453,
    "scheduler_time": 111.23246296436653
}
#Debug simulation 
Total elapsed time: 22.461295621935278. Arrivals time: 0.3245394858531654 Scheduler time: 22.02195314830169 Scheduler overhead time: 0.04147277167066932 Adapter cache time: 0.01338523579761386 Engine time: 0.04323976580053568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 21.35160755319521,
    "estimated_duration": 3600.136632465312,
    "input_throughput": 5346.122373922276,
    "output_throughput": 4701.939322899601,
    "total_throughput": 10048.061696821876,
    "itl": 178.71544125886373,
    "ttft": 1491036.032314712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3560935185849718,
    "arrivals": 140795,
    "finished_requests": 77268,
    "scheduler_time": 111.6338478206313
}
#Debug simulation 
Total elapsed time: 21.35172597831115. Arrivals time: 0.32311949878931046 Scheduler time: 20.914736142382026 Scheduler overhead time: 0.04161389824002981 Adapter cache time: 0.013385562226176262 Engine time: 0.04232464637607336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 22.466562459710985,
    "estimated_duration": 3600.169784177175,
    "input_throughput": 5361.893787576438,
    "output_throughput": 4716.744769825086,
    "total_throughput": 10078.638557401524,
    "itl": 181.03703584591275,
    "ttft": 1485268.6488396176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1392091623577254,
    "arrivals": 140795,
    "finished_requests": 77456,
    "scheduler_time": 111.23473431717959
}
#Debug simulation 
Total elapsed time: 22.466661978978664. Arrivals time: 0.3263572189025581 Scheduler time: 22.024040607735515 Scheduler overhead time: 0.042869878467172384 Adapter cache time: 0.013548130635172129 Engine time: 0.04313315358012915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 21.47246070811525,
    "estimated_duration": 3600.0726778811686,
    "input_throughput": 5343.816006326474,
    "output_throughput": 4700.52510438751,
    "total_throughput": 10044.341110713984,
    "itl": 178.69861987660477,
    "ttft": 1490890.6120649984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.311785206757488,
    "arrivals": 140795,
    "finished_requests": 77238,
    "scheduler_time": 111.63612374098108
}
#Debug simulation 
Total elapsed time: 21.472613653168082. Arrivals time: 0.3259389568120241 Scheduler time: 21.031060471665114 Scheduler overhead time: 0.04287120746448636 Adapter cache time: 0.013525173533707857 Engine time: 0.04222871456295252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 18.21822467306629,
    "estimated_duration": 3600.1316731121897,
    "input_throughput": 5346.7216612552365,
    "output_throughput": 4713.663982553778,
    "total_throughput": 10060.385643809015,
    "itl": 181.11099546173028,
    "ttft": 1480077.6318776687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3251911931228924,
    "arrivals": 139799,
    "finished_requests": 77595,
    "scheduler_time": 110.98006903704719
}
#Debug simulation 
Total elapsed time: 18.218320024665445. Arrivals time: 0.30404684599488974 Scheduler time: 17.80332034220919 Scheduler overhead time: 0.04035521997138858 Adapter cache time: 0.013368720188736916 Engine time: 0.04071389231830835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.147835441865027,
    "estimated_duration": 3600.1835866834563,
    "input_throughput": 5346.644563126954,
    "output_throughput": 4713.596012928009,
    "total_throughput": 10060.240576054965,
    "itl": 181.11498990908072,
    "ttft": 1480098.6463748869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.407334202516364,
    "arrivals": 139799,
    "finished_requests": 77595,
    "scheduler_time": 110.98021509597645
}
#Debug simulation 
Total elapsed time: 18.147986117750406. Arrivals time: 0.314286629203707 Scheduler time: 17.725358901079744 Scheduler overhead time: 0.03900246089324355 Adapter cache time: 0.013691828586161137 Engine time: 0.03939435072243214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.34965861821547,
    "estimated_duration": 3600.0477957153034,
    "input_throughput": 5331.4400500025595,
    "output_throughput": 4702.932561103949,
    "total_throughput": 10034.372611106508,
    "itl": 179.09167102312998,
    "ttft": 1484013.9572159126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.433569300528624,
    "arrivals": 139799,
    "finished_requests": 77364,
    "scheduler_time": 111.306714539251
}
#Debug simulation 
Total elapsed time: 18.349752911832184. Arrivals time: 0.3147867675870657 Scheduler time: 17.923056665807962 Scheduler overhead time: 0.04083641618490219 Adapter cache time: 0.013951599132269621 Engine time: 0.0407142392359674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 18.203093484975398,
    "estimated_duration": 3600.137834445206,
    "input_throughput": 5347.233324183715,
    "output_throughput": 4713.6648040630125,
    "total_throughput": 10060.898128246728,
    "itl": 181.10168648040784,
    "ttft": 1480224.6209629306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3531209082296094,
    "arrivals": 139799,
    "finished_requests": 77604,
    "scheduler_time": 110.98036187583371
}
#Debug simulation 
Total elapsed time: 18.203243606723845. Arrivals time: 0.31435564206913114 Scheduler time: 17.778092411812395 Scheduler overhead time: 0.04005836369469762 Adapter cache time: 0.013544817920774221 Engine time: 0.04057716066017747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 18.252576909959316,
    "estimated_duration": 3600.145952422793,
    "input_throughput": 5333.169614159347,
    "output_throughput": 4704.05428663331,
    "total_throughput": 10037.223900792656,
    "itl": 179.12791563409536,
    "ttft": 1484095.5872988254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4550586121156857,
    "arrivals": 139799,
    "finished_requests": 77393,
    "scheduler_time": 111.2982547318484
}
#Debug simulation 
Total elapsed time: 18.252687396947294. Arrivals time: 0.306183741427958 Scheduler time: 17.83686958393082 Scheduler overhead time: 0.039766133297234774 Adapter cache time: 0.01349180517718196 Engine time: 0.039727328810840845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 18.138812348246574,
    "estimated_duration": 3600.086049650504,
    "input_throughput": 5346.789419621979,
    "output_throughput": 4713.723718255965,
    "total_throughput": 10060.513137877944,
    "itl": 181.11081085741992,
    "ttft": 1480062.4126929638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.291701727397731,
    "arrivals": 139799,
    "finished_requests": 77595,
    "scheduler_time": 110.97903433794804
}
#Debug simulation 
Total elapsed time: 18.138932284899056. Arrivals time: 0.3167148204520345 Scheduler time: 17.71170513983816 Scheduler overhead time: 0.04007102455943823 Adapter cache time: 0.01376825524494052 Engine time: 0.04029292380437255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 18.343159919138998,
    "estimated_duration": 3600.1681085451296,
    "input_throughput": 5333.136792814662,
    "output_throughput": 4704.02533698454,
    "total_throughput": 10037.162129799202,
    "itl": 179.12751310288434,
    "ttft": 1484106.649732358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 440,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4734186649322516,
    "arrivals": 139799,
    "finished_requests": 77393,
    "scheduler_time": 111.29867650385643
}
#Debug simulation 
Total elapsed time: 18.343275549821556. Arrivals time: 0.31797766545787454 Scheduler time: 17.912799569778144 Scheduler overhead time: 0.04089961340650916 Adapter cache time: 0.013893466908484697 Engine time: 0.04111076286062598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.08253198582679,
    "estimated_duration": 3600.098386654304,
    "input_throughput": 5344.4572713138905,
    "output_throughput": 4715.001418551497,
    "total_throughput": 10059.458689865389,
    "itl": 181.05487610062525,
    "ttft": 1454341.5914192176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.199711195621645,
    "arrivals": 135085,
    "finished_requests": 77492,
    "scheduler_time": 109.9655240688351
}
#Debug simulation 
Total elapsed time: 16.08265503309667. Arrivals time: 0.3048612088896334 Scheduler time: 15.673155872616917 Scheduler overhead time: 0.03816918469965458 Adapter cache time: 0.011987438891083002 Engine time: 0.03858159715309739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 16.327225798740983,
    "estimated_duration": 3600.133318265132,
    "input_throughput": 5344.309862744659,
    "output_throughput": 4714.847895738383,
    "total_throughput": 10059.157758483041,
    "itl": 181.05854571151932,
    "ttft": 1454399.6459700172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.276700117122387,
    "arrivals": 135085,
    "finished_requests": 77489,
    "scheduler_time": 109.96560798555262
}
#Debug simulation 
Total elapsed time: 16.32733937771991. Arrivals time: 0.31134953862056136 Scheduler time: 15.909423270262778 Scheduler overhead time: 0.03875522967427969 Adapter cache time: 0.012217574752867222 Engine time: 0.03962353756651282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.653727945871651,
    "estimated_duration": 3600.1929111549716,
    "input_throughput": 5328.364749722784,
    "output_throughput": 4702.4724557242625,
    "total_throughput": 10030.837205447046,
    "itl": 178.82697882045315,
    "ttft": 1458945.3996988575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3257137336395757,
    "arrivals": 135085,
    "finished_requests": 77261,
    "scheduler_time": 110.34891661470239
}
#Debug simulation 
Total elapsed time: 15.65385157102719. Arrivals time: 0.30685992212966084 Scheduler time: 15.240017699543387 Scheduler overhead time: 0.038765739649534225 Adapter cache time: 0.01296756137162447 Engine time: 0.039145343005657196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 16.38332658307627,
    "estimated_duration": 3600.1765832474216,
    "input_throughput": 5344.412296200327,
    "output_throughput": 4715.020946191572,
    "total_throughput": 10059.433242391899,
    "itl": 181.05803605552458,
    "ttft": 1454326.3802951563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2264428929542193,
    "arrivals": 135085,
    "finished_requests": 77493,
    "scheduler_time": 109.96771315701464
}
#Debug simulation 
Total elapsed time: 16.383431611116976. Arrivals time: 0.2960081226192415 Scheduler time: 15.980251808650792 Scheduler overhead time: 0.03909887978807092 Adapter cache time: 0.012296904344111681 Engine time: 0.03960154624655843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 15.591698912903666,
    "estimated_duration": 3600.0111677848304,
    "input_throughput": 5328.409025965141,
    "output_throughput": 4702.554856355337,
    "total_throughput": 10030.963882320479,
    "itl": 178.8259486302012,
    "ttft": 1458954.1469464353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3423132334463348,
    "arrivals": 135085,
    "finished_requests": 77257,
    "scheduler_time": 110.34237765564669
}
#Debug simulation 
Total elapsed time: 15.591822557616979. Arrivals time: 0.3086899700574577 Scheduler time: 15.176760548260063 Scheduler overhead time: 0.03862676024436951 Adapter cache time: 0.012277184519916773 Engine time: 0.0391680053435266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 16.176191938109696,
    "estimated_duration": 3600.047004896402,
    "input_throughput": 5344.399663068752,
    "output_throughput": 4714.699551676668,
    "total_throughput": 10059.09921474542,
    "itl": 181.05386309238543,
    "ttft": 1454386.2975117348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1720997156016482,
    "arrivals": 135085,
    "finished_requests": 77488,
    "scheduler_time": 109.96419554742506
}
#Debug simulation 
Total elapsed time: 16.17629187228158. Arrivals time: 0.3023383365944028 Scheduler time: 15.769156523514539 Scheduler overhead time: 0.03788477275520563 Adapter cache time: 0.012235877104103565 Engine time: 0.038516155909746885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 15.656258952338248,
    "estimated_duration": 3600.0405682222404,
    "input_throughput": 5328.36551046772,
    "output_throughput": 4702.516452018746,
    "total_throughput": 10030.881962486466,
    "itl": 178.82609079965516,
    "ttft": 1458969.5584346787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.359289994612338,
    "arrivals": 135085,
    "finished_requests": 77257,
    "scheduler_time": 110.34323803995366
}
#Debug simulation 
Total elapsed time: 15.656412236392498. Arrivals time: 0.3045515464618802 Scheduler time: 15.246094195637852 Scheduler overhead time: 0.03808430302888155 Adapter cache time: 0.012534737586975098 Engine time: 0.03863378521054983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 13.825033572036773,
    "estimated_duration": 3600.001446607045,
    "input_throughput": 5366.907565609363,
    "output_throughput": 4719.298936952475,
    "total_throughput": 10086.206502561838,
    "itl": 181.15339784297632,
    "ttft": 1428752.0404633887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2792838769638994,
    "arrivals": 133166,
    "finished_requests": 78039,
    "scheduler_time": 109.16958271772614
}
#Debug simulation 
Total elapsed time: 13.82512840628624. Arrivals time: 0.2806137013249099 Scheduler time: 13.441761321388185 Scheduler overhead time: 0.03670716006308794 Adapter cache time: 0.012675548437982798 Engine time: 0.037705790251493454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.840827873907983,
    "estimated_duration": 3600.0441560953373,
    "input_throughput": 5365.155304358578,
    "output_throughput": 4719.929051767446,
    "total_throughput": 10085.084356126024,
    "itl": 181.19757375519416,
    "ttft": 1428727.2694147346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3724006726802376,
    "arrivals": 133166,
    "finished_requests": 78041,
    "scheduler_time": 109.15828288635785
}
#Debug simulation 
Total elapsed time: 13.840950904879719. Arrivals time: 0.2952336547896266 Scheduler time: 13.444197531789541 Scheduler overhead time: 0.036031126510351896 Adapter cache time: 0.012382694520056248 Engine time: 0.03725564572960138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.693446011282504,
    "estimated_duration": 3600.0851783473745,
    "input_throughput": 5350.195633104956,
    "output_throughput": 4706.659470701286,
    "total_throughput": 10056.855103806243,
    "itl": 179.1579153028802,
    "ttft": 1432507.6105551992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3683147061243732,
    "arrivals": 133166,
    "finished_requests": 77825,
    "scheduler_time": 109.50629537750346
}
#Debug simulation 
Total elapsed time: 13.69354344997555. Arrivals time: 0.2927895481698215 Scheduler time: 13.297414597589523 Scheduler overhead time: 0.03681288845837116 Adapter cache time: 0.012546776328235865 Engine time: 0.038121501449495554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 13.836983831133693,
    "estimated_duration": 3600.0602680797238,
    "input_throughput": 5366.9312625996645,
    "output_throughput": 4719.360437002482,
    "total_throughput": 10086.291699602147,
    "itl": 181.1556108289064,
    "ttft": 1428736.265720919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3054099865769944,
    "arrivals": 133166,
    "finished_requests": 78041,
    "scheduler_time": 109.171085744463
}
#Debug simulation 
Total elapsed time: 13.837130691856146. Arrivals time: 0.2988332789391279 Scheduler time: 13.436787884682417 Scheduler overhead time: 0.0363537254743278 Adapter cache time: 0.012212057132273912 Engine time: 0.03713984088972211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 13.644042918924242,
    "estimated_duration": 3600.128780458889,
    "input_throughput": 5350.130835471081,
    "output_throughput": 4706.602467104021,
    "total_throughput": 10056.733302575103,
    "itl": 179.15943680575862,
    "ttft": 1432522.9302303065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3857944824360353,
    "arrivals": 133166,
    "finished_requests": 77825,
    "scheduler_time": 109.50703743578238
}
#Debug simulation 
Total elapsed time: 13.644140740856528. Arrivals time: 0.2794511988759041 Scheduler time: 13.26202462054789 Scheduler overhead time: 0.03681366518139839 Adapter cache time: 0.012543798424303532 Engine time: 0.03727421211078763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 13.809702922124416,
    "estimated_duration": 3600.149910228596,
    "input_throughput": 5366.876513976373,
    "output_throughput": 4718.887941786091,
    "total_throughput": 10085.764455762464,
    "itl": 181.153382937248,
    "ttft": 1428837.358970128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 418,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.249841023269102,
    "arrivals": 133166,
    "finished_requests": 78037,
    "scheduler_time": 109.17592204085342
}
#Debug simulation 
Total elapsed time: 13.809816469438374. Arrivals time: 0.2847291985526681 Scheduler time: 13.422809753101319 Scheduler overhead time: 0.03677551634609699 Adapter cache time: 0.012312184553593397 Engine time: 0.037298611365258694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 13.657314755022526,
    "estimated_duration": 3600.03626105713,
    "input_throughput": 5350.57305071248,
    "output_throughput": 4707.052032588148,
    "total_throughput": 10057.625083300629,
    "itl": 179.25947111374998,
    "ttft": 1432547.26215411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 419,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4030227511748685,
    "arrivals": 133166,
    "finished_requests": 77834,
    "scheduler_time": 109.48667631279028
}
#Debug simulation 
Total elapsed time: 13.6574344499968. Arrivals time: 0.2930076867341995 Scheduler time: 13.262141688261181 Scheduler overhead time: 0.03678347636014223 Adapter cache time: 0.012486135587096214 Engine time: 0.03718779236078262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 11.694749530870467,
    "estimated_duration": 3600.028344478388,
    "input_throughput": 5333.145231883398,
    "output_throughput": 4719.7381170791505,
    "total_throughput": 10052.883348962549,
    "itl": 181.4683127894094,
    "ttft": 1431708.6364216493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3190702176350266,
    "arrivals": 132222,
    "finished_requests": 77717,
    "scheduler_time": 109.00321433501726
}
#Debug simulation 
Total elapsed time: 11.694846756756306. Arrivals time: 0.2885766006074846 Scheduler time: 11.307521851733327 Scheduler overhead time: 0.035184542648494244 Adapter cache time: 0.01229415787383914 Engine time: 0.035596009343862534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 11.802769696339965,
    "estimated_duration": 3600.0011056153903,
    "input_throughput": 5331.268362685458,
    "output_throughput": 4719.496050570147,
    "total_throughput": 10050.764413255605,
    "itl": 181.49225380436832,
    "ttft": 1431582.6805162039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3859952551336086,
    "arrivals": 132222,
    "finished_requests": 77703,
    "scheduler_time": 108.9992068566654
}
#Debug simulation 
Total elapsed time: 11.802891252096742. Arrivals time: 0.28575248876586556 Scheduler time: 11.417087119538337 Scheduler overhead time: 0.03575934749096632 Adapter cache time: 0.012226000428199768 Engine time: 0.03645153762772679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 11.66169612808153,
    "estimated_duration": 3600.174333631315,
    "input_throughput": 5318.632162094876,
    "output_throughput": 4708.802804807748,
    "total_throughput": 10027.434966902623,
    "itl": 179.66864744620662,
    "ttft": 1435152.49654925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.401785122063019,
    "arrivals": 132222,
    "finished_requests": 77522,
    "scheduler_time": 109.29142249872037
}
#Debug simulation 
Total elapsed time: 11.661791888065636. Arrivals time: 0.2836058051325381 Scheduler time: 11.278581134043634 Scheduler overhead time: 0.03575497353449464 Adapter cache time: 0.012373768724501133 Engine time: 0.035747116431593895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 11.735708716325462,
    "estimated_duration": 3600.0689974078373,
    "input_throughput": 5331.247543816372,
    "output_throughput": 4719.407603641339,
    "total_throughput": 10050.65514745771,
    "itl": 181.48926527850847,
    "ttft": 1431587.1942008925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 425,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3324692684179162,
    "arrivals": 132222,
    "finished_requests": 77704,
    "scheduler_time": 109.00240499348081
}
#Debug simulation 
Total elapsed time: 11.735814132262021. Arrivals time: 0.277912394143641 Scheduler time: 11.359055891633034 Scheduler overhead time: 0.03524088393896818 Adapter cache time: 0.012076475657522678 Engine time: 0.03596057463437319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 11.624205355066806,
    "estimated_duration": 3600.169492173403,
    "input_throughput": 5318.697089575171,
    "output_throughput": 4708.862467962792,
    "total_throughput": 10027.559557537963,
    "itl": 179.6734915514922,
    "ttft": 1435110.1196152726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4183846218697775,
    "arrivals": 132222,
    "finished_requests": 77522,
    "scheduler_time": 109.2911084144571
}
#Debug simulation 
Total elapsed time: 11.624322875868529. Arrivals time: 0.2742894268594682 Scheduler time: 11.250657370314002 Scheduler overhead time: 0.03540538065135479 Adapter cache time: 0.012160052079707384 Engine time: 0.036144856829196215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 11.711426279973239,
    "estimated_duration": 3600.1373138447857,
    "input_throughput": 5333.254908406473,
    "output_throughput": 4719.656090521151,
    "total_throughput": 10052.910998927624,
    "itl": 181.46438868034653,
    "ttft": 1431785.2374445894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2857216268079268,
    "arrivals": 132222,
    "finished_requests": 77719,
    "scheduler_time": 109.00746477353077
}
#Debug simulation 
Total elapsed time: 11.711530092172325. Arrivals time: 0.2824490494094789 Scheduler time: 11.330527925863862 Scheduler overhead time: 0.035422504879534245 Adapter cache time: 0.01221275795251131 Engine time: 0.0354527710005641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 11.654284966178238,
    "estimated_duration": 3600.0622860111976,
    "input_throughput": 5318.599646011915,
    "output_throughput": 4708.373537275871,
    "total_throughput": 10026.973183287786,
    "itl": 179.61675129777487,
    "ttft": 1435586.1808241508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4441749901697045,
    "arrivals": 132222,
    "finished_requests": 77511,
    "scheduler_time": 109.29816395761415
}
#Debug simulation 
Total elapsed time: 11.65441107423976. Arrivals time: 0.28358180867508054 Scheduler time: 11.270648845937103 Scheduler overhead time: 0.035651212092489004 Adapter cache time: 0.012441578786820173 Engine time: 0.03616441506892443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.776217877864838,
    "estimated_duration": 3600.0124538839414,
    "input_throughput": 5391.922180451928,
    "output_throughput": 4714.438690813249,
    "total_throughput": 10106.360871265179,
    "itl": 180.32973328889528,
    "ttft": 1412561.5856392898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394253351981926,
    "arrivals": 129353,
    "finished_requests": 77987,
    "scheduler_time": 108.2307475602157
}
#Debug simulation 
Total elapsed time: 9.7763134771958. Arrivals time: 0.2720312373712659 Scheduler time: 9.406920102890581 Scheduler overhead time: 0.034321113023906946 Adapter cache time: 0.013111036736518145 Engine time: 0.03462767926976085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.79815345397219,
    "estimated_duration": 3600.0625255676537,
    "input_throughput": 5392.853557991671,
    "output_throughput": 4713.963960202081,
    "total_throughput": 10106.817518193751,
    "itl": 180.31266307978723,
    "ttft": 1412652.930449504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6132769697881355,
    "arrivals": 129353,
    "finished_requests": 77995,
    "scheduler_time": 108.23934514804051
}
#Debug simulation 
Total elapsed time: 9.798246612306684. Arrivals time: 0.2757454216480255 Scheduler time: 9.425309763289988 Scheduler overhead time: 0.034123053308576345 Adapter cache time: 0.012883895542472601 Engine time: 0.03480692207813263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.580325601156801,
    "estimated_duration": 3600.048288430405,
    "input_throughput": 5379.0270153412,
    "output_throughput": 4703.313578991547,
    "total_throughput": 10082.340594332747,
    "itl": 178.41760051509414,
    "ttft": 1416604.610964278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6628034996800225,
    "arrivals": 129353,
    "finished_requests": 77787,
    "scheduler_time": 108.53083215562229
}
#Debug simulation 
Total elapsed time: 9.580453283153474. Arrivals time: 0.26110132224857807 Scheduler time: 9.221751827280968 Scheduler overhead time: 0.03412929642945528 Adapter cache time: 0.013107042759656906 Engine time: 0.03488909360021353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 9.765227543655783,
    "estimated_duration": 3600.0824571205085,
    "input_throughput": 5392.054274091925,
    "output_throughput": 4714.510904168399,
    "total_throughput": 10106.565178260325,
    "itl": 180.33010409640363,
    "ttft": 1412570.1633342449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 502,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5741438100417091,
    "arrivals": 129353,
    "finished_requests": 77989,
    "scheduler_time": 108.23254161460942
}
#Debug simulation 
Total elapsed time: 9.765320997685194. Arrivals time: 0.26749933790415525 Scheduler time: 9.400300798937678 Scheduler overhead time: 0.0344284032471478 Adapter cache time: 0.013061702251434326 Engine time: 0.034489850513637066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 9.585938252974302,
    "estimated_duration": 3600.180496110651,
    "input_throughput": 5379.098081588184,
    "output_throughput": 4703.398348580899,
    "total_throughput": 10082.496430169083,
    "itl": 178.4042943814886,
    "ttft": 1416629.5327669857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6822953365743205,
    "arrivals": 129353,
    "finished_requests": 77789,
    "scheduler_time": 108.53681179926855
}
#Debug simulation 
Total elapsed time: 9.586033758707345. Arrivals time: 0.26309374440461397 Scheduler time: 9.225006968714297 Scheduler overhead time: 0.03408844256773591 Adapter cache time: 0.013295913580805063 Engine time: 0.03504274459555745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.771684992592782,
    "estimated_duration": 3600.142560597242,
    "input_throughput": 5393.203094929372,
    "output_throughput": 4714.125819835458,
    "total_throughput": 10107.32891476483,
    "itl": 180.30636326654562,
    "ttft": 1412560.1502950403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4800748959765613,
    "arrivals": 129353,
    "finished_requests": 78000,
    "scheduler_time": 108.24411482029723
}
#Debug simulation 
Total elapsed time: 9.77181156957522. Arrivals time: 0.2702356521040201 Scheduler time: 9.404830409679562 Scheduler overhead time: 0.033956100698560476 Adapter cache time: 0.012907021678984165 Engine time: 0.03447019960731268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.631554225925356,
    "estimated_duration": 3600.1462365622856,
    "input_throughput": 5379.040385451565,
    "output_throughput": 4703.324500553813,
    "total_throughput": 10082.364886005378,
    "itl": 178.40976582370257,
    "ttft": 1416604.5721563036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7051825257018187,
    "arrivals": 129353,
    "finished_requests": 77788,
    "scheduler_time": 108.53555633227731
}
#Debug simulation 
Total elapsed time: 9.631647009868175. Arrivals time: 0.27176218945533037 Scheduler time: 9.261205295100808 Scheduler overhead time: 0.03430561441928148 Adapter cache time: 0.013317419681698084 Engine time: 0.03523023333400488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.401110523846,
    "estimated_duration": 3600.0579103697655,
    "input_throughput": 5364.319263968857,
    "output_throughput": 4720.488787430235,
    "total_throughput": 10084.808051399092,
    "itl": 180.87796331619995,
    "ttft": 1410659.931814008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.530243871966394,
    "arrivals": 128453,
    "finished_requests": 77814,
    "scheduler_time": 108.05952600046659
}
#Debug simulation 
Total elapsed time: 8.401205596979707. Arrivals time: 0.2653337735682726 Scheduler time: 8.040006786119193 Scheduler overhead time: 0.033601013477891684 Adapter cache time: 0.012872382532805204 Engine time: 0.03403309406712651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.460492209065706,
    "estimated_duration": 3600.081060849644,
    "input_throughput": 5364.284490705959,
    "output_throughput": 4720.410377645589,
    "total_throughput": 10084.694868351547,
    "itl": 180.88232228988346,
    "ttft": 1410674.9687585917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.631087388491729,
    "arrivals": 128453,
    "finished_requests": 77813,
    "scheduler_time": 108.05871269390953
}
#Debug simulation 
Total elapsed time: 8.460612583905458. Arrivals time: 0.26504038320854306 Scheduler time: 8.099948653019965 Scheduler overhead time: 0.03349510487169027 Adapter cache time: 0.01278475858271122 Engine time: 0.034041158854961395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.33921115892008,
    "estimated_duration": 3600.137846516023,
    "input_throughput": 5349.450443581588,
    "output_throughput": 4707.708905202491,
    "total_throughput": 10057.159348784078,
    "itl": 179.03801372130167,
    "ttft": 1413921.5880475538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6671960085071724,
    "arrivals": 128453,
    "finished_requests": 77622,
    "scheduler_time": 108.35624686166535
}
#Debug simulation 
Total elapsed time: 8.33930656593293. Arrivals time: 0.264835468493402 Scheduler time: 7.9769274913705885 Scheduler overhead time: 0.03359693428501487 Adapter cache time: 0.013092429377138615 Engine time: 0.0354935429058969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.458124125376344,
    "estimated_duration": 3600.1225771693935,
    "input_throughput": 5364.2501292786765,
    "output_throughput": 4720.311499327155,
    "total_throughput": 10084.56162860583,
    "itl": 180.8802020862344,
    "ttft": 1410692.343925462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5665293281781434,
    "arrivals": 128453,
    "finished_requests": 77814,
    "scheduler_time": 108.06104982936908
}
#Debug simulation 
Total elapsed time: 8.458220697008073. Arrivals time: 0.2655567009933293 Scheduler time: 8.096910384017974 Scheduler overhead time: 0.03336585080251098 Adapter cache time: 0.01282429276034236 Engine time: 0.03431213507428765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 8.317085005808622,
    "estimated_duration": 3600.037945177632,
    "input_throughput": 5349.343893943258,
    "output_throughput": 4707.6339911088835,
    "total_throughput": 10056.977885052142,
    "itl": 179.03056966066572,
    "ttft": 1414023.5968367136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6875681219063743,
    "arrivals": 128453,
    "finished_requests": 77617,
    "scheduler_time": 108.3520659246861
}
#Debug simulation 
Total elapsed time: 8.31721604289487. Arrivals time: 0.26456952514126897 Scheduler time: 7.956180156674236 Scheduler overhead time: 0.033683743327856064 Adapter cache time: 0.012886292766779661 Engine time: 0.034436353016644716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.48413582984358,
    "estimated_duration": 3600.173503393244,
    "input_throughput": 5364.438125495105,
    "output_throughput": 4720.459440074855,
    "total_throughput": 10084.89756556996,
    "itl": 180.87608194849898,
    "ttft": 1410723.1723305776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4950251474510716,
    "arrivals": 128453,
    "finished_requests": 77817,
    "scheduler_time": 108.06449985054157
}
#Debug simulation 
Total elapsed time: 8.484227856155485. Arrivals time: 0.268095709849149 Scheduler time: 8.121013245545328 Scheduler overhead time: 0.033286720514297485 Adapter cache time: 0.012750103138387203 Engine time: 0.03391931625083089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.360238809138536,
    "estimated_duration": 3600.061312061286,
    "input_throughput": 5349.309173007819,
    "output_throughput": 4707.603435313796,
    "total_throughput": 10056.912608321614,
    "itl": 179.03109422024647,
    "ttft": 1414034.3221268686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7100780496746284,
    "arrivals": 128453,
    "finished_requests": 77617,
    "scheduler_time": 108.35249924736475
}
#Debug simulation 
Total elapsed time: 8.360336040146649. Arrivals time: 0.2636260073632002 Scheduler time: 8.000070376787335 Scheduler overhead time: 0.033834162168204784 Adapter cache time: 0.013267472386360168 Engine time: 0.03427906567230821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.046694445889443,
    "estimated_duration": 3600.169981619909,
    "input_throughput": 5353.456114127114,
    "output_throughput": 4717.189490135847,
    "total_throughput": 10070.645604262962,
    "itl": 181.19224154391492,
    "ttft": 1397074.5523169183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85771606056721,
    "arrivals": 126425,
    "finished_requests": 77977,
    "scheduler_time": 107.38792629054134
}
#Debug simulation 
Total elapsed time: 7.046809953637421. Arrivals time: 0.24712010147050023 Scheduler time: 6.704127804376185 Scheduler overhead time: 0.03282122919335961 Adapter cache time: 0.014362605288624763 Engine time: 0.03326287120580673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.109837463591248,
    "estimated_duration": 3600.156769016321,
    "input_throughput": 5353.246882431144,
    "output_throughput": 4717.0945849227855,
    "total_throughput": 10070.34146735393,
    "itl": 181.19483825763743,
    "ttft": 1397126.9179955598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.977990061063325,
    "arrivals": 126425,
    "finished_requests": 77974,
    "scheduler_time": 107.38550905134035
}
#Debug simulation 
Total elapsed time: 7.109955173917115. Arrivals time: 0.2476805169135332 Scheduler time: 6.766279341187328 Scheduler overhead time: 0.032676881179213524 Adapter cache time: 0.014501087833195925 Engine time: 0.033624728210270405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.0574781550094485,
    "estimated_duration": 3600.1563952475753,
    "input_throughput": 5343.615356653708,
    "output_throughput": 4708.778213740412,
    "total_throughput": 10052.39357039412,
    "itl": 179.56311330966622,
    "ttft": 1399387.1360616754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.987727481722844,
    "arrivals": 126425,
    "finished_requests": 77830,
    "scheduler_time": 107.65540378881207
}
#Debug simulation 
Total elapsed time: 7.057572954334319. Arrivals time: 0.25417009368538857 Scheduler time: 6.706953094806522 Scheduler overhead time: 0.03303782409057021 Adapter cache time: 0.01459585689008236 Engine time: 0.033521829172968864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.114248424768448,
    "estimated_duration": 3600.0415079856934,
    "input_throughput": 5353.400775310335,
    "output_throughput": 4717.172277689051,
    "total_throughput": 10070.573052999387,
    "itl": 181.1923836620457,
    "ttft": 1397112.7492021986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9003569505596427,
    "arrivals": 126425,
    "finished_requests": 77973,
    "scheduler_time": 107.38278932884025
}
#Debug simulation 
Total elapsed time: 7.1143609569408. Arrivals time: 0.2620584275573492 Scheduler time: 6.7566342749632895 Scheduler overhead time: 0.03277749149128795 Adapter cache time: 0.014306697994470596 Engine time: 0.03348105028271675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.040916678030044,
    "estimated_duration": 3600.0255577062353,
    "input_throughput": 5343.510120038358,
    "output_throughput": 4708.855181239604,
    "total_throughput": 10052.365301277961,
    "itl": 179.55594062379222,
    "ttft": 1399293.1138098964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.011494947355245,
    "arrivals": 126425,
    "finished_requests": 77827,
    "scheduler_time": 107.65189056304723
}
#Debug simulation 
Total elapsed time: 7.0410374901257455. Arrivals time: 0.25640269881114364 Scheduler time: 6.687920324038714 Scheduler overhead time: 0.03303868183866143 Adapter cache time: 0.014522027224302292 Engine time: 0.03394659236073494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.351959203835577,
    "estimated_duration": 3600.039922587526,
    "input_throughput": 5352.508420559471,
    "output_throughput": 4717.750459776207,
    "total_throughput": 10070.25888033568,
    "itl": 181.21999775999421,
    "ttft": 1396647.9872779183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6624679639655875,
    "arrivals": 126425,
    "finished_requests": 77960,
    "scheduler_time": 107.38252512898303
}
#Debug simulation 
Total elapsed time: 7.352053496986628. Arrivals time: 0.25620048213750124 Scheduler time: 7.00050032325089 Scheduler overhead time: 0.032975082751363516 Adapter cache time: 0.013793176971375942 Engine time: 0.0334308547899127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.064022525213659,
    "estimated_duration": 3600.007231541423,
    "input_throughput": 5343.756765667109,
    "output_throughput": 4708.880263204811,
    "total_throughput": 10052.63702887192,
    "itl": 179.56177663504914,
    "ttft": 1399291.644379802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0377774887159426,
    "arrivals": 126425,
    "finished_requests": 77829,
    "scheduler_time": 107.64954826103313
}
#Debug simulation 
Total elapsed time: 7.064134822227061. Arrivals time: 0.2547696530818939 Scheduler time: 6.712167005985975 Scheduler overhead time: 0.03343335632234812 Adapter cache time: 0.01457258127629757 Engine time: 0.033862271811813116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.748484414070845,
    "estimated_duration": 3600.0524848595937,
    "input_throughput": 3704.506824855398,
    "output_throughput": 3268.5279032699773,
    "total_throughput": 6973.034728125375,
    "itl": 74.31776528329767,
    "ttft": 67035.02727591406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.333101078422487,
    "arrivals": 54189,
    "finished_requests": 53531,
    "scheduler_time": 41.03881588845274
}
#Debug simulation 
Total elapsed time: 6.748576154001057. Arrivals time: 0.14158769650384784 Scheduler time: 6.353404774796218 Scheduler overhead time: 0.06565994396805763 Adapter cache time: 0.09289408102631569 Engine time: 0.06535563059151173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.737336693331599,
    "estimated_duration": 3600.0554185268347,
    "input_throughput": 3705.127129809092,
    "output_throughput": 3268.9535665025146,
    "total_throughput": 6974.0806963116065,
    "itl": 74.39128399345337,
    "ttft": 66747.94041756736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.544038449129467,
    "arrivals": 54189,
    "finished_requests": 53536,
    "scheduler_time": 41.052740113706406
}
#Debug simulation 
Total elapsed time: 6.737433621194214. Arrivals time: 0.1438585026189685 Scheduler time: 6.341400010511279 Scheduler overhead time: 0.0656219907104969 Adapter cache time: 0.09222527081146836 Engine time: 0.06487652566283941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.826574182137847,
    "estimated_duration": 3600.044919452251,
    "input_throughput": 3704.4759991575665,
    "output_throughput": 3268.4881059179424,
    "total_throughput": 6972.964105075509,
    "itl": 74.37874122901331,
    "ttft": 67145.13712819117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.55949854079577,
    "arrivals": 54189,
    "finished_requests": 53530,
    "scheduler_time": 41.049818719715404
}
#Debug simulation 
Total elapsed time: 6.826664962805808. Arrivals time: 0.15893489588052034 Scheduler time: 6.411708770785481 Scheduler overhead time: 0.06667528906837106 Adapter cache time: 0.09361214796081185 Engine time: 0.06601974181830883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.69149787677452,
    "estimated_duration": 3600.0405687633533,
    "input_throughput": 3705.081302620397,
    "output_throughput": 3268.618443386633,
    "total_throughput": 6973.69974600703,
    "itl": 74.33784934069372,
    "ttft": 67107.10451352167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.651612175074582,
    "arrivals": 54189,
    "finished_requests": 53531,
    "scheduler_time": 41.05259622406902
}
#Debug simulation 
Total elapsed time: 6.691583910025656. Arrivals time: 0.14375706389546394 Scheduler time: 6.2974807266145945 Scheduler overhead time: 0.06503245234489441 Adapter cache time: 0.09153420617803931 Engine time: 0.06469754502177238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.752878723666072,
    "estimated_duration": 3600.0047376264783,
    "input_throughput": 3704.101514264052,
    "output_throughput": 3267.963754891218,
    "total_throughput": 6972.0652691552705,
    "itl": 74.35892522339368,
    "ttft": 67729.62739574615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.530133002157175,
    "arrivals": 54189,
    "finished_requests": 53528,
    "scheduler_time": 41.087616552904855
}
#Debug simulation 
Total elapsed time: 6.752968901768327. Arrivals time: 0.14272686513140798 Scheduler time: 6.360627476591617 Scheduler overhead time: 0.06544769089668989 Adapter cache time: 0.0904591497965157 Engine time: 0.06416481826454401 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.663898015860468,
    "estimated_duration": 3600.040522452407,
    "input_throughput": 3704.851075096843,
    "output_throughput": 3268.601263405796,
    "total_throughput": 6973.452338502639,
    "itl": 74.29707628880747,
    "ttft": 67060.66942125143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.90010791407753,
    "arrivals": 54189,
    "finished_requests": 53530,
    "scheduler_time": 41.035592737945315
}
#Debug simulation 
Total elapsed time: 6.6639849483035505. Arrivals time: 0.1438131583854556 Scheduler time: 6.270088460762054 Scheduler overhead time: 0.0647001857869327 Adapter cache time: 0.09194986987859011 Engine time: 0.06430319556966424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.793108283076435,
    "estimated_duration": 3600.039337447865,
    "input_throughput": 3704.682296459252,
    "output_throughput": 3268.6256723911174,
    "total_throughput": 6973.307968850369,
    "itl": 74.39492621214994,
    "ttft": 67252.5662943065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.12274364862428,
    "arrivals": 54189,
    "finished_requests": 53529,
    "scheduler_time": 41.053175424831906
}
#Debug simulation 
Total elapsed time: 6.7932004779577255. Arrivals time: 0.14506628457456827 Scheduler time: 6.3935686950571835 Scheduler overhead time: 0.06608063029125333 Adapter cache time: 0.09357211505994201 Engine time: 0.06535333022475243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.362454660702497,
    "estimated_duration": 3599.9398143481826,
    "input_throughput": 3459.003939557428,
    "output_throughput": 3031.329845156279,
    "total_throughput": 6490.333784713707,
    "itl": 67.90772437625586,
    "ttft": 39441.44711202795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.141127324142406,
    "arrivals": 50289,
    "finished_requests": 49927,
    "scheduler_time": 35.90918991995245
}
#Debug simulation 
Total elapsed time: 5.36253948090598. Arrivals time: 0.12620192067697644 Scheduler time: 4.9667012565769255 Scheduler overhead time: 0.06536322506144643 Adapter cache time: 0.10967597085982561 Engine time: 0.06449347361922264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.295547274872661,
    "estimated_duration": 3599.9210979980576,
    "input_throughput": 3459.096369341237,
    "output_throughput": 3031.474219273538,
    "total_throughput": 6490.570588614775,
    "itl": 67.96192919033489,
    "ttft": 39436.082231091525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.722248367739258,
    "arrivals": 50289,
    "finished_requests": 49928,
    "scheduler_time": 35.921036334565045
}
#Debug simulation 
Total elapsed time: 5.295634608715773. Arrivals time: 0.12672957545146346 Scheduler time: 4.903998971451074 Scheduler overhead time: 0.06422304967418313 Adapter cache time: 0.10807938454672694 Engine time: 0.06322691077366471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.326266723219305,
    "estimated_duration": 3599.9080527462943,
    "input_throughput": 3458.940288905638,
    "output_throughput": 3031.2660323852583,
    "total_throughput": 6490.206321290896,
    "itl": 67.96881868170878,
    "ttft": 39401.65498711011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.777447320893867,
    "arrivals": 50289,
    "finished_requests": 49928,
    "scheduler_time": 35.91764431872845
}
#Debug simulation 
Total elapsed time: 5.326356273144484. Arrivals time: 0.12581667257472873 Scheduler time: 4.934142980724573 Scheduler overhead time: 0.06440275581553578 Adapter cache time: 0.1090638623572886 Engine time: 0.06348324846476316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.336798667907715,
    "estimated_duration": 3599.911066092015,
    "input_throughput": 3458.9846169499015,
    "output_throughput": 3031.147381050632,
    "total_throughput": 6490.131998000534,
    "itl": 67.92044349350542,
    "ttft": 39467.04051676502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.67960510590421,
    "arrivals": 50289,
    "finished_requests": 49927,
    "scheduler_time": 35.911885926042615
}
#Debug simulation 
Total elapsed time: 5.3368950402364135. Arrivals time: 0.12719030026346445 Scheduler time: 4.942258630413562 Scheduler overhead time: 0.0649266135878861 Adapter cache time: 0.10852830996736884 Engine time: 0.06430276017636061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.304173492826521,
    "estimated_duration": 3599.943344917033,
    "input_throughput": 3458.953602028695,
    "output_throughput": 3031.1202023240407,
    "total_throughput": 6490.073804352735,
    "itl": 67.97817268356351,
    "ttft": 39484.337690375934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.12363429509024,
    "arrivals": 50289,
    "finished_requests": 49927,
    "scheduler_time": 35.92020522929665
}
#Debug simulation 
Total elapsed time: 5.3042724509723485. Arrivals time: 0.12807270418852568 Scheduler time: 4.9099281704984605 Scheduler overhead time: 0.06406736420467496 Adapter cache time: 0.10879654251039028 Engine time: 0.06397830042988062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.395416066981852,
    "estimated_duration": 3599.938736028558,
    "input_throughput": 3459.0374762147662,
    "output_throughput": 3031.1251941020355,
    "total_throughput": 6490.162670316802,
    "itl": 67.88545229301741,
    "ttft": 39438.2270971003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.597476927367286,
    "arrivals": 50289,
    "finished_requests": 49927,
    "scheduler_time": 35.906603991653256
}
#Debug simulation 
Total elapsed time: 5.395518002100289. Arrivals time: 0.1280729598365724 Scheduler time: 4.9972602520138025 Scheduler overhead time: 0.06522992951795459 Adapter cache time: 0.11030055023729801 Engine time: 0.06480606365948915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.3530761250294745,
    "estimated_duration": 3599.953784476147,
    "input_throughput": 3458.754957825626,
    "output_throughput": 3031.221969308674,
    "total_throughput": 6489.9769271343,
    "itl": 67.99717394790603,
    "ttft": 39578.574928941736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.412555187565925,
    "arrivals": 50289,
    "finished_requests": 49926,
    "scheduler_time": 35.92578321633032
}
#Debug simulation 
Total elapsed time: 5.353165402077138. Arrivals time: 0.1283979592844844 Scheduler time: 4.955905480775982 Scheduler overhead time: 0.06522122956812382 Adapter cache time: 0.10965412715449929 Engine time: 0.06439659837633371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.720937178935856,
    "estimated_duration": 3600.048321264964,
    "input_throughput": 3305.6253522226343,
    "output_throughput": 2934.8275515056275,
    "total_throughput": 6240.452903728262,
    "itl": 65.66430581411656,
    "ttft": 34736.790808815414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.83357704653777,
    "arrivals": 48457,
    "finished_requests": 48111,
    "scheduler_time": 33.82455242607312
}
#Debug simulation 
Total elapsed time: 4.721044939011335. Arrivals time: 0.12401025323197246 Scheduler time: 4.324434235692024 Scheduler overhead time: 0.06509598344564438 Adapter cache time: 0.1133263474330306 Engine time: 0.06400266848504543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.715682364068925,
    "estimated_duration": 3600.026891382699,
    "input_throughput": 3305.676696050802,
    "output_throughput": 2934.7058560282544,
    "total_throughput": 6240.382552079057,
    "itl": 65.72563342131734,
    "ttft": 34820.8644282517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8442,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.541170446424907,
    "arrivals": 48457,
    "finished_requests": 48110,
    "scheduler_time": 33.8333254557842
}
#Debug simulation 
Total elapsed time: 4.715786825865507. Arrivals time: 0.11938801594078541 Scheduler time: 4.3229482290335 Scheduler overhead time: 0.06524332519620657 Adapter cache time: 0.11452621314674616 Engine time: 0.06391038559377193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.762213192880154,
    "estimated_duration": 3600.0364701832245,
    "input_throughput": 3305.650678420578,
    "output_throughput": 2934.864434710091,
    "total_throughput": 6240.515113130669,
    "itl": 65.72769492822206,
    "ttft": 34686.623193865715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8411,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.4913327288076,
    "arrivals": 48457,
    "finished_requests": 48112,
    "scheduler_time": 33.83476168062538
}
#Debug simulation 
Total elapsed time: 4.762319989968091. Arrivals time: 0.1218745824880898 Scheduler time: 4.365823533385992 Scheduler overhead time: 0.06555549940094352 Adapter cache time: 0.11501212464645505 Engine time: 0.06401237985119224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.72448521014303,
    "estimated_duration": 3600.0208286707248,
    "input_throughput": 3305.976983581663,
    "output_throughput": 2934.977185646282,
    "total_throughput": 6240.9541692279445,
    "itl": 65.68871561758552,
    "ttft": 34521.97816166621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.411274507872427,
    "arrivals": 48457,
    "finished_requests": 48113,
    "scheduler_time": 33.828075794721066
}
#Debug simulation 
Total elapsed time: 4.724568107165396. Arrivals time: 0.12075406918302178 Scheduler time: 4.331110995262861 Scheduler overhead time: 0.06514179054647684 Adapter cache time: 0.1136032729409635 Engine time: 0.06405053939670324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.755394746083766,
    "estimated_duration": 3600.0296494437503,
    "input_throughput": 3306.028605025233,
    "output_throughput": 2935.0949933516927,
    "total_throughput": 6241.123598376926,
    "itl": 65.74075083703077,
    "ttft": 34460.86962562821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.884620415437244,
    "arrivals": 48457,
    "finished_requests": 48115,
    "scheduler_time": 33.83511064727211
}
#Debug simulation 
Total elapsed time: 4.755474912934005. Arrivals time: 0.12268364429473877 Scheduler time: 4.3578049056231976 Scheduler overhead time: 0.06544256815686822 Adapter cache time: 0.11506885755807161 Engine time: 0.06423919275403023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.736564960796386,
    "estimated_duration": 3600.046566959875,
    "input_throughput": 3305.701128763383,
    "output_throughput": 2934.9137027753795,
    "total_throughput": 6240.614831538763,
    "itl": 65.64494981517656,
    "ttft": 34656.34998177893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.271905092511947,
    "arrivals": 48457,
    "finished_requests": 48112,
    "scheduler_time": 33.82197535623686
}
#Debug simulation 
Total elapsed time: 4.736645828932524. Arrivals time: 0.12194468546658754 Scheduler time: 4.342337787151337 Scheduler overhead time: 0.06498652743175626 Adapter cache time: 0.11405711947008967 Engine time: 0.06340582109987736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.741243887227029,
    "estimated_duration": 3600.0552987616384,
    "input_throughput": 3305.9600512508723,
    "output_throughput": 2934.9490835972792,
    "total_throughput": 6240.909134848152,
    "itl": 65.75260979165316,
    "ttft": 34635.29488328965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.202561260794752,
    "arrivals": 48457,
    "finished_requests": 48113,
    "scheduler_time": 33.83952297462787
}
#Debug simulation 
Total elapsed time: 4.741327808238566. Arrivals time: 0.11871706321835518 Scheduler time: 4.349478323943913 Scheduler overhead time: 0.06486995611339808 Adapter cache time: 0.1144381039775908 Engine time: 0.06383226020261645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.497801998164505,
    "estimated_duration": 3599.996052874125,
    "input_throughput": 3243.3721672217234,
    "output_throughput": 2902.277071014701,
    "total_throughput": 6145.649238236424,
    "itl": 64.91126035218676,
    "ttft": 31251.065381820343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.555072661839798,
    "arrivals": 47448,
    "finished_requests": 47131,
    "scheduler_time": 33.06530463279519
}
#Debug simulation 
Total elapsed time: 4.4978828872554. Arrivals time: 0.11879328824579716 Scheduler time: 4.105612716637552 Scheduler overhead time: 0.06574653787538409 Adapter cache time: 0.11294623278081417 Engine time: 0.0645098309032619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.4995394898578525,
    "estimated_duration": 3599.9840001310517,
    "input_throughput": 3243.363025939824,
    "output_throughput": 2902.359010378835,
    "total_throughput": 6145.722036318659,
    "itl": 64.95433572950164,
    "ttft": 31556.734732862245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8200,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.780804696399212,
    "arrivals": 47448,
    "finished_requests": 47130,
    "scheduler_time": 33.0867741859538
}
#Debug simulation 
Total elapsed time: 4.499619897920638. Arrivals time: 0.11766981240361929 Scheduler time: 4.112584047950804 Scheduler overhead time: 0.0648326356895268 Adapter cache time: 0.11091448925435543 Engine time: 0.06361699383705854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.512547121848911,
    "estimated_duration": 3599.971452548506,
    "input_throughput": 3243.425997651762,
    "output_throughput": 2902.104957694586,
    "total_throughput": 6145.530955346348,
    "itl": 64.95793870125469,
    "ttft": 31637.732811229707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.827911950965127,
    "arrivals": 47448,
    "finished_requests": 47129,
    "scheduler_time": 33.08781923628651
}
#Debug simulation 
Total elapsed time: 4.512625387869775. Arrivals time: 0.11542380833998322 Scheduler time: 4.1260393327102065 Scheduler overhead time: 0.06527061155065894 Adapter cache time: 0.11140177864581347 Engine time: 0.06436276575550437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.4992090770974755,
    "estimated_duration": 3600.0200280502518,
    "input_throughput": 3243.3305673367818,
    "output_throughput": 2902.3299644415624,
    "total_throughput": 6145.660531778344,
    "itl": 64.91159555871106,
    "ttft": 31560.61627033091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8188,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.62414713437943,
    "arrivals": 47448,
    "finished_requests": 47130,
    "scheduler_time": 33.08171485577653
}
#Debug simulation 
Total elapsed time: 4.499289181083441. Arrivals time: 0.11804812448099256 Scheduler time: 4.111406683456153 Scheduler overhead time: 0.06539575662463903 Adapter cache time: 0.11059560906141996 Engine time: 0.06391921313479543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.432903928216547,
    "estimated_duration": 3599.9888961893043,
    "input_throughput": 3243.3586149000216,
    "output_throughput": 2902.355063111442,
    "total_throughput": 6145.713678011464,
    "itl": 64.96475588348324,
    "ttft": 31584.32453214132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8179,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.099792415852836,
    "arrivals": 47448,
    "finished_requests": 47130,
    "scheduler_time": 33.09076012325443
}
#Debug simulation 
Total elapsed time: 4.432977539952844. Arrivals time: 0.12181324604898691 Scheduler time: 4.043971817474812 Scheduler overhead time: 0.06533806631341577 Adapter cache time: 0.10952238505706191 Engine time: 0.062452973797917366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.5347753199748695,
    "estimated_duration": 3599.995389907325,
    "input_throughput": 3243.6910982546037,
    "output_throughput": 2902.264272140906,
    "total_throughput": 6145.95537039551,
    "itl": 64.88908692641071,
    "ttft": 31024.04005376699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.969910012726928,
    "arrivals": 47448,
    "finished_requests": 47134,
    "scheduler_time": 33.062799253252045
}
#Debug simulation 
Total elapsed time: 4.534853660967201. Arrivals time: 0.11885923892259598 Scheduler time: 4.142387729138136 Scheduler overhead time: 0.0655402084812522 Adapter cache time: 0.11298748478293419 Engine time: 0.06491000764071941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.546711147762835,
    "estimated_duration": 3600.0111778407268,
    "input_throughput": 3243.338540688436,
    "output_throughput": 2902.337099482824,
    "total_throughput": 6145.67564017126,
    "itl": 64.97951606570257,
    "ttft": 31573.38336350902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.505738059540825,
    "arrivals": 47448,
    "finished_requests": 47130,
    "scheduler_time": 33.092014326497186
}
#Debug simulation 
Total elapsed time: 4.546790291089565. Arrivals time: 0.11869015730917454 Scheduler time: 4.15813119802624 Scheduler overhead time: 0.0651234658434987 Adapter cache time: 0.11066878959536552 Engine time: 0.06404832331463695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.7651509139686823,
    "estimated_duration": 3599.840003286459,
    "input_throughput": 2946.9156935627925,
    "output_throughput": 2597.602668858362,
    "total_throughput": 5544.518362421155,
    "itl": 58.953010815075494,
    "ttft": 18117.624046673882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.87431532343149,
    "arrivals": 42675,
    "finished_requests": 42502,
    "scheduler_time": 27.275287107015217
}
#Debug simulation 
Total elapsed time: 3.765225644223392. Arrivals time: 0.10885161021724343 Scheduler time: 3.3277827673591673 Scheduler overhead time: 0.06955515965819359 Adapter cache time: 0.15960089955478907 Engine time: 0.06741396430879831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.812492218799889,
    "estimated_duration": 3599.8902513068565,
    "input_throughput": 2946.7812237189673,
    "output_throughput": 2597.513909376938,
    "total_throughput": 5544.295133095905,
    "itl": 59.03193727948222,
    "ttft": 18228.497795015293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.41180331440853,
    "arrivals": 42675,
    "finished_requests": 42501,
    "scheduler_time": 27.291644295548185
}
#Debug simulation 
Total elapsed time: 3.8125682659447193. Arrivals time: 0.1095383889041841 Scheduler time: 3.3727941918186843 Scheduler overhead time: 0.0693953325971961 Adapter cache time: 0.16032753605395555 Engine time: 0.06810762453824282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.756802754011005,
    "estimated_duration": 3599.869053717622,
    "input_throughput": 2946.8919123723595,
    "output_throughput": 2597.5817065743468,
    "total_throughput": 5544.473618946707,
    "itl": 59.032682582772864,
    "ttft": 18144.098548600745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12688,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.497272498968336,
    "arrivals": 42675,
    "finished_requests": 42502,
    "scheduler_time": 27.292075036889578
}
#Debug simulation 
Total elapsed time: 3.756879101973027. Arrivals time: 0.11022767052054405 Scheduler time: 3.317397396080196 Scheduler overhead time: 0.06925584794953465 Adapter cache time: 0.1603453508578241 Engine time: 0.06738281389698386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.778076102025807,
    "estimated_duration": 3599.8314902962384,
    "input_throughput": 2946.9226625180195,
    "output_throughput": 2597.608811747599,
    "total_throughput": 5544.531474265618,
    "itl": 58.97798130702099,
    "ttft": 18127.376966297852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.72406108945804,
    "arrivals": 42675,
    "finished_requests": 42502,
    "scheduler_time": 27.280526217057968
}
#Debug simulation 
Total elapsed time: 3.778154189232737. Arrivals time: 0.11620154045522213 Scheduler time: 3.3319831979461014 Scheduler overhead time: 0.06956487661227584 Adapter cache time: 0.16076497314497828 Engine time: 0.0674995044246316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.8318493124097586,
    "estimated_duration": 3599.884899597208,
    "input_throughput": 2946.50698448354,
    "output_throughput": 2597.3619326124,
    "total_throughput": 5543.86891709594,
    "itl": 59.04563718128538,
    "ttft": 18498.62199091197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.5564178599263,
    "arrivals": 42675,
    "finished_requests": 42499,
    "scheduler_time": 27.3027057088786
}
#Debug simulation 
Total elapsed time: 3.8319225972518325. Arrivals time: 0.10606414126232266 Scheduler time: 3.3962633064948022 Scheduler overhead time: 0.06961399735882878 Adapter cache time: 0.15989444544538856 Engine time: 0.06779787875711918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.8107248111627996,
    "estimated_duration": 3599.8659821319416,
    "input_throughput": 2946.8944268079094,
    "output_throughput": 2597.5839229609605,
    "total_throughput": 5544.47834976887,
    "itl": 58.9288004060253,
    "ttft": 18107.313102025095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12721,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.03642980145226,
    "arrivals": 42675,
    "finished_requests": 42502,
    "scheduler_time": 27.27020343751043
}
#Debug simulation 
Total elapsed time: 3.8108021900989115. Arrivals time: 0.10990674095228314 Scheduler time: 3.3696611979976296 Scheduler overhead time: 0.06967855617403984 Adapter cache time: 0.16158527648076415 Engine time: 0.06759266834706068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.7766279680654407,
    "estimated_duration": 3599.879146822072,
    "input_throughput": 2946.511693139422,
    "output_throughput": 2597.36608331817,
    "total_throughput": 5543.877776457592,
    "itl": 59.06224288061306,
    "ttft": 18507.41752951719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.09568123623702,
    "arrivals": 42675,
    "finished_requests": 42499,
    "scheduler_time": 27.306641099391474
}
#Debug simulation 
Total elapsed time: 3.7767025409266353. Arrivals time: 0.10869311122223735 Scheduler time: 3.3402152969501913 Scheduler overhead time: 0.06930440664291382 Adapter cache time: 0.15899962931871414 Engine time: 0.06733946688473225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.4085071752779186,
    "estimated_duration": 3599.9075652171323,
    "input_throughput": 2791.863907037234,
    "output_throughput": 2484.3882344130575,
    "total_throughput": 5276.252141450292,
    "itl": 56.079654639106806,
    "ttft": 14119.681687236713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.772597216933384,
    "arrivals": 40673,
    "finished_requests": 40523,
    "scheduler_time": 24.825558653616465
}
#Debug simulation 
Total elapsed time: 3.4085821262560785. Arrivals time: 0.1035890569910407 Scheduler time: 2.960378865711391 Scheduler overhead time: 0.07026457414031029 Adapter cache time: 0.17228703992441297 Engine time: 0.06926917284727097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.393225013744086,
    "estimated_duration": 3599.883940708756,
    "input_throughput": 2791.881951066799,
    "output_throughput": 2484.3570368658043,
    "total_throughput": 5276.238987932604,
    "itl": 56.179881377360836,
    "ttft": 14221.157267417337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.472621863449106,
    "arrivals": 40673,
    "finished_requests": 40522,
    "scheduler_time": 24.84774020175204
}
#Debug simulation 
Total elapsed time: 3.3933025039732456. Arrivals time: 0.10332335066050291 Scheduler time: 2.9451308478601277 Scheduler overhead time: 0.0706049152649939 Adapter cache time: 0.17253123177215457 Engine time: 0.06880545243620872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.3552431939169765,
    "estimated_duration": 3599.9168549741867,
    "input_throughput": 2791.856424715139,
    "output_throughput": 2484.3343222337085,
    "total_throughput": 5276.190746948848,
    "itl": 56.181246095029984,
    "ttft": 14221.953060014925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.5307928942228,
    "arrivals": 40673,
    "finished_requests": 40522,
    "scheduler_time": 24.84838750649364
}
#Debug simulation 
Total elapsed time: 3.355318324174732. Arrivals time: 0.10363928787410259 Scheduler time: 2.907606809400022 Scheduler overhead time: 0.0706592109054327 Adapter cache time: 0.17207732936367393 Engine time: 0.06819601682946086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.3846709770150483,
    "estimated_duration": 3599.9147718650997,
    "input_throughput": 2791.8583180214864,
    "output_throughput": 2484.38326093103,
    "total_throughput": 5276.241578952516,
    "itl": 56.11191294791173,
    "ttft": 14123.83266762152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.61722567487236,
    "arrivals": 40673,
    "finished_requests": 40523,
    "scheduler_time": 24.832881154353178
}
#Debug simulation 
Total elapsed time: 3.3847489561885595. Arrivals time: 0.10435166442766786 Scheduler time: 2.9346572323702276 Scheduler overhead time: 0.07061258517205715 Adapter cache time: 0.17307517444714904 Engine time: 0.06932924641296268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.405265451874584,
    "estimated_duration": 3599.9372693373834,
    "input_throughput": 2791.8405927806402,
    "output_throughput": 2484.3202341817896,
    "total_throughput": 5276.160826962429,
    "itl": 56.20176101954322,
    "ttft": 14224.570504952057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.0898051342226,
    "arrivals": 40673,
    "finished_requests": 40522,
    "scheduler_time": 24.853324673502087
}
#Debug simulation 
Total elapsed time: 3.4053413048386574. Arrivals time: 0.10185595694929361 Scheduler time: 2.9584896583110094 Scheduler overhead time: 0.0704933600500226 Adapter cache time: 0.1727574160322547 Engine time: 0.06874504312872887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.4059990141540766,
    "estimated_duration": 3599.917695044343,
    "input_throughput": 2791.8560509967997,
    "output_throughput": 2484.3812435800246,
    "total_throughput": 5276.237294576824,
    "itl": 56.047977576717976,
    "ttft": 14114.953206766158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.84707707866271,
    "arrivals": 40673,
    "finished_requests": 40523,
    "scheduler_time": 24.818224896536996
}
#Debug simulation 
Total elapsed time: 3.4060773751698434. Arrivals time: 0.10413033654913306 Scheduler time: 2.954435668885708 Scheduler overhead time: 0.07101665204390883 Adapter cache time: 0.17389335297048092 Engine time: 0.06953980354592204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.3519080807454884,
    "estimated_duration": 3599.884788763364,
    "input_throughput": 2791.8812933600966,
    "output_throughput": 2484.356451605287,
    "total_throughput": 5276.237744965384,
    "itl": 56.22454460455832,
    "ttft": 14227.022822601048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.62362660307501,
    "arrivals": 40673,
    "finished_requests": 40522,
    "scheduler_time": 24.857261302562794
}
#Debug simulation 
Total elapsed time: 3.35198150575161. Arrivals time: 0.10367356287315488 Scheduler time: 2.9061866216361523 Scheduler overhead time: 0.06986200716346502 Adapter cache time: 0.17140627931803465 Engine time: 0.06816376745700836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.249899963848293,
    "estimated_duration": 3599.9034352463536,
    "input_throughput": 2726.745918763306,
    "output_throughput": 2389.122418060481,
    "total_throughput": 5115.868336823787,
    "itl": 51.772614174690645,
    "ttft": 11966.043890434974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.1933855410654,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.323835327260934
}
#Debug simulation 
Total elapsed time: 3.24997670808807. Arrivals time: 0.10181876830756664 Scheduler time: 2.788763818796724 Scheduler overhead time: 0.07328100223094225 Adapter cache time: 0.17881196830421686 Engine time: 0.07256881007924676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.1746613709256053,
    "estimated_duration": 3599.894198149829,
    "input_throughput": 2726.7529154176136,
    "output_throughput": 2389.1285483946435,
    "total_throughput": 5115.881463812258,
    "itl": 52.33387005140901,
    "ttft": 12000.57724849451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.001381755728296,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.469348143823396
}
#Debug simulation 
Total elapsed time: 3.1747343256138265. Arrivals time: 0.09864586312323809 Scheduler time: 2.723889087792486 Scheduler overhead time: 0.07220687763765454 Adapter cache time: 0.17568751191720366 Engine time: 0.07006160728633404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.2092472668737173,
    "estimated_duration": 3599.9269852839775,
    "input_throughput": 2726.7280809101385,
    "output_throughput": 2389.106788876038,
    "total_throughput": 5115.834869786177,
    "itl": 52.334887376618234,
    "ttft": 12001.033539275417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.038072619781204,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.470030343008446
}
#Debug simulation 
Total elapsed time: 3.209328392986208. Arrivals time: 0.10036729974672198 Scheduler time: 2.7537249950692058 Scheduler overhead time: 0.07293734326958656 Adapter cache time: 0.17682019900530577 Engine time: 0.07127089658752084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.1849616789259017,
    "estimated_duration": 3599.9144708519666,
    "input_throughput": 2726.737559872335,
    "output_throughput": 2389.11509416071,
    "total_throughput": 5115.852654033046,
    "itl": 51.80412066912703,
    "ttft": 11966.711836993265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.054319605977014,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.332209929914598
}
#Debug simulation 
Total elapsed time: 3.185038708616048. Arrivals time: 0.1010484448634088 Scheduler time: 2.725423668976873 Scheduler overhead time: 0.07341434573754668 Adapter cache time: 0.17813405208289623 Engine time: 0.07252997811883688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.1755425352603197,
    "estimated_duration": 3599.916705595833,
    "input_throughput": 2726.735867177605,
    "output_throughput": 2389.1136110540892,
    "total_throughput": 5115.849478231694,
    "itl": 52.360375904079575,
    "ttft": 12001.450708213419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.606155297350604,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.47525931885667
}
#Debug simulation 
Total elapsed time: 3.1756168990395963. Arrivals time: 0.1036465666256845 Scheduler time: 2.7159824715927243 Scheduler overhead time: 0.07276065042242408 Adapter cache time: 0.17715411121025681 Engine time: 0.07179357204586267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.1739468313753605,
    "estimated_duration": 3599.922500269606,
    "input_throughput": 2726.73147804289,
    "output_throughput": 2389.1097653785273,
    "total_throughput": 5115.841243421418,
    "itl": 51.7337669914138,
    "ttft": 11964.62391511391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.25637032177339,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.31475435846337
}
#Debug simulation 
Total elapsed time: 3.174024662002921. Arrivals time: 0.10020187171176076 Scheduler time: 2.7161553162150085 Scheduler overhead time: 0.07337988307699561 Adapter cache time: 0.17782904021441936 Engine time: 0.0720665967091918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.188432576134801,
    "estimated_duration": 3599.933571935967,
    "input_throughput": 2726.7230919267085,
    "output_throughput": 2389.10241762455,
    "total_throughput": 5115.825509551259,
    "itl": 52.37763085847754,
    "ttft": 12002.393180415382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.1252673169975,
    "arrivals": 39791,
    "finished_requests": 39661,
    "scheduler_time": 22.480348580665886
}
#Debug simulation 
Total elapsed time: 3.188508261926472. Arrivals time: 0.10192288318648934 Scheduler time: 2.7312191063538194 Scheduler overhead time: 0.0727081336081028 Adapter cache time: 0.17761576594784856 Engine time: 0.07086189882829785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.9997029481455684,
    "estimated_duration": 3600.027510957111,
    "input_throughput": 2540.352809017451,
    "output_throughput": 2242.1323102206043,
    "total_throughput": 4782.485119238056,
    "itl": 44.239175415765274,
    "ttft": 11268.77776519468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.61483839482862,
    "arrivals": 36981,
    "finished_requests": 36866,
    "scheduler_time": 17.99347173480361
}
#Debug simulation 
Total elapsed time: 2.9997828230261803. Arrivals time: 0.09575518174096942 Scheduler time: 2.5304961507208645 Scheduler overhead time: 0.08185871737077832 Adapter cache time: 0.1724979979917407 Engine time: 0.08046946488320827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.9760811929591,
    "estimated_duration": 3600.017718059623,
    "input_throughput": 2540.2583309865095,
    "output_throughput": 2241.997021156418,
    "total_throughput": 4782.255352142927,
    "itl": 44.303240925048,
    "ttft": 11366.511462527531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.69415844707634,
    "arrivals": 36981,
    "finished_requests": 36865,
    "scheduler_time": 18.01471282058527
}
#Debug simulation 
Total elapsed time: 2.976161193102598. Arrivals time: 0.09488134877756238 Scheduler time: 2.5077980500645936 Scheduler overhead time: 0.08162337029352784 Adapter cache time: 0.17263865051791072 Engine time: 0.08061027200892568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.0267543396912515,
    "estimated_duration": 3600.040854687537,
    "input_throughput": 2540.242005335168,
    "output_throughput": 2241.9826123613634,
    "total_throughput": 4782.224617696531,
    "itl": 44.307869084170854,
    "ttft": 11366.369902310895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.76215661982332,
    "arrivals": 36981,
    "finished_requests": 36865,
    "scheduler_time": 18.015716515185428
}
#Debug simulation 
Total elapsed time: 3.026833155658096. Arrivals time: 0.09546493645757437 Scheduler time: 2.554913230240345 Scheduler overhead time: 0.08205329673364758 Adapter cache time: 0.17413456132635474 Engine time: 0.08122200053185225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.0210784641094506,
    "estimated_duration": 3600.0358297411617,
    "input_throughput": 2540.346938896311,
    "output_throughput": 2242.1271292125857,
    "total_throughput": 4782.474068108896,
    "itl": 44.258764732540506,
    "ttft": 11268.786079860998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.23979993343894,
    "arrivals": 36981,
    "finished_requests": 36866,
    "scheduler_time": 18.000040587852933
}
#Debug simulation 
Total elapsed time: 3.0211558281444013. Arrivals time: 0.09539720416069031 Scheduler time: 2.5510602267459035 Scheduler overhead time: 0.08233023714274168 Adapter cache time: 0.17347124591469765 Engine time: 0.07982108788564801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.9965932238847017,
    "estimated_duration": 3600.0057276409552,
    "input_throughput": 2540.2667917399685,
    "output_throughput": 2242.0044885009083,
    "total_throughput": 4782.271280240877,
    "itl": 44.31979061142111,
    "ttft": 11366.458220234932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.19758915783855,
    "arrivals": 36981,
    "finished_requests": 36865,
    "scheduler_time": 18.019880171654727
}
#Debug simulation 
Total elapsed time: 2.996672202832997. Arrivals time: 0.09469401277601719 Scheduler time: 2.5292412196286023 Scheduler overhead time: 0.0816151644103229 Adapter cache time: 0.17281823651865125 Engine time: 0.07941343123093247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.9896494541317225,
    "estimated_duration": 3600.001824649004,
    "input_throughput": 2540.269545805473,
    "output_throughput": 2242.0069192011965,
    "total_throughput": 4782.27646500667,
    "itl": 44.216587288600564,
    "ttft": 11366.20223225127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.890209596631266,
    "arrivals": 36981,
    "finished_requests": 36865,
    "scheduler_time": 17.98601322468019
}
#Debug simulation 
Total elapsed time: 2.9897290021181107. Arrivals time: 0.09701974876224995 Scheduler time: 2.518589566927403 Scheduler overhead time: 0.08206027606502175 Adapter cache time: 0.17300569359213114 Engine time: 0.08017335366457701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.052279456052929,
    "estimated_duration": 3600.0126091265934,
    "input_throughput": 2540.261935976575,
    "output_throughput": 2242.0002028710055,
    "total_throughput": 4782.26213884758,
    "itl": 44.33335218483276,
    "ttft": 11366.508038990378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.62909751117027,
    "arrivals": 36981,
    "finished_requests": 36865,
    "scheduler_time": 18.024266239944776
}
#Debug simulation 
Total elapsed time: 3.052355417981744. Arrivals time: 0.09524080157279968 Scheduler time: 2.5798431509174407 Scheduler overhead time: 0.0816482761874795 Adapter cache time: 0.17487001838162541 Engine time: 0.08197277598083019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.881919296924025,
    "estimated_duration": 3600.0139901925477,
    "input_throughput": 2471.2942850325308,
    "output_throughput": 2185.1578970056316,
    "total_throughput": 4656.452182038162,
    "itl": 41.48283681808448,
    "ttft": 9683.834133027975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.363041426238308,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.19439963036091
}
#Debug simulation 
Total elapsed time: 2.8819960579276085. Arrivals time: 0.09241623943671584 Scheduler time: 2.4192611919716 Scheduler overhead time: 0.08465048717334867 Adapter cache time: 0.16440862836316228 Engine time: 0.08093844633549452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.9308990477584302,
    "estimated_duration": 3600.018037835394,
    "input_throughput": 2471.291506458499,
    "output_throughput": 2185.1554401460726,
    "total_throughput": 4656.446946604571,
    "itl": 41.53233624092527,
    "ttft": 9684.037111380938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.12354568614061,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.212493015355374
}
#Debug simulation 
Total elapsed time: 2.9309821389615536. Arrivals time: 0.09290523221716285 Scheduler time: 2.4625459564849734 Scheduler overhead time: 0.08573729125782847 Adapter cache time: 0.1656838059425354 Engine time: 0.08352860948070884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.8821156308986247,
    "estimated_duration": 3600.019263458373,
    "input_throughput": 2471.2906651097624,
    "output_throughput": 2185.154696212075,
    "total_throughput": 4656.4453613218375,
    "itl": 41.53171489883014,
    "ttft": 9683.913406317693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.191521774959675,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.21307296575518
}
#Debug simulation 
Total elapsed time: 2.882192175835371. Arrivals time: 0.09233594732359052 Scheduler time: 2.4166344394907355 Scheduler overhead time: 0.08510318817570806 Adapter cache time: 0.1640597372315824 Engine time: 0.0837845210917294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.9225324988365173,
    "estimated_duration": 3599.9960625806507,
    "input_throughput": 2471.306591825109,
    "output_throughput": 2185.1687788682866,
    "total_throughput": 4656.475370693395,
    "itl": 41.497074421814546,
    "ttft": 9683.940029701227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.892058342483367,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.19971947017498
}
#Debug simulation 
Total elapsed time: 2.922610269859433. Arrivals time: 0.09269368881359696 Scheduler time: 2.4532285328023136 Scheduler overhead time: 0.08588069025427103 Adapter cache time: 0.1652515958994627 Engine time: 0.0840239766985178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.898555250838399,
    "estimated_duration": 3600.0070596792807,
    "input_throughput": 2471.2990426170422,
    "output_throughput": 2185.162103737881,
    "total_throughput": 4656.461146354924,
    "itl": 41.54322383905617,
    "ttft": 9683.968025974495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.57420138910334,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.21691098809836
}
#Debug simulation 
Total elapsed time: 2.8986337478272617. Arrivals time: 0.09243538603186607 Scheduler time: 2.433473104145378 Scheduler overhead time: 0.08542292146012187 Adapter cache time: 0.16438363445922732 Engine time: 0.08250300539657474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.8807635116390884,
    "estimated_duration": 3600.0236004945023,
    "input_throughput": 2471.287687885697,
    "output_throughput": 2185.1520637029816,
    "total_throughput": 4656.4397515886785,
    "itl": 41.4660947144243,
    "ttft": 9683.953033903197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.76526339117064,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.1883914643156
}
#Debug simulation 
Total elapsed time: 2.8808388859033585. Arrivals time: 0.09449511533603072 Scheduler time: 2.4130935110151768 Scheduler overhead time: 0.08565050037577748 Adapter cache time: 0.16390277445316315 Engine time: 0.08321544667705894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.88831422990188,
    "estimated_duration": 3600.015184125271,
    "input_throughput": 2471.2934654362334,
    "output_throughput": 2185.1571723054885,
    "total_throughput": 4656.450637741722,
    "itl": 41.55281875092431,
    "ttft": 9684.101325501786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.91782991923152,
    "arrivals": 35945,
    "finished_requests": 35849,
    "scheduler_time": 16.220528213971157
}
#Debug simulation 
Total elapsed time: 2.888394827954471. Arrivals time: 0.09209806751459837 Scheduler time: 2.4223834611475468 Scheduler overhead time: 0.08475203812122345 Adapter cache time: 0.16447305493056774 Engine time: 0.08420203439891338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.8273418452590704,
    "estimated_duration": 3600.0154389145305,
    "input_throughput": 2329.74750867426,
    "output_throughput": 2081.8702383842574,
    "total_throughput": 4411.617747058517,
    "itl": 37.74944103492575,
    "ttft": 7364.10360131455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.95204161364203,
    "arrivals": 34024,
    "finished_requests": 33953,
    "scheduler_time": 13.137419276541815
}
#Debug simulation 
Total elapsed time: 2.8274185843765736. Arrivals time: 0.08938129898160696 Scheduler time: 2.358072483446449 Scheduler overhead time: 0.09231839142739773 Adapter cache time: 0.15309335105121136 Engine time: 0.09082967601716518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.8262840430252254,
    "estimated_duration": 3600.0259564118473,
    "input_throughput": 2329.740702303009,
    "output_throughput": 2081.8641561879313,
    "total_throughput": 4411.60485849094,
    "itl": 37.775426636233284,
    "ttft": 7575.176283878913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.101178084973114,
    "arrivals": 34024,
    "finished_requests": 33953,
    "scheduler_time": 13.149100848672878
}
#Debug simulation 
Total elapsed time: 2.8263605758547783. Arrivals time: 0.08875250909477472 Scheduler time: 2.355495118536055 Scheduler overhead time: 0.09457831596955657 Adapter cache time: 0.15290659619495273 Engine time: 0.08993586897850037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.7878456781618297,
    "estimated_duration": 3600.029191724216,
    "input_throughput": 2329.738608586956,
    "output_throughput": 2081.862285236198,
    "total_throughput": 4411.600893823154,
    "itl": 37.77697936301411,
    "ttft": 7575.2175010086685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.140998412313774,
    "arrivals": 34024,
    "finished_requests": 33953,
    "scheduler_time": 13.149495571888998
}
#Debug simulation 
Total elapsed time: 2.7879236452281475. Arrivals time: 0.08820503950119019 Scheduler time: 2.3225006945431232 Scheduler overhead time: 0.0915121934376657 Adapter cache time: 0.15255774883553386 Engine time: 0.08959775697439909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.7924762801267207,
    "estimated_duration": 3600.010653815207,
    "input_throughput": 2329.586161394313,
    "output_throughput": 2081.7968947001623,
    "total_throughput": 4411.383056094475,
    "itl": 37.757365189272235,
    "ttft": 7469.860921088156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.303340257246592,
    "arrivals": 34024,
    "finished_requests": 33952,
    "scheduler_time": 13.140943471829845
}
#Debug simulation 
Total elapsed time: 2.7925510141067207. Arrivals time: 0.08980544190853834 Scheduler time: 2.3247391134500504 Scheduler overhead time: 0.0917045371606946 Adapter cache time: 0.15236857812851667 Engine time: 0.09041455062106252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.7896495386958122,
    "estimated_duration": 3600.0236138733794,
    "input_throughput": 2329.742218267292,
    "output_throughput": 2081.8655108587313,
    "total_throughput": 4411.6077291260235,
    "itl": 37.78155732791183,
    "ttft": 7575.331663272508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.36847991365819,
    "arrivals": 34024,
    "finished_requests": 33953,
    "scheduler_time": 13.151831552720814
}
#Debug simulation 
Total elapsed time: 2.7897268310189247. Arrivals time: 0.08872515708208084 Scheduler time: 2.3228973671793938 Scheduler overhead time: 0.09250981640070677 Adapter cache time: 0.15209018671885133 Engine time: 0.08956307591870427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.7949699540622532,
    "estimated_duration": 3600.0003813847566,
    "input_throughput": 2329.5928087580037,
    "output_throughput": 2081.8028350089257,
    "total_throughput": 4411.395643766929,
    "itl": 37.741031836382504,
    "ttft": 7469.792125860017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.56786868405461,
    "arrivals": 34024,
    "finished_requests": 33952,
    "scheduler_time": 13.13359659944487
}
#Debug simulation 
Total elapsed time: 2.7950522019527853. Arrivals time: 0.08893649280071259 Scheduler time: 2.3270907518453896 Scheduler overhead time: 0.09202213771641254 Adapter cache time: 0.15215657697990537 Engine time: 0.09109151782467961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.807362083811313,
    "estimated_duration": 3600.0257659213817,
    "input_throughput": 2329.7408255780692,
    "output_throughput": 2081.8642663469404,
    "total_throughput": 4411.605091925009,
    "itl": 37.78638510805417,
    "ttft": 7575.271155032925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.597880248053485,
    "arrivals": 34024,
    "finished_requests": 33953,
    "scheduler_time": 13.154010620025034
}
#Debug simulation 
Total elapsed time: 2.807443032041192. Arrivals time: 0.09557729307562113 Scheduler time: 2.333599695004523 Scheduler overhead time: 0.0921384165994823 Adapter cache time: 0.15380375972017646 Engine time: 0.08858851669356227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.3929258179850876,
    "estimated_duration": 3599.7743998130163,
    "input_throughput": 1856.9927605316675,
    "output_throughput": 1665.745220120313,
    "total_throughput": 3522.7379806519803,
    "itl": 33.901963125881295,
    "ttft": 7889.546887222596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.56070155165379,
    "arrivals": 27120,
    "finished_requests": 27061,
    "scheduler_time": 5.265955107192757
}
#Debug simulation 
Total elapsed time: 2.393002200871706. Arrivals time: 0.07478026300668716 Scheduler time: 1.8825157955288887 Scheduler overhead time: 0.09964234801009297 Adapter cache time: 0.1948117301799357 Engine time: 0.09374289447441697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.3819548301398754,
    "estimated_duration": 3599.7662564734474,
    "input_throughput": 1856.8986216756336,
    "output_throughput": 1665.6800949831973,
    "total_throughput": 3522.5787166588307,
    "itl": 33.958279094621055,
    "ttft": 8022.527629727754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.481105059268444,
    "arrivals": 27120,
    "finished_requests": 27060,
    "scheduler_time": 5.293937464588143
}
#Debug simulation 
Total elapsed time: 2.382033829111606. Arrivals time: 0.07463412545621395 Scheduler time: 1.870008077006787 Scheduler overhead time: 0.09915394755080342 Adapter cache time: 0.19393042847514153 Engine time: 0.09679654892534018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.395733029115945,
    "estimated_duration": 3599.781552554648,
    "input_throughput": 1856.8907313990478,
    "output_throughput": 1665.6730172265013,
    "total_throughput": 3522.563748625549,
    "itl": 33.961014253454124,
    "ttft": 8022.434016333684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.55180196658798,
    "arrivals": 27120,
    "finished_requests": 27060,
    "scheduler_time": 5.294672327045644
}
#Debug simulation 
Total elapsed time: 2.395807691849768. Arrivals time: 0.07403636164963245 Scheduler time: 1.8860184103250504 Scheduler overhead time: 0.0989026753231883 Adapter cache time: 0.1951211211271584 Engine time: 0.09447295870631933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.399829988833517,
    "estimated_duration": 3599.772552808441,
    "input_throughput": 1856.8953737882741,
    "output_throughput": 1665.677181554719,
    "total_throughput": 3522.572555342993,
    "itl": 33.919838562770984,
    "ttft": 8022.280688864269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.46973913577338,
    "arrivals": 27120,
    "finished_requests": 27060,
    "scheduler_time": 5.274713784574067
}
#Debug simulation 
Total elapsed time: 2.3999066562391818. Arrivals time: 0.07464607013389468 Scheduler time: 1.8882453329861164 Scheduler overhead time: 0.09928351361304522 Adapter cache time: 0.19394089374691248 Engine time: 0.09611002635210752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.403474668972194,
    "estimated_duration": 3599.7675800296984,
    "input_throughput": 1856.8979389343945,
    "output_throughput": 1665.6794825488516,
    "total_throughput": 3522.5774214832463,
    "itl": 33.97244738490553,
    "ttft": 8022.540821495735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.17588883678096,
    "arrivals": 27120,
    "finished_requests": 27060,
    "scheduler_time": 5.300502313161122
}
#Debug simulation 
Total elapsed time: 2.403572958894074. Arrivals time: 0.0747779980301857 Scheduler time: 1.8894360987469554 Scheduler overhead time: 0.09983204118907452 Adapter cache time: 0.19423483731225133 Engine time: 0.09715307457372546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.4092908781021833,
    "estimated_duration": 3599.755411330304,
    "input_throughput": 1856.9042160366537,
    "output_throughput": 1665.6851132516617,
    "total_throughput": 3522.5893292883156,
    "itl": 33.88055848037608,
    "ttft": 8022.189508166861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.54111239437187,
    "arrivals": 27120,
    "finished_requests": 27060,
    "scheduler_time": 5.256110377918365
}
#Debug simulation 
Total elapsed time: 2.4093661378137767. Arrivals time: 0.07519261725246906 Scheduler time: 1.8964279047213495 Scheduler overhead time: 0.0995690287090838 Adapter cache time: 0.19406584417447448 Engine time: 0.09661650890484452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.3991346298716962,
    "estimated_duration": 3599.767601117921,
    "input_throughput": 1856.897928056282,
    "output_throughput": 1665.6794727909385,
    "total_throughput": 3522.5774008472204,
    "itl": 33.98441809052965,
    "ttft": 8022.497935679206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.776694702209724,
    "arrivals": 27120,
    "finished_requests": 27060,
    "scheduler_time": 5.306327212106499
}
#Debug simulation 
Total elapsed time: 2.399213403929025. Arrivals time: 0.074471031781286 Scheduler time: 1.884746122173965 Scheduler overhead time: 0.09925215505063534 Adapter cache time: 0.19601968303322792 Engine time: 0.09720583399757743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.2419263762421906,
    "estimated_duration": 3600.0181084382793,
    "input_throughput": 1727.0924236259566,
    "output_throughput": 1530.5473011607398,
    "total_throughput": 3257.6397247866967,
    "itl": 30.919205684883547,
    "ttft": 5913.1582374849395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.18798657652595,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.380143384974322
}
#Debug simulation 
Total elapsed time: 2.242013798095286. Arrivals time: 0.07127799186855555 Scheduler time: 1.7269061305560172 Scheduler overhead time: 0.11010414641350508 Adapter cache time: 0.1783495000563562 Engine time: 0.10347984731197357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.2506058258004487,
    "estimated_duration": 3600.0291699909303,
    "input_throughput": 1727.0871169123511,
    "output_throughput": 1530.542598357302,
    "total_throughput": 3257.629715269653,
    "itl": 30.95947939745806,
    "ttft": 5913.279101270799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.66120590494331,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.3962434731686026
}
#Debug simulation 
Total elapsed time: 2.250681050121784. Arrivals time: 0.07122500566765666 Scheduler time: 1.7397523187100887 Scheduler overhead time: 0.10710964817553759 Adapter cache time: 0.17911966377869248 Engine time: 0.1021873839199543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.226427320856601,
    "estimated_duration": 3600.006559278703,
    "input_throughput": 1727.0979643008623,
    "output_throughput": 1530.5522113004101,
    "total_throughput": 3257.6501756012726,
    "itl": 30.96019173117364,
    "ttft": 5913.254577662704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.73509436814704,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.396617013236401
}
#Debug simulation 
Total elapsed time: 2.2265000827610493. Arrivals time: 0.06980191683396697 Scheduler time: 1.7210475294850767 Scheduler overhead time: 0.10675229830667377 Adapter cache time: 0.17713982658460736 Engine time: 0.10074447095394135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.2461683470755816,
    "estimated_duration": 3600.0311701070314,
    "input_throughput": 1727.0861573721172,
    "output_throughput": 1530.5417480138606,
    "total_throughput": 3257.627905385978,
    "itl": 30.932365086714533,
    "ttft": 5913.0324161150465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.97318770752115,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.3852646543105944
}
#Debug simulation 
Total elapsed time: 2.246244147885591. Arrivals time: 0.07107492908835411 Scheduler time: 1.7376414402388036 Scheduler overhead time: 0.1073982366360724 Adapter cache time: 0.1754047702997923 Engine time: 0.10325397364795208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.241860545706004,
    "estimated_duration": 3600.0215437334805,
    "input_throughput": 1727.0907755601763,
    "output_throughput": 1530.5458406467583,
    "total_throughput": 3257.6366162069344,
    "itl": 30.96858083061146,
    "ttft": 5913.206471201417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.23082328180122,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.3997597458304507
}
#Debug simulation 
Total elapsed time: 2.241936843842268. Arrivals time: 0.07196194166317582 Scheduler time: 1.7301323120482266 Scheduler overhead time: 0.10717605985701084 Adapter cache time: 0.17885226057842374 Engine time: 0.10253154253587127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.2485049259848893,
    "estimated_duration": 3600.0058420388023,
    "input_throughput": 1727.0983083957408,
    "output_throughput": 1530.552516236892,
    "total_throughput": 3257.650824632633,
    "itl": 30.905878765295597,
    "ttft": 5913.08056000265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12147,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.32014093217694,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.374525563356999
}
#Debug simulation 
Total elapsed time: 2.248582173138857. Arrivals time: 0.07201210502535105 Scheduler time: 1.7340057687833905 Scheduler overhead time: 0.10704058920964599 Adapter cache time: 0.17688004905357957 Engine time: 0.10707764932885766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.2206315957009792,
    "estimated_duration": 3600.017819792627,
    "input_throughput": 1727.0925621024155,
    "output_throughput": 1530.5474238784168,
    "total_throughput": 3257.639985980832,
    "itl": 30.976969549761915,
    "ttft": 5913.279186985588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.761079497634874,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.4032136783996743
}
#Debug simulation 
Total elapsed time: 2.2207095995545387. Arrivals time: 0.0709161777049303 Scheduler time: 1.713671765755862 Scheduler overhead time: 0.10634564282372594 Adapter cache time: 0.17677034810185432 Engine time: 0.10196613566949964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.166199436876923,
    "estimated_duration": 3599.876430142961,
    "input_throughput": 1634.7075001589153,
    "output_throughput": 1468.529573885973,
    "total_throughput": 3103.2370740448882,
    "itl": 29.678897886267993,
    "ttft": 5854.819816208463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.93084812471905,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.4865716075691913
}
#Debug simulation 
Total elapsed time: 2.166277846787125. Arrivals time: 0.0679780412465334 Scheduler time: 1.6598759908229113 Scheduler overhead time: 0.10903173359110951 Adapter cache time: 0.16843477543443441 Engine time: 0.10838554846122861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.182583936024457,
    "estimated_duration": 3599.886088540781,
    "input_throughput": 1634.703114282538,
    "output_throughput": 1468.5256338605147,
    "total_throughput": 3103.228748143053,
    "itl": 29.71247673104067,
    "ttft": 5854.933742650587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.128849589808254,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.4969534214231632
}
#Debug simulation 
Total elapsed time: 2.182688341010362. Arrivals time: 0.06863792845979333 Scheduler time: 1.6763116749934852 Scheduler overhead time: 0.11019864678382874 Adapter cache time: 0.16971802478656173 Engine time: 0.10490385396406054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.2107591843232512,
    "estimated_duration": 3599.871940348758,
    "input_throughput": 1634.7095389815122,
    "output_throughput": 1468.5314054498945,
    "total_throughput": 3103.2409444314067,
    "itl": 29.711509346977717,
    "ttft": 5854.92002255351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.178788923047144,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.496930194936916
}
#Debug simulation 
Total elapsed time: 2.2108330209739506. Arrivals time: 0.06895358208566904 Scheduler time: 1.700647085905075 Scheduler overhead time: 0.11016991082578897 Adapter cache time: 0.16987035842612386 Engine time: 0.1080356277525425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.1744527388364077,
    "estimated_duration": 3599.8819153056793,
    "input_throughput": 1634.7050093448147,
    "output_throughput": 1468.5273362782239,
    "total_throughput": 3103.232345623039,
    "itl": 29.689292853934653,
    "ttft": 5854.874415393544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.63041962014227,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.4898843472229946
}
#Debug simulation 
Total elapsed time: 2.1745269647799432. Arrivals time: 0.06807669112458825 Scheduler time: 1.6642384701408446 Scheduler overhead time: 0.11510628694668412 Adapter cache time: 0.16766693629324436 Engine time: 0.10614332975819707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.156670853961259,
    "estimated_duration": 3599.8861071102388,
    "input_throughput": 1634.703105850174,
    "output_throughput": 1468.5256262853518,
    "total_throughput": 3103.2287321355257,
    "itl": 29.719528899546496,
    "ttft": 5855.029377623383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.65247052088472,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.4994369754285135
}
#Debug simulation 
Total elapsed time: 2.1567461788654327. Arrivals time: 0.06815503863617778 Scheduler time: 1.6554720420390368 Scheduler overhead time: 0.10909864725545049 Adapter cache time: 0.16778370551764965 Engine time: 0.10352927586063743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.171304517891258,
    "estimated_duration": 3599.885751161373,
    "input_throughput": 1634.7032674860584,
    "output_throughput": 1468.5257714899685,
    "total_throughput": 3103.229038976027,
    "itl": 29.66854039639609,
    "ttft": 5854.931724128402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.17593122343898,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.4831117952298785
}
#Debug simulation 
Total elapsed time: 2.171399849001318. Arrivals time: 0.06856253603473306 Scheduler time: 1.6625689533539116 Scheduler overhead time: 0.11000418150797486 Adapter cache time: 0.17002575565129519 Engine time: 0.10720727732405066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.1699301688931882,
    "estimated_duration": 3599.862441227002,
    "input_throughput": 1634.7138525643782,
    "output_throughput": 1468.535280530915,
    "total_throughput": 3103.2491330952935,
    "itl": 29.724372931840307,
    "ttft": 5854.934648790192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.09437307014899,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.5013868231484
}
#Debug simulation 
Total elapsed time: 2.1700090947560966. Arrivals time: 0.0693403109908104 Scheduler time: 1.6625863783992827 Scheduler overhead time: 0.11056139087304473 Adapter cache time: 0.16901204362511635 Engine time: 0.1054120403714478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.975018460303545,
    "estimated_duration": 3599.9684382576206,
    "input_throughput": 1450.9863321268917,
    "output_throughput": 1297.4369303805972,
    "total_throughput": 2748.423262507489,
    "itl": 27.139912142213703,
    "ttft": 6654.714804922648,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.470937989542325,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.1866330529260085
}
#Debug simulation 
Total elapsed time: 1.9750963342376053. Arrivals time: 0.06313936319202185 Scheduler time: 1.476269060280174 Scheduler overhead time: 0.11612435430288315 Adapter cache time: 0.14997859811410308 Engine time: 0.11284095980226994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9959741160273552,
    "estimated_duration": 3599.9448703227335,
    "input_throughput": 1450.9958313699717,
    "output_throughput": 1297.44542437431,
    "total_throughput": 2748.441255744282,
    "itl": 27.161284724065705,
    "ttft": 6654.80738098048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8971,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.281442035982387,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.18841802310627093
}
#Debug simulation 
Total elapsed time: 1.9960485869087279. Arrivals time: 0.06166167417541146 Scheduler time: 1.4969973526895046 Scheduler overhead time: 0.11625220673158765 Adapter cache time: 0.15120140882208943 Engine time: 0.1134457211010158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9790641199797392,
    "estimated_duration": 3599.9503622074612,
    "input_throughput": 1450.99361781116,
    "output_throughput": 1297.443445063488,
    "total_throughput": 2748.437062874648,
    "itl": 27.162837964566886,
    "ttft": 6654.851049453445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8975,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.34479984229549,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.18858173364394684
}
#Debug simulation 
Total elapsed time: 1.9791376972571015. Arrivals time: 0.061554351821541786 Scheduler time: 1.4811087287962437 Scheduler overhead time: 0.1152925742790103 Adapter cache time: 0.15100432140752673 Engine time: 0.11378848925232887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.9816826968453825,
    "estimated_duration": 3599.966878702413,
    "input_throughput": 1450.9869607141447,
    "output_throughput": 1297.4374924481356,
    "total_throughput": 2748.4244531622803,
    "itl": 27.146638918849895,
    "ttft": 6654.646764216909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.05940648323116,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.18728539311868464
}
#Debug simulation 
Total elapsed time: 1.9817586210556328. Arrivals time: 0.061881646048277617 Scheduler time: 1.4836830194108188 Scheduler overhead time: 0.11651010811328888 Adapter cache time: 0.15120533062145114 Engine time: 0.1118224672973156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9776465711183846,
    "estimated_duration": 3599.9602303103193,
    "input_throughput": 1450.9896403910357,
    "output_throughput": 1297.4398885504852,
    "total_throughput": 2748.429528941521,
    "itl": 27.167009326470566,
    "ttft": 6654.785073585825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8978,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.741595020684652,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.18901848965841642
}
#Debug simulation 
Total elapsed time: 1.9777243370190263. Arrivals time: 0.06205175630748272 Scheduler time: 1.4761185771785676 Scheduler overhead time: 0.11772078461945057 Adapter cache time: 0.15048455959185958 Engine time: 0.11445465916767716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.9922629413194954,
    "estimated_duration": 3599.9666232869276,
    "input_throughput": 1450.9870636608043,
    "output_throughput": 1297.437584500552,
    "total_throughput": 2748.4246481613563,
    "itl": 27.13330322800029,
    "ttft": 6654.628684325116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.838691447040166,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.18604672226799884
}
#Debug simulation 
Total elapsed time: 1.9923457084223628. Arrivals time: 0.06318685272708535 Scheduler time: 1.4903167076408863 Scheduler overhead time: 0.1163343214429915 Adapter cache time: 0.15151366218924522 Engine time: 0.11343707516789436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9894675039686263,
    "estimated_duration": 3599.9553101436372,
    "input_throughput": 1450.9916235020105,
    "output_throughput": 1297.441661800418,
    "total_throughput": 2748.4332853024284,
    "itl": 27.17164741508459,
    "ttft": 6654.7925610530065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8977,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.10893641669052,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.18936146435591328
}
#Debug simulation 
Total elapsed time: 1.9895459627732635. Arrivals time: 0.06190763646736741 Scheduler time: 1.4933162271045148 Scheduler overhead time: 0.1156148724257946 Adapter cache time: 0.15008505806326866 Engine time: 0.11227448843419552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.928468890953809,
    "estimated_duration": 3600.0183702944873,
    "input_throughput": 1394.8712155013886,
    "output_throughput": 1245.361700649671,
    "total_throughput": 2640.2329161510597,
    "itl": 26.630586332183604,
    "ttft": 6209.051390907269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.962839542727913,
    "arrivals": 20441,
    "finished_requests": 20406,
    "scheduler_time": 0.12822792326231608
}
#Debug simulation 
Total elapsed time: 1.9285484780557454. Arrivals time: 0.06028689630329609 Scheduler time: 1.4359955489635468 Scheduler overhead time: 0.11758473282679915 Adapter cache time: 0.14165862184017897 Engine time: 0.11546937748789787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9195285318419337,
    "estimated_duration": 3599.9978493164112,
    "input_throughput": 1394.9738889298471,
    "output_throughput": 1245.532132984866,
    "total_throughput": 2640.506021914713,
    "itl": 26.43539757259929,
    "ttft": 6032.814586487212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7510,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.532984908982495,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.11866853798654255
}
#Debug simulation 
Total elapsed time: 1.9195987321436405. Arrivals time: 0.05939374351873994 Scheduler time: 1.4262901498004794 Scheduler overhead time: 0.11868854286149144 Adapter cache time: 0.14269942697137594 Engine time: 0.11455393070355058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9609151021577418,
    "estimated_duration": 3600.006814217618,
    "input_throughput": 1394.9704151022281,
    "output_throughput": 1245.5290313039254,
    "total_throughput": 2640.4994464061533,
    "itl": 26.435769056810244,
    "ttft": 6032.690263614417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7512,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.578491596635665,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.11879200881979543
}
#Debug simulation 
Total elapsed time: 1.9609932550229132. Arrivals time: 0.061082837637513876 Scheduler time: 1.4522098926827312 Scheduler overhead time: 0.12440005270764232 Adapter cache time: 0.1447305497713387 Engine time: 0.11939221201464534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.9512100820429623,
    "estimated_duration": 3600.022247260626,
    "input_throughput": 1394.9644349618477,
    "output_throughput": 1245.5236918082812,
    "total_throughput": 2640.488126770129,
    "itl": 26.423637307408335,
    "ttft": 6032.687136950724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.484250609612804,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.11800860866579953
}
#Debug simulation 
Total elapsed time: 1.9512781128287315. Arrivals time: 0.060019444208592176 Scheduler time: 1.4545604577288032 Scheduler overhead time: 0.11866918439045548 Adapter cache time: 0.14338340144604445 Engine time: 0.11685912543907762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9338998752646148,
    "estimated_duration": 3600.0031409235594,
    "input_throughput": 1394.9718384722466,
    "output_throughput": 1245.5303021901473,
    "total_throughput": 2640.5021406623937,
    "itl": 26.43813499970915,
    "ttft": 6032.694766077942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.89296554639847,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.11894800510740043
}
#Debug simulation 
Total elapsed time: 1.933998454362154. Arrivals time: 0.06054415414109826 Scheduler time: 1.439710235223174 Scheduler overhead time: 0.11871607648208737 Adapter cache time: 0.1426313016563654 Engine time: 0.11458232719451189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.9051479790359735,
    "estimated_duration": 3600.00287436369,
    "input_throughput": 1394.8772196154355,
    "output_throughput": 1245.3670612117053,
    "total_throughput": 2640.2442808271408,
    "itl": 26.624126260873943,
    "ttft": 6208.984964960861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.428367262060924,
    "arrivals": 20441,
    "finished_requests": 20406,
    "scheduler_time": 0.1279180991471399
}
#Debug simulation 
Total elapsed time: 1.9052187479101121. Arrivals time: 0.05835117772221565 Scheduler time: 1.4185944856144488 Scheduler overhead time: 0.11760324519127607 Adapter cache time: 0.14030860690400004 Engine time: 0.11316036945208907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9273954797536135,
    "estimated_duration": 3600.003709973827,
    "input_throughput": 1394.9716179699467,
    "output_throughput": 1245.5301053099747,
    "total_throughput": 2640.5017232799214,
    "itl": 26.443961701644877,
    "ttft": 6032.6898044234385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7511,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.214694587996068,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.1191640479056048
}
#Debug simulation 
Total elapsed time: 1.9274723269045353. Arrivals time: 0.060281076934188604 Scheduler time: 1.4310222663916647 Scheduler overhead time: 0.1185877500101924 Adapter cache time: 0.14256267109885812 Engine time: 0.1172712529078126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.797639454714954,
    "estimated_duration": 3599.8539910092577,
    "input_throughput": 1286.3291154488636,
    "output_throughput": 1128.3940988009792,
    "total_throughput": 2414.723214249843,
    "itl": 24.840833517272245,
    "ttft": 4503.355143259527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.721725540580826,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008348161386308278
}
#Debug simulation 
Total elapsed time: 1.7977090259082615. Arrivals time: 0.055891613475978374 Scheduler time: 1.309374117758125 Scheduler overhead time: 0.12433421704918146 Adapter cache time: 0.127209163736552 Engine time: 0.12026550667360425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.7972048111259937,
    "estimated_duration": 3599.8525691378095,
    "input_throughput": 1286.329623523738,
    "output_throughput": 1128.394544494607,
    "total_throughput": 2414.724168018345,
    "itl": 24.85170088420637,
    "ttft": 4503.478818742655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5134,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.75444313287118,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008721785190149809
}
#Debug simulation 
Total elapsed time: 1.7972843223251402. Arrivals time: 0.05607134522870183 Scheduler time: 1.3106060801073909 Scheduler overhead time: 0.12391733471304178 Adapter cache time: 0.12691068090498447 Engine time: 0.11937979329377413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.8040414000861347,
    "estimated_duration": 3599.8575170346517,
    "input_throughput": 1286.3278555020172,
    "output_throughput": 1128.3929935499443,
    "total_throughput": 2414.7208490519615,
    "itl": 24.85220613490647,
    "ttft": 4503.39296684327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.790295198483975,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008624209309144292
}
#Debug simulation 
Total elapsed time: 1.8041204791516066. Arrivals time: 0.05709805944934487 Scheduler time: 1.3151535484939814 Scheduler overhead time: 0.12338715931400657 Adapter cache time: 0.12722763931378722 Engine time: 0.12082065967842937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.793713765218854,
    "estimated_duration": 3599.85265873529,
    "input_throughput": 1286.329591508013,
    "output_throughput": 1128.394516409761,
    "total_throughput": 2414.724107917774,
    "itl": 24.844276772315492,
    "ttft": 4503.396330345401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.01419829892375,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008438648627262358
}
#Debug simulation 
Total elapsed time: 1.7937922021374106. Arrivals time: 0.05569185642525554 Scheduler time: 1.3064465736970305 Scheduler overhead time: 0.12315769912675023 Adapter cache time: 0.12711403612047434 Engine time: 0.12094142939895391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8007583511061966,
    "estimated_duration": 3599.870150394352,
    "input_throughput": 1286.3233412718332,
    "output_throughput": 1128.3890335752853,
    "total_throughput": 2414.7123748471186,
    "itl": 24.853516728298217,
    "ttft": 4503.559476396236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.015997817123946,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008608780809002593
}
#Debug simulation 
Total elapsed time: 1.8008533520624042. Arrivals time: 0.056652231607586145 Scheduler time: 1.3122940980829298 Scheduler overhead time: 0.12292841961607337 Adapter cache time: 0.1268401714041829 Engine time: 0.12164860311895609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.8098634202033281,
    "estimated_duration": 3599.8475305026664,
    "input_throughput": 1286.3314239737826,
    "output_throughput": 1128.396123886056,
    "total_throughput": 2414.727547859839,
    "itl": 24.83776657190439,
    "ttft": 4503.294733932135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5136,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.356898314619249,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008339821526218015
}
#Debug simulation 
Total elapsed time: 1.8099372554570436. Arrivals time: 0.05581199051812291 Scheduler time: 1.3214919832535088 Scheduler overhead time: 0.1241066800430417 Adapter cache time: 0.12735654832795262 Engine time: 0.12044688779860735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_256_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 540, 33, 540, 540, 33, 540, 66, 540, 33, 66, 33, 540, 66, 66, 66, 66, 540, 33, 33, 33, 66, 540, 33, 540, 540, 66, 66, 66, 33, 540, 33, 66, 66, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 540, 33, 540, 540, 66, 33, 33, 540, 66, 33, 66, 66, 540, 66, 33, 33, 540, 540, 540, 540, 540, 540, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 540, 540, 33, 540, 33, 66, 540, 540, 540, 66, 33, 540, 66, 33, 33, 33, 33, 33, 540, 66, 33, 540, 33, 540, 33, 33, 66, 66, 540, 66, 540, 33, 66, 33, 540, 540, 33, 540, 66, 33, 540, 33, 33, 540, 540, 66, 540, 540, 33, 540, 66, 66, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 66, 540, 540, 66, 33, 540, 33, 66, 66, 33, 66, 33, 540, 33, 33, 540, 33, 540, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 66, 33, 540, 33, 540, 66, 66, 33, 66, 540, 66, 66, 540, 33, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 540, 33, 540, 66, 540, 540, 33, 540, 66, 66, 540, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 540, 66, 33, 33, 33, 33]
Prompts retrieved: 54855 . Total input tokens: 12175253 . Total output tokens: 11005577
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.7928332118317485,
    "estimated_duration": 3599.858197175874,
    "input_throughput": 1286.3276124689442,
    "output_throughput": 1128.3927803563827,
    "total_throughput": 2414.720392825327,
    "itl": 24.855943115827465,
    "ttft": 4503.415315018159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.225428727454194,
    "arrivals": 18559,
    "finished_requests": 18536,
    "scheduler_time": 0.0008738464910330335
}
#Debug simulation 
Total elapsed time: 1.7929111821576953. Arrivals time: 0.055749764665961266 Scheduler time: 1.3065700544975698 Scheduler overhead time: 0.12251663580536842 Adapter cache time: 0.12682216009125113 Engine time: 0.12088665971532464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.4754447676241398,
    "estimated_duration": 3599.6328170737675,
    "input_throughput": 924.0403588452549,
    "output_throughput": 829.5732236454951,
    "total_throughput": 1753.61358249075,
    "itl": 22.65080071165587,
    "ttft": 5834.130225387581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.433375163027375,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 9.853498901842345e-05
}
#Debug simulation 
Total elapsed time: 1.4755152529105544. Arrivals time: 0.044810648541897535 Scheduler time: 0.9901055535301566 Scheduler overhead time: 0.13199436105787754 Adapter cache time: 0.114248504396528 Engine time: 0.12917407741770148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.4618787062354386,
    "estimated_duration": 3599.6394291536035,
    "input_throughput": 924.0386615006335,
    "output_throughput": 829.5716998249868,
    "total_throughput": 1753.6103613256203,
    "itl": 22.664526441779223,
    "ttft": 5834.348083399191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.934582461023773,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 0.00010662460510092207
}
#Debug simulation 
Total elapsed time: 1.4619545149616897. Arrivals time: 0.04519360326230526 Scheduler time: 0.9767655595205724 Scheduler overhead time: 0.13261784659698606 Adapter cache time: 0.11362962005659938 Engine time: 0.12810806976631284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.4850270319730043,
    "estimated_duration": 3599.6386763272385,
    "input_throughput": 924.0388547535483,
    "output_throughput": 829.5718733211355,
    "total_throughput": 1753.610728074684,
    "itl": 22.667392664190185,
    "ttft": 5834.338147717967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.973638503085937,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 0.00010662460510092207
}
#Debug simulation 
Total elapsed time: 1.485102036036551. Arrivals time: 0.04528577486053109 Scheduler time: 0.9981591566465795 Scheduler overhead time: 0.13289411319419742 Adapter cache time: 0.11442360328510404 Engine time: 0.1289791543968022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.4726587939076126,
    "estimated_duration": 3599.631832980276,
    "input_throughput": 924.0406114661187,
    "output_throughput": 829.5734504402474,
    "total_throughput": 1753.614061906366,
    "itl": 22.65625537827501,
    "ttft": 5834.281124213948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.920318997589835,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 0.00010174581105064636
}
#Debug simulation 
Total elapsed time: 1.4727311059832573. Arrivals time: 0.04492495767772198 Scheduler time: 0.9902733527123928 Scheduler overhead time: 0.13166567450389266 Adapter cache time: 0.11411598231643438 Engine time: 0.12681094650179148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.462843008339405,
    "estimated_duration": 3599.6322466596766,
    "input_throughput": 924.0405052728912,
    "output_throughput": 829.5733551034396,
    "total_throughput": 1753.6138603763306,
    "itl": 22.666758642392598,
    "ttft": 5834.457094700036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.28530211187808,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 0.00010662460510092207
}
#Debug simulation 
Total elapsed time: 1.4629150950349867. Arrivals time: 0.045421378687024117 Scheduler time: 0.9786598631180823 Scheduler overhead time: 0.1319497050717473 Adapter cache time: 0.11257492564618587 Engine time: 0.1286089769564569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.4847096870653331,
    "estimated_duration": 3599.6404942678214,
    "input_throughput": 924.0383880825747,
    "output_throughput": 829.5714543591928,
    "total_throughput": 1753.6098424417673,
    "itl": 22.64738597268198,
    "ttft": 5834.205469653577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.91407861133792,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 0.00010174581105064636
}
#Debug simulation 
Total elapsed time: 1.484783167950809. Arrivals time: 0.04528534505516291 Scheduler time: 0.9964568363502622 Scheduler overhead time: 0.13352197920903563 Adapter cache time: 0.11463123373687267 Engine time: 0.12949625216424465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_256_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 66, 270, 270, 66, 270, 135, 270, 66, 135, 66, 270, 135, 135, 135, 135, 270, 66, 66, 66, 135, 270, 66, 270, 270, 135, 135, 135, 66, 270, 66, 135, 135, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 270, 66, 270, 270, 135, 66, 66, 270, 135, 66, 135, 135, 270, 135, 66, 66, 270, 270, 270, 270, 270, 270, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 270, 270, 66, 270, 66, 135, 270, 270, 270, 135, 66, 270, 135, 66, 66, 66, 66, 66, 270, 135, 66, 270, 66, 270, 66, 66, 135, 135, 270, 135, 270, 66, 135, 66, 270, 270, 66, 270, 135, 66, 270, 66, 66, 270, 270, 135, 270, 270, 66, 270, 135, 135, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 66, 66, 66, 66, 66, 270, 66, 66, 66, 270, 66, 135, 270, 270, 135, 66, 270, 66, 135, 135, 66, 135, 66, 270, 66, 66, 270, 66, 270, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 135, 66, 270, 66, 270, 135, 135, 66, 135, 270, 135, 135, 270, 66, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 66, 270, 135, 270, 270, 66, 270, 135, 135, 270, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 270, 135, 66, 66, 66, 66]
Prompts retrieved: 40305 . Total input tokens: 8933800 . Total output tokens: 8066537
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.4657498891465366,
    "estimated_duration": 3599.6249059126812,
    "input_throughput": 924.0423896768888,
    "output_throughput": 829.57504685974,
    "total_throughput": 1753.617436536629,
    "itl": 22.66889145010412,
    "ttft": 5834.5453096070205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.592447458056633,
    "arrivals": 13666,
    "finished_requests": 13644,
    "scheduler_time": 0.00010745859110994848
}
#Debug simulation 
Total elapsed time: 1.4658158319070935. Arrivals time: 0.04475661180913448 Scheduler time: 0.982659618370235 Scheduler overhead time: 0.13214423460885882 Adapter cache time: 0.11326853791251779 Engine time: 0.1277119806036353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8318648 . Total output tokens: 7487535
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.396382541861385,
    "estimated_duration": 3599.9618922053196,
    "input_throughput": 865.3941606286086,
    "output_throughput": 760.4841612150759,
    "total_throughput": 1625.8783218436845,
    "itl": 21.894975469240485,
    "ttft": 5146.034568820503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6248,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.12192742409106,
    "arrivals": 12685,
    "finished_requests": 12667,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.39645044086501. Arrivals time: 0.04318331414833665 Scheduler time: 0.9142505428753793 Scheduler overhead time: 0.13467512838542461 Adapter cache time: 0.10589342564344406 Engine time: 0.13192624878138304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8318648 . Total output tokens: 7487535
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.400209965184331,
    "estimated_duration": 3599.9541013180847,
    "input_throughput": 865.2604761987142,
    "output_throughput": 760.466084553034,
    "total_throughput": 1625.7265607517481,
    "itl": 21.904021272352022,
    "ttft": 5430.012541704631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.396987506295048,
    "arrivals": 12685,
    "finished_requests": 12666,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4002883350476623. Arrivals time: 0.04330969136208296 Scheduler time: 0.9184516263194382 Scheduler overhead time: 0.1355546205304563 Adapter cache time: 0.10501650488004088 Engine time: 0.13143185153603554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8318648 . Total output tokens: 7487535
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.3940525189973414,
    "estimated_duration": 3599.949364347659,
    "input_throughput": 865.2616147461968,
    "output_throughput": 760.4670852074843,
    "total_throughput": 1625.7286999536811,
    "itl": 21.903902864010256,
    "ttft": 5430.033216727498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.427944443914466,
    "arrivals": 12685,
    "finished_requests": 12666,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3941130847670138. Arrivals time: 0.042642789892852306 Scheduler time: 0.9135254635475576 Scheduler overhead time: 0.13464492186903954 Adapter cache time: 0.1051382152363658 Engine time: 0.13147773779928684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8318648 . Total output tokens: 7487535
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 1.3953875140286982,
    "estimated_duration": 3599.9529650684412,
    "input_throughput": 865.2607493000344,
    "output_throughput": 760.4663245782026,
    "total_throughput": 1625.727073878237,
    "itl": 21.898259156416092,
    "ttft": 5429.957389186078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6245,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.530914260389036,
    "arrivals": 12685,
    "finished_requests": 12666,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3954603280872107. Arrivals time: 0.04301004111766815 Scheduler time: 0.9112183670513332 Scheduler overhead time: 0.13743845280259848 Adapter cache time: 0.10567977977916598 Engine time: 0.13090061908587813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_256_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 270, 33, 270, 270, 33, 270, 135, 270, 33, 135, 33, 270, 135, 135, 135, 135, 270, 33, 33, 33, 135, 270, 33, 270, 270, 135, 135, 135, 33, 270, 33, 135, 135, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 270, 33, 270, 270, 135, 33, 33, 270, 135, 33, 135, 135, 270, 135, 33, 33, 270, 270, 270, 270, 270, 270, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 270, 270, 33, 270, 33, 135, 270, 270, 270, 135, 33, 270, 135, 33, 33, 33, 33, 33, 270, 135, 33, 270, 33, 270, 33, 33, 135, 135, 270, 135, 270, 33, 135, 33, 270, 270, 33, 270, 135, 33, 270, 33, 33, 270, 270, 135, 270, 270, 33, 270, 135, 135, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 33, 33, 33, 33, 33, 270, 33, 33, 33, 270, 33, 135, 270, 270, 135, 33, 270, 33, 135, 135, 33, 135, 33, 270, 33, 33, 270, 33, 270, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 135, 33, 270, 33, 270, 135, 135, 33, 135, 270, 135, 135, 270, 33, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 270, 33, 270, 135, 270, 270, 33, 270, 135, 135, 270, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 270, 135, 33, 33, 33, 33]
Prompts retrieved: 37500 . Total input tokens: 8318648 . Total output tokens: 7487535
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 1.403887191787362,
    "estimated_duration": 3599.9533936687426,
    "input_throughput": 865.2606462845291,
    "output_throughput": 760.466234039226,
    "total_throughput": 1625.726880323755,
    "itl": 21.90746314523643,
    "ttft": 5430.021371364578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6246,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.692193163036222,
    "arrivals": 12685,
    "finished_requests": 12666,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4039565538987517. Arrivals time: 0.04322522785514593 Scheduler time: 0.9201941746287048 Scheduler overhead time: 0.13505830615758896 Adapter cache time: 0.10566970938816667 Engine time: 0.13313828501850367 
