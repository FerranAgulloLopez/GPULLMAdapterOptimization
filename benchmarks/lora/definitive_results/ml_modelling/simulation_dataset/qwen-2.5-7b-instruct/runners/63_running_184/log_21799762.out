INFO 06-01 00:47:07 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:07 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.828950136899948,
    "estimated_duration": 3600.037737910112,
    "input_throughput": 4590.7715982983555,
    "output_throughput": 4072.269811402196,
    "total_throughput": 8663.04140970055,
    "itl": 61.25609841861935,
    "ttft": 14148.723193165135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.882199962518673,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.89003871426425
}
#Debug simulation 
Total elapsed time: 4.829067116603255. Arrivals time: 0.15893397387117147 Scheduler time: 4.447507748380303 Scheduler overhead time: 0.07225586660206318 Adapter cache time: 0.0426001725718379 Engine time: 0.07368471613153815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.807364372070879,
    "estimated_duration": 3600.0560184077895,
    "input_throughput": 4590.748287108443,
    "output_throughput": 4072.2491330798453,
    "total_throughput": 8662.997420188289,
    "itl": 61.25830132555803,
    "ttft": 14148.83941763181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.00068467746722,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.890594969018586
}
#Debug simulation 
Total elapsed time: 4.807473404332995. Arrivals time: 0.1572972829453647 Scheduler time: 4.43063276167959 Scheduler overhead time: 0.07136059598997235 Adapter cache time: 0.04255715385079384 Engine time: 0.07205562200397253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.880598206073046,
    "estimated_duration": 3600.0392980329466,
    "input_throughput": 4590.769608829073,
    "output_throughput": 4072.26804663226,
    "total_throughput": 8663.037655461332,
    "itl": 61.25815034743227,
    "ttft": 14148.748060286822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.005314099825931,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.890311780298916
}
#Debug simulation 
Total elapsed time: 4.880744526162744. Arrivals time: 0.15661508264020085 Scheduler time: 4.5027553625404835 Scheduler overhead time: 0.07184792822226882 Adapter cache time: 0.04285992542281747 Engine time: 0.07255501067265868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.836523126810789,
    "estimated_duration": 3600.053093500501,
    "input_throughput": 4590.752016918192,
    "output_throughput": 4072.2524416285974,
    "total_throughput": 8663.00445854679,
    "itl": 61.253762041320094,
    "ttft": 14148.753589653059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9091593261365627,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.88985032841538
}
#Debug simulation 
Total elapsed time: 4.836646175943315. Arrivals time: 0.15968986554071307 Scheduler time: 4.454737661406398 Scheduler overhead time: 0.07226828392595053 Adapter cache time: 0.042919937055557966 Engine time: 0.07307328470051289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.851350137963891,
    "estimated_duration": 3600.0295753423347,
    "input_throughput": 4590.782007236265,
    "output_throughput": 4072.279044709214,
    "total_throughput": 8663.061051945479,
    "itl": 61.26005745428682,
    "ttft": 14094.963898318505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.03348294798285,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.89061777852191
}
#Debug simulation 
Total elapsed time: 4.851441920269281. Arrivals time: 0.15632493700832129 Scheduler time: 4.4759346093051136 Scheduler overhead time: 0.0708438865840435 Adapter cache time: 0.04272000025957823 Engine time: 0.07212080247700214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.854822195135057,
    "estimated_duration": 3600.0345977767147,
    "input_throughput": 4590.775602602987,
    "output_throughput": 4072.2733634431806,
    "total_throughput": 8663.048966046168,
    "itl": 61.253678277259446,
    "ttft": 14148.665521694777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8388809313648096,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.88961972220012
}
#Debug simulation 
Total elapsed time: 4.854964121244848. Arrivals time: 0.1555788698606193 Scheduler time: 4.477705229073763 Scheduler overhead time: 0.07221483765169978 Adapter cache time: 0.04286771733313799 Engine time: 0.0725060272961855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.929172410164028,
    "estimated_duration": 3600.039877440319,
    "input_throughput": 4590.768869968992,
    "output_throughput": 4072.267391222262,
    "total_throughput": 8663.036261191253,
    "itl": 61.26237566970164,
    "ttft": 14148.929751624111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0551125992462014,
    "arrivals": 66631,
    "finished_requests": 66371,
    "scheduler_time": 48.89114681438861
}
#Debug simulation 
Total elapsed time: 4.929302780888975. Arrivals time: 0.1570868087001145 Scheduler time: 4.551491419319063 Scheduler overhead time: 0.07118101511150599 Adapter cache time: 0.04318952281028032 Engine time: 0.0726421750150621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.773063037078828,
    "estimated_duration": 3599.922283526408,
    "input_throughput": 4490.950839128414,
    "output_throughput": 3985.4865938787843,
    "total_throughput": 8476.437433007199,
    "itl": 55.467538310600546,
    "ttft": 14014.348171517113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.17372579045834,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.51822998763425
}
#Debug simulation 
Total elapsed time: 4.773162151686847. Arrivals time: 0.15451086778193712 Scheduler time: 4.3933861763216555 Scheduler overhead time: 0.0743587245233357 Adapter cache time: 0.0399127583950758 Engine time: 0.07595305610448122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.772022268269211,
    "estimated_duration": 3599.9143673099124,
    "input_throughput": 4490.9607147353,
    "output_throughput": 3985.4953579691205,
    "total_throughput": 8476.45607270442,
    "itl": 55.47779437396258,
    "ttft": 14014.144714701995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3802912366925786,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.52015073434814
}
#Debug simulation 
Total elapsed time: 4.772163101937622. Arrivals time: 0.15457175439223647 Scheduler time: 4.393048903439194 Scheduler overhead time: 0.07420670241117477 Adapter cache time: 0.039972830563783646 Engine time: 0.07478218525648117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.789422797039151,
    "estimated_duration": 3599.9191001177996,
    "input_throughput": 4490.954810476426,
    "output_throughput": 3985.4901182447434,
    "total_throughput": 8476.44492872117,
    "itl": 55.47745928583813,
    "ttft": 14014.252653090256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3841083524748288,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.52021153686064
}
#Debug simulation 
Total elapsed time: 4.7895249389112. Arrivals time: 0.15645176451653242 Scheduler time: 4.406641898211092 Scheduler overhead time: 0.0753868124447763 Adapter cache time: 0.03991974797099829 Engine time: 0.07542774081230164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.748006935697049,
    "estimated_duration": 3599.905530159679,
    "input_throughput": 4490.971739273082,
    "output_throughput": 3985.5051416762035,
    "total_throughput": 8476.476880949285,
    "itl": 55.475428949053104,
    "ttft": 14014.191475775728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.228702373551165,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.519924407646336
}
#Debug simulation 
Total elapsed time: 4.748107021674514. Arrivals time: 0.15558220352977514 Scheduler time: 4.367172506637871 Scheduler overhead time: 0.07428965345025063 Adapter cache time: 0.03998527675867081 Engine time: 0.07548767235130072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.75979342404753,
    "estimated_duration": 3599.931811202245,
    "input_throughput": 4490.938953257782,
    "output_throughput": 3985.4760457833454,
    "total_throughput": 8476.414999041126,
    "itl": 55.47951196739705,
    "ttft": 14014.405416821366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4338065260835027,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.52082473186718
}
#Debug simulation 
Total elapsed time: 4.759937211871147. Arrivals time: 0.1544135375879705 Scheduler time: 4.381166463252157 Scheduler overhead time: 0.0736629655584693 Adapter cache time: 0.040044821333140135 Engine time: 0.07560504088178277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.812895193696022,
    "estimated_duration": 3599.9245157814757,
    "input_throughput": 4490.94805436231,
    "output_throughput": 3985.4841225428977,
    "total_throughput": 8476.432176905208,
    "itl": 55.464875775467384,
    "ttft": 14014.30844299795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.103672206108385,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.517597454729824
}
#Debug simulation 
Total elapsed time: 4.81299092900008. Arrivals time: 0.15862022759392858 Scheduler time: 4.426145125646144 Scheduler overhead time: 0.07528984220698476 Adapter cache time: 0.040491186548024416 Engine time: 0.07688092021271586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.778580910991877,
    "estimated_duration": 3599.9378265917576,
    "input_throughput": 4490.931449031769,
    "output_throughput": 3985.4693861708843,
    "total_throughput": 8476.400835202654,
    "itl": 55.480144538380046,
    "ttft": 14014.326421710302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1039,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.475667951069816,
    "arrivals": 65160,
    "finished_requests": 64908,
    "scheduler_time": 46.52087741868522
}
#Debug simulation 
Total elapsed time: 4.778709785081446. Arrivals time: 0.15875642141327262 Scheduler time: 4.39320688508451 Scheduler overhead time: 0.07491634972393513 Adapter cache time: 0.04015394486486912 Engine time: 0.07601078366860747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.730509491171688,
    "estimated_duration": 3599.9876812763446,
    "input_throughput": 4461.831378907709,
    "output_throughput": 3939.9651487060773,
    "total_throughput": 8401.796527613787,
    "itl": 53.18985529484392,
    "ttft": 12665.466550148434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0138009355077857,
    "arrivals": 64686,
    "finished_requests": 64460,
    "scheduler_time": 45.36543857691598
}
#Debug simulation 
Total elapsed time: 4.730649406090379. Arrivals time: 0.155588339548558 Scheduler time: 4.351219935808331 Scheduler overhead time: 0.07498086337000132 Adapter cache time: 0.03609530860558152 Engine time: 0.07662845216691494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.736164352856576,
    "estimated_duration": 3599.9569376528552,
    "input_throughput": 4461.798370975094,
    "output_throughput": 3939.9204617285127,
    "total_throughput": 8401.718832703607,
    "itl": 53.20149508949696,
    "ttft": 12721.127750149428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149686606070033,
    "arrivals": 64686,
    "finished_requests": 64459,
    "scheduler_time": 45.36787001732538
}
#Debug simulation 
Total elapsed time: 4.7362565831281245. Arrivals time: 0.15645701298490167 Scheduler time: 4.356679600197822 Scheduler overhead time: 0.07510795770213008 Adapter cache time: 0.03613149654120207 Engine time: 0.07614043913781643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.744358703959733,
    "estimated_duration": 3599.9630921847283,
    "input_throughput": 4461.790743041257,
    "output_throughput": 3939.913726002218,
    "total_throughput": 8401.704469043476,
    "itl": 53.20151602159025,
    "ttft": 12721.173657067022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.153047785051173,
    "arrivals": 64686,
    "finished_requests": 64459,
    "scheduler_time": 45.367975182334376
}
#Debug simulation 
Total elapsed time: 4.744453644845635. Arrivals time: 0.15538977272808552 Scheduler time: 4.363881436176598 Scheduler overhead time: 0.07630431838333607 Adapter cache time: 0.03627173136919737 Engine time: 0.07652484392747283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.757706405129284,
    "estimated_duration": 3600.0100763327127,
    "input_throughput": 4461.803622606167,
    "output_throughput": 3939.9406388464595,
    "total_throughput": 8401.744261452626,
    "itl": 53.19761849014322,
    "ttft": 12665.57135265377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0446776092308396,
    "arrivals": 64686,
    "finished_requests": 64460,
    "scheduler_time": 45.367756809586886
}
#Debug simulation 
Total elapsed time: 4.757858909200877. Arrivals time: 0.15648295963183045 Scheduler time: 4.376654010266066 Scheduler overhead time: 0.075289664324373 Adapter cache time: 0.03635844774544239 Engine time: 0.0771233425475657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.766471040900797,
    "estimated_duration": 3599.9842906120293,
    "input_throughput": 4461.83558130728,
    "output_throughput": 3939.968859583169,
    "total_throughput": 8401.804440890448,
    "itl": 53.202313048889025,
    "ttft": 12665.637946468309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1853665081597877,
    "arrivals": 64686,
    "finished_requests": 64460,
    "scheduler_time": 45.368536967841656
}
#Debug simulation 
Total elapsed time: 4.766563811339438. Arrivals time: 0.15559155959635973 Scheduler time: 4.385856306180358 Scheduler overhead time: 0.07646091701462865 Adapter cache time: 0.03649533959105611 Engine time: 0.0763472756370902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.750622768886387,
    "estimated_duration": 3600.0026262685556,
    "input_throughput": 4461.812856133665,
    "output_throughput": 3939.948792398993,
    "total_throughput": 8401.761648532658,
    "itl": 53.188270516925655,
    "ttft": 12665.62863009876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9674530940455985,
    "arrivals": 64686,
    "finished_requests": 64460,
    "scheduler_time": 45.365375866977736
}
#Debug simulation 
Total elapsed time: 4.75071822013706. Arrivals time: 0.15768714901059866 Scheduler time: 4.369927313178778 Scheduler overhead time: 0.07537720818072557 Adapter cache time: 0.036401940044015646 Engine time: 0.0756879379041493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.7330588307231665,
    "estimated_duration": 3599.9738751541486,
    "input_throughput": 4461.848490306673,
    "output_throughput": 3939.98025871581,
    "total_throughput": 8401.828749022483,
    "itl": 53.20325775400711,
    "ttft": 12665.593544937032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.209133973792197,
    "arrivals": 64686,
    "finished_requests": 64460,
    "scheduler_time": 45.36848329056724
}
#Debug simulation 
Total elapsed time: 4.73320638993755. Arrivals time: 0.15887278504669666 Scheduler time: 4.349825653247535 Scheduler overhead time: 0.07550199469551444 Adapter cache time: 0.03628550050780177 Engine time: 0.07706819055601954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.67050688713789,
    "estimated_duration": 3600.032061823683,
    "input_throughput": 4419.031754939729,
    "output_throughput": 3881.0651572147854,
    "total_throughput": 8300.096912154515,
    "itl": 50.00205329310564,
    "ttft": 10585.397348288692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.726115087578097,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.712958588633725
}
#Debug simulation 
Total elapsed time: 4.670628663152456. Arrivals time: 0.15693822409957647 Scheduler time: 4.2864816463552415 Scheduler overhead time: 0.07911943783983588 Adapter cache time: 0.030736411921679974 Engine time: 0.08019159594550729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.677147239912301,
    "estimated_duration": 3600.004073449495,
    "input_throughput": 4419.066110877051,
    "output_throughput": 3881.0953307094956,
    "total_throughput": 8300.161441586546,
    "itl": 50.00542150958273,
    "ttft": 10528.949816807371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.838794420103082,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.71352878144554
}
#Debug simulation 
Total elapsed time: 4.677241483237594. Arrivals time: 0.1560808108188212 Scheduler time: 4.2967649372294545 Scheduler overhead time: 0.07789383688941598 Adapter cache time: 0.030512318946421146 Engine time: 0.0788181982934475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.68027110863477,
    "estimated_duration": 3600.017622506618,
    "input_throughput": 4419.0494792420295,
    "output_throughput": 3881.080723785906,
    "total_throughput": 8300.130203027935,
    "itl": 50.00533458996209,
    "ttft": 10528.954879801111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8423379461653644,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.71370680515623
}
#Debug simulation 
Total elapsed time: 4.680372565984726. Arrivals time: 0.15468754898756742 Scheduler time: 4.29994717054069 Scheduler overhead time: 0.07834612485021353 Adapter cache time: 0.030748602002859116 Engine time: 0.07929264847189188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 4.672539085149765,
    "estimated_duration": 3600.008091585631,
    "input_throughput": 4419.061178552241,
    "output_throughput": 3881.090998838845,
    "total_throughput": 8300.152177391084,
    "itl": 50.00085780430492,
    "ttft": 10528.98229201791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.756258165778115,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.71216747422952
}
#Debug simulation 
Total elapsed time: 4.672640056349337. Arrivals time: 0.15246410854160786 Scheduler time: 4.294021480716765 Scheduler overhead time: 0.07852399023249745 Adapter cache time: 0.03089691884815693 Engine time: 0.07967911940068007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 4.6731945388019085,
    "estimated_duration": 3600.0094764478113,
    "input_throughput": 4419.059478614854,
    "output_throughput": 3881.089505849402,
    "total_throughput": 8300.148984464257,
    "itl": 50.00629451615638,
    "ttft": 10529.088475780422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.867740211021158,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.713771417771135
}
#Debug simulation 
Total elapsed time: 4.673291174694896. Arrivals time: 0.15453970339149237 Scheduler time: 4.291140295099467 Scheduler overhead time: 0.07922185817733407 Adapter cache time: 0.0306231495924294 Engine time: 0.07990982895717025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 4.655104583129287,
    "estimated_duration": 3600.0430855959153,
    "input_throughput": 4419.018223324024,
    "output_throughput": 3881.0532729185993,
    "total_throughput": 8300.071496242623,
    "itl": 50.00114453189613,
    "ttft": 10585.427019700266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.686388366324804,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.71275895450268
}
#Debug simulation 
Total elapsed time: 4.655198626685888. Arrivals time: 0.15310706105083227 Scheduler time: 4.27703031944111 Scheduler overhead time: 0.07763589918613434 Adapter cache time: 0.0303698037751019 Engine time: 0.07969015510752797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 4.660114991012961,
    "estimated_duration": 3600.0117957490306,
    "input_throughput": 4419.056631643617,
    "output_throughput": 3881.087005464366,
    "total_throughput": 8300.143637107984,
    "itl": 50.00709247848214,
    "ttft": 10528.981151433902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8892441084980927,
    "arrivals": 63755,
    "finished_requests": 63569,
    "scheduler_time": 43.71400108568688
}
#Debug simulation 
Total elapsed time: 4.660209737718105. Arrivals time: 0.15333148138597608 Scheduler time: 4.281773963943124 Scheduler overhead time: 0.07823754893615842 Adapter cache time: 0.030546674970537424 Engine time: 0.0787841072306037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.4015581547282636,
    "estimated_duration": 3599.9857171966964,
    "input_throughput": 1862.3715555240572,
    "output_throughput": 1631.0425821834392,
    "total_throughput": 3493.414137707496,
    "itl": 30.338684630601925,
    "ttft": 8681.864861130563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.423299244887914,
    "arrivals": 27111,
    "finished_requests": 27046,
    "scheduler_time": 3.1643520226767308
}
#Debug simulation 
Total elapsed time: 2.401646438986063. Arrivals time: 0.07742484472692013 Scheduler time: 1.8923641317524016 Scheduler overhead time: 0.11849004682153463 Adapter cache time: 0.14907851023599505 Engine time: 0.10907523706555367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.445034369826317,
    "estimated_duration": 3599.9801835421863,
    "input_throughput": 1862.3744182400258,
    "output_throughput": 1631.0450893156124,
    "total_throughput": 3493.419507555638,
    "itl": 30.351905219476798,
    "ttft": 8681.795779785278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.300234090621448,
    "arrivals": 27111,
    "finished_requests": 27046,
    "scheduler_time": 3.17033971491984
}
#Debug simulation 
Total elapsed time: 2.445126081816852. Arrivals time: 0.07805895991623402 Scheduler time: 1.9401679006405175 Scheduler overhead time: 0.11205528164282441 Adapter cache time: 0.15091061685234308 Engine time: 0.11049434915184975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.377869240939617,
    "estimated_duration": 3599.960226865439,
    "input_throughput": 1862.3847424663795,
    "output_throughput": 1631.0541311487318,
    "total_throughput": 3493.4388736151113,
    "itl": 30.35278559452388,
    "ttft": 8681.729096223577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.32520516736321,
    "arrivals": 27111,
    "finished_requests": 27046,
    "scheduler_time": 3.170508637749535
}
#Debug simulation 
Total elapsed time: 2.3779627052135766. Arrivals time: 0.07783913472667336 Scheduler time: 1.8745966758579016 Scheduler overhead time: 0.11196417128667235 Adapter cache time: 0.1489449213258922 Engine time: 0.11054148990660906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.40940898982808,
    "estimated_duration": 3599.9747634240257,
    "input_throughput": 1862.3769444492366,
    "output_throughput": 1630.967822234266,
    "total_throughput": 3493.3447666835023,
    "itl": 30.836702588101765,
    "ttft": 8815.488127637664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4423,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.796617304851353,
    "arrivals": 27111,
    "finished_requests": 27045,
    "scheduler_time": 3.3904579707537033
}
#Debug simulation 
Total elapsed time: 2.409498960711062. Arrivals time: 0.07840512506663799 Scheduler time: 1.90639927983284 Scheduler overhead time: 0.11194194667041302 Adapter cache time: 0.1481170025654137 Engine time: 0.11127203376963735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3881686232052743,
    "estimated_duration": 3599.984985923603,
    "input_throughput": 1862.371933831804,
    "output_throughput": 1631.0429135008085,
    "total_throughput": 3493.4148473326127,
    "itl": 30.35502936389687,
    "ttft": 8681.737233357653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.52816803483185,
    "arrivals": 27111,
    "finished_requests": 27046,
    "scheduler_time": 3.172036783071156
}
#Debug simulation 
Total elapsed time: 2.3882601633667946. Arrivals time: 0.07725592702627182 Scheduler time: 1.8873811028897762 Scheduler overhead time: 0.11247222125530243 Adapter cache time: 0.14873743010684848 Engine time: 0.10881180828437209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.3858765456825495,
    "estimated_duration": 3599.9854968403242,
    "input_throughput": 1862.3716695204719,
    "output_throughput": 1631.0426820201264,
    "total_throughput": 3493.4143515405985,
    "itl": 30.33316582688064,
    "ttft": 8681.68696168281,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.111370543147128,
    "arrivals": 27111,
    "finished_requests": 27046,
    "scheduler_time": 3.162186507524649
}
#Debug simulation 
Total elapsed time: 2.3859634078107774. Arrivals time: 0.07837553741410375 Scheduler time: 1.877673245035112 Scheduler overhead time: 0.11210557166486979 Adapter cache time: 0.14979067025706172 Engine time: 0.11404915759339929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.4139861236326396,
    "estimated_duration": 3599.9890992558544,
    "input_throughput": 1862.369805893544,
    "output_throughput": 1631.0410498781043,
    "total_throughput": 3493.4108557716486,
    "itl": 30.35737927980615,
    "ttft": 8681.814078791354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.703288459553312,
    "arrivals": 27111,
    "finished_requests": 27046,
    "scheduler_time": 3.1731211251241898
}
#Debug simulation 
Total elapsed time: 2.41407722979784. Arrivals time: 0.07729221461340785 Scheduler time: 1.9105695160105824 Scheduler overhead time: 0.11282166186720133 Adapter cache time: 0.1489680176600814 Engine time: 0.11053787916898727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.2515646046958864,
    "estimated_duration": 3600.0015185268244,
    "input_throughput": 1715.4645541725163,
    "output_throughput": 1532.3154647605177,
    "total_throughput": 3247.7800189330337,
    "itl": 28.649848189982276,
    "ttft": 9338.010963062208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8715744773952805,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.505181097138842
}
#Debug simulation 
Total elapsed time: 2.251658292952925. Arrivals time: 0.0736828981898725 Scheduler time: 1.7551913117058575 Scheduler overhead time: 0.12001425214111805 Adapter cache time: 0.1340776663273573 Engine time: 0.11201554583385587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2524059009738266,
    "estimated_duration": 3600.035819532771,
    "input_throughput": 1715.4482092907363,
    "output_throughput": 1532.3008649163762,
    "total_throughput": 3247.7490742071127,
    "itl": 28.65652071420768,
    "ttft": 9480.676904188986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.391539978810766,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.5077693575332636
}
#Debug simulation 
Total elapsed time: 2.2524974308907986. Arrivals time: 0.07489532185718417 Scheduler time: 1.7547035897150636 Scheduler overhead time: 0.11664948239922523 Adapter cache time: 0.1346948747523129 Engine time: 0.11532500013709068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2302485411055386,
    "estimated_duration": 3600.000803766334,
    "input_throughput": 1715.4648947686308,
    "output_throughput": 1532.3157689933812,
    "total_throughput": 3247.780663762012,
    "itl": 28.657359569664024,
    "ttft": 9337.995094004556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.404977524969619,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.5076493058980305
}
#Debug simulation 
Total elapsed time: 2.230336348991841. Arrivals time: 0.07298030657693744 Scheduler time: 1.7373337540775537 Scheduler overhead time: 0.11653100932016969 Adapter cache time: 0.13369272742420435 Engine time: 0.11372604826465249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.274703203700483,
    "estimated_duration": 3600.004349446628,
    "input_throughput": 1715.4632051900962,
    "output_throughput": 1532.3142598002526,
    "total_throughput": 3247.777464990349,
    "itl": 28.650925690750277,
    "ttft": 9338.04032571598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.010469375892711,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.505685739035986
}
#Debug simulation 
Total elapsed time: 2.274794830940664. Arrivals time: 0.07390634901821613 Scheduler time: 1.7780672661028802 Scheduler overhead time: 0.11670228792354465 Adapter cache time: 0.13499788474291563 Engine time: 0.11473843222483993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.253007596824318,
    "estimated_duration": 3600.0006647249556,
    "input_throughput": 1715.4649610243416,
    "output_throughput": 1532.315828175397,
    "total_throughput": 3247.7807891997386,
    "itl": 28.65769506078021,
    "ttft": 9338.077034598478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.520167993325469,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.5082014431296653
}
#Debug simulation 
Total elapsed time: 2.253100147936493. Arrivals time: 0.07287666760385036 Scheduler time: 1.7610396584495902 Scheduler overhead time: 0.1161733535118401 Adapter cache time: 0.13371142279356718 Engine time: 0.1132514220662415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.2835158240050077,
    "estimated_duration": 3600.021915005075,
    "input_throughput": 1715.4548349440518,
    "output_throughput": 1532.3067831914084,
    "total_throughput": 3247.76161813546,
    "itl": 28.64689262757561,
    "ttft": 9480.564653218975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.696389459077963,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.504096254597775
}
#Debug simulation 
Total elapsed time: 2.283604848664254. Arrivals time: 0.07298719696700573 Scheduler time: 1.7827939055860043 Scheduler overhead time: 0.12111050169914961 Adapter cache time: 0.1346406559459865 Engine time: 0.11478461185470223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2509943321347237,
    "estimated_duration": 3600.00322067455,
    "input_throughput": 1715.463743069328,
    "output_throughput": 1532.3147402535872,
    "total_throughput": 3247.7784833229152,
    "itl": 28.660005949613076,
    "ttft": 9338.010267514435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.617878685369693,
    "arrivals": 25189,
    "finished_requests": 25122,
    "scheduler_time": 1.5088374371001556
}
#Debug simulation 
Total elapsed time: 2.2510892781428993. Arrivals time: 0.07273974269628525 Scheduler time: 1.7563915471546352 Scheduler overhead time: 0.11654203711077571 Adapter cache time: 0.13420936139300466 Engine time: 0.11492397589609027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.193909741938114,
    "estimated_duration": 3599.938562071822,
    "input_throughput": 1658.6121949158073,
    "output_throughput": 1474.7271122717793,
    "total_throughput": 3133.3393071875867,
    "itl": 27.680451297973548,
    "ttft": 7456.770406725719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.785823339244912,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.7899475699176519
}
#Debug simulation 
Total elapsed time: 2.1940011368133128. Arrivals time: 0.07177993841469288 Scheduler time: 1.6993563510477543 Scheduler overhead time: 0.1213482110761106 Adapter cache time: 0.1260247346945107 Engine time: 0.11738294595852494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1989028709940612,
    "estimated_duration": 3599.9563222111146,
    "input_throughput": 1658.6040122655256,
    "output_throughput": 1474.719836806027,
    "total_throughput": 3133.3238490715526,
    "itl": 27.683572574517804,
    "ttft": 7456.9215877108645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.044085141941909,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.7903409172736818
}
#Debug simulation 
Total elapsed time: 2.198992684017867. Arrivals time: 0.06951513700187206 Scheduler time: 1.7044940521009266 Scheduler overhead time: 0.12492815777659416 Adapter cache time: 0.12615900579839945 Engine time: 0.11478917021304369 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1785667561925948,
    "estimated_duration": 3599.948477574498,
    "input_throughput": 1658.6076265244096,
    "output_throughput": 1474.7230503634717,
    "total_throughput": 3133.330676887881,
    "itl": 27.68325540290517,
    "ttft": 7456.852818451675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.047108968850161,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.7904597595568935
}
#Debug simulation 
Total elapsed time: 2.178658419288695. Arrivals time: 0.07127965381368995 Scheduler time: 1.6892034178599715 Scheduler overhead time: 0.11888067843392491 Adapter cache time: 0.12609124509617686 Engine time: 0.11559669766575098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.2134489780291915,
    "estimated_duration": 3599.9377173889497,
    "input_throughput": 1658.6125840895716,
    "output_throughput": 1474.7274582990806,
    "total_throughput": 3133.3400423886524,
    "itl": 27.68069698127379,
    "ttft": 7456.926406729174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8482381013431066,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.7900942672371524
}
#Debug simulation 
Total elapsed time: 2.213542152196169. Arrivals time: 0.0720819323323667 Scheduler time: 1.717609183397144 Scheduler overhead time: 0.12062432104721665 Adapter cache time: 0.1263161371462047 Engine time: 0.11880045477300882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.21495858207345,
    "estimated_duration": 3599.960094370229,
    "input_throughput": 1658.602274324527,
    "output_throughput": 1474.7182915450442,
    "total_throughput": 3133.320565869571,
    "itl": 27.683799704817844,
    "ttft": 7456.88082592642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.109845522381369,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.7907685826960379
}
#Debug simulation 
Total elapsed time: 2.215048959944397. Arrivals time: 0.07111946307122707 Scheduler time: 1.7219468229450285 Scheduler overhead time: 0.12034832360222936 Adapter cache time: 0.12729874346405268 Engine time: 0.11642361292615533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1783545832149684,
    "estimated_duration": 3599.936529569256,
    "input_throughput": 1658.6131313583014,
    "output_throughput": 1474.727944893859,
    "total_throughput": 3133.3410762521603,
    "itl": 27.678311077311804,
    "ttft": 7456.966770420691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6986922147938968,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.789416032092229
}
#Debug simulation 
Total elapsed time: 2.178468526341021. Arrivals time: 0.06987974653020501 Scheduler time: 1.686149665620178 Scheduler overhead time: 0.1209755246527493 Adapter cache time: 0.12546617444604635 Engine time: 0.11838319525122643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.204937334638089,
    "estimated_duration": 3599.936143937846,
    "input_throughput": 1658.6133090318199,
    "output_throughput": 1474.728102869277,
    "total_throughput": 3133.3414119010968,
    "itl": 27.684651905299287,
    "ttft": 7456.946524998554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.152364888079513,
    "arrivals": 24288,
    "finished_requests": 24238,
    "scheduler_time": 0.7908151189225262
}
#Debug simulation 
Total elapsed time: 2.205032499972731. Arrivals time: 0.0732257291674614 Scheduler time: 1.7130712447687984 Scheduler overhead time: 0.11813625460490584 Adapter cache time: 0.12636818271130323 Engine time: 0.11654515052214265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1361343557946384,
    "estimated_duration": 3599.8831998901414,
    "input_throughput": 1631.6082144496372,
    "output_throughput": 1450.0526017508848,
    "total_throughput": 3081.660816200522,
    "itl": 27.304317562251754,
    "ttft": 7153.496078683223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4965785067831325,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6128634214241384
}
#Debug simulation 
Total elapsed time: 2.1362304519861937. Arrivals time: 0.07019095215946436 Scheduler time: 1.6481933905743062 Scheduler overhead time: 0.11946693947538733 Adapter cache time: 0.12194130616262555 Engine time: 0.11832219688221812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2281714850105345,
    "estimated_duration": 3599.894799503065,
    "input_throughput": 1631.6029570671901,
    "output_throughput": 1450.0479293785418,
    "total_throughput": 3081.650886445732,
    "itl": 27.45532485259849,
    "ttft": 7153.665372245569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5956153802713444,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6403916400054664
}
#Debug simulation 
Total elapsed time: 2.2282651332207024. Arrivals time: 0.07028564997017384 Scheduler time: 1.7368699642829597 Scheduler overhead time: 0.1206838465295732 Adapter cache time: 0.1215890278108418 Engine time: 0.12058284552767873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2050666911527514,
    "estimated_duration": 3599.8964607790435,
    "input_throughput": 1631.6022041169792,
    "output_throughput": 1450.0472602121313,
    "total_throughput": 3081.6494643291103,
    "itl": 27.45559440015211,
    "ttft": 7153.6803116357505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5978778613731361,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6403237122547752
}
#Debug simulation 
Total elapsed time: 2.205162938218564. Arrivals time: 0.070681048091501 Scheduler time: 1.7148410840891302 Scheduler overhead time: 0.12007694691419601 Adapter cache time: 0.1214335160329938 Engine time: 0.11989341117441654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.1826680623926222,
    "estimated_duration": 3599.8822959578924,
    "input_throughput": 1631.6086241472776,
    "output_throughput": 1450.05296585982,
    "total_throughput": 3081.6615900070974,
    "itl": 27.30461882946805,
    "ttft": 7153.498910657794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5181121528334833,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6127074670045536
}
#Debug simulation 
Total elapsed time: 2.182765649165958. Arrivals time: 0.07218766119331121 Scheduler time: 1.6911719446070492 Scheduler overhead time: 0.12184571847319603 Adapter cache time: 0.12144895968958735 Engine time: 0.11776131624355912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1843061009421945,
    "estimated_duration": 3599.8929120291223,
    "input_throughput": 1631.6038125393225,
    "output_throughput": 1450.048689658847,
    "total_throughput": 3081.6525021981697,
    "itl": 27.455637334178363,
    "ttft": 7153.664928719115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6227771110832723,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6404437638900071
}
#Debug simulation 
Total elapsed time: 2.1844065240584314. Arrivals time: 0.07016556756570935 Scheduler time: 1.695957156829536 Scheduler overhead time: 0.12035992834717035 Adapter cache time: 0.12085359171032906 Engine time: 0.11876596231013536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.220318442210555,
    "estimated_duration": 3599.893106923583,
    "input_throughput": 1631.6037242059926,
    "output_throughput": 1450.0486111547223,
    "total_throughput": 3081.652335360715,
    "itl": 27.30425189739949,
    "ttft": 7153.369116446395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4621345942071489,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6126285723137394
}
#Debug simulation 
Total elapsed time: 2.220416333992034. Arrivals time: 0.07045666966587305 Scheduler time: 1.7277068123221397 Scheduler overhead time: 0.120561049785465 Adapter cache time: 0.1221712650731206 Engine time: 0.12078862078487873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1591599700041115,
    "estimated_duration": 3599.8759744758972,
    "input_throughput": 1631.6114892972478,
    "output_throughput": 1450.0555121930215,
    "total_throughput": 3081.6670014902693,
    "itl": 27.30629778543974,
    "ttft": 7153.474097697584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6433861461654296,
    "arrivals": 23803,
    "finished_requests": 23756,
    "scheduler_time": 0.6131327555908836
}
#Debug simulation 
Total elapsed time: 2.159279204905033. Arrivals time: 0.06990699889138341 Scheduler time: 1.6683320943266153 Scheduler overhead time: 0.12133674463257194 Adapter cache time: 0.1224305396899581 Engine time: 0.11864927783608437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9969011498615146,
    "estimated_duration": 3599.7208445149736,
    "input_throughput": 1441.4773323066263,
    "output_throughput": 1295.9427137546736,
    "total_throughput": 2737.4200460612997,
    "itl": 25.765510708526524,
    "ttft": 8497.420859947608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.396419384819642,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.10417865490229213
}
#Debug simulation 
Total elapsed time: 1.996997679118067. Arrivals time: 0.06385039957240224 Scheduler time: 1.5046000210568309 Scheduler overhead time: 0.12572873895987868 Adapter cache time: 0.11868221219629049 Engine time: 0.12325104605406523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9954281048849225,
    "estimated_duration": 3599.729118030905,
    "input_throughput": 1441.47401925576,
    "output_throughput": 1295.939735196472,
    "total_throughput": 2737.413754452232,
    "itl": 26.00437209295217,
    "ttft": 8497.867905327474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.79117028390499,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.11441823588908086
}
#Debug simulation 
Total elapsed time: 1.9955256157554686. Arrivals time: 0.06425925623625517 Scheduler time: 1.5059379278682172 Scheduler overhead time: 0.1241130968555808 Adapter cache time: 0.11846458399668336 Engine time: 0.12178540043532848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.988323895726353,
    "estimated_duration": 3599.7362478476416,
    "input_throughput": 1441.471164200589,
    "output_throughput": 1295.9371683937459,
    "total_throughput": 2737.4083325943348,
    "itl": 26.00394429126132,
    "ttft": 8497.876917751042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.802361615877537,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.11450267636993168
}
#Debug simulation 
Total elapsed time: 1.9884160477668047. Arrivals time: 0.06332643143832684 Scheduler time: 1.5001851618289948 Scheduler overhead time: 0.1240506093017757 Adapter cache time: 0.1186842443421483 Engine time: 0.12156634451821446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.0050632799975574,
    "estimated_duration": 3599.726062949318,
    "input_throughput": 1441.4752426323882,
    "output_throughput": 1295.9408350583928,
    "total_throughput": 2737.416077690781,
    "itl": 25.767264098329015,
    "ttft": 8497.481905414701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5022555015257435,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.10425575649908377
}
#Debug simulation 
Total elapsed time: 2.005157200153917. Arrivals time: 0.06401293631643057 Scheduler time: 1.5106080821715295 Scheduler overhead time: 0.12621603719890118 Adapter cache time: 0.11812151316553354 Engine time: 0.12484471406787634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0228599160909653,
    "estimated_duration": 3599.7359044491263,
    "input_throughput": 1441.471301710415,
    "output_throughput": 1295.9372920202873,
    "total_throughput": 2737.4085937307023,
    "itl": 26.005160700991887,
    "ttft": 8497.868027857992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.896425448115745,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.1145294471762063
}
#Debug simulation 
Total elapsed time: 2.022958606015891. Arrivals time: 0.06458046054467559 Scheduler time: 1.5293885823339224 Scheduler overhead time: 0.12489733146503568 Adapter cache time: 0.11838911008089781 Engine time: 0.12497234856709838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9954068819060922,
    "estimated_duration": 3599.726726155446,
    "input_throughput": 1441.4749770580024,
    "output_throughput": 1295.940596296962,
    "total_throughput": 2737.4155733549646,
    "itl": 25.764275022994642,
    "ttft": 8497.398118037732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.24621506605046,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.1040764504712441
}
#Debug simulation 
Total elapsed time: 1.9955051178112626. Arrivals time: 0.06375695485621691 Scheduler time: 1.5052523193880916 Scheduler overhead time: 0.12559470208361745 Adapter cache time: 0.11829757271334529 Engine time: 0.12133544869720936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.013464506249875,
    "estimated_duration": 3599.72489555093,
    "input_throughput": 1441.4757101058547,
    "output_throughput": 1295.9412553347433,
    "total_throughput": 2737.416965440598,
    "itl": 26.004578979396587,
    "ttft": 8497.87166260602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.973764026760817,
    "arrivals": 21290,
    "finished_requests": 21240,
    "scheduler_time": 0.11457335632265876
}
#Debug simulation 
Total elapsed time: 2.013559754937887. Arrivals time: 0.0637801825068891 Scheduler time: 1.5236040824092925 Scheduler overhead time: 0.12439732160419226 Adapter cache time: 0.11839980632066727 Engine time: 0.12225968390703201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9376051239669323,
    "estimated_duration": 3599.60101393717,
    "input_throughput": 1392.285417354724,
    "output_throughput": 1259.3548513982958,
    "total_throughput": 2651.64026875302,
    "itl": 25.279609159888146,
    "ttft": 4797.689170587369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7460369985737847,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03868276884835695
}
#Debug simulation 
Total elapsed time: 1.9377132579684258. Arrivals time: 0.06377372238785028 Scheduler time: 1.4494520733132958 Scheduler overhead time: 0.12856963742524385 Adapter cache time: 0.10879599954932928 Engine time: 0.12445214437320828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9252997790463269,
    "estimated_duration": 3599.6100051080243,
    "input_throughput": 1392.2819396790735,
    "output_throughput": 1259.351705759013,
    "total_throughput": 2651.6336454380867,
    "itl": 25.282405317757476,
    "ttft": 4797.80213765171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9842462438019015,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03874902862703112
}
#Debug simulation 
Total elapsed time: 1.9253941993229091. Arrivals time: 0.06126002222299576 Scheduler time: 1.4452936290763319 Scheduler overhead time: 0.1272221733815968 Adapter cache time: 0.10818764800205827 Engine time: 0.12172963144257665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.006834998726845,
    "estimated_duration": 3599.617184469446,
    "input_throughput": 1392.2791628017742,
    "output_throughput": 1259.3491940082936,
    "total_throughput": 2651.628356810068,
    "itl": 25.281958029655225,
    "ttft": 4797.740066358151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9930415815486913,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03873272427286219
}
#Debug simulation 
Total elapsed time: 2.0069340928457677. Arrivals time: 0.0628028605133295 Scheduler time: 1.5170574132353067 Scheduler overhead time: 0.12779609812423587 Adapter cache time: 0.11033751862123609 Engine time: 0.12693872768431902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9660435291007161,
    "estimated_duration": 3599.6132711110968,
    "input_throughput": 1392.2806764330662,
    "output_throughput": 1259.350563123338,
    "total_throughput": 2651.631239556404,
    "itl": 25.27994561919257,
    "ttft": 4797.7207169097655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7938408254086413,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03871416820467406
}
#Debug simulation 
Total elapsed time: 1.966139845084399. Arrivals time: 0.06214977568015456 Scheduler time: 1.4791708225384355 Scheduler overhead time: 0.12788183521479368 Adapter cache time: 0.10892635909840465 Engine time: 0.12582871643826365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9563422841019928,
    "estimated_duration": 3599.6091403285473,
    "input_throughput": 1392.2822741645136,
    "output_throughput": 1259.3520083089475,
    "total_throughput": 2651.634282473461,
    "itl": 25.28269350627387,
    "ttft": 4797.7252423874825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.051642846018083,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03875486652909425
}
#Debug simulation 
Total elapsed time: 1.9564392268657684. Arrivals time: 0.06327571207657456 Scheduler time: 1.4695373619906604 Scheduler overhead time: 0.12599751073867083 Adapter cache time: 0.10979563277214766 Engine time: 0.12532810727134347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9287282419390976,
    "estimated_duration": 3599.606737022577,
    "input_throughput": 1392.28320373281,
    "output_throughput": 1259.3528491252982,
    "total_throughput": 2651.636052858108,
    "itl": 25.278466497448022,
    "ttft": 4797.686778397954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.65982156096017,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03861863566169826
}
#Debug simulation 
Total elapsed time: 1.928825388662517. Arrivals time: 0.06281322101131082 Scheduler time: 1.4441471341997385 Scheduler overhead time: 0.1264448668807745 Adapter cache time: 0.1089428816922009 Engine time: 0.12430633278563619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9503434598445892,
    "estimated_duration": 3599.6219485763518,
    "input_throughput": 1392.2773201174955,
    "output_throughput": 1259.3475272570965,
    "total_throughput": 2651.624847374592,
    "itl": 25.283139920977106,
    "ttft": 4797.641857833542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0928900879622,
    "arrivals": 20438,
    "finished_requests": 20411,
    "scheduler_time": 0.03875319855707625
}
#Debug simulation 
Total elapsed time: 1.9504392058588564. Arrivals time: 0.06209018174558878 Scheduler time: 1.4654591078869998 Scheduler overhead time: 0.12704499252140522 Adapter cache time: 0.10885411128401756 Engine time: 0.12516675423830748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8825715291313827,
    "estimated_duration": 3600.01698373823,
    "input_throughput": 1375.1865678309207,
    "output_throughput": 1209.3573501642607,
    "total_throughput": 2584.5439179951813,
    "itl": 24.71997096041734,
    "ttft": 5986.019340461668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0015589845320543,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.03495303377979028
}
#Debug simulation 
Total elapsed time: 1.8826642162166536. Arrivals time: 0.06215854873880744 Scheduler time: 1.3960186024196446 Scheduler overhead time: 0.12913196114823222 Adapter cache time: 0.10589710948988795 Engine time: 0.1258412655442953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8888581688515842,
    "estimated_duration": 3600.015093750369,
    "input_throughput": 1375.1872897962048,
    "output_throughput": 1209.3579850701296,
    "total_throughput": 2584.5452748663342,
    "itl": 24.721225954156154,
    "ttft": 5985.96842869841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1356834282982224,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.03500157147628528
}
#Debug simulation 
Total elapsed time: 1.8889505048282444. Arrivals time: 0.06068180641159415 Scheduler time: 1.4050355306826532 Scheduler overhead time: 0.12850497802719474 Adapter cache time: 0.10608377447351813 Engine time: 0.1258635576814413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9318404807709157,
    "estimated_duration": 3600.016851015006,
    "input_throughput": 1375.1866185304598,
    "output_throughput": 1209.3573947501093,
    "total_throughput": 2584.544013280569,
    "itl": 24.721370895822314,
    "ttft": 5985.999336417542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1391874721832638,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.03499598381822984
}
#Debug simulation 
Total elapsed time: 1.9319358998909593. Arrivals time: 0.0619252254255116 Scheduler time: 1.441164587624371 Scheduler overhead time: 0.12977505754679441 Adapter cache time: 0.10696589387953281 Engine time: 0.12853460712358356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9426809381693602,
    "estimated_duration": 3600.0184977219023,
    "input_throughput": 1375.1859894977783,
    "output_throughput": 1209.3568415704067,
    "total_throughput": 2584.542831068185,
    "itl": 24.72050229724346,
    "ttft": 5986.037124117783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0319002174143495,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.03492638809551958
}
#Debug simulation 
Total elapsed time: 1.9427780881524086. Arrivals time: 0.06124467542394996 Scheduler time: 1.4450801047496498 Scheduler overhead time: 0.1360294404439628 Adapter cache time: 0.10753338225185871 Engine time: 0.12801074609160423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9060080372728407,
    "estimated_duration": 3600.0256807825167,
    "input_throughput": 1375.1832456161524,
    "output_throughput": 1209.3544285644261,
    "total_throughput": 2584.5376741805785,
    "itl": 24.722073980671528,
    "ttft": 5986.096465199022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1711289339326334,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.034999903504267224
}
#Debug simulation 
Total elapsed time: 1.9061027220450342. Arrivals time: 0.06099546840414405 Scheduler time: 1.4167964407242835 Scheduler overhead time: 0.13134519662708044 Adapter cache time: 0.10723725752905011 Engine time: 0.12652636971324682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9443417340517044,
    "estimated_duration": 3600.006704506421,
    "input_throughput": 1375.1904944518055,
    "output_throughput": 1209.3608032868692,
    "total_throughput": 2584.5512977386747,
    "itl": 24.719623834474937,
    "ttft": 5986.068320289223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9554928928659903,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.03495290865778639
}
#Debug simulation 
Total elapsed time: 1.9444350181147456. Arrivals time: 0.06140673765912652 Scheduler time: 1.4522616886533797 Scheduler overhead time: 0.13157652877271175 Adapter cache time: 0.1069315099157393 Engine time: 0.12916012248024344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9140531532466412,
    "estimated_duration": 3600.0260603729744,
    "input_throughput": 1375.1831006154139,
    "output_throughput": 1209.354301048849,
    "total_throughput": 2584.5374016642627,
    "itl": 24.72241177877921,
    "ttft": 5985.974011557175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1946448919922132,
    "arrivals": 19983,
    "finished_requests": 19950,
    "scheduler_time": 0.03498622623012931
}
#Debug simulation 
Total elapsed time: 1.9141494343057275. Arrivals time: 0.061363850720226765 Scheduler time: 1.425988720729947 Scheduler overhead time: 0.1300740442238748 Adapter cache time: 0.10622070590034127 Engine time: 0.12717212736606598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8028688919730484,
    "estimated_duration": 3600.0028693111763,
    "input_throughput": 1277.5673150727291,
    "output_throughput": 1132.5082640226058,
    "total_throughput": 2410.075579095335,
    "itl": 23.97270220651887,
    "ttft": 6237.179665541359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.106395060091817,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0033672413384645667
}
#Debug simulation 
Total elapsed time: 1.8029637839645147. Arrivals time: 0.05789142893627286 Scheduler time: 1.3197477478533983 Scheduler overhead time: 0.1313258744776249 Adapter cache time: 0.09965435415506363 Engine time: 0.13010642398148775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8580663027241826,
    "estimated_duration": 3600.022245675791,
    "input_throughput": 1277.5604388346317,
    "output_throughput": 1132.5021685344238,
    "total_throughput": 2410.0626073690555,
    "itl": 24.10858073140997,
    "ttft": 6430.91340417012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3135630565020318,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.00357736298061992
}
#Debug simulation 
Total elapsed time: 1.8581625618971884. Arrivals time: 0.058543126098811626 Scheduler time: 1.3730344749055803 Scheduler overhead time: 0.13146945321932435 Adapter cache time: 0.09924402739852667 Engine time: 0.1316449288278818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8005018061958253,
    "estimated_duration": 3600.023086899638,
    "input_throughput": 1277.5601403047942,
    "output_throughput": 1132.5019039006124,
    "total_throughput": 2410.0620442054064,
    "itl": 24.108585838150503,
    "ttft": 6430.856273177289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3191744227707014,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003571775322564501
}
#Debug simulation 
Total elapsed time: 1.8005914972163737. Arrivals time: 0.05740952771157026 Scheduler time: 1.3220333396457136 Scheduler overhead time: 0.1318126441910863 Adapter cache time: 0.09796756552532315 Engine time: 0.12712949560955167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8102242890745401,
    "estimated_duration": 3600.0197220670334,
    "input_throughput": 1277.561334402701,
    "output_throughput": 1132.5029624168499,
    "total_throughput": 2410.064296819551,
    "itl": 24.10710376811085,
    "ttft": 6430.7930295214655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1599312167684164,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003573443294582554
}
#Debug simulation 
Total elapsed time: 1.8103171130642295. Arrivals time: 0.057483232114464045 Scheduler time: 1.3302471339702606 Scheduler overhead time: 0.13134058099240065 Adapter cache time: 0.09853311348706484 Engine time: 0.1290538408793509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.792593558318913,
    "estimated_duration": 3600.0184338893164,
    "input_throughput": 1277.5617915464832,
    "output_throughput": 1132.503367655075,
    "total_throughput": 2410.0651592015583,
    "itl": 24.108770473086903,
    "ttft": 6430.846574218693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.366457846462735,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0035798649386469994
}
#Debug simulation 
Total elapsed time: 1.7926877029240131. Arrivals time: 0.057818705681711435 Scheduler time: 1.3151042270474136 Scheduler overhead time: 0.13077773805707693 Adapter cache time: 0.09781839698553085 Engine time: 0.12721539614722133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8257341403514147,
    "estimated_duration": 3600.0099446342906,
    "input_throughput": 1277.5648041903444,
    "output_throughput": 1132.5060382337826,
    "total_throughput": 2410.070842424127,
    "itl": 23.972132748322977,
    "ttft": 6237.199242221544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0349010493256374,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0033736629825290125
}
#Debug simulation 
Total elapsed time: 1.8258272842504084. Arrivals time: 0.05813488224521279 Scheduler time: 1.3408788777887821 Scheduler overhead time: 0.1322507350705564 Adapter cache time: 0.10038824332877994 Engine time: 0.1293174303136766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8278911258094013,
    "estimated_duration": 3600.0075358694944,
    "input_throughput": 1277.5656590088674,
    "output_throughput": 1132.5067959934954,
    "total_throughput": 2410.072455002363,
    "itl": 24.109294942336362,
    "ttft": 6237.497929924437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4049385051057164,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003580698924656026
}
#Debug simulation 
Total elapsed time: 1.8279855446889997. Arrivals time: 0.05835798382759094 Scheduler time: 1.3450786019675434 Scheduler overhead time: 0.13025109423324466 Adapter cache time: 0.09902973659336567 Engine time: 0.13109890697523952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.799063759855926,
    "estimated_duration": 3599.8146558411104,
    "input_throughput": 1234.6957899035178,
    "output_throughput": 1119.0623365743104,
    "total_throughput": 2353.7581264778282,
    "itl": 23.848315643860992,
    "ttft": 5806.784501046605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.160704347216563,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0018451841629341325
}
#Debug simulation 
Total elapsed time: 1.7991853808052838. Arrivals time: 0.05579947028309107 Scheduler time: 1.317655778490007 Scheduler overhead time: 0.1341822324320674 Adapter cache time: 0.09608305711299181 Engine time: 0.13052388839423656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7854119669646025,
    "estimated_duration": 3599.8181821149856,
    "input_throughput": 1234.6945804325703,
    "output_throughput": 1119.061240374424,
    "total_throughput": 2353.7558208069945,
    "itl": 23.849860673373243,
    "ttft": 5806.826549818743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3026067125494647,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0018298389167781615
}
#Debug simulation 
Total elapsed time: 1.7855055290274322. Arrivals time: 0.05609862972050905 Scheduler time: 1.304848758969456 Scheduler overhead time: 0.13285906426608562 Adapter cache time: 0.09599226713180542 Engine time: 0.13108761422336102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8063382008112967,
    "estimated_duration": 3599.8215918150895,
    "input_throughput": 1234.6934109473245,
    "output_throughput": 1119.0601804154426,
    "total_throughput": 2353.753591362767,
    "itl": 23.849893787952457,
    "ttft": 5806.738447333426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.306893382165581,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.001833883724819411
}
#Debug simulation 
Total elapsed time: 1.8064336460083723. Arrivals time: 0.05740674352273345 Scheduler time: 1.3186709159053862 Scheduler overhead time: 0.1330335596576333 Adapter cache time: 0.09765338711440563 Engine time: 0.1343223238363862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8071475182659924,
    "estimated_duration": 3599.833180253201,
    "input_throughput": 1234.6894362719818,
    "output_throughput": 1119.0565779819424,
    "total_throughput": 2353.746014253924,
    "itl": 23.848547753867777,
    "ttft": 5806.729175096825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1959633344365086,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0018315068887962145
}
#Debug simulation 
Total elapsed time: 1.8072345880791545. Arrivals time: 0.05615075910463929 Scheduler time: 1.3241866654716432 Scheduler overhead time: 0.13406595354899764 Adapter cache time: 0.09586171107366681 Engine time: 0.1314196903258562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7824088791385293,
    "estimated_duration": 3599.8365464913245,
    "input_throughput": 1234.688281703268,
    "output_throughput": 1119.0555315425092,
    "total_throughput": 2353.7438132457773,
    "itl": 23.84976110583576,
    "ttft": 5806.697114442143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3397151204198634,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.001844350176925106
}
#Debug simulation 
Total elapsed time: 1.7825089562684298. Arrivals time: 0.05569950956851244 Scheduler time: 1.2966095795854926 Scheduler overhead time: 0.13928326033055782 Adapter cache time: 0.09551861602813005 Engine time: 0.1292638354934752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7890825597569346,
    "estimated_duration": 3599.836730800716,
    "input_throughput": 1234.6882184879994,
    "output_throughput": 1119.0554742475651,
    "total_throughput": 2353.7436927355648,
    "itl": 23.84768779255388,
    "ttft": 5806.917986060959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.110975508200898,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.001829004930769135
}
#Debug simulation 
Total elapsed time: 1.7891760407947004. Arrivals time: 0.056091105099767447 Scheduler time: 1.3109484715387225 Scheduler overhead time: 0.13229428650811315 Adapter cache time: 0.09643455129116774 Engine time: 0.1289281491190195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8092777989804745,
    "estimated_duration": 3599.8348661746,
    "input_throughput": 1234.6888580261957,
    "output_throughput": 1119.0560538908378,
    "total_throughput": 2353.7449119170337,
    "itl": 23.850159833946673,
    "ttft": 5806.746674759947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3658719079941593,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0018338837248194108
}
#Debug simulation 
Total elapsed time: 1.809373059310019. Arrivals time: 0.05657167686149478 Scheduler time: 1.323889676015824 Scheduler overhead time: 0.1353597124107182 Adapter cache time: 0.09639729419723153 Engine time: 0.13082558987662196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7052983520552516,
    "estimated_duration": 3600.008148321354,
    "input_throughput": 1192.6436894322105,
    "output_throughput": 1037.6248736386347,
    "total_throughput": 2230.268563070845,
    "itl": 23.081163264024415,
    "ttft": 4654.281343498761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.573090700381454,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.705391882918775. Arrivals time: 0.05451612360775471 Scheduler time: 1.2249766858294606 Scheduler overhead time: 0.1355496342293918 Adapter cache time: 0.09000125853344798 Engine time: 0.13371012546122074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6972574843093753,
    "estimated_duration": 3600.0208064986828,
    "input_throughput": 1192.6394959299719,
    "output_throughput": 1037.6212252042624,
    "total_throughput": 2230.2607211342342,
    "itl": 23.081523771358476,
    "ttft": 4654.330853128865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6771639288705824,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6973488391377032. Arrivals time: 0.054063168819993734 Scheduler time: 1.2180145867168903 Scheduler overhead time: 0.13576890481635928 Adapter cache time: 0.08962855394929647 Engine time: 0.1331626079045236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.719796339981258,
    "estimated_duration": 3600.023864281466,
    "input_throughput": 1192.6384829276544,
    "output_throughput": 1037.6203438711275,
    "total_throughput": 2230.258826798782,
    "itl": 23.08152662615364,
    "ttft": 4654.404684540089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6807273652777177,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7198925442062318. Arrivals time: 0.053911230992525816 Scheduler time: 1.237791292835027 Scheduler overhead time: 0.1381317088380456 Adapter cache time: 0.08934446098282933 Engine time: 0.13359518256038427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.6829198841005564,
    "estimated_duration": 3600.014237707189,
    "input_throughput": 1192.641672088081,
    "output_throughput": 1037.6231185071852,
    "total_throughput": 2230.2647905952663,
    "itl": 23.081477054009486,
    "ttft": 4654.305106879638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.600348009003783,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6830164403654635. Arrivals time: 0.0537585224956274 Scheduler time: 1.205860362853855 Scheduler overhead time: 0.13533681631088257 Adapter cache time: 0.08878013351932168 Engine time: 0.13322828384116292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6989069902338088,
    "estimated_duration": 3600.009301883796,
    "input_throughput": 1192.643307269596,
    "output_throughput": 1037.624541149193,
    "total_throughput": 2230.267848418789,
    "itl": 23.08180889366882,
    "ttft": 4654.475337630484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.704369077123705,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6990093910135329. Arrivals time: 0.05489806830883026 Scheduler time: 1.2175284009426832 Scheduler overhead time: 0.13557447772473097 Adapter cache time: 0.08909361995756626 Engine time: 0.13505050027742982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.751947277225554,
    "estimated_duration": 3600.0209449985464,
    "input_throughput": 1192.6394500467923,
    "output_throughput": 1037.6211852849397,
    "total_throughput": 2230.260635331732,
    "itl": 23.080993500280023,
    "ttft": 4654.350143339971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5398759018746027,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7520407154224813. Arrivals time: 0.05474416399374604 Scheduler time: 1.2607070319354534 Scheduler overhead time: 0.14036875404417515 Adapter cache time: 0.09054046031087637 Engine time: 0.1383437467738986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7128776730969548,
    "estimated_duration": 3600.0103253496673,
    "input_throughput": 1192.642968206757,
    "output_throughput": 1037.6242461574543,
    "total_throughput": 2230.267214364211,
    "itl": 23.08217275668675,
    "ttft": 4654.366960360205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.722980637513099,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7129686730913818. Arrivals time: 0.054590179584920406 Scheduler time: 1.2346175909042358 Scheduler overhead time: 0.13536853715777397 Adapter cache time: 0.08942667488008738 Engine time: 0.13277524942532182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.5066781672649086,
    "estimated_duration": 3599.532387851328,
    "input_throughput": 922.906822900689,
    "output_throughput": 839.2701258074569,
    "total_throughput": 1762.176948708146,
    "itl": 22.31576755601069,
    "ttft": 5537.815936628937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.118694492387797,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5067676799371839. Arrivals time: 0.046398456674069166 Scheduler time: 1.016146163456142 Scheduler overhead time: 0.1399723645299673 Adapter cache time: 0.09977590013295412 Engine time: 0.13620270555838943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5145355206914246,
    "estimated_duration": 3599.5441153107936,
    "input_throughput": 922.90381603315,
    "output_throughput": 839.26739143164,
    "total_throughput": 1762.1712074647899,
    "itl": 22.319904732275607,
    "ttft": 5537.87946172649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.582867990384954,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5146272466517985. Arrivals time: 0.04730378929525614 Scheduler time: 1.0198258622549474 Scheduler overhead time: 0.141420423053205 Adapter cache time: 0.10006712796166539 Engine time: 0.13675716193392873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5151640777476132,
    "estimated_duration": 3599.542417280225,
    "input_throughput": 922.9042513992908,
    "output_throughput": 839.2677873435423,
    "total_throughput": 1762.1720387428331,
    "itl": 22.319630212674504,
    "ttft": 5537.9546183723105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.6006177601776646,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5152546288445592. Arrivals time: 0.04646098334342241 Scheduler time: 1.0251661860384047 Scheduler overhead time: 0.13894815323874354 Adapter cache time: 0.09982713917270303 Engine time: 0.13686098949983716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.5121179008856416,
    "estimated_duration": 3599.5403905798635,
    "input_throughput": 922.9047710351824,
    "output_throughput": 839.2682598884073,
    "total_throughput": 1762.1730309235897,
    "itl": 22.316566221564276,
    "ttft": 5537.870716534451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.2553044280616765,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.512208360247314. Arrivals time: 0.04727248568087816 Scheduler time: 1.019621233921498 Scheduler overhead time: 0.13910745969042182 Adapter cache time: 0.10013626189902425 Engine time: 0.13797857146710157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4987237923778594,
    "estimated_duration": 3599.5326809357666,
    "input_throughput": 922.9067477549265,
    "output_throughput": 839.270057471638,
    "total_throughput": 1762.1768052265645,
    "itl": 22.32045576444443,
    "ttft": 5538.0052534649285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.702815574668172,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4988157814368606. Arrivals time: 0.046505377162247896 Scheduler time: 1.0097825680859387 Scheduler overhead time: 0.1385690369643271 Adapter cache time: 0.09970730729401112 Engine time: 0.13573758769780397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.506689048372209,
    "estimated_duration": 3599.5238149109564,
    "input_throughput": 922.9090209762036,
    "output_throughput": 839.2721246865071,
    "total_throughput": 1762.1811456627106,
    "itl": 22.31417359905475,
    "ttft": 5537.850071104433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.960837086532054,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5067775971256196. Arrivals time: 0.04743378283455968 Scheduler time: 1.0165606727823615 Scheduler overhead time: 0.13866781210526824 Adapter cache time: 0.10018451139330864 Engine time: 0.1354143312200904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.495838712900877,
    "estimated_duration": 3599.537395487972,
    "input_throughput": 922.9055389629167,
    "output_throughput": 839.2689582241333,
    "total_throughput": 1762.1744971870498,
    "itl": 22.32146581726429,
    "ttft": 5538.021172447948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2326,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.790857811048312,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4959307010285556. Arrivals time: 0.046943232882767916 Scheduler time: 1.0042729848064482 Scheduler overhead time: 0.13998252479359508 Adapter cache time: 0.09970555314794183 Engine time: 0.13636157615110278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4173503178171813,
    "estimated_duration": 3599.91695110178,
    "input_throughput": 863.8332612223862,
    "output_throughput": 768.6810661432294,
    "total_throughput": 1632.5143273656156,
    "itl": 21.730754103784484,
    "ttft": 5692.743963587867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9694526038808835,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4174480200745165. Arrivals time: 0.04393358901143074 Scheduler time: 0.9311932628042996 Scheduler overhead time: 0.14160814974457026 Adapter cache time: 0.09133847104385495 Engine time: 0.13994682766497135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4380010971799493,
    "estimated_duration": 3599.923073286241,
    "input_throughput": 863.8317921502808,
    "output_throughput": 768.6797588910513,
    "total_throughput": 1632.511551041332,
    "itl": 21.73339994962684,
    "ttft": 5692.8956833459915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.240110684626258,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.438091641291976. Arrivals time: 0.04430801700800657 Scheduler time: 0.9487796225585043 Scheduler overhead time: 0.14209417905658484 Adapter cache time: 0.09285961743444204 Engine time: 0.13872208632528782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4416682589799166,
    "estimated_duration": 3599.9280868543246,
    "input_throughput": 863.8305891041647,
    "output_throughput": 768.6786883618038,
    "total_throughput": 1632.5092774659686,
    "itl": 21.73301186536606,
    "ttft": 5692.889314973312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.24624522700899,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4417674071155488. Arrivals time: 0.04391916003078222 Scheduler time: 0.9496599701233208 Scheduler overhead time: 0.14645231189206243 Adapter cache time: 0.09190765721723437 Engine time: 0.13886546809226274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.4121913369745016,
    "estimated_duration": 3599.9264524300143,
    "input_throughput": 863.830981297098,
    "output_throughput": 768.679037354249,
    "total_throughput": 1632.510018651347,
    "itl": 21.731918890058388,
    "ttft": 5692.813034890705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.052565433462098,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4122788337990642. Arrivals time: 0.0439422819763422 Scheduler time: 0.9298761780373752 Scheduler overhead time: 0.14076022524386644 Adapter cache time: 0.09091216046363115 Engine time: 0.137280881870538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4556603617966175,
    "estimated_duration": 3599.9317460954353,
    "input_throughput": 863.8297110418494,
    "output_throughput": 768.6779070190296,
    "total_throughput": 1632.507618060879,
    "itl": 21.73362215806505,
    "ttft": 5692.862656387762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.303966214973466,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4557528640143573. Arrivals time: 0.04492207942530513 Scheduler time: 0.9641236988827586 Scheduler overhead time: 0.14182938169687986 Adapter cache time: 0.09228633530437946 Engine time: 0.14282504143193364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.425736126024276,
    "estimated_duration": 3599.9223583282487,
    "input_throughput": 863.8319637104929,
    "output_throughput": 768.6799115537152,
    "total_throughput": 1632.5118752642081,
    "itl": 21.72978820590039,
    "ttft": 5692.957167592055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.878095232488021,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.425827237777412. Arrivals time: 0.044460201635956764 Scheduler time: 0.9380862168036401 Scheduler overhead time: 0.14248158549889922 Adapter cache time: 0.09201761707663536 Engine time: 0.13875347608700395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4496135809458792,
    "estimated_duration": 3599.9275877067494,
    "input_throughput": 863.8307088785028,
    "output_throughput": 768.6787949428652,
    "total_throughput": 1632.509503821368,
    "itl": 21.73352787497352,
    "ttft": 5693.014547830579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.357663081772656,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4497089688666165. Arrivals time: 0.04471172206103802 Scheduler time: 0.9608192299492657 Scheduler overhead time: 0.1418005982413888 Adapter cache time: 0.09205111442133784 Engine time: 0.14061458176001906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4132629870437086,
    "estimated_duration": 3599.931194450524,
    "input_throughput": 839.5007673087723,
    "output_throughput": 733.1467901577065,
    "total_throughput": 1572.647557466479,
    "itl": 21.360226351512402,
    "ttft": 6490.585277769613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9066838644701358,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4133584131486714. Arrivals time: 0.043164595030248165 Scheduler time: 0.9234428592026234 Scheduler overhead time: 0.1465078336186707 Adapter cache time: 0.08891011402010918 Engine time: 0.14006118848919868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3978271251544356,
    "estimated_duration": 3599.9353565528704,
    "input_throughput": 839.4997967113122,
    "output_throughput": 733.1459425224926,
    "total_throughput": 1572.645739233805,
    "itl": 21.361488429871574,
    "ttft": 6490.672468077562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.03645434406121,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.397922609001398. Arrivals time: 0.0435504000633955 Scheduler time: 0.9114160789176822 Scheduler overhead time: 0.14294132310897112 Adapter cache time: 0.08814906235784292 Engine time: 0.14149932423606515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3854047106578946,
    "estimated_duration": 3599.9366565068244,
    "input_throughput": 839.4994935640116,
    "output_throughput": 733.1456777800659,
    "total_throughput": 1572.6451713440774,
    "itl": 21.361429220907524,
    "ttft": 6490.661850928199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.039442427959304,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3854963388293982. Arrivals time: 0.04289646912366152 Scheduler time: 0.8994760112836957 Scheduler overhead time: 0.14290923858061433 Adapter cache time: 0.08826975477859378 Engine time: 0.14130803709849715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3786707376129925,
    "estimated_duration": 3599.9486446201777,
    "input_throughput": 839.4966979643843,
    "output_throughput": 733.1432363470464,
    "total_throughput": 1572.6399343114306,
    "itl": 21.3602801303417,
    "ttft": 6490.740541051184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9392086582723855,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.378764125984162. Arrivals time: 0.0427000829949975 Scheduler time: 0.8953987122513354 Scheduler overhead time: 0.14240669226273894 Adapter cache time: 0.0884391157887876 Engine time: 0.1396098299883306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3932496588677168,
    "estimated_duration": 3599.944018055441,
    "input_throughput": 839.4977768661116,
    "output_throughput": 733.1441785657662,
    "total_throughput": 1572.6419554318777,
    "itl": 21.362046078622882,
    "ttft": 6490.674078147406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.069371829126032,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.393339924979955. Arrivals time: 0.04291266854852438 Scheduler time: 0.9092449955642223 Scheduler overhead time: 0.14202810218557715 Adapter cache time: 0.0885132304392755 Engine time: 0.14045107504352927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3871455239132047,
    "estimated_duration": 3599.948043182387,
    "input_throughput": 839.4968382178083,
    "output_throughput": 733.1433588321607,
    "total_throughput": 1572.6401970499692,
    "itl": 21.36057382980221,
    "ttft": 6490.757909764666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8628013337240261,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.387236796785146. Arrivals time: 0.04305652854964137 Scheduler time: 0.9056552373804152 Scheduler overhead time: 0.1415671119466424 Adapter cache time: 0.08794398047029972 Engine time: 0.13850684044882655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3880469761788845,
    "estimated_duration": 3599.949298311983,
    "input_throughput": 839.4965455255395,
    "output_throughput": 733.1431032202476,
    "total_throughput": 1572.639648745787,
    "itl": 21.361680108822547,
    "ttft": 6490.71899902637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0928877871856066,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.388139076065272. Arrivals time: 0.04305065609514713 Scheduler time: 0.9038511756807566 Scheduler overhead time: 0.14307646779343486 Adapter cache time: 0.08781425515189767 Engine time: 0.13976667542010546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2847668258473277,
    "estimated_duration": 3600.0111518812546,
    "input_throughput": 728.1685776529135,
    "output_throughput": 658.6499041151336,
    "total_throughput": 1386.8184817680471,
    "itl": 21.034469309472904,
    "ttft": 5387.614953141785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2410565208248627,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2848522989079356. Arrivals time: 0.03971831779927015 Scheduler time: 0.8077074326574802 Scheduler overhead time: 0.1433574603870511 Adapter cache time: 0.08082500612363219 Engine time: 0.14185187127441168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3101342027075589,
    "estimated_duration": 3599.9955893960982,
    "input_throughput": 728.1717254658482,
    "output_throughput": 658.6527514045542,
    "total_throughput": 1386.8244768704023,
    "itl": 20.875118578746353,
    "ttft": 5387.411043097668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.46226732673124,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.310213322751224. Arrivals time: 0.04003436351194978 Scheduler time: 0.8288312046788633 Scheduler overhead time: 0.14552898751571774 Adapter cache time: 0.08165216632187366 Engine time: 0.14243216533213854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.315764406695962,
    "estimated_duration": 3599.9982709286483,
    "input_throughput": 728.1711830722032,
    "output_throughput": 658.6522607935431,
    "total_throughput": 1386.8234438657464,
    "itl": 20.875430499730797,
    "ttft": 5387.2833817414175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.468964758552567,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3158527398481965. Arrivals time: 0.03965963749215007 Scheduler time: 0.8336786208674312 Scheduler overhead time: 0.14742758870124817 Adapter cache time: 0.0811218898743391 Engine time: 0.14169670455157757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3038894459605217,
    "estimated_duration": 3600.007395783943,
    "input_throughput": 728.1693373935851,
    "output_throughput": 658.6505913229257,
    "total_throughput": 1386.819928716511,
    "itl": 21.0296444421096,
    "ttft": 5387.6098301512375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3041409384947786,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3039769637398422. Arrivals time: 0.039916093461215496 Scheduler time: 0.8270502872765064 Scheduler overhead time: 0.14312193356454372 Adapter cache time: 0.0803592661395669 Engine time: 0.14202961837872863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3095166902057827,
    "estimated_duration": 3600.0126069230027,
    "input_throughput": 728.1682833440331,
    "output_throughput": 658.6496379040914,
    "total_throughput": 1386.8179212481245,
    "itl": 20.875964356505392,
    "ttft": 5387.499362103387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.517631473895168,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3096063253469765. Arrivals time: 0.039586417842656374 Scheduler time: 0.8306111730635166 Scheduler overhead time: 0.14431145461276174 Adapter cache time: 0.08151364512741566 Engine time: 0.14214895479381084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2959672017022967,
    "estimated_duration": 3600.0058183805813,
    "input_throughput": 728.1696564532808,
    "output_throughput": 658.6508799218085,
    "total_throughput": 1386.8205363750892,
    "itl": 21.034390539172623,
    "ttft": 5387.773826656685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1664632623013285,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2960804859176278. Arrivals time: 0.039291017688810825 Scheduler time: 0.8162234905175865 Scheduler overhead time: 0.1468605543486774 Adapter cache time: 0.08014539442956448 Engine time: 0.14220697060227394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.309321688953787,
    "estimated_duration": 3599.993894000386,
    "input_throughput": 728.1720683939913,
    "output_throughput": 658.65306159315,
    "total_throughput": 1386.8251299871413,
    "itl": 20.87616142109314,
    "ttft": 5387.534977450801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5572439166158913,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3093989468179643. Arrivals time: 0.03935772320255637 Scheduler time: 0.8244831417687237 Scheduler overhead time: 0.1494876048527658 Adapter cache time: 0.0822412259876728 Engine time: 0.14082244830206037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2660971148870885,
    "estimated_duration": 3600.0200983150694,
    "input_throughput": 705.6071718013183,
    "output_throughput": 630.8023116489983,
    "total_throughput": 1336.4094834503167,
    "itl": 20.612728142121068,
    "ttft": 4594.432447459402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0444058129471143,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.266177891753614. Arrivals time: 0.03875027550384402 Scheduler time: 0.7917214636690915 Scheduler overhead time: 0.14528598124161363 Adapter cache time: 0.07688295654952526 Engine time: 0.14177790423855186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2608370641246438,
    "estimated_duration": 3600.0016625170656,
    "input_throughput": 705.6107852527855,
    "output_throughput": 630.8055420208393,
    "total_throughput": 1336.4163272736248,
    "itl": 20.61390471993445,
    "ttft": 4244.059845794375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1808128949743755,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2609274252317846. Arrivals time: 0.038233387283980846 Scheduler time: 0.787521977443248 Scheduler overhead time: 0.1450992664322257 Adapter cache time: 0.07617410738021135 Engine time: 0.1421975214034319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2543767550960183,
    "estimated_duration": 3600.004989713551,
    "input_throughput": 705.6101331132103,
    "output_throughput": 630.8049590177633,
    "total_throughput": 1336.4150921309736,
    "itl": 20.61423969092197,
    "ttft": 4243.995470498475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.184494716022169,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2544671390205622. Arrivals time: 0.038516608998179436 Scheduler time: 0.7807530048303306 Scheduler overhead time: 0.14538932079449296 Adapter cache time: 0.07637384347617626 Engine time: 0.14176271576434374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.274715246167034,
    "estimated_duration": 3600.0193221782506,
    "input_throughput": 705.6073239248645,
    "output_throughput": 630.8024476451849,
    "total_throughput": 1336.4097715700493,
    "itl": 20.61367440285966,
    "ttft": 4594.439794902907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0794812560011455,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2748083393089473. Arrivals time: 0.038867556024342775 Scheduler time: 0.7930285893380642 Scheduler overhead time: 0.14469089964404702 Adapter cache time: 0.07738607283681631 Engine time: 0.14897840516641736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.292716662865132,
    "estimated_duration": 3600.002683462186,
    "input_throughput": 705.6105851446324,
    "output_throughput": 630.8053631271282,
    "total_throughput": 1336.4159482717607,
    "itl": 20.6145540684502,
    "ttft": 4244.03588016948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2156816550530527,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2928062807768583. Arrivals time: 0.03865201072767377 Scheduler time: 0.813359341584146 Scheduler overhead time: 0.14655017433688045 Adapter cache time: 0.07727582706138492 Engine time: 0.1447590789757669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2625302239321172,
    "estimated_duration": 3600.0090951634047,
    "input_throughput": 705.6093284355161,
    "output_throughput": 630.804239647879,
    "total_throughput": 1336.413568083395,
    "itl": 20.612608007234535,
    "ttft": 4243.983802422615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9973535969946192,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2626223899424076. Arrivals time: 0.03884441964328289 Scheduler time: 0.7844322761520743 Scheduler overhead time: 0.1459542252123356 Adapter cache time: 0.07657018816098571 Engine time: 0.14421034418046474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3087040935643017,
    "estimated_duration": 3600.0081372707427,
    "input_throughput": 705.6095161845356,
    "output_throughput": 630.8044074927085,
    "total_throughput": 1336.4139236772442,
    "itl": 20.614318398195255,
    "ttft": 4243.86473977294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2409581661224394,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3087818520143628. Arrivals time: 0.038932183757424355 Scheduler time: 0.8244117451831698 Scheduler overhead time: 0.14948741998523474 Adapter cache time: 0.07744633965194225 Engine time: 0.1454075900837779 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.1765320687554777,
    "estimated_duration": 3599.9313034482097,
    "input_throughput": 644.1139578910742,
    "output_throughput": 556.9803507304194,
    "total_throughput": 1201.0943086214936,
    "itl": 20.087391965362826,
    "ttft": 3126.5522347792685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7414175262977614,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1766115850768983. Arrivals time: 0.03596179559826851 Scheduler time: 0.7061945106834173 Scheduler overhead time: 0.14655119320377707 Adapter cache time: 0.07115482771769166 Engine time: 0.14382571494206786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1830224180594087,
    "estimated_duration": 3599.9296879087237,
    "input_throughput": 644.1142469499233,
    "output_throughput": 556.9806006863429,
    "total_throughput": 1201.0948476362662,
    "itl": 20.088030945418346,
    "ttft": 3126.605729292757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8553790528513545,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1831190888769925. Arrivals time: 0.0366177037358284 Scheduler time: 0.7066671596840024 Scheduler overhead time: 0.14824356604367495 Adapter cache time: 0.07117049396038055 Engine time: 0.14682853687554598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1890623969957232,
    "estimated_duration": 3599.93130442109,
    "input_throughput": 644.1139577170027,
    "output_throughput": 556.9803505798957,
    "total_throughput": 1201.0943082968984,
    "itl": 20.088088788626514,
    "ttft": 3126.602287634216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8589045303873832,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1891549513675272. Arrivals time: 0.03613791102543473 Scheduler time: 0.7164259348064661 Scheduler overhead time: 0.14616995118558407 Adapter cache time: 0.07173677999526262 Engine time: 0.14539968175813556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1995396162383258,
    "estimated_duration": 3599.921409243012,
    "input_throughput": 644.1157282062966,
    "output_throughput": 556.9818815632502,
    "total_throughput": 1201.0976097695468,
    "itl": 20.08758299091146,
    "ttft": 3126.5970651963394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7703912266157449,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1996229100041091. Arrivals time: 0.036051175091415644 Scheduler time: 0.7260955176316202 Scheduler overhead time: 0.14713584631681442 Adapter cache time: 0.07139607518911362 Engine time: 0.1457477598451078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.181362590752542,
    "estimated_duration": 3599.9401813855925,
    "input_throughput": 644.1123694192949,
    "output_throughput": 556.9789771418518,
    "total_throughput": 1201.0913465611468,
    "itl": 20.088170117296798,
    "ttft": 3126.5897083262457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8850613179616655,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1814173408783972. Arrivals time: 0.03591881785541773 Scheduler time: 0.7087846989743412 Scheduler overhead time: 0.14647667109966278 Adapter cache time: 0.07097605615854263 Engine time: 0.14599151397123933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2058608098886907,
    "estimated_duration": 3599.9229616082025,
    "input_throughput": 644.1154504495652,
    "output_throughput": 556.9816413805313,
    "total_throughput": 1201.0970918300964,
    "itl": 20.08683151527486,
    "ttft": 3126.597623113755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7013386177993144,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2059335899539292. Arrivals time: 0.036711764987558126 Scheduler time: 0.7263421644456685 Scheduler overhead time: 0.14918662328273058 Adapter cache time: 0.07192778633907437 Engine time: 0.14815029315650463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.207112945150584,
    "estimated_duration": 3599.924570654369,
    "input_throughput": 644.1151625514507,
    "output_throughput": 556.9813924283221,
    "total_throughput": 1201.0965549797727,
    "itl": 20.088572648421735,
    "ttft": 3126.742747511421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9063137078657706,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2071996708400548. Arrivals time: 0.036199483089149 Scheduler time: 0.7321046036668122 Scheduler overhead time: 0.14756380440667272 Adapter cache time: 0.07195812929421663 Engine time: 0.1465075919404626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0421751732937992,
    "estimated_duration": 3598.5545183804247,
    "input_throughput": 458.97762325505875,
    "output_throughput": 415.03609084466007,
    "total_throughput": 874.0137140997189,
    "itl": 19.54855519905297,
    "ttft": 3197.0380707709824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4889560280834244,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0422485461458564. Arrivals time: 0.03038940392434597 Scheduler time: 0.5741680320352316 Scheduler overhead time: 0.14827262610197067 Adapter cache time: 0.0641469107940793 Engine time: 0.1507401168346405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0369017319753766,
    "estimated_duration": 3598.5651983053926,
    "input_throughput": 458.97626108810937,
    "output_throughput": 415.0348590886504,
    "total_throughput": 874.0111201767598,
    "itl": 19.549381833087605,
    "ttft": 3196.9882344901507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.71878118288471,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0369941820390522. Arrivals time: 0.030397913418710232 Scheduler time: 0.5697411275468767 Scheduler overhead time: 0.14825741667300463 Adapter cache time: 0.06465245177969337 Engine time: 0.14908011350780725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.038921299856156,
    "estimated_duration": 3598.5523259873635,
    "input_throughput": 458.9779028839943,
    "output_throughput": 415.0363437025216,
    "total_throughput": 874.0142465865159,
    "itl": 19.549201099296067,
    "ttft": 3197.0380894369123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.725582335945168,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0390123650431633. Arrivals time: 0.03066999325528741 Scheduler time: 0.5714436019770801 Scheduler overhead time: 0.14831961691379547 Adapter cache time: 0.0648090410977602 Engine time: 0.14873576955869794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.042848514392972,
    "estimated_duration": 3598.5561206111906,
    "input_throughput": 458.9774188986324,
    "output_throughput": 415.03590605287934,
    "total_throughput": 874.0133249515118,
    "itl": 19.548555606792554,
    "ttft": 3197.044040194257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5564389583980254,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.042919003404677. Arrivals time: 0.03068322828039527 Scheduler time: 0.5726274959743023 Scheduler overhead time: 0.1504253218881786 Adapter cache time: 0.06480773072689772 Engine time: 0.1491338205523789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0474841590039432,
    "estimated_duration": 3598.5579981018464,
    "input_throughput": 458.97717943443155,
    "output_throughput": 415.03568951446704,
    "total_throughput": 874.0128689488986,
    "itl": 19.550357807277805,
    "ttft": 3197.0499855119388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.774500558860601,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0475852182134986. Arrivals time: 0.030262884218245745 Scheduler time: 0.5764781199395657 Scheduler overhead time: 0.15219477424398065 Adapter cache time: 0.06477588275447488 Engine time: 0.1475642193108797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0376272518187761,
    "estimated_duration": 3598.557992355728,
    "input_throughput": 458.9771801673188,
    "output_throughput": 415.0356901771892,
    "total_throughput": 874.0128703445081,
    "itl": 19.54795567314316,
    "ttft": 3197.0382121423986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.408657336188396,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0377101399935782. Arrivals time: 0.030645671766251326 Scheduler time: 0.5676864786073565 Scheduler overhead time: 0.1509211715310812 Adapter cache time: 0.06469072587788105 Engine time: 0.1484816838055849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0598314641974866,
    "estimated_duration": 3598.5601993171526,
    "input_throughput": 458.9768986811479,
    "output_throughput": 415.0354356399001,
    "total_throughput": 874.0123343210479,
    "itl": 19.55008117273913,
    "ttft": 3197.017207860512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.817522939704413,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.059897897299379. Arrivals time: 0.031187550630420446 Scheduler time: 0.5864412849768996 Scheduler overhead time: 0.15078124403953552 Adapter cache time: 0.06487722368910909 Engine time: 0.1514065433293581 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0069176219403744,
    "estimated_duration": 3599.9969782974053,
    "input_throughput": 426.81369158445534,
    "output_throughput": 387.7303254460362,
    "total_throughput": 814.5440170304915,
    "itl": 19.198716666053244,
    "ttft": 5716.671409377226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1300994697772344,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0070060677826405. Arrivals time: 0.029708505608141422 Scheduler time: 0.5398848000913858 Scheduler overhead time: 0.14939229097217321 Adapter cache time: 0.06118655717000365 Engine time: 0.151316927280277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.996849121991545,
    "estimated_duration": 3600.003107847938,
    "input_throughput": 426.812964869502,
    "output_throughput": 387.72966527643314,
    "total_throughput": 814.5426301459352,
    "itl": 19.199393165393744,
    "ttft": 5716.57418692847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2649428985500752,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9969158289022744. Arrivals time: 0.02945621870458126 Scheduler time: 0.5331512093544006 Scheduler overhead time: 0.14907448319718242 Adapter cache time: 0.060900965705513954 Engine time: 0.14928987389430404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0239476719871163,
    "estimated_duration": 3600.005475406086,
    "input_throughput": 426.812684174231,
    "output_throughput": 387.729410284452,
    "total_throughput": 814.542094458683,
    "itl": 19.19910118145821,
    "ttft": 5716.6757816729105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2700504912808555,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0240345117636025. Arrivals time: 0.029467275831848383 Scheduler time: 0.5554955247789621 Scheduler overhead time: 0.150903956964612 Adapter cache time: 0.06126122456043959 Engine time: 0.1511384374462068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9940005508251488,
    "estimated_duration": 3600.000392730724,
    "input_throughput": 426.8132867714747,
    "output_throughput": 387.7299577018147,
    "total_throughput": 814.5432444732894,
    "itl": 19.198569201503428,
    "ttft": 5716.559105503621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.16892299871657,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9940609657205641. Arrivals time: 0.029298383742570877 Scheduler time: 0.5326388706453145 Scheduler overhead time: 0.14891195390373468 Adapter cache time: 0.06029177317395806 Engine time: 0.14780033472925425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0003410652279854,
    "estimated_duration": 3599.998998348168,
    "input_throughput": 426.8134520884656,
    "output_throughput": 387.7301078807147,
    "total_throughput": 814.5435599691804,
    "itl": 19.19929115967805,
    "ttft": 5716.6910871401515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2996026310883475,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.000431061256677. Arrivals time: 0.02918845135718584 Scheduler time: 0.5373525749891996 Scheduler overhead time: 0.14875152939930558 Adapter cache time: 0.06104171788319945 Engine time: 0.1485662627965212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.016384658869356,
    "estimated_duration": 3600.0083745689894,
    "input_throughput": 426.812340452947,
    "output_throughput": 387.72909803775536,
    "total_throughput": 814.5414384907024,
    "itl": 19.197863672219913,
    "ttft": 5716.648712293058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0810750052518774,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0164464418776333. Arrivals time: 0.029509572312235832 Scheduler time: 0.5493330806493759 Scheduler overhead time: 0.1530629345215857 Adapter cache time: 0.06128415744751692 Engine time: 0.1478186845779419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0194284562021494,
    "estimated_duration": 3600.0061468259496,
    "input_throughput": 426.8126045714463,
    "output_throughput": 387.7293379709011,
    "total_throughput": 814.5419425423473,
    "itl": 19.200265575327307,
    "ttft": 5716.681411118057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 696,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3266396951675477,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0195039510726929. Arrivals time: 0.029710146598517895 Scheduler time: 0.5516952415928245 Scheduler overhead time: 0.14963269140571356 Adapter cache time: 0.06123877177014947 Engine time: 0.15201868349686265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9340912722982466,
    "estimated_duration": 3599.437692384946,
    "input_throughput": 359.52837931819965,
    "output_throughput": 326.2873538510462,
    "total_throughput": 685.8157331692458,
    "itl": 18.929299864417136,
    "ttft": 6749.164534800695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6679658204433727,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9341608532704413. Arrivals time: 0.027172934263944626 Scheduler time: 0.4748597932048142 Scheduler overhead time: 0.14948821067810059 Adapter cache time: 0.055391811300069094 Engine time: 0.15105868224054575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9350692750886083,
    "estimated_duration": 3599.4439350418897,
    "input_throughput": 359.52775577401496,
    "output_throughput": 326.2867879580772,
    "total_throughput": 685.8145437320921,
    "itl": 18.92986445844357,
    "ttft": 6749.071085507372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.775037344086454,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9351439783349633. Arrivals time: 0.026979669462889433 Scheduler time: 0.47555056773126125 Scheduler overhead time: 0.1500646248459816 Adapter cache time: 0.05543534504249692 Engine time: 0.15109643852338195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9423538842238486,
    "estimated_duration": 3599.444549729131,
    "input_throughput": 359.5276943764518,
    "output_throughput": 326.28673223716726,
    "total_throughput": 685.814426613619,
    "itl": 18.92985512344081,
    "ttft": 6749.05995759869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.778777880631398,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9425619579851627. Arrivals time: 0.027797271963208914 Scheduler time: 0.4795608217827976 Scheduler overhead time: 0.150198707357049 Adapter cache time: 0.055743268225342035 Engine time: 0.15276107797399163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9432539297267795,
    "estimated_duration": 3599.4390461236526,
    "input_throughput": 359.52824410060686,
    "output_throughput": 326.28723113530776,
    "total_throughput": 685.8154752359146,
    "itl": 18.929347259640725,
    "ttft": 6749.26649904919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.693318280398369,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9433256699703634. Arrivals time: 0.02755863405764103 Scheduler time: 0.48245502542704344 Scheduler overhead time: 0.14989164704456925 Adapter cache time: 0.055420930963009596 Engine time: 0.15206493576988578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9370825900696218,
    "estimated_duration": 3599.425267333905,
    "input_throughput": 359.52962039368583,
    "output_throughput": 326.28848018003606,
    "total_throughput": 685.818100573722,
    "itl": 18.929954296330806,
    "ttft": 6749.139524599976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.803928637914363,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9371459959074855. Arrivals time: 0.027129958849400282 Scheduler time: 0.47564133582636714 Scheduler overhead time: 0.1503309989348054 Adapter cache time: 0.05546705238521099 Engine time: 0.15194127708673477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.926885252352804,
    "estimated_duration": 3599.434650326502,
    "input_throughput": 359.52868317323475,
    "output_throughput": 326.2876296124633,
    "total_throughput": 685.8163127856981,
    "itl": 18.9289707384035,
    "ttft": 6749.017699368358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6295774107216647,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9271276923827827. Arrivals time: 0.027210148982703686 Scheduler time: 0.46883927611634135 Scheduler overhead time: 0.1493703774176538 Adapter cache time: 0.055400487035512924 Engine time: 0.1501508024521172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9276741971261799,
    "estimated_duration": 3599.4261974755254,
    "input_throughput": 359.5295274862485,
    "output_throughput": 326.2883958625702,
    "total_throughput": 685.8179233488187,
    "itl": 18.930057929238963,
    "ttft": 6749.249677441447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 545,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8235462285950756,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9277321919798851. Arrivals time: 0.027065080124884844 Scheduler time: 0.4697125214152038 Scheduler overhead time: 0.14980388106778264 Adapter cache time: 0.05462290672585368 Engine time: 0.15072065265849233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7860311949625611,
    "estimated_duration": 3598.357396755406,
    "input_throughput": 219.7069142472784,
    "output_throughput": 202.52991007984014,
    "total_throughput": 422.23682432711854,
    "itl": 18.374353004455614,
    "ttft": 3306.322665521546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7995667934324857,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.786111940164119. Arrivals time: 0.02263034228235483 Scheduler time: 0.34056725492700934 Scheduler overhead time: 0.15032121958211064 Adapter cache time: 0.0440981169231236 Engine time: 0.1520410319790244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7841165577992797,
    "estimated_duration": 3598.359006344543,
    "input_throughput": 219.70681596974083,
    "output_throughput": 202.5298194857825,
    "total_throughput": 422.23663545552336,
    "itl": 18.37552322190169,
    "ttft": 3306.3177994755442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9203619148233042,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7842158759012818. Arrivals time: 0.02227155538275838 Scheduler time: 0.3400564994663 Scheduler overhead time: 0.14974942430853844 Adapter cache time: 0.04423386789858341 Engine time: 0.15135485911741853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7987609030678868,
    "estimated_duration": 3598.3592198802467,
    "input_throughput": 219.70680293178472,
    "output_throughput": 202.52980746715266,
    "total_throughput": 422.2366103989374,
    "itl": 18.37558914084613,
    "ttft": 3306.343028570175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.923476338405174,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7988179512321949. Arrivals time: 0.022977581713348627 Scheduler time: 0.35256649320945144 Scheduler overhead time: 0.1502865799702704 Adapter cache time: 0.043967445846647024 Engine time: 0.15240698913112283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.7977169640362263,
    "estimated_duration": 3598.3577772919753,
    "input_throughput": 219.70689101264736,
    "output_throughput": 202.52988866172612,
    "total_throughput": 422.23677967437345,
    "itl": 18.374486485975996,
    "ttft": 3306.2907283646396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8365998745430154,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7977943262085319. Arrivals time: 0.022332926280796528 Scheduler time: 0.3493767352774739 Scheduler overhead time: 0.15125521644949913 Adapter cache time: 0.04457155708223581 Engine time: 0.15340702841058373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7921208590269089,
    "estimated_duration": 3598.3596036748304,
    "input_throughput": 219.70677949825105,
    "output_throughput": 202.5297858656865,
    "total_throughput": 422.2365653639376,
    "itl": 18.375693585059587,
    "ttft": 3306.37807425495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.949255864620212,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7922301320359111. Arrivals time: 0.022401354741305113 Scheduler time: 0.3457499179057777 Scheduler overhead time: 0.15180817944929004 Adapter cache time: 0.04408663883805275 Engine time: 0.15195473609492183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7795044728554785,
    "estimated_duration": 3598.3562833077667,
    "input_throughput": 219.7069822316929,
    "output_throughput": 202.5299727491348,
    "total_throughput": 422.2369549808277,
    "itl": 18.373995111027316,
    "ttft": 3306.3297599812054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7581495734024537,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7795618828386068. Arrivals time: 0.022077057976275682 Scheduler time: 0.33725403854623437 Scheduler overhead time: 0.14927526423707604 Adapter cache time: 0.04425217118114233 Engine time: 0.1507625561207533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7798745753243566,
    "estimated_duration": 3598.359982569495,
    "input_throughput": 219.70675636389902,
    "output_throughput": 202.52976454001157,
    "total_throughput": 422.2365209039106,
    "itl": 18.376261169504392,
    "ttft": 3306.39234248803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.973400591611857,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7799521810375154. Arrivals time: 0.022424721159040928 Scheduler time: 0.338944086804986 Scheduler overhead time: 0.14872011775150895 Adapter cache time: 0.04373079026117921 Engine time: 0.14972778595983982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.182769870851189,
    "estimated_duration": 3600.106345612191,
    "input_throughput": 4767.585830046175,
    "output_throughput": 4188.792650078135,
    "total_throughput": 8956.378480124311,
    "itl": 204.48437611838153,
    "ttft": 2162726.8888375396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 863203,
    "finished_requests": 69430,
    "scheduler_time": 42.328508725259624
}
#Debug simulation 
Total elapsed time: 5.182868395000696. Arrivals time: 0.3462735735811293 Scheduler time: 4.7533427104353905 Scheduler overhead time: 0.027528697159141302 Adapter cache time: 0.013994817156344652 Engine time: 0.028764646034687757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.32005917513743,
    "estimated_duration": 3600.132320486898,
    "input_throughput": 4767.551432020334,
    "output_throughput": 4188.762428032228,
    "total_throughput": 8956.313860052562,
    "itl": 204.48496048187843,
    "ttft": 2162745.650816897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 863203,
    "finished_requests": 69430,
    "scheduler_time": 42.3283603960567
}
#Debug simulation 
Total elapsed time: 5.320175109896809. Arrivals time: 0.31998512614518404 Scheduler time: 4.916909892112017 Scheduler overhead time: 0.02753389161080122 Adapter cache time: 0.013962277676910162 Engine time: 0.0287587339989841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.146777036134154,
    "estimated_duration": 3600.126159541856,
    "input_throughput": 4612.612798578492,
    "output_throughput": 4058.268614080811,
    "total_throughput": 8670.881412659302,
    "itl": 172.30426353969074,
    "ttft": 2181546.059936137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 863203,
    "finished_requests": 67151,
    "scheduler_time": 36.657955272790986
}
#Debug simulation 
Total elapsed time: 5.146872096229345. Arrivals time: 0.33769829431548715 Scheduler time: 4.706154929008335 Scheduler overhead time: 0.03200630936771631 Adapter cache time: 0.02229597559198737 Engine time: 0.033522522542625666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.208042528945953,
    "estimated_duration": 3600.1148496377573,
    "input_throughput": 4767.574568274404,
    "output_throughput": 4188.782755504968,
    "total_throughput": 8956.357323779372,
    "itl": 204.4845207876693,
    "ttft": 2162733.0384746813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 863203,
    "finished_requests": 69430,
    "scheduler_time": 42.328459145608925
}
#Debug simulation 
Total elapsed time: 5.208143328782171. Arrivals time: 0.3466837154701352 Scheduler time: 4.777520647738129 Scheduler overhead time: 0.027629773132503033 Adapter cache time: 0.014059342909604311 Engine time: 0.029293568339198828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_128_slots_128_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.189372840803117,
    "estimated_duration": 3600.1315341747377,
    "input_throughput": 4612.605912413312,
    "output_throughput": 4058.262555495526,
    "total_throughput": 8670.868467908838,
    "itl": 172.30440359370544,
    "ttft": 2181549.910220555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42398110998794475,
    "arrivals": 863203,
    "finished_requests": 67151,
    "scheduler_time": 36.657922492856635
}
#Debug simulation 
Total elapsed time: 5.189503387082368. Arrivals time: 0.30439313873648643 Scheduler time: 4.782127991784364 Scheduler overhead time: 0.03208199515938759 Adapter cache time: 0.022269804496318102 Engine time: 0.033321121241897345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_128_slots_128_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_128_slots_128_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.5542239816859365,
    "estimated_duration": 3600.09738206661,
    "input_throughput": 4767.597700411991,
    "output_throughput": 4188.803079360975,
    "total_throughput": 8956.400779772966,
    "itl": 204.4841678953001,
    "ttft": 2162720.414323804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 863203,
    "finished_requests": 69430,
    "scheduler_time": 42.32856117315458
}
#Debug simulation 
Total elapsed time: 5.554321915842593. Arrivals time: 0.3481468725949526 Scheduler time: 5.123619566205889 Scheduler overhead time: 0.02730650221928954 Adapter cache time: 0.013844787608832121 Engine time: 0.028435190673917532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_128_slots_128_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_128_slots_128_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 8640, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640]
Prompts retrieved: 2592000 . Total input tokens: 577126872 . Total output tokens: 517998278
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.089748951140791,
    "estimated_duration": 3600.1369065949734,
    "input_throughput": 4612.599029103597,
    "output_throughput": 4058.2564994225377,
    "total_throughput": 8670.855528526134,
    "itl": 172.30451597371862,
    "ttft": 2181553.7633906305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4293885228037832,
    "arrivals": 863203,
    "finished_requests": 67151,
    "scheduler_time": 36.65788750027672
}
#Debug simulation 
Total elapsed time: 5.089847452938557. Arrivals time: 0.33805394172668457 Scheduler time: 4.649214392062277 Scheduler overhead time: 0.03191615780815482 Adapter cache time: 0.022137409076094627 Engine time: 0.033353421837091446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.284862676169723,
    "estimated_duration": 3600.003189896379,
    "input_throughput": 4868.952352374034,
    "output_throughput": 4286.21925761242,
    "total_throughput": 9155.171609986453,
    "itl": 199.87150396239502,
    "ttft": 2140673.710434065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 802767,
    "finished_requests": 70988,
    "scheduler_time": 43.36110888096344
}
#Debug simulation 
Total elapsed time: 5.285028272308409. Arrivals time: 0.25753982551395893 Scheduler time: 4.934511375613511 Scheduler overhead time: 0.028438309207558632 Adapter cache time: 0.021336165256798267 Engine time: 0.029846503399312496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.263646436855197,
    "estimated_duration": 3600.030444779375,
    "input_throughput": 4868.915490817246,
    "output_throughput": 4286.186807774521,
    "total_throughput": 9155.102298591768,
    "itl": 199.87163690294426,
    "ttft": 2140686.184797836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41786563513334835,
    "arrivals": 802767,
    "finished_requests": 70988,
    "scheduler_time": 43.360987167863925
}
#Debug simulation 
Total elapsed time: 5.263741302769631. Arrivals time: 0.3078376562334597 Scheduler time: 4.863770434632897 Scheduler overhead time: 0.027979130391031504 Adapter cache time: 0.021474367007613182 Engine time: 0.02946852659806609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.1779716070741415,
    "estimated_duration": 3600.1087166889492,
    "input_throughput": 4747.896617888952,
    "output_throughput": 4182.1592581924415,
    "total_throughput": 8930.055876081395,
    "itl": 168.10891951737761,
    "ttft": 2154534.2824770566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4185736971721064,
    "arrivals": 802767,
    "finished_requests": 69126,
    "scheduler_time": 37.93386537627993
}
#Debug simulation 
Total elapsed time: 5.178068624343723. Arrivals time: 0.2502145557664335 Scheduler time: 4.815607393626124 Scheduler overhead time: 0.03277137130498886 Adapter cache time: 0.02968281041830778 Engine time: 0.03434851113706827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 5.27787070767954,
    "estimated_duration": 3600.0129758560556,
    "input_throughput": 4868.939117040798,
    "output_throughput": 4286.207606329744,
    "total_throughput": 9155.14672337054,
    "itl": 199.87121148237873,
    "ttft": 2140673.501766548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 802767,
    "finished_requests": 70988,
    "scheduler_time": 43.36108784323729
}
#Debug simulation 
Total elapsed time: 5.2779712080955505. Arrivals time: 0.25625527277588844 Scheduler time: 4.928885510656983 Scheduler overhead time: 0.02810549968853593 Adapter cache time: 0.021579677239060402 Engine time: 0.029824659693986177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_128_slots_128_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 5.27303668204695,
    "estimated_duration": 3600.114088863336,
    "input_throughput": 4747.88953296665,
    "output_throughput": 4182.153017476649,
    "total_throughput": 8930.0425504433,
    "itl": 168.1090540379897,
    "ttft": 2154538.1626075874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879447,
    "arrivals": 802767,
    "finished_requests": 69126,
    "scheduler_time": 37.9338301378505
}
#Debug simulation 
Total elapsed time: 5.273138946387917. Arrivals time: 0.3012775434181094 Scheduler time: 4.859329936094582 Scheduler overhead time: 0.032806516624987125 Adapter cache time: 0.0296695320867002 Engine time: 0.03450307575985789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_128_slots_128_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_128_slots_128_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.239867453929037,
    "estimated_duration": 3600.2151060866863,
    "input_throughput": 4868.768527293087,
    "output_throughput": 4286.1200081938805,
    "total_throughput": 9154.888535486967,
    "itl": 199.87040029790384,
    "ttft": 2140704.330049799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 802767,
    "finished_requests": 70990,
    "scheduler_time": 43.36383472687646
}
#Debug simulation 
Total elapsed time: 5.239995991811156. Arrivals time: 0.256634836550802 Scheduler time: 4.891510348301381 Scheduler overhead time: 0.027919532265514135 Adapter cache time: 0.021385930478572845 Engine time: 0.029412120580673218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_128_slots_128_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_128_slots_128_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 4320, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320]
Prompts retrieved: 2410560 . Total input tokens: 536675938 . Total output tokens: 481710298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.140520330984145,
    "estimated_duration": 3600.1194598494494,
    "input_throughput": 4747.882449632601,
    "output_throughput": 4182.146778159863,
    "total_throughput": 8930.029227792464,
    "itl": 168.10914996261704,
    "ttft": 2154542.0479383743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378326,
    "arrivals": 802767,
    "finished_requests": 69126,
    "scheduler_time": 37.93379371114846
}
#Debug simulation 
Total elapsed time: 5.140616414137185. Arrivals time: 0.2460685232654214 Scheduler time: 4.782458425499499 Scheduler overhead time: 0.03268401464447379 Adapter cache time: 0.02964978525415063 Engine time: 0.0343039627186954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_128_slots_128_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_128_slots_128_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 5.707882496062666,
    "estimated_duration": 3600.1346180269047,
    "input_throughput": 5383.107315754038,
    "output_throughput": 4681.493829593804,
    "total_throughput": 10064.601145347842,
    "itl": 182.31026148160564,
    "ttft": 2087880.8439392801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 757465,
    "finished_requests": 77818,
    "scheduler_time": 47.20764891950378
}
#Debug simulation 
Total elapsed time: 5.708000182174146. Arrivals time: 0.27632482163608074 Scheduler time: 5.332314212340862 Scheduler overhead time: 0.030834740959107876 Adapter cache time: 0.021593788638710976 Engine time: 0.03241335181519389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_128_slots_128_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_128_slots_128_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [42 43 43]
Adapter prompts. [34560, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 1080, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 34560, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080]
Prompts retrieved: 2274480 . Total input tokens: 506350051 . Total output tokens: 454613738
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 5.75057755317539,
    "estimated_duration": 3600.0303036574855,
    "input_throughput": 5383.213296930022,
    "output_throughput": 4681.5822585929845,
    "total_throughput": 10064.795555523007,
    "itl": 182.30997680328161,
    "ttft": 2087880.0166952896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 757465,
    "finished_requests": 77817,
    "scheduler_time": 47.20616453952528
}
#Debug simulation 
Total elapsed time: 5.7506803763099015. Arrivals time: 0.26954005658626556 Scheduler time: 5.381723322439939 Scheduler overhead time: 0.030796011444181204 Adapter cache time: 0.021346050314605236 Engine time: 0.03271429240703583 
