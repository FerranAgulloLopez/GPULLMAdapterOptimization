INFO 06-01 00:47:01 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:02 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 25.462114204186946,
    "estimated_duration": 3600.034729956457,
    "input_throughput": 5230.572872897745,
    "output_throughput": 4555.217721524134,
    "total_throughput": 9785.790594421878,
    "itl": 43.93998482902994,
    "ttft": 315474.68091783125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8707375038089866,
    "arrivals": 78583,
    "finished_requests": 74800,
    "scheduler_time": 102.60808853318386
}
#Debug simulation 
Total elapsed time: 25.46229320485145. Arrivals time: 0.22416643938049674 Scheduler time: 24.928267890121788 Scheduler overhead time: 0.12196838296949863 Adapter cache time: 0.023544189054518938 Engine time: 0.11150273913517594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 26.578067551832646,
    "estimated_duration": 3600.0200974577333,
    "input_throughput": 5216.407267632061,
    "output_throughput": 4546.526285105598,
    "total_throughput": 9762.933552737659,
    "itl": 43.47673920321206,
    "ttft": 334975.9935380156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9360725734103537,
    "arrivals": 78583,
    "finished_requests": 74572,
    "scheduler_time": 105.80650761582297
}
#Debug simulation 
Total elapsed time: 26.578189567197114. Arrivals time: 0.2279582666233182 Scheduler time: 26.038230046629906 Scheduler overhead time: 0.12367894500494003 Adapter cache time: 0.02353794639930129 Engine time: 0.11191746592521667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 25.509477912914008,
    "estimated_duration": 3600.0426278364303,
    "input_throughput": 5241.512379352123,
    "output_throughput": 4558.0251947909865,
    "total_throughput": 9799.53757414311,
    "itl": 43.86526746758229,
    "ttft": 313731.8766857869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0811469145677686,
    "arrivals": 78583,
    "finished_requests": 74881,
    "scheduler_time": 103.05861528026584
}
#Debug simulation 
Total elapsed time: 25.509695589076728. Arrivals time: 0.21819832967594266 Scheduler time: 24.980094166006893 Scheduler overhead time: 0.12222820660099387 Adapter cache time: 0.02354659838601947 Engine time: 0.11290709627792239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 27.21857317816466,
    "estimated_duration": 3600.0164471362264,
    "input_throughput": 5229.151665397281,
    "output_throughput": 4560.116666427772,
    "total_throughput": 9789.268331825053,
    "itl": 43.55232295746648,
    "ttft": 330758.72164101107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7678260328178035,
    "arrivals": 78583,
    "finished_requests": 74750,
    "scheduler_time": 106.94425229353261
}
#Debug simulation 
Total elapsed time: 27.218736148439348. Arrivals time: 0.22781636752188206 Scheduler time: 26.68083763308823 Scheduler overhead time: 0.12258261162787676 Adapter cache time: 0.02316181594505906 Engine time: 0.11193324578925967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 27.21782994410023,
    "estimated_duration": 3600.027640847132,
    "input_throughput": 5232.112605548693,
    "output_throughput": 4559.510825349523,
    "total_throughput": 9791.623430898215,
    "itl": 43.56159219599154,
    "ttft": 329421.57707445783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9354148086532965,
    "arrivals": 78583,
    "finished_requests": 74783,
    "scheduler_time": 106.95492358795515
}
#Debug simulation 
Total elapsed time: 27.217937636189163. Arrivals time: 0.23028265265747905 Scheduler time: 26.675962771754712 Scheduler overhead time: 0.1227139225229621 Adapter cache time: 0.02326932270079851 Engine time: 0.11296397866681218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 25.227345822844654,
    "estimated_duration": 3600.0084284054215,
    "input_throughput": 5229.274145988177,
    "output_throughput": 4557.677385013117,
    "total_throughput": 9786.951531001294,
    "itl": 43.90910761218273,
    "ttft": 317537.69640517794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8255975286824926,
    "arrivals": 78583,
    "finished_requests": 74766,
    "scheduler_time": 102.74190980038254
}
#Debug simulation 
Total elapsed time: 25.227457548025995. Arrivals time: 0.22465828899294138 Scheduler time: 24.691462310496718 Scheduler overhead time: 0.12374615017324686 Adapter cache time: 0.02345149079337716 Engine time: 0.11155639868229628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 66, 66, 4320, 66, 1080, 1080, 1080, 66, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 66, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 66, 66, 1080, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 1080, 4320, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 1080, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66]
Prompts retrieved: 234972 . Total input tokens: 52388090 . Total output tokens: 46994386
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 27.102657875046134,
    "estimated_duration": 3599.990242534092,
    "input_throughput": 5229.1894510104985,
    "output_throughput": 4560.120137560216,
    "total_throughput": 9789.309588570715,
    "itl": 43.55250261250222,
    "ttft": 330810.1058302664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.967345428317814,
    "arrivals": 78583,
    "finished_requests": 74749,
    "scheduler_time": 106.94198999392042
}
#Debug simulation 
Total elapsed time: 27.10281904414296. Arrivals time: 0.22900809859856963 Scheduler time: 26.56261419504881 Scheduler overhead time: 0.1228846637532115 Adapter cache time: 0.023326691705733538 Engine time: 0.11229467345401645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 25.480004248209298,
    "estimated_duration": 3600.020449398503,
    "input_throughput": 5148.44714370908,
    "output_throughput": 4509.094942144622,
    "total_throughput": 9657.542085853702,
    "itl": 43.371547798755444,
    "ttft": 316152.2502552376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.726894579844142,
    "arrivals": 78101,
    "finished_requests": 74298,
    "scheduler_time": 101.57594583791173
}
#Debug simulation 
Total elapsed time: 25.48011137312278. Arrivals time: 0.22652682196348906 Scheduler time: 24.938133996911347 Scheduler overhead time: 0.1255929763428867 Adapter cache time: 0.02319257613271475 Engine time: 0.11368870176374912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 24.90951850032434,
    "estimated_duration": 3599.982224094629,
    "input_throughput": 5158.646305446824,
    "output_throughput": 4526.057348546426,
    "total_throughput": 9684.703653993249,
    "itl": 43.707221354013534,
    "ttft": 307981.87782521703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9662517886119963,
    "arrivals": 78101,
    "finished_requests": 74422,
    "scheduler_time": 100.70791594647268
}
#Debug simulation 
Total elapsed time: 24.909632290247828. Arrivals time: 0.21962832706049085 Scheduler time: 24.378089640755206 Scheduler overhead time: 0.12306810030713677 Adapter cache time: 0.023472069762647152 Engine time: 0.11259521916508675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 24.928063575178385,
    "estimated_duration": 3599.9886673533993,
    "input_throughput": 5158.637072503024,
    "output_throughput": 4526.049247810173,
    "total_throughput": 9684.686320313196,
    "itl": 43.70800113075866,
    "ttft": 307982.7835065183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9709223238192246,
    "arrivals": 78101,
    "finished_requests": 74422,
    "scheduler_time": 100.70828812987062
}
#Debug simulation 
Total elapsed time: 24.928205368109047. Arrivals time: 0.21474531991407275 Scheduler time: 24.397695302963257 Scheduler overhead time: 0.1255270391702652 Adapter cache time: 0.023594381753355265 Engine time: 0.11329065635800362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 24.900159129872918,
    "estimated_duration": 3599.9937667981108,
    "input_throughput": 5158.629765216889,
    "output_throughput": 4526.0428365941,
    "total_throughput": 9684.672601810988,
    "itl": 43.70618075524118,
    "ttft": 307978.5852906046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8440817883982983,
    "arrivals": 78101,
    "finished_requests": 74422,
    "scheduler_time": 100.70922966667756
}
#Debug simulation 
Total elapsed time: 24.900261969771236. Arrivals time: 0.22119997814297676 Scheduler time: 24.36497944360599 Scheduler overhead time: 0.12464010249823332 Adapter cache time: 0.023560498375445604 Engine time: 0.11273836204782128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 24.937951173167676,
    "estimated_duration": 3599.9808428715846,
    "input_throughput": 5158.648284691011,
    "output_throughput": 4526.059085081974,
    "total_throughput": 9684.707369772985,
    "itl": 43.70816319305013,
    "ttft": 307980.4131459705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0085227059572954,
    "arrivals": 78101,
    "finished_requests": 74422,
    "scheduler_time": 100.70654860019074
}
#Debug simulation 
Total elapsed time: 24.938094128854573. Arrivals time: 0.2277126470580697 Scheduler time: 24.397808424197137 Scheduler overhead time: 0.12313745589926839 Adapter cache time: 0.023714174050837755 Engine time: 0.11255733016878366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 26.048978195060045,
    "estimated_duration": 3600.0139794070406,
    "input_throughput": 5106.406282074464,
    "output_throughput": 4472.248466838416,
    "total_throughput": 9578.654748912879,
    "itl": 42.87520513265055,
    "ttft": 344787.1346424292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6432044606934664,
    "arrivals": 78101,
    "finished_requests": 73730,
    "scheduler_time": 102.8283405282326
}
#Debug simulation 
Total elapsed time: 26.04910153709352. Arrivals time: 0.21940719243139029 Scheduler time: 25.512420419603586 Scheduler overhead time: 0.12395668867975473 Adapter cache time: 0.025242795702069998 Engine time: 0.11441293964162469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 1080, 4320, 4320, 33, 33, 4320, 33, 1080, 1080, 1080, 33, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 33, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 33, 33, 1080, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 1080, 4320, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 1080, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33]
Prompts retrieved: 233586 . Total input tokens: 52087403 . Total output tokens: 46722705
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 24.91879118513316,
    "estimated_duration": 3600.0009965002387,
    "input_throughput": 5158.619405398481,
    "output_throughput": 4526.033747168414,
    "total_throughput": 9684.653152566894,
    "itl": 43.710178622188806,
    "ttft": 307983.57194202644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.048260902464421,
    "arrivals": 78101,
    "finished_requests": 74422,
    "scheduler_time": 100.70751096905087
}
#Debug simulation 
Total elapsed time: 24.91888680541888. Arrivals time: 0.22140867682173848 Scheduler time: 24.381305295508355 Scheduler overhead time: 0.1263166661374271 Adapter cache time: 0.023670990485697985 Engine time: 0.11315710470080376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 22.433614430949092,
    "estimated_duration": 3599.883917959564,
    "input_throughput": 4837.935999300638,
    "output_throughput": 4332.308584227849,
    "total_throughput": 9170.244583528487,
    "itl": 42.052058555643,
    "ttft": 297184.8880057089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1051,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2165726188734,
    "arrivals": 73678,
    "finished_requests": 70421,
    "scheduler_time": 95.82118034597124
}
#Debug simulation 
Total elapsed time: 22.433737467974424. Arrivals time: 0.20266483537852764 Scheduler time: 21.910027435980737 Scheduler overhead time: 0.12578889820724726 Adapter cache time: 0.024717714171856642 Engine time: 0.1159067265689373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 23.69693173794076,
    "estimated_duration": 3599.8538189265637,
    "input_throughput": 4800.557708521924,
    "output_throughput": 4306.315139380453,
    "total_throughput": 9106.872847902376,
    "itl": 42.87884186536552,
    "ttft": 326491.1692394771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.265573422596795,
    "arrivals": 73678,
    "finished_requests": 69928,
    "scheduler_time": 98.11267053052428
}
#Debug simulation 
Total elapsed time: 23.697074205148965. Arrivals time: 0.2137296451255679 Scheduler time: 23.162376914639026 Scheduler overhead time: 0.12633370934054255 Adapter cache time: 0.024566227570176125 Engine time: 0.11530278949066997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 24.063834195956588,
    "estimated_duration": 3599.8258728394394,
    "input_throughput": 4808.2217338882965,
    "output_throughput": 4315.122049986121,
    "total_throughput": 9123.343783874418,
    "itl": 43.062086846252726,
    "ttft": 324495.4445263774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2292427214793515,
    "arrivals": 73678,
    "finished_requests": 70026,
    "scheduler_time": 98.95069921754761
}
#Debug simulation 
Total elapsed time: 24.063922873698175. Arrivals time: 0.21315666986629367 Scheduler time: 23.526924974750727 Scheduler overhead time: 0.12872273894026875 Adapter cache time: 0.02461807895451784 Engine time: 0.1153052025474608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 23.920604415237904,
    "estimated_duration": 3599.843466291458,
    "input_throughput": 4808.1982347503035,
    "output_throughput": 4315.10096076559,
    "total_throughput": 9123.299195515892,
    "itl": 43.05943559386659,
    "ttft": 324491.6766548966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0885975511301913,
    "arrivals": 73678,
    "finished_requests": 70026,
    "scheduler_time": 98.95243824142565
}
#Debug simulation 
Total elapsed time: 23.920728251338005. Arrivals time: 0.20748922554776073 Scheduler time: 23.38877848442644 Scheduler overhead time: 0.1300857444293797 Adapter cache time: 0.024503113236278296 Engine time: 0.11526177125051618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 22.88258660817519,
    "estimated_duration": 3599.8333611732146,
    "input_throughput": 4817.620500730039,
    "output_throughput": 4319.477720194339,
    "total_throughput": 9137.098220924378,
    "itl": 42.32764939857475,
    "ttft": 313710.97338062193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4464524479396657,
    "arrivals": 73678,
    "finished_requests": 70124,
    "scheduler_time": 96.657204027912
}
#Debug simulation 
Total elapsed time: 22.88267651712522. Arrivals time: 0.21047260472550988 Scheduler time: 22.35105083230883 Scheduler overhead time: 0.1266124490648508 Adapter cache time: 0.024618645198643208 Engine time: 0.1156442929059267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 22.585088656749576,
    "estimated_duration": 3599.8656696129515,
    "input_throughput": 4841.140086728224,
    "output_throughput": 4337.481293205815,
    "total_throughput": 9178.621379934038,
    "itl": 42.946886483372396,
    "ttft": 293468.1175030284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1057,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1604831617115243,
    "arrivals": 73678,
    "finished_requests": 70469,
    "scheduler_time": 95.36419634631355
}
#Debug simulation 
Total elapsed time: 22.58521577483043. Arrivals time: 0.20396075351163745 Scheduler time: 22.061137756332755 Scheduler overhead time: 0.1262609250843525 Adapter cache time: 0.024577321484684944 Engine time: 0.11493583163246512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 270, 270, 4320, 270, 540, 540, 540, 270, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 540, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 4320, 270, 540, 540, 270, 540, 270, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 270, 540, 4320, 4320, 540, 270, 270, 270, 4320, 540, 540, 540, 540, 4320, 540, 4320, 270, 270, 540, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 4320, 4320, 540, 540, 270, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 270, 4320, 270, 270, 4320, 540, 4320, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 540, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270]
Prompts retrieved: 220320 . Total input tokens: 49124623 . Total output tokens: 44066949
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 23.419387590140104,
    "estimated_duration": 3599.841629514771,
    "input_throughput": 4824.675023923503,
    "output_throughput": 4323.780766460558,
    "total_throughput": 9148.455790384061,
    "itl": 42.71515578864805,
    "ttft": 310983.14886718034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3855538993329226,
    "arrivals": 73678,
    "finished_requests": 70243,
    "scheduler_time": 97.72670797445947
}
#Debug simulation 
Total elapsed time: 23.419483983889222. Arrivals time: 0.21396108623594046 Scheduler time: 22.88412177748978 Scheduler overhead time: 0.1272698543034494 Adapter cache time: 0.02459496445953846 Engine time: 0.115375189576298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 20.072347849607468,
    "estimated_duration": 3600.031540105158,
    "input_throughput": 4786.042513254401,
    "output_throughput": 4202.264294483958,
    "total_throughput": 8988.30680773836,
    "itl": 40.13045265683777,
    "ttft": 264117.06013139215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4889560280834244,
    "arrivals": 71837,
    "finished_requests": 68988,
    "scheduler_time": 87.4974004384903
}
#Debug simulation 
Total elapsed time: 20.072461867704988. Arrivals time: 0.20230393391102552 Scheduler time: 19.543744588270783 Scheduler overhead time: 0.12925763381645083 Adapter cache time: 0.025372070726007223 Engine time: 0.11643296107649803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.677891948726028,
    "estimated_duration": 3600.0108533544058,
    "input_throughput": 4791.555554319281,
    "output_throughput": 4209.805085970395,
    "total_throughput": 9001.360640289677,
    "itl": 40.04286652494422,
    "ttft": 257223.44917576516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7981758179469094,
    "arrivals": 71837,
    "finished_requests": 69075,
    "scheduler_time": 86.61881798461266
}
#Debug simulation 
Total elapsed time: 19.678007239941508. Arrivals time: 0.20119753759354353 Scheduler time: 19.15095171984285 Scheduler overhead time: 0.12936739344149828 Adapter cache time: 0.0254430347122252 Engine time: 0.11589963780716062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.681747214868665,
    "estimated_duration": 3600.0388610699556,
    "input_throughput": 4786.292499875648,
    "output_throughput": 4205.226827885017,
    "total_throughput": 8991.519327760665,
    "itl": 40.55126754361433,
    "ttft": 260349.88165966503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7779800685680853,
    "arrivals": 71837,
    "finished_requests": 69027,
    "scheduler_time": 86.915825709512
}
#Debug simulation 
Total elapsed time: 19.681842986959964. Arrivals time: 0.19503388227894902 Scheduler time: 19.16408075718209 Scheduler overhead time: 0.12756726564839482 Adapter cache time: 0.025456910021603107 Engine time: 0.11497369408607483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 19.756006507202983,
    "estimated_duration": 3600.0175150024556,
    "input_throughput": 4786.320879882787,
    "output_throughput": 4205.251762501403,
    "total_throughput": 8991.572642384192,
    "itl": 40.550243039581275,
    "ttft": 260347.35216395807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.61490324139591,
    "arrivals": 71837,
    "finished_requests": 69027,
    "scheduler_time": 86.91656203403988
}
#Debug simulation 
Total elapsed time: 19.75612223893404. Arrivals time: 0.19623492006212473 Scheduler time: 19.23533848207444 Scheduler overhead time: 0.12813611049205065 Adapter cache time: 0.02544969553127885 Engine time: 0.11575451586395502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 20.860667747911066,
    "estimated_duration": 3600.0143594232477,
    "input_throughput": 4775.078453507624,
    "output_throughput": 4193.606606174391,
    "total_throughput": 8968.685059682015,
    "itl": 40.7285896250976,
    "ttft": 276634.3765618948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1099,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6413822630047803,
    "arrivals": 71837,
    "finished_requests": 68831,
    "scheduler_time": 89.20946905086385
}
#Debug simulation 
Total elapsed time: 20.860761234071106. Arrivals time: 0.203554374165833 Scheduler time: 20.331530910450965 Scheduler overhead time: 0.12944205524399877 Adapter cache time: 0.02512852055951953 Engine time: 0.11608803318813443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 20.033722158987075,
    "estimated_duration": 3600.002456089968,
    "input_throughput": 4785.958679237473,
    "output_throughput": 4202.280188561607,
    "total_throughput": 8988.23886779908,
    "itl": 40.12981715620893,
    "ttft": 264115.6503918249,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.408657336188396,
    "arrivals": 71837,
    "finished_requests": 68987,
    "scheduler_time": 87.49732137179441
}
#Debug simulation 
Total elapsed time: 20.033867130056024. Arrivals time: 0.2052744901739061 Scheduler time: 19.50363785866648 Scheduler overhead time: 0.12800935795530677 Adapter cache time: 0.025364774279296398 Engine time: 0.11635429272428155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 135, 135, 4320, 135, 540, 540, 540, 135, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 540, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 4320, 135, 540, 540, 135, 540, 135, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 135, 540, 4320, 4320, 540, 135, 135, 135, 4320, 540, 540, 540, 540, 4320, 540, 4320, 135, 135, 540, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 4320, 4320, 540, 540, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 540, 4320, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 540, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135]
Prompts retrieved: 214650 . Total input tokens: 47843602 . Total output tokens: 42937940
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.761028012260795,
    "estimated_duration": 3600.036967849665,
    "input_throughput": 4791.520796605423,
    "output_throughput": 4209.774548246493,
    "total_throughput": 9001.295344851917,
    "itl": 40.044706765200004,
    "ttft": 257226.1488670025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9030684266612523,
    "arrivals": 71837,
    "finished_requests": 69075,
    "scheduler_time": 86.61934478528094
}
#Debug simulation 
Total elapsed time: 19.761106425896287. Arrivals time: 0.19579807110130787 Scheduler time: 19.23740705382079 Scheduler overhead time: 0.13035056460648775 Adapter cache time: 0.02555073844268918 Engine time: 0.1165093001909554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 19.327490409836173,
    "estimated_duration": 3600.0050541948335,
    "input_throughput": 4713.146160789173,
    "output_throughput": 4204.774652291577,
    "total_throughput": 8917.920813080751,
    "itl": 40.60315790978283,
    "ttft": 242206.09439913495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.406322858997237,
    "arrivals": 70891,
    "finished_requests": 68389,
    "scheduler_time": 84.61925217553822
}
#Debug simulation 
Total elapsed time: 19.327631559688598. Arrivals time: 0.19416002137586474 Scheduler time: 18.80976733705029 Scheduler overhead time: 0.12753837183117867 Adapter cache time: 0.02524828491732478 Engine time: 0.11595102399587631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.436819854658097,
    "estimated_duration": 3600.012508069888,
    "input_throughput": 4699.4581163470675,
    "output_throughput": 4184.359350483557,
    "total_throughput": 8883.817466830626,
    "itl": 40.59929319517538,
    "ttft": 252332.33131682524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.605419037810067,
    "arrivals": 70891,
    "finished_requests": 68198,
    "scheduler_time": 84.88058181044528
}
#Debug simulation 
Total elapsed time: 19.436913998797536. Arrivals time: 0.19156594295054674 Scheduler time: 18.916062087751925 Scheduler overhead time: 0.13054523756727576 Adapter cache time: 0.02517718682065606 Engine time: 0.11831778846681118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.67782351700589,
    "estimated_duration": 3600.041895674376,
    "input_throughput": 4715.981783545231,
    "output_throughput": 4202.302761581075,
    "total_throughput": 8918.284545126307,
    "itl": 40.513695910898576,
    "ttft": 243130.26850523642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5886405705473834,
    "arrivals": 70891,
    "finished_requests": 68412,
    "scheduler_time": 85.29460363553613
}
#Debug simulation 
Total elapsed time: 19.677936784923077. Arrivals time: 0.19809924159199 Scheduler time: 19.15499059855938 Scheduler overhead time: 0.12836654391139746 Adapter cache time: 0.025298796128481627 Engine time: 0.11607154458761215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 19.859816601034254,
    "estimated_duration": 3600.0206219080674,
    "input_throughput": 4727.923750330853,
    "output_throughput": 4212.378925752513,
    "total_throughput": 8940.302676083367,
    "itl": 40.810154644627495,
    "ttft": 237389.04959396363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.393750456517991,
    "arrivals": 70891,
    "finished_requests": 68567,
    "scheduler_time": 85.9792106021298
}
#Debug simulation 
Total elapsed time: 19.85992327099666. Arrivals time: 0.19968854170292616 Scheduler time: 19.337368764914572 Scheduler overhead time: 0.12771530961617827 Adapter cache time: 0.024902131874114275 Engine time: 0.1154202800244093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 19.526105009950697,
    "estimated_duration": 3600.0322105252862,
    "input_throughput": 4712.795610660504,
    "output_throughput": 4198.211325946647,
    "total_throughput": 8911.006936607151,
    "itl": 40.14338230022113,
    "ttft": 243453.8909144888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.674766939021647,
    "arrivals": 70891,
    "finished_requests": 68364,
    "scheduler_time": 84.61147659011179
}
#Debug simulation 
Total elapsed time: 19.526183672249317. Arrivals time: 0.19392435904592276 Scheduler time: 19.002314587123692 Scheduler overhead time: 0.13312380900606513 Adapter cache time: 0.025176596827805042 Engine time: 0.11667161621153355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 19.47947804071009,
    "estimated_duration": 3600.00704709909,
    "input_throughput": 4703.606348116662,
    "output_throughput": 4193.402346855039,
    "total_throughput": 8897.0086949717,
    "itl": 40.599594142312846,
    "ttft": 251284.35172653658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3010155255719216,
    "arrivals": 70891,
    "finished_requests": 68223,
    "scheduler_time": 84.89949885121577
}
#Debug simulation 
Total elapsed time: 19.479635979048908. Arrivals time: 0.19907600339502096 Scheduler time: 18.956093763932586 Scheduler overhead time: 0.12853964185342193 Adapter cache time: 0.02522076480090618 Engine time: 0.11579404631629586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 66, 66, 4320, 66, 540, 540, 540, 66, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 540, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 4320, 66, 540, 540, 66, 540, 66, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 66, 540, 4320, 4320, 540, 66, 66, 66, 4320, 540, 540, 540, 540, 4320, 540, 4320, 66, 66, 540, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 4320, 4320, 540, 540, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 540, 4320, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 540, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66]
Prompts retrieved: 211752 . Total input tokens: 47203189 . Total output tokens: 42355653
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.43981052422896,
    "estimated_duration": 3600.044444315843,
    "input_throughput": 4712.7795954819885,
    "output_throughput": 4198.197059445533,
    "total_throughput": 8910.976654927521,
    "itl": 40.15791445388401,
    "ttft": 243550.6901029631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7255568828434273,
    "arrivals": 70891,
    "finished_requests": 68364,
    "scheduler_time": 84.61293000453877
}
#Debug simulation 
Total elapsed time: 19.43989288015291. Arrivals time: 0.19481741823256016 Scheduler time: 18.920089746825397 Scheduler overhead time: 0.12779339822009206 Adapter cache time: 0.025191420689225197 Engine time: 0.1166253350675106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 17.909284309018403,
    "estimated_duration": 3600.014349668498,
    "input_throughput": 4659.931425424673,
    "output_throughput": 4153.367889041011,
    "total_throughput": 8813.299314465685,
    "itl": 39.11311014121073,
    "ttft": 234124.26482650873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4828350525955587,
    "arrivals": 70422,
    "finished_requests": 67836,
    "scheduler_time": 79.34503048297671
}
#Debug simulation 
Total elapsed time: 17.909424254205078. Arrivals time: 0.19250534661114216 Scheduler time: 17.390365842264146 Scheduler overhead time: 0.1284527569077909 Adapter cache time: 0.025480310898274183 Engine time: 0.11708279373124242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 18.75875356607139,
    "estimated_duration": 3600.0126508447215,
    "input_throughput": 4642.226186643708,
    "output_throughput": 4145.784875644247,
    "total_throughput": 8788.011062287955,
    "itl": 39.75252858665693,
    "ttft": 253388.14004994798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1070,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4943596354592668,
    "arrivals": 70422,
    "finished_requests": 67591,
    "scheduler_time": 81.76817856772261
}
#Debug simulation 
Total elapsed time: 18.758848960045725. Arrivals time: 0.19089515460655093 Scheduler time: 18.241239768918604 Scheduler overhead time: 0.1295365751720965 Adapter cache time: 0.025004657451063395 Engine time: 0.11696618050336838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 19.548656144645065,
    "estimated_duration": 3600.027248239354,
    "input_throughput": 4653.915885829448,
    "output_throughput": 4151.768297673245,
    "total_throughput": 8805.684183502693,
    "itl": 39.817436376693124,
    "ttft": 249552.34303051766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.384766264669556,
    "arrivals": 70422,
    "finished_requests": 67778,
    "scheduler_time": 83.71381200389574
}
#Debug simulation 
Total elapsed time: 19.54880417883396. Arrivals time: 0.19592155329883099 Scheduler time: 19.026980267837644 Scheduler overhead time: 0.12938810558989644 Adapter cache time: 0.024905485101044178 Engine time: 0.11632864829152822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 17.82157767098397,
    "estimated_duration": 3600.0454461806944,
    "input_throughput": 4671.061588358617,
    "output_throughput": 4159.576100875807,
    "total_throughput": 8830.637689234425,
    "itl": 39.6898223662879,
    "ttft": 224140.68270599906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1137,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5610823360876727,
    "arrivals": 70422,
    "finished_requests": 68037,
    "scheduler_time": 79.46595767575062
}
#Debug simulation 
Total elapsed time: 17.82168180635199. Arrivals time: 0.1950261378660798 Scheduler time: 17.301454063039273 Scheduler overhead time: 0.12871517706662416 Adapter cache time: 0.025246435310691595 Engine time: 0.11610333854332566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 18.92362330527976,
    "estimated_duration": 3600.0229740906384,
    "input_throughput": 4642.212874827958,
    "output_throughput": 4145.772987398784,
    "total_throughput": 8787.985862226742,
    "itl": 39.74496411044988,
    "ttft": 253398.305593367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1070,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.544197438266129,
    "arrivals": 70422,
    "finished_requests": 67591,
    "scheduler_time": 81.77037586765884
}
#Debug simulation 
Total elapsed time: 18.92371900891885. Arrivals time: 0.1896253377199173 Scheduler time: 18.407278058119118 Scheduler overhead time: 0.12946112174540758 Adapter cache time: 0.02519052103161812 Engine time: 0.11660256749019027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 18.23317863000557,
    "estimated_duration": 3600.008040109534,
    "input_throughput": 4640.195747866092,
    "output_throughput": 4144.784909854258,
    "total_throughput": 8784.98065772035,
    "itl": 39.376671072293554,
    "ttft": 247673.167781479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3010155255719216,
    "arrivals": 70422,
    "finished_requests": 67609,
    "scheduler_time": 80.2061282850739
}
#Debug simulation 
Total elapsed time: 18.233279446605593. Arrivals time: 0.19454432418569922 Scheduler time: 17.711244025733322 Scheduler overhead time: 0.12830818397924304 Adapter cache time: 0.02540390659123659 Engine time: 0.11838155472651124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 540, 4320, 4320, 33, 33, 4320, 33, 540, 540, 540, 33, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 540, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 4320, 33, 540, 540, 33, 540, 33, 540, 540, 4320, 4320, 4320, 4320, 540, 540, 33, 540, 4320, 4320, 540, 33, 33, 33, 4320, 540, 540, 540, 540, 4320, 540, 4320, 33, 33, 540, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 4320, 4320, 540, 540, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 540, 4320, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 540, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33]
Prompts retrieved: 210366 . Total input tokens: 46882551 . Total output tokens: 42078605
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 18.73817304475233,
    "estimated_duration": 3600.0225799636096,
    "input_throughput": 4651.952210857879,
    "output_throughput": 4144.583170961895,
    "total_throughput": 8796.535381819775,
    "itl": 39.3861042569352,
    "ttft": 247494.9964762218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.611693723686088,
    "arrivals": 70422,
    "finished_requests": 67693,
    "scheduler_time": 81.48014006266722
}
#Debug simulation 
Total elapsed time: 18.73828106885776. Arrivals time: 0.1883510798215866 Scheduler time: 18.224587353412062 Scheduler overhead time: 0.12857856415212154 Adapter cache time: 0.024864130187779665 Engine time: 0.11665729153901339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 16.90203828178346,
    "estimated_duration": 3599.988758949227,
    "input_throughput": 4520.91300550351,
    "output_throughput": 4045.3006870640043,
    "total_throughput": 8566.213692567515,
    "itl": 39.882389821095025,
    "ttft": 220605.74571870934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.911303336746159,
    "arrivals": 68030,
    "finished_requests": 65788,
    "scheduler_time": 76.60240519883943
}
#Debug simulation 
Total elapsed time: 16.90214438783005. Arrivals time: 0.187916477676481 Scheduler time: 16.38586245337501 Scheduler overhead time: 0.12942921463400126 Adapter cache time: 0.025980632286518812 Engine time: 0.11718514561653137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 17.712088630069047,
    "estimated_duration": 3600.0216787537374,
    "input_throughput": 4513.29198818179,
    "output_throughput": 4035.068201319486,
    "total_throughput": 8548.360189501276,
    "itl": 39.34738916557004,
    "ttft": 231076.6488052856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.965916292835033,
    "arrivals": 68030,
    "finished_requests": 65711,
    "scheduler_time": 78.79347408868249
}
#Debug simulation 
Total elapsed time: 17.71216668887064. Arrivals time: 0.18259722273796797 Scheduler time: 17.1998677062802 Scheduler overhead time: 0.13027914753183722 Adapter cache time: 0.026014847680926323 Engine time: 0.11757294554263353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 17.605812137015164,
    "estimated_duration": 3600.0213645143745,
    "input_throughput": 4527.860073463437,
    "output_throughput": 4044.7640515500775,
    "total_throughput": 8572.624125013515,
    "itl": 39.39920887832625,
    "ttft": 218562.65996276974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.018376600630518,
    "arrivals": 68030,
    "finished_requests": 65939,
    "scheduler_time": 78.56969844292958
}
#Debug simulation 
Total elapsed time: 17.60592152690515. Arrivals time: 0.18583914823830128 Scheduler time: 17.09111040458083 Scheduler overhead time: 0.12975002359598875 Adapter cache time: 0.025946037843823433 Engine time: 0.11717160232365131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 16.90473948325962,
    "estimated_duration": 3599.9936116740837,
    "input_throughput": 4520.922189201218,
    "output_throughput": 4045.299678525771,
    "total_throughput": 8566.22186772699,
    "itl": 39.91668406299044,
    "ttft": 220448.46741048878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9905915679060375,
    "arrivals": 68030,
    "finished_requests": 65790,
    "scheduler_time": 76.60104579769074
}
#Debug simulation 
Total elapsed time: 16.904882811009884. Arrivals time: 0.18504244554787874 Scheduler time: 16.391900890506804 Scheduler overhead time: 0.12902477849274874 Adapter cache time: 0.026170126628130674 Engine time: 0.11718896077945828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 16.901861577760428,
    "estimated_duration": 3599.9873183608497,
    "input_throughput": 4520.933148011891,
    "output_throughput": 4045.289805807104,
    "total_throughput": 8566.222953818995,
    "itl": 39.918843799992814,
    "ttft": 220529.23596612885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.221604004241515,
    "arrivals": 68030,
    "finished_requests": 65789,
    "scheduler_time": 76.60754727880092
}
#Debug simulation 
Total elapsed time: 16.901943311095238. Arrivals time: 0.18074573297053576 Scheduler time: 16.393093774095178 Scheduler overhead time: 0.12887739297002554 Adapter cache time: 0.026179034262895584 Engine time: 0.11721278540790081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 17.242013954091817,
    "estimated_duration": 3599.9994858085965,
    "input_throughput": 4528.1112023099595,
    "output_throughput": 4051.644189811281,
    "total_throughput": 8579.75539212124,
    "itl": 39.914275204582125,
    "ttft": 215349.86366200805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8063340254103712,
    "arrivals": 68030,
    "finished_requests": 65890,
    "scheduler_time": 76.67103715592087
}
#Debug simulation 
Total elapsed time: 17.24212714890018. Arrivals time: 0.18605786189436913 Scheduler time: 16.726295043248683 Scheduler overhead time: 0.13024197705090046 Adapter cache time: 0.026211491785943508 Engine time: 0.11736018769443035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 135, 135, 4320, 135, 270, 270, 270, 135, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 270, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 4320, 135, 270, 270, 135, 270, 135, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 135, 270, 4320, 4320, 270, 135, 135, 135, 4320, 270, 270, 270, 270, 4320, 270, 4320, 135, 135, 270, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 4320, 4320, 270, 270, 135, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 135, 4320, 135, 135, 4320, 270, 4320, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 270, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135]
Prompts retrieved: 203040 . Total input tokens: 45261739 . Total output tokens: 40617405
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 16.897278871852905,
    "estimated_duration": 3599.9822688506856,
    "input_throughput": 4521.407269374279,
    "output_throughput": 4045.4771474887084,
    "total_throughput": 8566.884416862988,
    "itl": 39.91802446993673,
    "ttft": 220173.6511709295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.275426624827121,
    "arrivals": 68030,
    "finished_requests": 65796,
    "scheduler_time": 76.6096726335951
}
#Debug simulation 
Total elapsed time: 16.897363369818777. Arrivals time: 0.1818553670309484 Scheduler time: 16.384810738731176 Scheduler overhead time: 0.13068181928247213 Adapter cache time: 0.02621310716494918 Engine time: 0.11740192957222462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 16.54270152375102,
    "estimated_duration": 3600.0088868010253,
    "input_throughput": 4462.682316952836,
    "output_throughput": 3966.6474303315413,
    "total_throughput": 8429.329747284377,
    "itl": 38.061910798263476,
    "ttft": 216154.3990651213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7950048024767105,
    "arrivals": 67080,
    "finished_requests": 64877,
    "scheduler_time": 73.88436070689608
}
#Debug simulation 
Total elapsed time: 16.542838386725634. Arrivals time: 0.18333593849092722 Scheduler time: 16.026197402272373 Scheduler overhead time: 0.13206057529896498 Adapter cache time: 0.026107408106327057 Engine time: 0.11848522303625941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 16.434691354166716,
    "estimated_duration": 3600.0253195178775,
    "input_throughput": 4484.989289509306,
    "output_throughput": 3987.8016752178314,
    "total_throughput": 8472.790964727137,
    "itl": 38.28334482784094,
    "ttft": 197314.82444184553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.104982050729446,
    "arrivals": 67080,
    "finished_requests": 65229,
    "scheduler_time": 73.81993200054578
}
#Debug simulation 
Total elapsed time: 16.434784645214677. Arrivals time: 0.18234675051644444 Scheduler time: 15.921712883748114 Scheduler overhead time: 0.1304144081659615 Adapter cache time: 0.026027111802250147 Engine time: 0.11823785537853837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 16.45939960097894,
    "estimated_duration": 3600.03071602751,
    "input_throughput": 4484.982566431141,
    "output_throughput": 3987.795697432681,
    "total_throughput": 8472.778263863822,
    "itl": 38.28730601578859,
    "ttft": 197359.71015218872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.111689068265196,
    "arrivals": 67080,
    "finished_requests": 65229,
    "scheduler_time": 73.81822133823854
}
#Debug simulation 
Total elapsed time: 16.459520930889994. Arrivals time: 0.17917003575712442 Scheduler time: 15.946435750462115 Scheduler overhead time: 0.13302026316523552 Adapter cache time: 0.026336046867072582 Engine time: 0.11787853855639696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 16.581816082354635,
    "estimated_duration": 3600.008760701168,
    "input_throughput": 4462.682473270123,
    "output_throughput": 3966.647569273891,
    "total_throughput": 8429.330042544014,
    "itl": 38.0633005439292,
    "ttft": 216155.3120362998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.882541161971122,
    "arrivals": 67080,
    "finished_requests": 64877,
    "scheduler_time": 73.88399719678442
}
#Debug simulation 
Total elapsed time: 16.58190626837313. Arrivals time: 0.18052636785432696 Scheduler time: 16.069674987345934 Scheduler overhead time: 0.13090687105432153 Adapter cache time: 0.026110021397471428 Engine time: 0.11819348018616438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 16.56649199128151,
    "estimated_duration": 3600.01449438245,
    "input_throughput": 4462.675365632362,
    "output_throughput": 3966.6412516624046,
    "total_throughput": 8429.316617294766,
    "itl": 38.06705358058243,
    "ttft": 216158.6460925375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.105820818915956,
    "arrivals": 67080,
    "finished_requests": 64877,
    "scheduler_time": 73.88354815086453
}
#Debug simulation 
Total elapsed time: 16.566618701908737. Arrivals time: 0.17751585179939866 Scheduler time: 16.057438443414867 Scheduler overhead time: 0.13115269737318158 Adapter cache time: 0.026042355224490166 Engine time: 0.11821208707988262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 16.041719131171703,
    "estimated_duration": 3600.001537789128,
    "input_throughput": 4494.16613581116,
    "output_throughput": 3996.711348305761,
    "total_throughput": 8490.877484116922,
    "itl": 38.647877391838755,
    "ttft": 189351.50480581657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8631449810135106,
    "arrivals": 67080,
    "finished_requests": 65318,
    "scheduler_time": 72.80005822334726
}
#Debug simulation 
Total elapsed time: 16.041828808374703. Arrivals time: 0.18362349830567837 Scheduler time: 15.528959050774574 Scheduler overhead time: 0.1297003086656332 Adapter cache time: 0.02640149835497141 Engine time: 0.1171842273324728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 66, 66, 4320, 66, 270, 270, 270, 66, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 270, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 4320, 66, 270, 270, 66, 270, 66, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 66, 270, 4320, 4320, 270, 66, 66, 66, 4320, 270, 270, 270, 270, 4320, 270, 4320, 66, 66, 270, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 4320, 4320, 270, 270, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 270, 4320, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 270, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66]
Prompts retrieved: 200142 . Total input tokens: 44611233 . Total output tokens: 40046224
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 16.419355830177665,
    "estimated_duration": 3600.028349294076,
    "input_throughput": 4484.9855149518635,
    "output_throughput": 3987.7983190924265,
    "total_throughput": 8472.78383404429,
    "itl": 38.28796188684598,
    "ttft": 197311.38120276097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.218328279145102,
    "arrivals": 67080,
    "finished_requests": 65229,
    "scheduler_time": 73.81813284492554
}
#Debug simulation 
Total elapsed time: 16.419474631082267. Arrivals time: 0.1822848441079259 Scheduler time: 15.90505871316418 Scheduler overhead time: 0.13175686821341515 Adapter cache time: 0.02628330932930112 Engine time: 0.11782019212841988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 15.214018187951297,
    "estimated_duration": 3600.002769439579,
    "input_throughput": 4452.892129995637,
    "output_throughput": 3958.3519548842855,
    "total_throughput": 8411.244084879923,
    "itl": 37.323253741318844,
    "ttft": 207139.93170217556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7888838269888447,
    "arrivals": 66631,
    "finished_requests": 64365,
    "scheduler_time": 69.08966164119164
}
#Debug simulation 
Total elapsed time: 15.214098542928696. Arrivals time: 0.17491241171956062 Scheduler time: 14.706245726905763 Scheduler overhead time: 0.1314607043750584 Adapter cache time: 0.025928582064807415 Engine time: 0.1189094902947545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.2225123741664,
    "estimated_duration": 3600.0102985203434,
    "input_throughput": 4461.779736186283,
    "output_throughput": 3967.416428189223,
    "total_throughput": 8429.196164375506,
    "itl": 37.693948724936234,
    "ttft": 197156.93837542096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.035783352507281,
    "arrivals": 66631,
    "finished_requests": 64556,
    "scheduler_time": 69.16941702116848
}
#Debug simulation 
Total elapsed time: 15.222647022921592. Arrivals time: 0.18053653417155147 Scheduler time: 14.710251884069294 Scheduler overhead time: 0.1308448500931263 Adapter cache time: 0.025864305905997753 Engine time: 0.11879830341786146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.25080091599375,
    "estimated_duration": 3600.019675226931,
    "input_throughput": 4461.768114916618,
    "output_throughput": 3967.4060945513224,
    "total_throughput": 8429.174209467941,
    "itl": 37.689627194075534,
    "ttft": 197157.06533672631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.043061998914862,
    "arrivals": 66631,
    "finished_requests": 64556,
    "scheduler_time": 69.16931423252872
}
#Debug simulation 
Total elapsed time: 15.250877041835338. Arrivals time: 0.17502696765586734 Scheduler time: 14.743991679977626 Scheduler overhead time: 0.13066325662657619 Adapter cache time: 0.02583685191348195 Engine time: 0.11911426903679967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 15.132443709298968,
    "estimated_duration": 3600.0101672399082,
    "input_throughput": 4453.79519922103,
    "output_throughput": 3953.957999766786,
    "total_throughput": 8407.753198987815,
    "itl": 37.62484603556967,
    "ttft": 206436.77856355943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.907966062538282,
    "arrivals": 66631,
    "finished_requests": 64371,
    "scheduler_time": 69.02088032244629
}
#Debug simulation 
Total elapsed time: 15.132550929207355. Arrivals time: 0.18110919604077935 Scheduler time: 14.61916751274839 Scheduler overhead time: 0.13112850347533822 Adapter cache time: 0.02610814431682229 Engine time: 0.1186394696123898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 15.509837990161031,
    "estimated_duration": 3600.0351524955145,
    "input_throughput": 4462.956143320608,
    "output_throughput": 3965.2293367482016,
    "total_throughput": 8428.18548006881,
    "itl": 37.196470823189735,
    "ttft": 199619.17513146365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9957156874611948,
    "arrivals": 66631,
    "finished_requests": 64534,
    "scheduler_time": 69.7111534835486
}
#Debug simulation 
Total elapsed time: 15.509953620377928. Arrivals time: 0.17952132737264037 Scheduler time: 14.998117386829108 Scheduler overhead time: 0.13110745372250676 Adapter cache time: 0.026013563852757215 Engine time: 0.11860472103580832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 15.244476849678904,
    "estimated_duration": 3600.0318924962394,
    "input_throughput": 4461.91047181585,
    "output_throughput": 3967.399019372693,
    "total_throughput": 8429.309491188542,
    "itl": 37.68518367005795,
    "ttft": 197098.9885236137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6986922147938968,
    "arrivals": 66631,
    "finished_requests": 64557,
    "scheduler_time": 69.17002338684084
}
#Debug simulation 
Total elapsed time: 15.244568604044616. Arrivals time: 0.1770369317382574 Scheduler time: 14.735608199145645 Scheduler overhead time: 0.13094878941774368 Adapter cache time: 0.026042500976473093 Engine time: 0.11837461264804006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 270, 4320, 4320, 33, 33, 4320, 33, 270, 270, 270, 33, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 270, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 4320, 33, 270, 270, 33, 270, 33, 270, 270, 4320, 4320, 4320, 4320, 270, 270, 33, 270, 4320, 4320, 270, 33, 33, 33, 4320, 270, 270, 270, 270, 4320, 270, 4320, 33, 33, 270, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 4320, 4320, 270, 270, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 270, 4320, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 270, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33]
Prompts retrieved: 198756 . Total input tokens: 44307814 . Total output tokens: 39759755
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.186844220384955,
    "estimated_duration": 3600.029930822546,
    "input_throughput": 4452.858811742523,
    "output_throughput": 3958.3251455756913,
    "total_throughput": 8411.183957318215,
    "itl": 37.33012170776254,
    "ttft": 207142.2246483193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1238,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.148926388993908,
    "arrivals": 66631,
    "finished_requests": 64366,
    "scheduler_time": 69.0893953074816
}
#Debug simulation 
Total elapsed time: 15.186954481061548. Arrivals time: 0.17763187130913138 Scheduler time: 14.678319308441132 Scheduler overhead time: 0.13045041263103485 Adapter cache time: 0.025881049688905478 Engine time: 0.11812155274674296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 15.496466545853764,
    "estimated_duration": 3599.8671544827866,
    "input_throughput": 4383.3736976516675,
    "output_throughput": 3895.0381773225645,
    "total_throughput": 8278.411874974232,
    "itl": 37.16970711471016,
    "ttft": 190194.15029462866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1242,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.801125777964576,
    "arrivals": 65160,
    "finished_requests": 63328,
    "scheduler_time": 68.8173174529468
}
#Debug simulation 
Total elapsed time: 15.496545197907835. Arrivals time: 0.17351792799308896 Scheduler time: 14.98755213804543 Scheduler overhead time: 0.132822182495147 Adapter cache time: 0.026234119664877653 Engine time: 0.11954191839322448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 14.423826691694558,
    "estimated_duration": 3599.8836727993253,
    "input_throughput": 4400.719423158736,
    "output_throughput": 3906.0687172331995,
    "total_throughput": 8306.788140391936,
    "itl": 36.98855263250199,
    "ttft": 169259.99192108974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.331576457812892,
    "arrivals": 65160,
    "finished_requests": 63579,
    "scheduler_time": 66.42638625173088
}
#Debug simulation 
Total elapsed time: 14.423964223824441. Arrivals time: 0.17555965622887015 Scheduler time: 13.915025708731264 Scheduler overhead time: 0.13145631225779653 Adapter cache time: 0.026552727445960045 Engine time: 0.11888444609940052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.268035104963928,
    "estimated_duration": 3599.873687498717,
    "input_throughput": 4382.824057074815,
    "output_throughput": 3899.232644952352,
    "total_throughput": 8282.056702027166,
    "itl": 37.20023292623051,
    "ttft": 185519.11974913912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0934362465701355,
    "arrivals": 65160,
    "finished_requests": 63397,
    "scheduler_time": 68.48900225704914
}
#Debug simulation 
Total elapsed time: 15.268123909831047. Arrivals time: 0.1760738235898316 Scheduler time: 14.757248929236084 Scheduler overhead time: 0.1322868149727583 Adapter cache time: 0.026120455469936132 Engine time: 0.11958346841856837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 14.49956675292924,
    "estimated_duration": 3599.8723533930497,
    "input_throughput": 4398.989587804137,
    "output_throughput": 3908.4266381663547,
    "total_throughput": 8307.416225970492,
    "itl": 37.029103441675026,
    "ttft": 170957.0413221552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.172873698950222,
    "arrivals": 65160,
    "finished_requests": 63556,
    "scheduler_time": 66.50846897102578
}
#Debug simulation 
Total elapsed time: 14.499687580857426. Arrivals time: 0.17114055808633566 Scheduler time: 13.99529187567532 Scheduler overhead time: 0.1314401193521917 Adapter cache time: 0.026357694063335657 Engine time: 0.11891158018261194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 15.13992686290294,
    "estimated_duration": 3599.8705989323894,
    "input_throughput": 4397.964194795033,
    "output_throughput": 3908.401875382035,
    "total_throughput": 8306.366070177068,
    "itl": 37.68749006402981,
    "ttft": 176147.54636795685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.185870020147399,
    "arrivals": 65160,
    "finished_requests": 63540,
    "scheduler_time": 68.0508884836587
}
#Debug simulation 
Total elapsed time: 15.14002014696598. Arrivals time: 0.17444243468344212 Scheduler time: 14.629050824325532 Scheduler overhead time: 0.1323350863531232 Adapter cache time: 0.02648523822426796 Engine time: 0.12065861886367202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 15.213756932877004,
    "estimated_duration": 3599.8603042189816,
    "input_throughput": 4382.506727138907,
    "output_throughput": 3899.006020747573,
    "total_throughput": 8281.51274788648,
    "itl": 37.206929898970984,
    "ttft": 185817.18404520495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.743542969217428,
    "arrivals": 65160,
    "finished_requests": 63391,
    "scheduler_time": 68.48114435762018
}
#Debug simulation 
Total elapsed time: 15.213842493947595. Arrivals time: 0.17351924860849977 Scheduler time: 14.705272805411369 Scheduler overhead time: 0.13269367720931768 Adapter cache time: 0.026103587355464697 Engine time: 0.11938440520316362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 66, 66, 4320, 66, 135, 135, 135, 66, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 135, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 4320, 66, 135, 135, 66, 135, 66, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 66, 135, 4320, 4320, 135, 66, 66, 66, 4320, 135, 135, 135, 135, 4320, 135, 4320, 66, 66, 135, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 4320, 4320, 135, 135, 66, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 66, 4320, 66, 66, 4320, 135, 4320, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 135, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66]
Prompts retrieved: 194337 . Total input tokens: 43344562 . Total output tokens: 38859128
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 15.354471686296165,
    "estimated_duration": 3599.878859633926,
    "input_throughput": 4406.114655095079,
    "output_throughput": 3910.4876994198435,
    "total_throughput": 8316.602354514922,
    "itl": 37.39238903831439,
    "ttft": 170608.4858127457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2223658216,
    "arrivals": 65160,
    "finished_requests": 63689,
    "scheduler_time": 68.89020366333273
}
#Debug simulation 
Total elapsed time: 15.354586645029485. Arrivals time: 0.17383968038484454 Scheduler time: 14.84781346982345 Scheduler overhead time: 0.13127499585971236 Adapter cache time: 0.026075699366629124 Engine time: 0.11905199196189642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 13.302412089891732,
    "estimated_duration": 3599.9489033353957,
    "input_throughput": 4379.272435059674,
    "output_throughput": 3872.759412524665,
    "total_throughput": 8252.03184758434,
    "itl": 36.346435110727306,
    "ttft": 149726.27499183395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.045964797479205,
    "arrivals": 64686,
    "finished_requests": 63285,
    "scheduler_time": 62.12000685370825
}
#Debug simulation 
Total elapsed time: 13.302506513893604. Arrivals time: 0.16986290086060762 Scheduler time: 12.798141477629542 Scheduler overhead time: 0.13177440827712417 Adapter cache time: 0.026544146705418825 Engine time: 0.11940702656283975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 13.56447673868388,
    "estimated_duration": 3599.9777714110314,
    "input_throughput": 4362.176379173817,
    "output_throughput": 3852.451009597226,
    "total_throughput": 8214.627388771043,
    "itl": 36.355396923750675,
    "ttft": 166596.12418303208,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2356161361234115,
    "arrivals": 64686,
    "finished_requests": 63013,
    "scheduler_time": 62.721848402030055
}
#Debug simulation 
Total elapsed time: 13.564609861932695. Arrivals time: 0.17635768745094538 Scheduler time: 13.051638895180076 Scheduler overhead time: 0.1326285214163363 Adapter cache time: 0.02656423021107912 Engine time: 0.12014731299132109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 13.409529493190348,
    "estimated_duration": 3599.9682970647445,
    "input_throughput": 4363.467592980719,
    "output_throughput": 3853.8397716757686,
    "total_throughput": 8217.307364656488,
    "itl": 35.89023969773076,
    "ttft": 166165.05961999993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.277363201882627,
    "arrivals": 64686,
    "finished_requests": 63008,
    "scheduler_time": 62.45820129741904
}
#Debug simulation 
Total elapsed time: 13.40962138120085. Arrivals time: 0.17393213091418147 Scheduler time: 12.900858362670988 Scheduler overhead time: 0.1318912310525775 Adapter cache time: 0.026443087961524725 Engine time: 0.11948367534205317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 13.626684403046966,
    "estimated_duration": 3599.9675938421665,
    "input_throughput": 4355.915599580119,
    "output_throughput": 3849.880211062711,
    "total_throughput": 8205.79581064283,
    "itl": 35.89129253169405,
    "ttft": 172224.79501394264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.028404211092229,
    "arrivals": 64686,
    "finished_requests": 62930,
    "scheduler_time": 63.01564470073471
}
#Debug simulation 
Total elapsed time: 13.626781392842531. Arrivals time: 0.17159094847738743 Scheduler time: 13.11894115852192 Scheduler overhead time: 0.13292301259934902 Adapter cache time: 0.026547382585704327 Engine time: 0.11975090252235532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 13.53074621874839,
    "estimated_duration": 3599.959467084599,
    "input_throughput": 4366.493051859297,
    "output_throughput": 3857.3495415618445,
    "total_throughput": 8223.842593421141,
    "itl": 36.153182901789,
    "ttft": 163530.7129824428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.303827872201785,
    "arrivals": 64686,
    "finished_requests": 63071,
    "scheduler_time": 62.71872147348261
}
#Debug simulation 
Total elapsed time: 13.530855493620038. Arrivals time: 0.17098561860620975 Scheduler time: 13.024188995361328 Scheduler overhead time: 0.131996329408139 Adapter cache time: 0.026365730445832014 Engine time: 0.11999551439657807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 13.625861523207277,
    "estimated_duration": 3599.962321723328,
    "input_throughput": 4358.225614008467,
    "output_throughput": 3847.4511014797454,
    "total_throughput": 8205.676715488213,
    "itl": 35.93698682890703,
    "ttft": 171619.8426471718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8691250816033147,
    "arrivals": 64686,
    "finished_requests": 62918,
    "scheduler_time": 62.62605393893791
}
#Debug simulation 
Total elapsed time: 13.625938578974456. Arrivals time: 0.17069168062880635 Scheduler time: 13.11994755687192 Scheduler overhead time: 0.1321065970696509 Adapter cache time: 0.02635018201544881 Engine time: 0.11982725653797388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 135, 4320, 4320, 33, 33, 4320, 33, 135, 135, 135, 33, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 135, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 4320, 33, 135, 135, 33, 135, 33, 135, 135, 4320, 4320, 4320, 4320, 135, 135, 33, 135, 4320, 4320, 135, 33, 33, 33, 4320, 135, 135, 135, 135, 4320, 135, 4320, 33, 33, 135, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 4320, 4320, 135, 135, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 135, 4320, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 135, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33]
Prompts retrieved: 192951 . Total input tokens: 43038885 . Total output tokens: 38572296
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 13.62415456213057,
    "estimated_duration": 3599.945750794187,
    "input_throughput": 4358.673459603772,
    "output_throughput": 3848.4752157566795,
    "total_throughput": 8207.148675360451,
    "itl": 35.8723432221678,
    "ttft": 171106.5671307055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1289,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.323128902800412,
    "arrivals": 64686,
    "finished_requests": 62951,
    "scheduler_time": 63.008321220826545
}
#Debug simulation 
Total elapsed time: 13.624292292166501. Arrivals time: 0.17501624627038836 Scheduler time: 13.111145875416696 Scheduler overhead time: 0.1349658123217523 Adapter cache time: 0.02639064099639654 Engine time: 0.11916123423725367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 12.674509280826896,
    "estimated_duration": 3600.0152601631316,
    "input_throughput": 4336.232174552678,
    "output_throughput": 3812.357450778718,
    "total_throughput": 8148.589625331396,
    "itl": 35.5027426002558,
    "ttft": 143494.58993614637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1281,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9204847999779577,
    "arrivals": 63755,
    "finished_requests": 62373,
    "scheduler_time": 58.912582902260546
}
#Debug simulation 
Total elapsed time: 12.67459957068786. Arrivals time: 0.17612280510365963 Scheduler time: 12.161118546500802 Scheduler overhead time: 0.13302260916680098 Adapter cache time: 0.026415458414703608 Engine time: 0.12041451828554273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 12.88232910213992,
    "estimated_duration": 3600.036267994192,
    "input_throughput": 4325.13337113556,
    "output_throughput": 3805.236664360766,
    "total_throughput": 8130.370035496327,
    "itl": 35.73988164357546,
    "ttft": 154552.35589287404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.070178403959144,
    "arrivals": 63755,
    "finished_requests": 62209,
    "scheduler_time": 59.5147250394132
}
#Debug simulation 
Total elapsed time: 12.882453818805516. Arrivals time: 0.17105149663984776 Scheduler time: 12.374669954646379 Scheduler overhead time: 0.13301618350669742 Adapter cache time: 0.02620175341144204 Engine time: 0.120291693136096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 12.839174401015043,
    "estimated_duration": 3600.004004682627,
    "input_throughput": 4336.811009013415,
    "output_throughput": 3809.822706352554,
    "total_throughput": 8146.63371536597,
    "itl": 35.59587049913556,
    "ttft": 142578.86255003963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.155310074631059,
    "arrivals": 63755,
    "finished_requests": 62408,
    "scheduler_time": 59.255290716547975
}
#Debug simulation 
Total elapsed time: 12.839263654313982. Arrivals time: 0.1704653617925942 Scheduler time: 12.331799729727209 Scheduler overhead time: 0.13284361315891147 Adapter cache time: 0.026331677567213774 Engine time: 0.12036217236891389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 12.905527003109455,
    "estimated_duration": 3600.0132755090563,
    "input_throughput": 4323.462389954413,
    "output_throughput": 3804.3162488236626,
    "total_throughput": 8127.778638778076,
    "itl": 35.568472583600084,
    "ttft": 150975.0195393849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1260,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9529656461486162,
    "arrivals": 63755,
    "finished_requests": 62268,
    "scheduler_time": 59.40657631897232
}
#Debug simulation 
Total elapsed time: 12.90561438119039. Arrivals time: 0.16765833273530006 Scheduler time: 12.401362754404545 Scheduler overhead time: 0.1325339348986745 Adapter cache time: 0.026208408642560244 Engine time: 0.1205892120487988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 12.832934794016182,
    "estimated_duration": 3600.0266842762376,
    "input_throughput": 4340.107829823269,
    "output_throughput": 3820.204739055961,
    "total_throughput": 8160.31256887923,
    "itl": 35.870759845855666,
    "ttft": 140146.8238125559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1261,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.171135142967094,
    "arrivals": 63755,
    "finished_requests": 62459,
    "scheduler_time": 59.400073956633854
}
#Debug simulation 
Total elapsed time: 12.833059220109135. Arrivals time: 0.17024027649313211 Scheduler time: 12.326460054609925 Scheduler overhead time: 0.1330200033262372 Adapter cache time: 0.02627616049721837 Engine time: 0.11974227475002408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 12.762328756041825,
    "estimated_duration": 3600.0244431595493,
    "input_throughput": 4338.498598162933,
    "output_throughput": 3811.8513406415286,
    "total_throughput": 8150.349938804462,
    "itl": 35.66485793511608,
    "ttft": 140356.6603203361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8063340254103712,
    "arrivals": 63755,
    "finished_requests": 62441,
    "scheduler_time": 59.12576697832463
}
#Debug simulation 
Total elapsed time: 12.762410072144121. Arrivals time: 0.1692939349450171 Scheduler time: 12.255975114181638 Scheduler overhead time: 0.1326394360512495 Adapter cache time: 0.0262832366861403 Engine time: 0.12064011581242085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [42 43 43]
Adapter prompts. [4320, 66, 4320, 4320, 33, 33, 4320, 33, 66, 66, 66, 33, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 66, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 4320, 33, 66, 66, 33, 66, 33, 66, 66, 4320, 4320, 4320, 4320, 66, 66, 33, 66, 4320, 4320, 66, 33, 33, 33, 4320, 66, 66, 66, 66, 4320, 66, 4320, 33, 33, 66, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 4320, 4320, 66, 66, 33, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 33, 4320, 33, 33, 4320, 66, 4320, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 66, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33]
Prompts retrieved: 189984 . Total input tokens: 42380508 . Total output tokens: 37972669
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 13.032449461054057,
    "estimated_duration": 3600.0449669331956,
    "input_throughput": 4338.895525881873,
    "output_throughput": 3814.4948538513145,
    "total_throughput": 8153.390379733188,
    "itl": 35.776344661152834,
    "ttft": 142623.2360137343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1247,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1804850701615655,
    "arrivals": 63755,
    "finished_requests": 62429,
    "scheduler_time": 59.66968362833655
}
#Debug simulation 
Total elapsed time: 13.032551683019847. Arrivals time: 0.17385333543643355 Scheduler time: 12.521762662567198 Scheduler overhead time: 0.1344708651304245 Adapter cache time: 0.026024754159152508 Engine time: 0.1192827639169991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 3.0911030187271535,
    "estimated_duration": 3599.966199811725,
    "input_throughput": 1842.43313182965,
    "output_throughput": 1614.5765480531413,
    "total_throughput": 3457.0096798827913,
    "itl": 23.735645516797916,
    "ttft": 79425.35125976535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.194542156358771,
    "arrivals": 27111,
    "finished_requests": 26762,
    "scheduler_time": 3.688522576776039
}
#Debug simulation 
Total elapsed time: 3.0911867199465632. Arrivals time: 0.07861996814608574 Scheduler time: 2.609634761698544 Scheduler overhead time: 0.1506075020879507 Adapter cache time: 0.04537418205291033 Engine time: 0.13733148435130715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 3.110645767301321,
    "estimated_duration": 3599.953245853046,
    "input_throughput": 1842.8475446569212,
    "output_throughput": 1614.6309696371197,
    "total_throughput": 3457.478514294041,
    "itl": 23.738488927792538,
    "ttft": 77892.25228354544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.140219089380468,
    "arrivals": 27111,
    "finished_requests": 26775,
    "scheduler_time": 3.7115852696782015
}
#Debug simulation 
Total elapsed time: 3.110735340975225. Arrivals time: 0.08032188145443797 Scheduler time: 2.6266266643069685 Scheduler overhead time: 0.14965910417959094 Adapter cache time: 0.04501254856586456 Engine time: 0.13947432022541761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 3.096066885162145,
    "estimated_duration": 3599.946370494328,
    "input_throughput": 1843.9474694420196,
    "output_throughput": 1615.4526766468014,
    "total_throughput": 3459.400146088821,
    "itl": 23.743624923696693,
    "ttft": 76980.98302676856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.07981543110557,
    "arrivals": 27111,
    "finished_requests": 26782,
    "scheduler_time": 3.7089092524519844
}
#Debug simulation 
Total elapsed time: 3.0961495330557227. Arrivals time: 0.07890062406659126 Scheduler time: 2.610687063075602 Scheduler overhead time: 0.15294479671865702 Adapter cache time: 0.0453517590649426 Engine time: 0.1384272212162614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 3.0690926578827202,
    "estimated_duration": 3599.97138942176,
    "input_throughput": 1842.4304758336891,
    "output_throughput": 1614.5742205283502,
    "total_throughput": 3457.0046963620393,
    "itl": 23.737058937484438,
    "ttft": 79426.34534263393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.524057349172603,
    "arrivals": 27111,
    "finished_requests": 26762,
    "scheduler_time": 3.690092484462942
}
#Debug simulation 
Total elapsed time: 3.069163927808404. Arrivals time: 0.07840806106105447 Scheduler time: 2.5899349790997803 Scheduler overhead time: 0.14883045852184296 Adapter cache time: 0.0449748900718987 Engine time: 0.13727361056953669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 3.1209735609591007,
    "estimated_duration": 3599.963040553439,
    "input_throughput": 1844.1233771609473,
    "output_throughput": 1615.0568587799069,
    "total_throughput": 3459.1802359408543,
    "itl": 23.75694820462503,
    "ttft": 76567.5807624341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.292951737771498,
    "arrivals": 27111,
    "finished_requests": 26784,
    "scheduler_time": 3.7290744730921057
}
#Debug simulation 
Total elapsed time: 3.1210545380599797. Arrivals time: 0.08014998072758317 Scheduler time: 2.6278589237481356 Scheduler overhead time: 0.15321272984147072 Adapter cache time: 0.04527309164404869 Engine time: 0.1447137831710279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 3.081208708230406,
    "estimated_duration": 3599.9652522941697,
    "input_throughput": 1844.320857199612,
    "output_throughput": 1615.503370843305,
    "total_throughput": 3459.8242280429167,
    "itl": 23.733585919372,
    "ttft": 76299.31410623628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.897753770706606,
    "arrivals": 27111,
    "finished_requests": 26785,
    "scheduler_time": 3.6758172287624933
}
#Debug simulation 
Total elapsed time: 3.0812814091332257. Arrivals time: 0.07834743475541472 Scheduler time: 2.6027810210362077 Scheduler overhead time: 0.1485526291653514 Adapter cache time: 0.044827521312981844 Engine time: 0.13707234431058168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 270, 270, 1080, 270, 540, 540, 540, 270, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 540, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 1080, 270, 540, 540, 270, 540, 270, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 270, 540, 1080, 1080, 540, 270, 270, 270, 1080, 540, 540, 540, 540, 1080, 540, 1080, 270, 270, 540, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 1080, 1080, 540, 540, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 270, 1080, 270, 270, 1080, 540, 1080, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 540, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270]
Prompts retrieved: 81000 . Total input tokens: 18039508 . Total output tokens: 16188378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 3.116728574037552,
    "estimated_duration": 3599.964110590597,
    "input_throughput": 1843.4139330659286,
    "output_throughput": 1615.0938791015142,
    "total_throughput": 3458.507812167443,
    "itl": 23.748007276524966,
    "ttft": 77853.77005371707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.450047778113609,
    "arrivals": 27111,
    "finished_requests": 26776,
    "scheduler_time": 3.708919341192379
}
#Debug simulation 
Total elapsed time: 3.116815543733537. Arrivals time: 0.07949499180540442 Scheduler time: 2.6323336455971003 Scheduler overhead time: 0.1513190884143114 Adapter cache time: 0.045305587351322174 Engine time: 0.1386984083801508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.8216937398537993,
    "estimated_duration": 3600.0193589124938,
    "input_throughput": 1702.7780655745646,
    "output_throughput": 1522.569034644248,
    "total_throughput": 3225.3471002188126,
    "itl": 23.488743273530492,
    "ttft": 62879.04046324536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.870909947767737,
    "arrivals": 25189,
    "finished_requests": 24941,
    "scheduler_time": 1.611851450497185
}
#Debug simulation 
Total elapsed time: 2.821767710149288. Arrivals time: 0.07358939712867141 Scheduler time: 2.3490870110690594 Scheduler overhead time: 0.14645335171371698 Adapter cache time: 0.045842014253139496 Engine time: 0.13687997963279486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.8295285841450095,
    "estimated_duration": 3600.0079656719286,
    "input_throughput": 1703.192342480158,
    "output_throughput": 1522.3199649162748,
    "total_throughput": 3225.512307396433,
    "itl": 23.498876265779664,
    "ttft": 62570.681103648305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.826020303462759,
    "arrivals": 25189,
    "finished_requests": 24945,
    "scheduler_time": 1.6489239072435546
}
#Debug simulation 
Total elapsed time: 2.829609396867454. Arrivals time: 0.07375196972861886 Scheduler time: 2.351556701119989 Scheduler overhead time: 0.1485761171206832 Adapter cache time: 0.04594037402421236 Engine time: 0.13935102941468358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.835184011142701,
    "estimated_duration": 3600.0198970425477,
    "input_throughput": 1702.7989220381662,
    "output_throughput": 1522.4407522032159,
    "total_throughput": 3225.239674241382,
    "itl": 23.503203546516797,
    "ttft": 63554.97934636756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.77529130373012,
    "arrivals": 25189,
    "finished_requests": 24938,
    "scheduler_time": 1.6789063929821637
}
#Debug simulation 
Total elapsed time: 2.835256192833185. Arrivals time: 0.07374194357544184 Scheduler time: 2.359341484028846 Scheduler overhead time: 0.1489287791773677 Adapter cache time: 0.04597241850569844 Engine time: 0.13694554241374135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.8553745290264487,
    "estimated_duration": 3600.012230019873,
    "input_throughput": 1702.7161599298681,
    "output_throughput": 1521.9848294709136,
    "total_throughput": 3224.700989400782,
    "itl": 23.488293777420797,
    "ttft": 63461.96055870772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.173401589089861,
    "arrivals": 25189,
    "finished_requests": 24938,
    "scheduler_time": 1.6115516878727851
}
#Debug simulation 
Total elapsed time: 2.8554639448411763. Arrivals time: 0.07402078760787845 Scheduler time: 2.3754322701133788 Scheduler overhead time: 0.15207547368481755 Adapter cache time: 0.04589114338159561 Engine time: 0.13735405588522553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.837398447096348,
    "estimated_duration": 3600.001059269489,
    "input_throughput": 1703.207832178864,
    "output_throughput": 1522.2137187681813,
    "total_throughput": 3225.421550947045,
    "itl": 23.49944423677105,
    "ttft": 62767.34916047387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.037573491966942,
    "arrivals": 25189,
    "finished_requests": 24943,
    "scheduler_time": 1.6338299123968685
}
#Debug simulation 
Total elapsed time: 2.837496838066727. Arrivals time: 0.07415304705500603 Scheduler time: 2.3629767731763422 Scheduler overhead time: 0.14716874668374658 Adapter cache time: 0.0459106620401144 Engine time: 0.13680421840399504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.8288329811766744,
    "estimated_duration": 3600.018337222794,
    "input_throughput": 1702.773826626937,
    "output_throughput": 1522.367245559068,
    "total_throughput": 3225.1410721860047,
    "itl": 23.490170138234053,
    "ttft": 63333.84483400053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.480813578212683,
    "arrivals": 25189,
    "finished_requests": 24940,
    "scheduler_time": 1.645483709596237
}
#Debug simulation 
Total elapsed time: 2.8289254340343177. Arrivals time: 0.07354567898437381 Scheduler time: 2.356288256123662 Scheduler overhead time: 0.14650122169405222 Adapter cache time: 0.045694243628531694 Engine time: 0.13698842003941536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 135, 135, 1080, 135, 540, 540, 540, 135, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 540, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 1080, 135, 540, 540, 135, 540, 135, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 135, 540, 1080, 1080, 540, 135, 135, 135, 1080, 540, 540, 540, 540, 1080, 540, 1080, 135, 135, 540, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 1080, 1080, 540, 540, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 540, 1080, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 540, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135]
Prompts retrieved: 75330 . Total input tokens: 16766095 . Total output tokens: 15046268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.849281494040042,
    "estimated_duration": 3600.003225117317,
    "input_throughput": 1703.9754179109366,
    "output_throughput": 1522.6058581715222,
    "total_throughput": 3226.5812760824588,
    "itl": 23.50141585189929,
    "ttft": 61858.07598567786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.21758727930372,
    "arrivals": 25189,
    "finished_requests": 24950,
    "scheduler_time": 1.6432674055362466
}
#Debug simulation 
Total elapsed time: 2.849364022258669. Arrivals time: 0.07370883179828525 Scheduler time: 2.3718695268034935 Scheduler overhead time: 0.14908975269645452 Adapter cache time: 0.04622946819290519 Engine time: 0.1376291373744607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.7016594782471657,
    "estimated_duration": 3599.9276638612446,
    "input_throughput": 1648.1592281873948,
    "output_throughput": 1467.7083800991766,
    "total_throughput": 3115.8676082865713,
    "itl": 23.285991152195244,
    "ttft": 51586.28371045107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.98414799429322,
    "arrivals": 24288,
    "finished_requests": 24099,
    "scheduler_time": 0.7599093172866135
}
#Debug simulation 
Total elapsed time: 2.7017480661161244. Arrivals time: 0.0706351469270885 Scheduler time: 2.2333307452499866 Scheduler overhead time: 0.14441508427262306 Adapter cache time: 0.045774771831929684 Engine time: 0.13750029634684324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6740828468464315,
    "estimated_duration": 3599.938492963599,
    "input_throughput": 1647.5137038014864,
    "output_throughput": 1467.2897912907233,
    "total_throughput": 3114.8034950922097,
    "itl": 23.29319482457918,
    "ttft": 51781.51151201922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.16300575144692,
    "arrivals": 24288,
    "finished_requests": 24097,
    "scheduler_time": 0.7311477771717243
}
#Debug simulation 
Total elapsed time: 2.674163110088557. Arrivals time: 0.07087159901857376 Scheduler time: 2.204471700359136 Scheduler overhead time: 0.14374116947874427 Adapter cache time: 0.04641204513609409 Engine time: 0.13811991410329938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.670470132958144,
    "estimated_duration": 3599.9402150718997,
    "input_throughput": 1648.1534818715033,
    "output_throughput": 1467.7032629261241,
    "total_throughput": 3115.8567447976275,
    "itl": 23.29223288723059,
    "ttft": 51590.466572759135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4896,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.014659510514214,
    "arrivals": 24288,
    "finished_requests": 24099,
    "scheduler_time": 0.7625616869664515
}
#Debug simulation 
Total elapsed time: 2.6705415439791977. Arrivals time: 0.0702929375693202 Scheduler time: 2.1995031079277396 Scheduler overhead time: 0.14653769275173545 Adapter cache time: 0.04578267643228173 Engine time: 0.13779732258990407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.692078759893775,
    "estimated_duration": 3599.9399347212757,
    "input_throughput": 1647.513043980608,
    "output_throughput": 1467.2892036486073,
    "total_throughput": 3114.8022476292153,
    "itl": 23.287193273401858,
    "ttft": 51769.66100469479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.537446318915036,
    "arrivals": 24288,
    "finished_requests": 24097,
    "scheduler_time": 0.7259568641545794
}
#Debug simulation 
Total elapsed time: 2.6921917740255594. Arrivals time: 0.07135609211400151 Scheduler time: 2.213608681689948 Scheduler overhead time: 0.15245712688192725 Adapter cache time: 0.04688708297908306 Engine time: 0.13705285685136914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.7075081137008965,
    "estimated_duration": 3599.9428735001147,
    "input_throughput": 1647.92642785247,
    "output_throughput": 1467.4374526570753,
    "total_throughput": 3115.363880509545,
    "itl": 23.29329508571593,
    "ttft": 51513.11535883838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.36584965087348,
    "arrivals": 24288,
    "finished_requests": 24099,
    "scheduler_time": 0.7215807804361208
}
#Debug simulation 
Total elapsed time: 2.707580940797925. Arrivals time: 0.07096181018278003 Scheduler time: 2.2255308642052114 Scheduler overhead time: 0.1491117742843926 Adapter cache time: 0.04665581835433841 Engine time: 0.14391238242387772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.6863398933783174,
    "estimated_duration": 3599.9465494356373,
    "input_throughput": 1648.4314193304656,
    "output_throughput": 1467.695402540994,
    "total_throughput": 3116.1268218714595,
    "itl": 23.281396521515475,
    "ttft": 50643.74810869792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.827659412421426,
    "arrivals": 24288,
    "finished_requests": 24104,
    "scheduler_time": 0.706354757125573
}
#Debug simulation 
Total elapsed time: 2.6864417479373515. Arrivals time: 0.0709057617932558 Scheduler time: 2.216526528354734 Scheduler overhead time: 0.14490950107574463 Adapter cache time: 0.0461670788936317 Engine time: 0.13760808063670993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 66, 66, 1080, 66, 540, 540, 540, 66, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 540, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 1080, 66, 540, 540, 66, 540, 66, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 66, 540, 1080, 1080, 540, 66, 66, 66, 1080, 540, 540, 540, 540, 1080, 540, 1080, 66, 66, 540, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 1080, 1080, 540, 540, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 540, 1080, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 540, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66]
Prompts retrieved: 72432 . Total input tokens: 16119817 . Total output tokens: 14474454
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6722679678350687,
    "estimated_duration": 3599.9523799266585,
    "input_throughput": 1647.7987411935856,
    "output_throughput": 1467.5885796321659,
    "total_throughput": 3115.3873208257514,
    "itl": 23.29396209662397,
    "ttft": 50773.26942309989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.595501492841855,
    "arrivals": 24288,
    "finished_requests": 24104,
    "scheduler_time": 0.7229312466030721
}
#Debug simulation 
Total elapsed time: 2.672337998636067. Arrivals time: 0.07055087061598897 Scheduler time: 2.2039095568470657 Scheduler overhead time: 0.1447647330351174 Adapter cache time: 0.04604124091565609 Engine time: 0.13671471131965518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.5869288500398397,
    "estimated_duration": 3599.8901381232236,
    "input_throughput": 1622.0381111530817,
    "output_throughput": 1441.0409209611357,
    "total_throughput": 3063.0790321142176,
    "itl": 23.212447208404487,
    "ttft": 48953.70408989415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.017813359476472,
    "arrivals": 23803,
    "finished_requests": 23619,
    "scheduler_time": 0.44651198777159756
}
#Debug simulation 
Total elapsed time: 2.587037878111005. Arrivals time: 0.06922717951238155 Scheduler time: 2.11924859136343 Scheduler overhead time: 0.14641749719157815 Adapter cache time: 0.045721841510385275 Engine time: 0.13586183497682214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.597214997280389,
    "estimated_duration": 3599.886505277088,
    "input_throughput": 1622.0533595823874,
    "output_throughput": 1440.7723666834822,
    "total_throughput": 3062.8257262658694,
    "itl": 23.215821887129,
    "ttft": 48648.10855029365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.036606448424184,
    "arrivals": 23803,
    "finished_requests": 23621,
    "scheduler_time": 0.43001212398803285
}
#Debug simulation 
Total elapsed time: 2.597288749180734. Arrivals time: 0.0695668663829565 Scheduler time: 2.1298831324093044 Scheduler overhead time: 0.14489521319046617 Adapter cache time: 0.04589594854041934 Engine time: 0.13670561742037535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.6096908100880682,
    "estimated_duration": 3599.8949349722993,
    "input_throughput": 1622.3990159437644,
    "output_throughput": 1441.086502164797,
    "total_throughput": 3063.4855181085613,
    "itl": 23.22107195508862,
    "ttft": 48683.08910066651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.045069824809655,
    "arrivals": 23803,
    "finished_requests": 23621,
    "scheduler_time": 0.4410953429508594
}
#Debug simulation 
Total elapsed time: 2.6097959321923554. Arrivals time: 0.07458197511732578 Scheduler time: 2.1368582933209836 Scheduler overhead time: 0.1442973017692566 Adapter cache time: 0.04581825202330947 Engine time: 0.1378918932750821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.575842293910682,
    "estimated_duration": 3599.893847132145,
    "input_throughput": 1621.9489373697822,
    "output_throughput": 1440.7844287219639,
    "total_throughput": 3062.733366091746,
    "itl": 23.213706731542263,
    "ttft": 49235.793834592565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.379828736164015,
    "arrivals": 23803,
    "finished_requests": 23617,
    "scheduler_time": 0.4333432493881271
}
#Debug simulation 
Total elapsed time: 2.575928180012852. Arrivals time: 0.06969558540731668 Scheduler time: 2.1089621582068503 Scheduler overhead time: 0.144033282995224 Adapter cache time: 0.04556462308391929 Engine time: 0.13709365762770176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.5902982209809124,
    "estimated_duration": 3599.87598969449,
    "input_throughput": 1621.865868911639,
    "output_throughput": 1440.6568489711044,
    "total_throughput": 3062.5227178827436,
    "itl": 23.21838998094164,
    "ttft": 48802.69149789133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.244622754155323,
    "arrivals": 23803,
    "finished_requests": 23620,
    "scheduler_time": 0.4308108162742851
}
#Debug simulation 
Total elapsed time: 2.590370420832187. Arrivals time: 0.06959726242348552 Scheduler time: 2.1214445275254548 Scheduler overhead time: 0.14497793465852737 Adapter cache time: 0.04615105874836445 Engine time: 0.13714626617729664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.598635785281658,
    "estimated_duration": 3599.87216857369,
    "input_throughput": 1622.0450967606273,
    "output_throughput": 1440.0175220815997,
    "total_throughput": 3062.062618842227,
    "itl": 23.206397998852772,
    "ttft": 49531.64592242168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.612375791188413,
    "arrivals": 23803,
    "finished_requests": 23616,
    "scheduler_time": 0.4508464183318517
}
#Debug simulation 
Total elapsed time: 2.5987213090993464. Arrivals time: 0.06956449896097183 Scheduler time: 2.128017531707883 Scheduler overhead time: 0.147582673933357 Adapter cache time: 0.04575472604483366 Engine time: 0.13719781814143062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 540, 1080, 1080, 33, 33, 1080, 33, 540, 540, 540, 33, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 540, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 1080, 33, 540, 540, 33, 540, 33, 540, 540, 1080, 1080, 1080, 1080, 540, 540, 33, 540, 1080, 1080, 540, 33, 33, 33, 1080, 540, 540, 540, 540, 1080, 540, 1080, 33, 33, 540, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 1080, 1080, 540, 540, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 540, 1080, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 540, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33]
Prompts retrieved: 71046 . Total input tokens: 15797628 . Total output tokens: 14189361
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.598691739141941,
    "estimated_duration": 3599.8899542216063,
    "input_throughput": 1621.7562409521945,
    "output_throughput": 1440.1090216439607,
    "total_throughput": 3061.8652625961554,
    "itl": 23.211542762411533,
    "ttft": 49138.52541434386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.452987129277318,
    "arrivals": 23803,
    "finished_requests": 23618,
    "scheduler_time": 0.4228481507132703
}
#Debug simulation 
Total elapsed time: 2.5987649452872574. Arrivals time: 0.07070373930037022 Scheduler time: 2.127205647993833 Scheduler overhead time: 0.14599566534161568 Adapter cache time: 0.045948893297463655 Engine time: 0.13791540870442986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.3424035431817174,
    "estimated_duration": 3599.734875662483,
    "input_throughput": 1434.509256476746,
    "output_throughput": 1289.6833128983164,
    "total_throughput": 2724.1925693750622,
    "itl": 22.804946508171103,
    "ttft": 44946.020073731874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.649832819258926,
    "arrivals": 21290,
    "finished_requests": 21138,
    "scheduler_time": 0.08036770905840279
}
#Debug simulation 
Total elapsed time: 2.3425062582828104. Arrivals time: 0.06378352828323841 Scheduler time: 1.8715988011099398 Scheduler overhead time: 0.1458004703745246 Adapter cache time: 0.049690612591803074 Engine time: 0.14078327687457204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3867692830972373,
    "estimated_duration": 3599.7156689694884,
    "input_throughput": 1434.1791060064302,
    "output_throughput": 1288.3342537238902,
    "total_throughput": 2722.5133597303206,
    "itl": 22.8137486963222,
    "ttft": 50543.98307179135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5272,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.218553083690992,
    "arrivals": 21290,
    "finished_requests": 21123,
    "scheduler_time": 0.11031213197809495
}
#Debug simulation 
Total elapsed time: 2.386842596810311. Arrivals time: 0.06317333271726966 Scheduler time: 1.9120541922748089 Scheduler overhead time: 0.15405877213925123 Adapter cache time: 0.04786540009081364 Engine time: 0.13780222414061427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3762367819435894,
    "estimated_duration": 3599.715116561025,
    "input_throughput": 1433.7995738203865,
    "output_throughput": 1288.2980596615726,
    "total_throughput": 2722.097633481959,
    "itl": 22.81603005413129,
    "ttft": 51193.122415373844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.290665200090732,
    "arrivals": 21290,
    "finished_requests": 21119,
    "scheduler_time": 0.10584787001449616
}
#Debug simulation 
Total elapsed time: 2.3763088937848806. Arrivals time: 0.0633499207906425 Scheduler time: 1.9100539349019527 Scheduler overhead time: 0.14397301711142063 Adapter cache time: 0.047571268863976 Engine time: 0.1399615523405373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.352033567149192,
    "estimated_duration": 3599.726698578502,
    "input_throughput": 1434.8319837835497,
    "output_throughput": 1289.4726151940877,
    "total_throughput": 2724.3045989776374,
    "itl": 22.80897956213675,
    "ttft": 44653.58303402864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.078418178517133,
    "arrivals": 21290,
    "finished_requests": 21140,
    "scheduler_time": 0.07935632801457479
}
#Debug simulation 
Total elapsed time: 2.352130729239434. Arrivals time: 0.0635587852448225 Scheduler time: 1.88455515448004 Scheduler overhead time: 0.14510772144421935 Adapter cache time: 0.04950892925262451 Engine time: 0.13816045876592398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3921717437915504,
    "estimated_duration": 3599.7134928018677,
    "input_throughput": 1434.115523450117,
    "output_throughput": 1288.9256351312006,
    "total_throughput": 2723.0411585813176,
    "itl": 22.819421943325036,
    "ttft": 51034.401141916904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.510504502913655,
    "arrivals": 21290,
    "finished_requests": 21120,
    "scheduler_time": 0.11557433957604339
}
#Debug simulation 
Total elapsed time: 2.3922448880039155. Arrivals time: 0.06352627789601684 Scheduler time: 1.9165513515472412 Scheduler overhead time: 0.148434953764081 Adapter cache time: 0.047734880819916725 Engine time: 0.14408497558906674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.3644010862335563,
    "estimated_duration": 3599.714868022488,
    "input_throughput": 1434.4802822776633,
    "output_throughput": 1289.598529383022,
    "total_throughput": 2724.078811660685,
    "itl": 22.807136044859845,
    "ttft": 44764.34100477051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5777,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.273520553651288,
    "arrivals": 21290,
    "finished_requests": 21139,
    "scheduler_time": 0.07940561629994468
}
#Debug simulation 
Total elapsed time: 2.3644822742789984. Arrivals time: 0.06392338871955872 Scheduler time: 1.8961788560263813 Scheduler overhead time: 0.1443282780237496 Adapter cache time: 0.04967242060229182 Engine time: 0.13924873527139425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 135, 135, 1080, 135, 270, 270, 270, 135, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 270, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 1080, 135, 270, 270, 135, 270, 135, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 135, 270, 1080, 1080, 270, 135, 135, 135, 1080, 270, 270, 270, 270, 1080, 270, 1080, 135, 135, 270, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 1080, 1080, 270, 270, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 135, 1080, 135, 135, 1080, 270, 1080, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 270, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135]
Prompts retrieved: 63720 . Total input tokens: 14155558 . Total output tokens: 12743855
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.3982977010309696,
    "estimated_duration": 3599.714745480513,
    "input_throughput": 1434.1975309243148,
    "output_throughput": 1288.8410132566476,
    "total_throughput": 2723.0385441809626,
    "itl": 22.818153711824564,
    "ttft": 51166.41064546175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.697950963451174,
    "arrivals": 21290,
    "finished_requests": 21119,
    "scheduler_time": 0.11882758061311634
}
#Debug simulation 
Total elapsed time: 2.398389648180455. Arrivals time: 0.06354703288525343 Scheduler time: 1.931929330341518 Scheduler overhead time: 0.14567770902067423 Adapter cache time: 0.04734799824655056 Engine time: 0.13880273047834635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.2528246650472283,
    "estimated_duration": 3599.619076487697,
    "input_throughput": 1387.149277159651,
    "output_throughput": 1255.0572446704948,
    "total_throughput": 2642.206521830146,
    "itl": 22.70930545384624,
    "ttft": 33502.03764266147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.395812336512424,
    "arrivals": 20438,
    "finished_requests": 20339,
    "scheduler_time": 0.014665762691822348
}
#Debug simulation 
Total elapsed time: 2.2528949142433703. Arrivals time: 0.061574521008878946 Scheduler time: 1.7866383576765656 Scheduler overhead time: 0.1447415710426867 Adapter cache time: 0.04926670761778951 Engine time: 0.13938018633052707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2745846598409116,
    "estimated_duration": 3599.5986459851247,
    "input_throughput": 1388.0650292978935,
    "output_throughput": 1256.1064287106317,
    "total_throughput": 2644.171458008525,
    "itl": 22.719412388112616,
    "ttft": 31545.89382414847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.62943476100698,
    "arrivals": 20438,
    "finished_requests": 20350,
    "scheduler_time": 0.014247133511008191
}
#Debug simulation 
Total elapsed time: 2.274684068746865. Arrivals time: 0.06416987022385001 Scheduler time: 1.8036999013274908 Scheduler overhead time: 0.14645388582721353 Adapter cache time: 0.049383838661015034 Engine time: 0.1396744642406702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2687170612625778,
    "estimated_duration": 3599.617135075084,
    "input_throughput": 1387.9498325856778,
    "output_throughput": 1255.908289786964,
    "total_throughput": 2643.858122372642,
    "itl": 22.721215304122833,
    "ttft": 31902.296706036595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.59979576671404,
    "arrivals": 20438,
    "finished_requests": 20348,
    "scheduler_time": 0.012290620121328567
}
#Debug simulation 
Total elapsed time: 2.2687897942960262. Arrivals time: 0.06160374544560909 Scheduler time: 1.7980752768926322 Scheduler overhead time: 0.14587034424766898 Adapter cache time: 0.04910589288920164 Engine time: 0.14256512001156807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.2670281431637704,
    "estimated_duration": 3599.6028166313185,
    "input_throughput": 1387.9011809073415,
    "output_throughput": 1255.5701921106995,
    "total_throughput": 2643.471373018041,
    "itl": 22.714856674000735,
    "ttft": 32277.85607726639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.82796020743747,
    "arrivals": 20438,
    "finished_requests": 20346,
    "scheduler_time": 0.01250936525745085
}
#Debug simulation 
Total elapsed time: 2.2671125908382237. Arrivals time: 0.06154093658551574 Scheduler time: 1.798652799334377 Scheduler overhead time: 0.1451922059059143 Adapter cache time: 0.04905727319419384 Engine time: 0.1414092923514545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.25935997068882,
    "estimated_duration": 3599.6116542406694,
    "input_throughput": 1388.1528009037595,
    "output_throughput": 1255.691011744289,
    "total_throughput": 2643.8438126480482,
    "itl": 22.721764285686202,
    "ttft": 32133.449837742097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.800491711552077,
    "arrivals": 20438,
    "finished_requests": 20347,
    "scheduler_time": 0.012415286872040248
}
#Debug simulation 
Total elapsed time: 2.2594407335855067. Arrivals time: 0.06174730183556676 Scheduler time: 1.793506185989827 Scheduler overhead time: 0.14533115923404694 Adapter cache time: 0.04913046024739742 Engine time: 0.13837672350928187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.253444558940828,
    "estimated_duration": 3599.621919678221,
    "input_throughput": 1387.8938153723086,
    "output_throughput": 1255.563528850834,
    "total_throughput": 2643.4573442231426,
    "itl": 22.708082411954216,
    "ttft": 32223.445431207423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.037306580354095,
    "arrivals": 20438,
    "finished_requests": 20346,
    "scheduler_time": 0.015425268750867126
}
#Debug simulation 
Total elapsed time: 2.253515234682709. Arrivals time: 0.06209157686680555 Scheduler time: 1.7850435771979392 Scheduler overhead time: 0.1458264966495335 Adapter cache time: 0.049365177284926176 Engine time: 0.1395462192595005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 66, 66, 1080, 66, 270, 270, 270, 66, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 270, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 1080, 66, 270, 270, 66, 270, 66, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 66, 270, 1080, 1080, 270, 66, 66, 66, 1080, 270, 270, 270, 270, 1080, 270, 1080, 66, 66, 270, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 1080, 1080, 270, 270, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 270, 1080, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 270, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66]
Prompts retrieved: 60822 . Total input tokens: 13485301 . Total output tokens: 12173679
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.2656227219849825,
    "estimated_duration": 3599.6013249794646,
    "input_throughput": 1387.1561179149433,
    "output_throughput": 1255.0634340112022,
    "total_throughput": 2642.2195519261454,
    "itl": 22.720874833198142,
    "ttft": 33536.32119076507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.055252910851017,
    "arrivals": 20438,
    "finished_requests": 20339,
    "scheduler_time": 0.01220517460518789
}
#Debug simulation 
Total elapsed time: 2.2657074336893857. Arrivals time: 0.06194614293053746 Scheduler time: 1.793727797921747 Scheduler overhead time: 0.15003476943820715 Adapter cache time: 0.0492029907181859 Engine time: 0.13889601733535528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.1478094668127596,
    "estimated_duration": 3600.0147543822495,
    "input_throughput": 1369.739386205976,
    "output_throughput": 1205.1478385522564,
    "total_throughput": 2574.887224758232,
    "itl": 22.527999811177366,
    "ttft": 33536.61773847969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.096664029873253,
    "arrivals": 19983,
    "finished_requests": 19870,
    "scheduler_time": 0.006604332430602248
}
#Debug simulation 
Total elapsed time: 2.1478813248686492. Arrivals time: 0.06143245752900839 Scheduler time: 1.6800073855556548 Scheduler overhead time: 0.14644898334518075 Adapter cache time: 0.05015610717236996 Engine time: 0.13793389219790697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1412727828137577,
    "estimated_duration": 3600.0165999696414,
    "input_throughput": 1370.0034049958524,
    "output_throughput": 1205.3333309731383,
    "total_throughput": 2575.3367359689905,
    "itl": 22.534015177971057,
    "ttft": 32798.90962420279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.244681607845607,
    "arrivals": 19983,
    "finished_requests": 19874,
    "scheduler_time": 0.006119352853235067
}
#Debug simulation 
Total elapsed time: 2.141345849726349. Arrivals time: 0.06064854236319661 Scheduler time: 1.6738507431000471 Scheduler overhead time: 0.1449824683368206 Adapter cache time: 0.050139658618718386 Engine time: 0.14014958357438445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.1525778169743717,
    "estimated_duration": 3600.0119089575896,
    "input_throughput": 1369.9749125074634,
    "output_throughput": 1205.4310123814435,
    "total_throughput": 2575.4059248889066,
    "itl": 22.539684194642277,
    "ttft": 32456.55820740432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.272963556311247,
    "arrivals": 19983,
    "finished_requests": 19876,
    "scheduler_time": 0.00776979529732978
}
#Debug simulation 
Total elapsed time: 2.152672365773469. Arrivals time: 0.06305979890748858 Scheduler time: 1.6794571122154593 Scheduler overhead time: 0.14623011276125908 Adapter cache time: 0.04999298742040992 Engine time: 0.14171524485573173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.1444385312497616,
    "estimated_duration": 3600.0198029659146,
    "input_throughput": 1369.3221898220413,
    "output_throughput": 1205.015315867437,
    "total_throughput": 2574.3375056894783,
    "itl": 22.530814285907677,
    "ttft": 33304.98520641217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.620586041498946,
    "arrivals": 19983,
    "finished_requests": 19871,
    "scheduler_time": 0.007443936373908707
}
#Debug simulation 
Total elapsed time: 2.144512876868248. Arrivals time: 0.060790116898715496 Scheduler time: 1.6732967738062143 Scheduler overhead time: 0.1496532578021288 Adapter cache time: 0.050286991987377405 Engine time: 0.13847128301858902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.136663612909615,
    "estimated_duration": 3600.006886139318,
    "input_throughput": 1369.677380058539,
    "output_throughput": 1205.3054722496104,
    "total_throughput": 2574.982852308149,
    "itl": 22.538426747461177,
    "ttft": 33540.141264982296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5890,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.488823077938395,
    "arrivals": 19983,
    "finished_requests": 19870,
    "scheduler_time": 0.009339343448014228
}
#Debug simulation 
Total elapsed time: 2.1367461211048067. Arrivals time: 0.06043440941721201 Scheduler time: 1.668132159858942 Scheduler overhead time: 0.14862615009769797 Adapter cache time: 0.05002413410693407 Engine time: 0.13764647720381618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.143549161963165,
    "estimated_duration": 3600.0019955215685,
    "input_throughput": 1369.6792407709813,
    "output_throughput": 1205.3071096621295,
    "total_throughput": 2574.986350433111,
    "itl": 22.52622676674372,
    "ttft": 33560.14435202334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.641296739924133,
    "arrivals": 19983,
    "finished_requests": 19870,
    "scheduler_time": 0.005424314667443116
}
#Debug simulation 
Total elapsed time: 2.143621535040438. Arrivals time: 0.06091152178123593 Scheduler time: 1.675269524101168 Scheduler overhead time: 0.1465286212041974 Adapter cache time: 0.050275275483727455 Engine time: 0.1384830130264163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 270, 1080, 1080, 33, 33, 1080, 33, 270, 270, 270, 33, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 270, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 1080, 33, 270, 270, 33, 270, 33, 270, 270, 1080, 1080, 1080, 1080, 270, 270, 33, 270, 1080, 1080, 270, 33, 33, 33, 1080, 270, 270, 270, 270, 1080, 270, 1080, 33, 33, 270, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 1080, 1080, 270, 270, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 270, 1080, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 270, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33]
Prompts retrieved: 59436 . Total input tokens: 13178530 . Total output tokens: 11909268
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.146164075937122,
    "estimated_duration": 3599.999914541112,
    "input_throughput": 1369.4436436197586,
    "output_throughput": 1205.2055841654246,
    "total_throughput": 2574.6492277851835,
    "itl": 22.53977842910785,
    "ttft": 33359.11859282108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.802944804987312,
    "arrivals": 19983,
    "finished_requests": 19871,
    "scheduler_time": 0.008613338923504476
}
#Debug simulation 
Total elapsed time: 2.1462359516881406. Arrivals time: 0.060357311740517616 Scheduler time: 1.6780706136487424 Scheduler overhead time: 0.14551548892632127 Adapter cache time: 0.050048965495079756 Engine time: 0.14074102276936173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9906922038644552,
    "estimated_duration": 3600.006039978822,
    "input_throughput": 1274.1159178796775,
    "output_throughput": 1129.0556057022368,
    "total_throughput": 2403.1715235819142,
    "itl": 22.341782045844802,
    "ttft": 27344.28895056629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6237,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.088262058907787,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 4.9721944268566354e-05
}
#Debug simulation 
Total elapsed time: 1.9907866711728275. Arrivals time: 0.057479224633425474 Scheduler time: 1.5217847172170877 Scheduler overhead time: 0.14914561854675412 Adapter cache time: 0.051092111971229315 Engine time: 0.13893493684008718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0284542869776487,
    "estimated_duration": 3600.004225322621,
    "input_throughput": 1274.1165601240214,
    "output_throughput": 1129.0561748259456,
    "total_throughput": 2403.172734949967,
    "itl": 22.352194840531087,
    "ttft": 27360.44338123692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.347680095610638,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 2.028526943176985. Arrivals time: 0.058081324212253094 Scheduler time: 1.5567707340233028 Scheduler overhead time: 0.1448919279500842 Adapter cache time: 0.051386024337261915 Engine time: 0.1451581073924899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.012409931048751,
    "estimated_duration": 3600.010245941606,
    "input_throughput": 1274.1144293049883,
    "output_throughput": 1129.0542866043636,
    "total_throughput": 2403.168715909352,
    "itl": 22.35104285534699,
    "ttft": 27352.891577403258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.396456055957277,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 4.3805190161008066e-05
}
#Debug simulation 
Total elapsed time: 2.01249997317791. Arrivals time: 0.057520678266882896 Scheduler time: 1.5455224751494825 Scheduler overhead time: 0.1468715355731547 Adapter cache time: 0.05146481841802597 Engine time: 0.13876009173691273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 2.016585493925959,
    "estimated_duration": 3600.001182649545,
    "input_throughput": 1274.1176369903767,
    "output_throughput": 1129.0571290891944,
    "total_throughput": 2403.174766079571,
    "itl": 22.346088974569255,
    "ttft": 27359.478913953564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.60674795409212,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 2.0166783309541643. Arrivals time: 0.05907495692372322 Scheduler time: 1.5443121115677059 Scheduler overhead time: 0.1495297010987997 Adapter cache time: 0.051394980400800705 Engine time: 0.1396730737760663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0048852590844035,
    "estimated_duration": 3600.0023922872847,
    "input_throughput": 1274.1172088737783,
    "output_throughput": 1129.056749714415,
    "total_throughput": 2403.1739585881933,
    "itl": 22.3532682565991,
    "ttft": 27349.609818081284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.60774390833354,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 2.004958014935255. Arrivals time: 0.05725286668166518 Scheduler time: 1.537917404435575 Scheduler overhead time: 0.14781605638563633 Adapter cache time: 0.05093814991414547 Engine time: 0.13910922780632973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 2.0155154848471284,
    "estimated_duration": 3600.0188552518925,
    "input_throughput": 1274.111382308041,
    "output_throughput": 1129.0515865133157,
    "total_throughput": 2403.1629688213566,
    "itl": 22.339771440338545,
    "ttft": 27546.343692908198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.62203323665172,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 2.0156064010225236. Arrivals time: 0.05835107062011957 Scheduler time: 1.5467546954751015 Scheduler overhead time: 0.1470053936354816 Adapter cache time: 0.051245035603642464 Engine time: 0.140099267475307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 2.0092566879466176,
    "estimated_duration": 3600.006342022494,
    "input_throughput": 1274.1158109802407,
    "output_throughput": 1129.0555109734867,
    "total_throughput": 2403.1713219537273,
    "itl": 22.354994623995708,
    "ttft": 27334.315767560056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.89268917787661,
    "arrivals": 18589,
    "finished_requests": 18499,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 2.0093487622216344. Arrivals time: 0.058057486079633236 Scheduler time: 1.5371400783769786 Scheduler overhead time: 0.14732214901596308 Adapter cache time: 0.051540442276746035 Engine time: 0.14315086975693703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9635229278355837,
    "estimated_duration": 3599.8175808195797,
    "input_throughput": 1232.0568752237248,
    "output_throughput": 1115.8262633645707,
    "total_throughput": 2347.8831385882954,
    "itl": 22.330157911682434,
    "ttft": 24522.055270239813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.907693282015696,
    "arrivals": 18102,
    "finished_requests": 18024,
    "scheduler_time": 0.002433952421736574
}
#Debug simulation 
Total elapsed time: 1.9635944007895887. Arrivals time: 0.05657574720680714 Scheduler time: 1.4975725137628615 Scheduler overhead time: 0.1459916178137064 Adapter cache time: 0.051371652632951736 Engine time: 0.13992827385663986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9624085831455886,
    "estimated_duration": 3599.818864374297,
    "input_throughput": 1232.056435920395,
    "output_throughput": 1115.8258655045345,
    "total_throughput": 2347.882301424929,
    "itl": 22.33913428027874,
    "ttft": 24519.289098189412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.21218075863739,
    "arrivals": 18102,
    "finished_requests": 18024,
    "scheduler_time": 0.0024364072986303234
}
#Debug simulation 
Total elapsed time: 1.9624877870082855. Arrivals time: 0.05636361334472895 Scheduler time: 1.4899924546480179 Scheduler overhead time: 0.1489010564982891 Adapter cache time: 0.05109312292188406 Engine time: 0.14380883146077394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.978231478948146,
    "estimated_duration": 3599.8159684706584,
    "input_throughput": 1232.0574270590384,
    "output_throughput": 1115.8267631404726,
    "total_throughput": 2347.884190199511,
    "itl": 22.339730029864736,
    "ttft": 24508.540584470473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.233463319502196,
    "arrivals": 18102,
    "finished_requests": 18024,
    "scheduler_time": 0.00015770868358172237
}
#Debug simulation 
Total elapsed time: 1.9783039828762412. Arrivals time: 0.05649369303137064 Scheduler time: 1.5084072519093752 Scheduler overhead time: 0.14814758813008666 Adapter cache time: 0.05129449116066098 Engine time: 0.1413014493882656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.9522260772064328,
    "estimated_duration": 3599.8303832605943,
    "input_throughput": 1232.0524935352028,
    "output_throughput": 1115.8222950387335,
    "total_throughput": 2347.8747885739363,
    "itl": 22.33378153022812,
    "ttft": 24528.800074018865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.484212730364103,
    "arrivals": 18102,
    "finished_requests": 18024,
    "scheduler_time": 0.002426702821036802
}
#Debug simulation 
Total elapsed time: 1.9522979259490967. Arrivals time: 0.05618087714537978 Scheduler time: 1.4865141920745373 Scheduler overhead time: 0.1465824102051556 Adapter cache time: 0.05099279712885618 Engine time: 0.1400567376986146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9693177049048245,
    "estimated_duration": 3599.824981094125,
    "input_throughput": 1232.0543424452758,
    "output_throughput": 1115.823969525082,
    "total_throughput": 2347.878311970358,
    "itl": 22.34086394197439,
    "ttft": 24521.946965254872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.45638476895074,
    "arrivals": 18102,
    "finished_requests": 18024,
    "scheduler_time": 0.002445465472373192
}
#Debug simulation 
Total elapsed time: 1.9693965171463788. Arrivals time: 0.05644520232453942 Scheduler time: 1.499002960510552 Scheduler overhead time: 0.14583887765184045 Adapter cache time: 0.051019920501857996 Engine time: 0.145033179782331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.9619967569597065,
    "estimated_duration": 3599.816006799868,
    "input_throughput": 1231.943241438715,
    "output_throughput": 1115.9598136159238,
    "total_throughput": 2347.9030550546386,
    "itl": 22.328249789259086,
    "ttft": 24310.607958180266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.51738147633018,
    "arrivals": 18102,
    "finished_requests": 18025,
    "scheduler_time": 0.002415417691449466
}
#Debug simulation 
Total elapsed time: 1.9620703677646816. Arrivals time: 0.05557142058387399 Scheduler time: 1.5002396199852228 Scheduler overhead time: 0.14627150259912014 Adapter cache time: 0.05087126465514302 Engine time: 0.13641466293483973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.9590177428908646,
    "estimated_duration": 3599.8326942259773,
    "input_throughput": 1232.0517026010389,
    "output_throughput": 1115.8215787202498,
    "total_throughput": 2347.8732813212887,
    "itl": 22.344109246608426,
    "ttft": 24523.476361486275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.766910881473038,
    "arrivals": 18102,
    "finished_requests": 18024,
    "scheduler_time": 0.0024400646836074246
}
#Debug simulation 
Total elapsed time: 1.959098692983389. Arrivals time: 0.05596037348732352 Scheduler time: 1.4962215842679143 Scheduler overhead time: 0.14620246831327677 Adapter cache time: 0.05110684176906943 Engine time: 0.13768624234944582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8326407219283283,
    "estimated_duration": 3600.0178513482992,
    "input_throughput": 1189.7149338845384,
    "output_throughput": 1034.9887566820053,
    "total_throughput": 2224.7036905665436,
    "itl": 22.101850441555253,
    "ttft": 17248.327309758195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.444058129470438,
    "arrivals": 17157,
    "finished_requests": 17100,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8327195579186082. Arrivals time: 0.054525273852050304 Scheduler time: 1.3676706268452108 Scheduler overhead time: 0.14530184399336576 Adapter cache time: 0.05294831469655037 Engine time: 0.14009337965399027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.796683716122061,
    "estimated_duration": 3600.023594943671,
    "input_throughput": 1189.7130357744268,
    "output_throughput": 1034.9871054270964,
    "total_throughput": 2224.7001412015234,
    "itl": 22.111982215974894,
    "ttft": 17269.716866398787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.79626347916796,
    "arrivals": 17157,
    "finished_requests": 17100,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7967552859336138. Arrivals time: 0.053622476290911436 Scheduler time: 1.3320450554601848 Scheduler overhead time: 0.1463248496875167 Adapter cache time: 0.052306321915239096 Engine time: 0.14042612677440047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8187824059277773,
    "estimated_duration": 3600.0046796471765,
    "input_throughput": 1189.7937311625349,
    "output_throughput": 1034.925599142595,
    "total_throughput": 2224.71933030513,
    "itl": 22.111021129699527,
    "ttft": 17051.394912637752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.83368533054339,
    "arrivals": 17157,
    "finished_requests": 17100,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.818861667998135. Arrivals time: 0.0546336923725903 Scheduler time: 1.349250647239387 Scheduler overhead time: 0.1490970985032618 Adapter cache time: 0.05281650135293603 Engine time: 0.1399327083490789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8195044100284576,
    "estimated_duration": 3600.002957266252,
    "input_throughput": 1189.3109674696702,
    "output_throughput": 1034.793316622402,
    "total_throughput": 2224.1042840920722,
    "itl": 22.10780654950037,
    "ttft": 17878.170929133365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.114593865163187,
    "arrivals": 17157,
    "finished_requests": 17096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8196170050650835. Arrivals time: 0.05489247478544712 Scheduler time: 1.3481611553579569 Scheduler overhead time: 0.14960995502769947 Adapter cache time: 0.053337101358920336 Engine time: 0.14022147376090288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.797649959102273,
    "estimated_duration": 3600.019104092387,
    "input_throughput": 1189.7889639338089,
    "output_throughput": 1034.921452434711,
    "total_throughput": 2224.71041636852,
    "itl": 22.112915183547056,
    "ttft": 17270.71671032859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.064106281119525,
    "arrivals": 17157,
    "finished_requests": 17100,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7977231070399284. Arrivals time: 0.05405405489727855 Scheduler time: 1.3344733910635114 Scheduler overhead time: 0.14519011368975043 Adapter cache time: 0.052664597518742085 Engine time: 0.13915375154465437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.839440198149532,
    "estimated_duration": 3600.016751848378,
    "input_throughput": 1189.7897413396254,
    "output_throughput": 1034.9221286503937,
    "total_throughput": 2224.7118699900193,
    "itl": 22.098917761578683,
    "ttft": 17253.200894050817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.982506120831758,
    "arrivals": 17157,
    "finished_requests": 17100,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.839519590139389. Arrivals time: 0.0549222556874156 Scheduler time: 1.3650405602529645 Scheduler overhead time: 0.15008519776165485 Adapter cache time: 0.053737432695925236 Engine time: 0.14157938584685326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.79265560163185,
    "estimated_duration": 3600.022331037305,
    "input_throughput": 1189.7878974450214,
    "output_throughput": 1034.9205247642094,
    "total_throughput": 2224.708422209231,
    "itl": 22.11592080911438,
    "ttft": 17268.524272895018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.41882854081517,
    "arrivals": 17157,
    "finished_requests": 17100,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7927375948056579. Arrivals time: 0.05395409790799022 Scheduler time: 1.323817417025566 Scheduler overhead time: 0.15046759461984038 Adapter cache time: 0.05233307462185621 Engine time: 0.13838436594232917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.598767161834985,
    "estimated_duration": 3599.538691758152,
    "input_throughput": 922.1651117684455,
    "output_throughput": 838.3118667148208,
    "total_throughput": 1760.4769784832663,
    "itl": 21.64911572252821,
    "ttft": 16272.156983786805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8707,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.647666786424146,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.598837989848107. Arrivals time: 0.04600949212908745 Scheduler time: 1.134198077954352 Scheduler overhead time: 0.1465706112794578 Adapter cache time: 0.060231493320316076 Engine time: 0.1385419862344861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.595289820805192,
    "estimated_duration": 3599.5417830283836,
    "input_throughput": 922.1643198172109,
    "output_throughput": 838.3111467763745,
    "total_throughput": 1760.4754665935855,
    "itl": 21.660601187708306,
    "ttft": 16292.333388919847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8701,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.442666616839173,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5953606530092657. Arrivals time: 0.04670515889301896 Scheduler time: 1.130039413459599 Scheduler overhead time: 0.14657059824094176 Adapter cache time: 0.06049355212599039 Engine time: 0.13851769268512726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.615374774672091,
    "estimated_duration": 3599.5377989314993,
    "input_throughput": 922.1653405015873,
    "output_throughput": 838.3120746490666,
    "total_throughput": 1760.4774151506538,
    "itl": 21.659740517870624,
    "ttft": 16291.89901103592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8700,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.481526854318652,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6154536847025156. Arrivals time: 0.047172939870506525 Scheduler time: 1.1430311887525022 Scheduler overhead time: 0.14667777996510267 Adapter cache time: 0.06126517988741398 Engine time: 0.14366450300440192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.5852528191171587,
    "estimated_duration": 3599.5333365600954,
    "input_throughput": 922.1664837176268,
    "output_throughput": 838.3131139115153,
    "total_throughput": 1760.479597629142,
    "itl": 21.653852812861313,
    "ttft": 16279.035968551167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.35700990962306,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5853248429484665. Arrivals time: 0.045855256263166666 Scheduler time: 1.1190567626617849 Scheduler overhead time: 0.14979646308347583 Adapter cache time: 0.060328735038638115 Engine time: 0.13707920722663403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.574657257180661,
    "estimated_duration": 3599.522350268626,
    "input_throughput": 922.1692983104499,
    "output_throughput": 838.3156725710584,
    "total_throughput": 1760.4849708815084,
    "itl": 21.664822474760307,
    "ttft": 16295.301087544543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8698,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.81224847050332,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.574727727100253. Arrivals time: 0.04761713882908225 Scheduler time: 1.1074933861382306 Scheduler overhead time: 0.14709177752956748 Adapter cache time: 0.06017304724082351 Engine time: 0.139182320330292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6137745366431773,
    "estimated_duration": 3599.538107507208,
    "input_throughput": 922.1652614476044,
    "output_throughput": 838.3120027835286,
    "total_throughput": 1760.477264231133,
    "itl": 21.645645906395124,
    "ttft": 16266.04336692678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.03735796800665,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6138538788072765. Arrivals time: 0.046855637803673744 Scheduler time: 1.1445689839310944 Scheduler overhead time: 0.14684872748330235 Adapter cache time: 0.061123352497816086 Engine time: 0.14122102642431855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.6170802498236299,
    "estimated_duration": 3599.544849679743,
    "input_throughput": 922.163534174419,
    "output_throughput": 838.3104325727389,
    "total_throughput": 1760.473966747158,
    "itl": 21.666006409754598,
    "ttft": 16299.740178288086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.21223499502746,
    "arrivals": 13744,
    "finished_requests": 13709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6171538140624762. Arrivals time: 0.04724589874967933 Scheduler time: 1.1462937435135245 Scheduler overhead time: 0.148112578317523 Adapter cache time: 0.06114513427019119 Engine time: 0.14042307948693633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4756196369417012,
    "estimated_duration": 3599.9256211001334,
    "input_throughput": 862.4917086623428,
    "output_throughput": 768.1130920574334,
    "total_throughput": 1630.6048007197762,
    "itl": 21.495340601784623,
    "ttft": 12484.826519444969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.45641504308899,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.47569023584947. Arrivals time: 0.04452926246449351 Scheduler time: 1.0027353204786777 Scheduler overhead time: 0.14872675715014338 Adapter cache time: 0.06252068979665637 Engine time: 0.1430177208967507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4717337028123438,
    "estimated_duration": 3599.9305175018258,
    "input_throughput": 862.4905355547395,
    "output_throughput": 768.1120473177571,
    "total_throughput": 1630.6025828724964,
    "itl": 21.506807331279113,
    "ttft": 12495.369697146743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.356472060445753,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.471812245901674. Arrivals time: 0.04468740802258253 Scheduler time: 1.0004628929309547 Scheduler overhead time: 0.1475148512981832 Adapter cache time: 0.06319919275119901 Engine time: 0.14203798165544868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.463939858134836,
    "estimated_duration": 3599.933411964399,
    "input_throughput": 862.4898420845306,
    "output_throughput": 768.1114297308968,
    "total_throughput": 1630.6012718154275,
    "itl": 21.509048751325423,
    "ttft": 12494.424670558225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.404024615829293,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4640168682672083. Arrivals time: 0.04448594944551587 Scheduler time: 0.9974334142170846 Scheduler overhead time: 0.14672649232670665 Adapter cache time: 0.06249333918094635 Engine time: 0.13926996104419231 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.460397023241967,
    "estimated_duration": 3599.9319870259314,
    "input_throughput": 862.4901834784675,
    "output_throughput": 768.1117337676196,
    "total_throughput": 1630.6019172460872,
    "itl": 21.498221684830213,
    "ttft": 12489.69067264012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.23077301202251,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.460474211256951. Arrivals time: 0.04428095929324627 Scheduler time: 0.9955321592278779 Scheduler overhead time: 0.14667352382093668 Adapter cache time: 0.06257825065404177 Engine time: 0.13806508760899305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.457439168356359,
    "estimated_duration": 3599.9279286285123,
    "input_throughput": 862.4911558112487,
    "output_throughput": 768.112599702366,
    "total_throughput": 1630.6037555136147,
    "itl": 21.511608358418055,
    "ttft": 12496.337480015285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.74669284172315,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4575214311480522. Arrivals time: 0.04466400993987918 Scheduler time: 0.9823984997346997 Scheduler overhead time: 0.1528933602385223 Adapter cache time: 0.06275421287864447 Engine time: 0.14025744516402483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4725528466515243,
    "estimated_duration": 3599.918507215384,
    "input_throughput": 862.4934130527619,
    "output_throughput": 768.114609944019,
    "total_throughput": 1630.6080229967808,
    "itl": 21.492007547408267,
    "ttft": 12478.83423630473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.81045779288305,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4726254027336836. Arrivals time: 0.0443341163918376 Scheduler time: 1.00249805720523 Scheduler overhead time: 0.14838713500648737 Adapter cache time: 0.0630183294415474 Engine time: 0.14034891687333584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4723337800242007,
    "estimated_duration": 3599.9195870766143,
    "input_throughput": 862.4931543322056,
    "output_throughput": 768.114379534098,
    "total_throughput": 1630.6075338663036,
    "itl": 21.51356508946014,
    "ttft": 12499.340237883618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.205952767987917,
    "arrivals": 12728,
    "finished_requests": 12693,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4724132209084928. Arrivals time: 0.04428308503702283 Scheduler time: 1.0010712682269514 Scheduler overhead time: 0.148406483232975 Adapter cache time: 0.06314025772735476 Engine time: 0.1414662399329245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4177659945562482,
    "estimated_duration": 3599.9370441504184,
    "input_throughput": 839.1074518673673,
    "output_throughput": 733.0078186472147,
    "total_throughput": 1572.115270514582,
    "itl": 21.226690614820463,
    "ttft": 9605.819299772458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.254422851989364,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.417846815660596. Arrivals time: 0.04343845555558801 Scheduler time: 0.9436006816104054 Scheduler overhead time: 0.1536195920780301 Adapter cache time: 0.062409366481006145 Engine time: 0.14004441676661372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.421356476843357,
    "estimated_duration": 3599.9319840710014,
    "input_throughput": 839.1086313203028,
    "output_throughput": 733.0088489660629,
    "total_throughput": 1572.1174802863657,
    "itl": 21.23884240012204,
    "ttft": 9615.800278519031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.165926032208965,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.421429059933871. Arrivals time: 0.04397791810333729 Scheduler time: 0.9425773513503373 Scheduler overhead time: 0.15542023163288832 Adapter cache time: 0.06216253759339452 Engine time: 0.14179292134940624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.420458648353815,
    "estimated_duration": 3599.9437549035533,
    "input_throughput": 839.105887664328,
    "output_throughput": 733.0064522273893,
    "total_throughput": 1572.1123398917173,
    "itl": 21.238988887195056,
    "ttft": 9616.168403985788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9229,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.21329467084393,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4205290493555367. Arrivals time: 0.04382278537377715 Scheduler time: 0.9517571884207428 Scheduler overhead time: 0.1461140443570912 Adapter cache time: 0.06284638587385416 Engine time: 0.1415345724672079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.4143419587053359,
    "estimated_duration": 3599.9428175858593,
    "input_throughput": 839.1061061424638,
    "output_throughput": 733.0066430803979,
    "total_throughput": 1572.1127492228616,
    "itl": 21.23218289244448,
    "ttft": 9610.8938411946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.082591013837654,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4144272110424936. Arrivals time: 0.04387796018272638 Scheduler time: 0.944826165214181 Scheduler overhead time: 0.14754385221749544 Adapter cache time: 0.06259692599996924 Engine time: 0.1418085559271276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3892354727722704,
    "estimated_duration": 3599.9367610482104,
    "input_throughput": 839.1075178555188,
    "output_throughput": 733.0078762915973,
    "total_throughput": 1572.1153941471161,
    "itl": 21.241297478351523,
    "ttft": 9617.64645186984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.54001246394555,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3893107459880412. Arrivals time: 0.04300447320565581 Scheduler time: 0.9214798551984131 Scheduler overhead time: 0.14856304042041302 Adapter cache time: 0.06170788500458002 Engine time: 0.14055123925209045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4023060840554535,
    "estimated_duration": 3599.9298904350317,
    "input_throughput": 839.109119326477,
    "output_throughput": 733.0092752670574,
    "total_throughput": 1572.1183945935343,
    "itl": 21.223238294113095,
    "ttft": 9602.72720202739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9230,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.598164221945066,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4023786266334355. Arrivals time: 0.0430733161047101 Scheduler time: 0.932896098587662 Scheduler overhead time: 0.15142781287431717 Adapter cache time: 0.061770472675561905 Engine time: 0.13918806705623865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4041511011309922,
    "estimated_duration": 3599.9308312541107,
    "input_throughput": 839.1089000306332,
    "output_throughput": 733.0090836997347,
    "total_throughput": 1572.117983730368,
    "itl": 21.246090254341844,
    "ttft": 9619.628182839087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.98986292972902,
    "arrivals": 12269,
    "finished_requests": 12242,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4042208278551698. Arrivals time: 0.043404520489275455 Scheduler time: 0.9368184767663479 Scheduler overhead time: 0.14739867765456438 Adapter cache time: 0.06222589174285531 Engine time: 0.14050805009901524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2972029908560216,
    "estimated_duration": 3599.9952287373294,
    "input_throughput": 728.1717984163665,
    "output_throughput": 658.6528173904446,
    "total_throughput": 1386.8246158068112,
    "itl": 20.976020540590746,
    "ttft": 6283.397328668922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.97664047823632,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2972771557979286. Arrivals time: 0.039832284674048424 Scheduler time: 0.8383327117189765 Scheduler overhead time: 0.14865581970661879 Adapter cache time: 0.05687846848741174 Engine time: 0.13863323582336307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2890749461948872,
    "estimated_duration": 3599.995719593623,
    "input_throughput": 728.1716991307735,
    "output_throughput": 658.6527275837043,
    "total_throughput": 1386.8244267144778,
    "itl": 20.883999204187454,
    "ttft": 5905.494836986286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.162957503301367,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2891464671120048. Arrivals time: 0.03935194993391633 Scheduler time: 0.8269842811860144 Scheduler overhead time: 0.1477684574201703 Adapter cache time: 0.05806227307766676 Engine time: 0.1422979710623622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2859570793807507,
    "estimated_duration": 3600.005064893079,
    "input_throughput": 728.1698088604929,
    "output_throughput": 658.6510177786163,
    "total_throughput": 1386.820826639109,
    "itl": 20.883012020233476,
    "ttft": 5905.178450269891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.210267503858372,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.286031219176948. Arrivals time: 0.0399147872813046 Scheduler time: 0.8249110621400177 Scheduler overhead time: 0.1493417895399034 Adapter cache time: 0.05775974923744798 Engine time: 0.13884173659607768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3124124691821635,
    "estimated_duration": 3600.0172027498957,
    "input_throughput": 728.1673537553143,
    "output_throughput": 658.648797063743,
    "total_throughput": 1386.8161508190574,
    "itl": 20.971156006366176,
    "ttft": 6296.865052928913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.61380784791464,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3124701883643866. Arrivals time: 0.0397465955466032 Scheduler time: 0.8496445044875145 Scheduler overhead time: 0.14916114136576653 Adapter cache time: 0.05775071540847421 Engine time: 0.1413284596055746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3063319739885628,
    "estimated_duration": 3599.999115843832,
    "input_throughput": 728.1710121713588,
    "output_throughput": 658.6521062087006,
    "total_throughput": 1386.8231183800594,
    "itl": 20.885924406093945,
    "ttft": 5905.668959710053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.51125091450238,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3063942580483854. Arrivals time: 0.0395757295191288 Scheduler time: 0.8384247589856386 Scheduler overhead time: 0.1478822291828692 Adapter cache time: 0.05862651392817497 Engine time: 0.14658371964469552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3045875187963247,
    "estimated_duration": 3600.0132007135535,
    "input_throughput": 728.1681632390718,
    "output_throughput": 658.64952926562,
    "total_throughput": 1386.8176925046916,
    "itl": 20.971075531778773,
    "ttft": 6281.354451456886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.410770607580407,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3046556701883674. Arrivals time: 0.03941263351589441 Scheduler time: 0.8407297600060701 Scheduler overhead time: 0.1490872115828097 Adapter cache time: 0.05756365414708853 Engine time: 0.14348048996180296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2790389293804765,
    "estimated_duration": 3600.0083768979807,
    "input_throughput": 728.1691389448362,
    "output_throughput": 658.6504118201931,
    "total_throughput": 1386.8195507650294,
    "itl": 20.885943954000417,
    "ttft": 5906.423366037355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.922285442536275,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.279125327244401. Arrivals time: 0.040263595059514046 Scheduler time: 0.8202888392843306 Scheduler overhead time: 0.14824430737644434 Adapter cache time: 0.057525817304849625 Engine time: 0.13789277290925384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2687697536312044,
    "estimated_duration": 3600.016167003953,
    "input_throughput": 705.6079423426686,
    "output_throughput": 630.8030005014992,
    "total_throughput": 1336.410942844168,
    "itl": 20.664889118670736,
    "ttft": 4898.7624711818935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7771,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.783050258102158,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2688396526500583. Arrivals time: 0.03883181978017092 Scheduler time: 0.805470572784543 Scheduler overhead time: 0.15035953279584646 Adapter cache time: 0.05637661088258028 Engine time: 0.14215407148003578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2673247870989144,
    "estimated_duration": 3600.0078024203167,
    "input_throughput": 705.609581815962,
    "output_throughput": 630.804466166227,
    "total_throughput": 1336.414047982189,
    "itl": 20.674627124789758,
    "ttft": 4550.07076589146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7773,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.40925910659831,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2673958824016154. Arrivals time: 0.03847594512626529 Scheduler time: 0.8036671709269285 Scheduler overhead time: 0.15348582714796066 Adapter cache time: 0.05606834404170513 Engine time: 0.1406769142486155 
