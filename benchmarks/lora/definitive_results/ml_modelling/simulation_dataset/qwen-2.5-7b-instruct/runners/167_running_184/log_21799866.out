INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.65005617402494,
    "estimated_duration": 3600.093046462914,
    "input_throughput": 7256.702163758678,
    "output_throughput": 6447.5450218725655,
    "total_throughput": 13704.247185631244,
    "itl": 118.2357929673279,
    "ttft": 2051193.425979315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.159603830657439,
    "arrivals": 2000260,
    "finished_requests": 105822,
    "scheduler_time": 237.688127878995
}
#Debug simulation 
Total elapsed time: 101.650270473212. Arrivals time: 0.5760056413710117 Scheduler time: 100.8755109673366 Scheduler overhead time: 0.07461950043216348 Adapter cache time: 0.02065375493839383 Engine time: 0.07459300989285111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.00331595167518,
    "estimated_duration": 3600.096868721258,
    "input_throughput": 7256.694459246437,
    "output_throughput": 6447.53817645044,
    "total_throughput": 13704.232635696877,
    "itl": 118.23588771614956,
    "ttft": 2051194.854714658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1635356229730025,
    "arrivals": 2000260,
    "finished_requests": 105822,
    "scheduler_time": 237.6881314500276
}
#Debug simulation 
Total elapsed time: 102.0035933079198. Arrivals time: 0.5922157978639007 Scheduler time: 101.21407073596492 Scheduler overhead time: 0.07442816812545061 Adapter cache time: 0.021083259023725986 Engine time: 0.07401358895003796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 101.8445818927139,
    "estimated_duration": 3600.002134344245,
    "input_throughput": 7256.88541980788,
    "output_throughput": 6447.707843992186,
    "total_throughput": 13704.593263800067,
    "itl": 118.23339179492031,
    "ttft": 2051156.229237576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 662,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0697128606005424,
    "arrivals": 2000260,
    "finished_requests": 105822,
    "scheduler_time": 237.68755915048197
}
#Debug simulation 
Total elapsed time: 101.84474874986336. Arrivals time: 0.5580633427016437 Scheduler time: 101.08815340558067 Scheduler overhead time: 0.07501078816130757 Adapter cache time: 0.020994904451072216 Engine time: 0.07484968239441514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 102.77306800987571,
    "estimated_duration": 3600.0388746067133,
    "input_throughput": 7189.437642621987,
    "output_throughput": 6382.336080331935,
    "total_throughput": 13571.773722953922,
    "itl": 117.42833998506447,
    "ttft": 2055850.8489165988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.07084027839825,
    "arrivals": 2000260,
    "finished_requests": 104912,
    "scheduler_time": 240.08635062901095
}
#Debug simulation 
Total elapsed time: 102.77331511909142. Arrivals time: 0.5737413316965103 Scheduler time: 101.99888266669586 Scheduler overhead time: 0.0756634664721787 Adapter cache time: 0.020922184456139803 Engine time: 0.07559616724029183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.17788084316999,
    "estimated_duration": 3600.1231965088036,
    "input_throughput": 7185.734372947795,
    "output_throughput": 6362.956140560504,
    "total_throughput": 13548.690513508298,
    "itl": 116.70886283442867,
    "ttft": 2059107.9851163945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8358908810699075,
    "arrivals": 2000260,
    "finished_requests": 104817,
    "scheduler_time": 240.79329352431836
}
#Debug simulation 
Total elapsed time: 106.17804818833247. Arrivals time: 0.5853634276427329 Scheduler time: 105.39253663131967 Scheduler overhead time: 0.07630744995549321 Adapter cache time: 0.02089838869869709 Engine time: 0.0749675570987165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.78602716699243,
    "estimated_duration": 3600.0648025858877,
    "input_throughput": 7189.385863668081,
    "output_throughput": 6382.290114193532,
    "total_throughput": 13571.675977861612,
    "itl": 117.42902695555902,
    "ttft": 2055861.4566323918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0971228197589498,
    "arrivals": 2000260,
    "finished_requests": 104912,
    "scheduler_time": 240.08644848697168
}
#Debug simulation 
Total elapsed time: 102.7861866960302. Arrivals time: 0.5829424280673265 Scheduler time: 102.00373275345191 Scheduler overhead time: 0.07587172649800777 Adapter cache time: 0.02087575849145651 Engine time: 0.07489597145467997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.65611506206915,
    "estimated_duration": 3600.0653289810566,
    "input_throughput": 7232.819024250827,
    "output_throughput": 6407.648720788362,
    "total_throughput": 13640.46774503919,
    "itl": 120.91582162677143,
    "ttft": 2063175.924801962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.726115087578097,
    "arrivals": 1885868,
    "finished_requests": 105629,
    "scheduler_time": 238.3498039376894
}
#Debug simulation 
Total elapsed time: 106.6562829320319. Arrivals time: 0.5927993268705904 Scheduler time: 105.8642825554125 Scheduler overhead time: 0.07597432099282742 Adapter cache time: 0.020255118142813444 Engine time: 0.07494196156039834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.38368008285761,
    "estimated_duration": 3600.0762638822366,
    "input_throughput": 7276.546961744283,
    "output_throughput": 6454.866590781797,
    "total_throughput": 13731.41355252608,
    "itl": 121.73072364321968,
    "ttft": 2052752.1995138223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.903368686756591,
    "arrivals": 1885868,
    "finished_requests": 106246,
    "scheduler_time": 236.44030016202132
}
#Debug simulation 
Total elapsed time: 104.38384588016197. Arrivals time: 0.5907485475763679 Scheduler time: 103.5925203282386 Scheduler overhead time: 0.07658858550712466 Adapter cache time: 0.020074271131306887 Engine time: 0.07587298285216093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.94140698760748,
    "estimated_duration": 3600.079757918172,
    "input_throughput": 7276.539899535032,
    "output_throughput": 6454.860326049528,
    "total_throughput": 13731.40022558456,
    "itl": 121.73077543129637,
    "ttft": 2052754.1121608887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.906572506688547,
    "arrivals": 1885868,
    "finished_requests": 106246,
    "scheduler_time": 236.4403641679411
}
#Debug simulation 
Total elapsed time: 103.94157668575644. Arrivals time: 0.733468683436513 Scheduler time: 103.00870439177379 Scheduler overhead time: 0.07597786793485284 Adapter cache time: 0.0203532287850976 Engine time: 0.07524784374982119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 107.50622953288257,
    "estimated_duration": 3600.0884236871566,
    "input_throughput": 7221.071523952953,
    "output_throughput": 6398.252845247795,
    "total_throughput": 13619.324369200749,
    "itl": 120.71942016794397,
    "ttft": 2063986.8383501747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7989550066646092,
    "arrivals": 1885868,
    "finished_requests": 105505,
    "scheduler_time": 239.28775935499684
}
#Debug simulation 
Total elapsed time: 107.5063910977915. Arrivals time: 0.6014753435738385 Scheduler time: 106.70276458188891 Scheduler overhead time: 0.07707002852112055 Adapter cache time: 0.02017125254496932 Engine time: 0.07588109094649553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 104.68022904312238,
    "estimated_duration": 3600.020103153492,
    "input_throughput": 7276.399644839186,
    "output_throughput": 6454.555900853334,
    "total_throughput": 13730.95554569252,
    "itl": 121.73108734172172,
    "ttft": 2052772.4902581507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9309687412530219,
    "arrivals": 1885868,
    "finished_requests": 106242,
    "scheduler_time": 236.4336671931349
}
#Debug simulation 
Total elapsed time: 104.68040371220559. Arrivals time: 1.0860667200759053 Scheduler time: 103.39505833433941 Scheduler overhead time: 0.07527240598574281 Adapter cache time: 0.020415698178112507 Engine time: 0.07532833656296134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.59958506422117,
    "estimated_duration": 3600.02608295264,
    "input_throughput": 7232.897873518698,
    "output_throughput": 6407.718574383303,
    "total_throughput": 13640.616447902003,
    "itl": 120.91495282672594,
    "ttft": 2063158.9166676963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.686388366324804,
    "arrivals": 1885868,
    "finished_requests": 105629,
    "scheduler_time": 238.34949289522189
}
#Debug simulation 
Total elapsed time: 106.59974049497396. Arrivals time: 0.5956464279443026 Scheduler time: 105.80450398707762 Scheduler overhead time: 0.07576553290709853 Adapter cache time: 0.02023359900340438 Engine time: 0.07521024346351624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.46796490624547,
    "estimated_duration": 3600.0449396603362,
    "input_throughput": 7276.349445368733,
    "output_throughput": 6454.511371236484,
    "total_throughput": 13730.860816605216,
    "itl": 121.73169253259749,
    "ttft": 2052782.799512822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9558679909631564,
    "arrivals": 1885868,
    "finished_requests": 106242,
    "scheduler_time": 236.4338306603503
}
#Debug simulation 
Total elapsed time: 104.46812175493687. Arrivals time: 0.7326684105210006 Scheduler time: 103.53661775868386 Scheduler overhead time: 0.07539810985326767 Adapter cache time: 0.019949947483837605 Engine time: 0.07521115057170391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.1834188150242,
    "estimated_duration": 3600.0222295386056,
    "input_throughput": 7319.729523830546,
    "output_throughput": 6446.750192143812,
    "total_throughput": 13766.479715974358,
    "itl": 121.3885413797255,
    "ttft": 2059461.6458573155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7567199650174257,
    "arrivals": 1866718,
    "finished_requests": 106263,
    "scheduler_time": 236.24209352981012
}
#Debug simulation 
Total elapsed time: 105.18357448885217. Arrivals time: 0.7242972934618592 Scheduler time: 104.25828351126984 Scheduler overhead time: 0.07577711530029774 Adapter cache time: 0.019893293734639883 Engine time: 0.07669383008033037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.68334496859461,
    "estimated_duration": 3600.0309394782917,
    "input_throughput": 7220.866275045732,
    "output_throughput": 6362.26393190922,
    "total_throughput": 13583.130206954953,
    "itl": 119.32164344727317,
    "ttft": 2057417.702226247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7940735487453698,
    "arrivals": 1866718,
    "finished_requests": 104862,
    "scheduler_time": 241.2269653904754
}
#Debug simulation 
Total elapsed time: 107.68350533070043. Arrivals time: 0.5875635375268757 Scheduler time: 106.89253758545965 Scheduler overhead time: 0.07732697948813438 Adapter cache time: 0.01981611829251051 Engine time: 0.07738013565540314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.66843820223585,
    "estimated_duration": 3600.034375680497,
    "input_throughput": 7220.859382790262,
    "output_throughput": 6362.257859182388,
    "total_throughput": 13583.11724197265,
    "itl": 119.3217161256009,
    "ttft": 2057419.3244916068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.797367949821066,
    "arrivals": 1866718,
    "finished_requests": 104862,
    "scheduler_time": 241.22699408655714
}
#Debug simulation 
Total elapsed time: 107.66860552597791. Arrivals time: 0.5747477728873491 Scheduler time: 106.89308474678546 Scheduler overhead time: 0.07607091218233109 Adapter cache time: 0.019930923357605934 Engine time: 0.0757820033468306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.29111290397123,
    "estimated_duration": 3600.0972187880225,
    "input_throughput": 7297.575705148456,
    "output_throughput": 6426.410342270886,
    "total_throughput": 13723.986047419343,
    "itl": 121.26838156067518,
    "ttft": 2057050.9126090978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7913405248010437,
    "arrivals": 1866718,
    "finished_requests": 105931,
    "scheduler_time": 237.37439747288823
}
#Debug simulation 
Total elapsed time: 104.29127659322694. Arrivals time: 0.7299760980531573 Scheduler time: 103.36115894000977 Scheduler overhead time: 0.0757681131362915 Adapter cache time: 0.01988244941458106 Engine time: 0.07646632194519043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 108.44768339581788,
    "estimated_duration": 3600.0569095658607,
    "input_throughput": 7220.814185166545,
    "output_throughput": 6362.218035814909,
    "total_throughput": 13583.032220981453,
    "itl": 119.32221784527873,
    "ttft": 2057429.2746596548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8197521238029049,
    "arrivals": 1866718,
    "finished_requests": 104862,
    "scheduler_time": 241.227143797951
}
#Debug simulation 
Total elapsed time: 108.44784634606913. Arrivals time: 0.5763092404231429 Scheduler time: 107.66867286991328 Scheduler overhead time: 0.0763586275279522 Adapter cache time: 0.019975730683654547 Engine time: 0.07765761809423566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.52874907618389,
    "estimated_duration": 3600.1237793956057,
    "input_throughput": 7319.563330243023,
    "output_throughput": 6446.751673603951,
    "total_throughput": 13766.315003846974,
    "itl": 121.38692645024899,
    "ttft": 2059517.73807982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7162888692738247,
    "arrivals": 1866718,
    "finished_requests": 106267,
    "scheduler_time": 236.25062036256864
}
#Debug simulation 
Total elapsed time: 105.52892037434503. Arrivals time: 1.0879740677773952 Scheduler time: 104.2396942479536 Scheduler overhead time: 0.07615416124463081 Adapter cache time: 0.01995399221777916 Engine time: 0.07676333980634809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.72224116092548,
    "estimated_duration": 3600.081193225262,
    "input_throughput": 7220.765478544983,
    "output_throughput": 6362.17512068952,
    "total_throughput": 13582.940599234502,
    "itl": 119.32281731223331,
    "ttft": 2057440.1110679815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8433938356488908,
    "arrivals": 1866718,
    "finished_requests": 104862,
    "scheduler_time": 241.2275595354587
}
#Debug simulation 
Total elapsed time: 107.72239825688303. Arrivals time: 0.5862903571687639 Scheduler time: 106.93392325751483 Scheduler overhead time: 0.07672470109537244 Adapter cache time: 0.019975371658802032 Engine time: 0.07661231001839042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 98.9829251668416,
    "estimated_duration": 3600.0265997049014,
    "input_throughput": 7331.069165478774,
    "output_throughput": 6486.557905409414,
    "total_throughput": 13817.627070888188,
    "itl": 122.21366117549782,
    "ttft": 2053155.5520021552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9372887419094644,
    "arrivals": 1857211,
    "finished_requests": 106912,
    "scheduler_time": 233.7955429941734
}
#Debug simulation 
Total elapsed time: 98.98309418186545. Arrivals time: 0.6057325326837599 Scheduler time: 98.1793257589452 Scheduler overhead time: 0.07431709626689553 Adapter cache time: 0.020595623180270195 Engine time: 0.07543896045535803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.22608505515382,
    "estimated_duration": 3600.0446055053285,
    "input_throughput": 7316.422679796992,
    "output_throughput": 6469.138178006258,
    "total_throughput": 13785.56085780325,
    "itl": 122.37521614817722,
    "ttft": 2051845.1144534005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.064720465736469,
    "arrivals": 1857211,
    "finished_requests": 106575,
    "scheduler_time": 235.0251027423504
}
#Debug simulation 
Total elapsed time: 102.22624699305743. Arrivals time: 0.5822788374498487 Scheduler time: 101.44408761523664 Scheduler overhead time: 0.07541159214451909 Adapter cache time: 0.02086322195827961 Engine time: 0.07562164589762688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.551167414058,
    "estimated_duration": 3600.0484148685828,
    "input_throughput": 7316.414937981189,
    "output_throughput": 6469.131332737967,
    "total_throughput": 13785.546270719156,
    "itl": 122.3753271205156,
    "ttft": 2051846.447184526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.068528626468042,
    "arrivals": 1857211,
    "finished_requests": 106575,
    "scheduler_time": 235.02510394485157
}
#Debug simulation 
Total elapsed time: 102.55133395874873. Arrivals time: 0.5976179521530867 Scheduler time: 101.75409722467884 Scheduler overhead time: 0.07569808606058359 Adapter cache time: 0.021063754800707102 Engine time: 0.07479898072779179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.34691503597423,
    "estimated_duration": 3600.121273038955,
    "input_throughput": 7283.112431895092,
    "output_throughput": 6464.846107907255,
    "total_throughput": 13747.958539802346,
    "itl": 121.63781179109095,
    "ttft": 2053685.2078395814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 544,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7009517083829184,
    "arrivals": 1857211,
    "finished_requests": 106439,
    "scheduler_time": 236.01349882982305
}
#Debug simulation 
Total elapsed time: 104.34707638900727. Arrivals time: 0.6016853414475918 Scheduler time: 103.54783316422254 Scheduler overhead time: 0.07502603903412819 Adapter cache time: 0.01983342133462429 Engine time: 0.07445430336520076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.04957397235557,
    "estimated_duration": 3600.1003468325193,
    "input_throughput": 7332.718106934503,
    "output_throughput": 6496.362252951394,
    "total_throughput": 13829.080359885897,
    "itl": 121.89671836848818,
    "ttft": 2049769.5109320853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8509335436113221,
    "arrivals": 1857211,
    "finished_requests": 106989,
    "scheduler_time": 234.5086621563029
}
#Debug simulation 
Total elapsed time: 103.04973085224628. Arrivals time: 0.5948821837082505 Scheduler time: 102.2553505091928 Scheduler overhead time: 0.07666114205494523 Adapter cache time: 0.020114227198064327 Engine time: 0.07512343162670732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.09169028606266,
    "estimated_duration": 3600.127941974423,
    "input_throughput": 7331.529163800901,
    "output_throughput": 6486.902792458012,
    "total_throughput": 13818.431956258913,
    "itl": 122.21405966467849,
    "ttft": 2053157.4933542726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8927018366730468,
    "arrivals": 1857211,
    "finished_requests": 106920,
    "scheduler_time": 233.80417247787182
}
#Debug simulation 
Total elapsed time: 99.09184835292399. Arrivals time: 0.6031732582487166 Scheduler time: 98.29221573658288 Scheduler overhead time: 0.07406824734061956 Adapter cache time: 0.020457067526876926 Engine time: 0.0739859794266522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.16865651402622,
    "estimated_duration": 3600.010498115022,
    "input_throughput": 7332.530283959354,
    "output_throughput": 6496.18050065275,
    "total_throughput": 13828.710784612105,
    "itl": 121.8984867002183,
    "ttft": 2049695.20779975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8749525168165528,
    "arrivals": 1857211,
    "finished_requests": 106984,
    "scheduler_time": 234.5009902730005
}
#Debug simulation 
Total elapsed time: 103.16881549591199. Arrivals time: 0.5864138077013195 Scheduler time: 102.38452242081985 Scheduler overhead time: 0.07560012815520167 Adapter cache time: 0.019979955162853003 Engine time: 0.07490947050973773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 102.56882975483313,
    "estimated_duration": 3600.0791290102584,
    "input_throughput": 7373.440429710166,
    "output_throughput": 6484.16525400586,
    "total_throughput": 13857.605683716027,
    "itl": 121.32029874303156,
    "ttft": 2043387.1988760359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6587843572115741,
    "arrivals": 1852456,
    "finished_requests": 106800,
    "scheduler_time": 235.5606954010914
}
#Debug simulation 
Total elapsed time: 102.56898324890062. Arrivals time: 0.5893745617941022 Scheduler time: 101.78236800944433 Scheduler overhead time: 0.07395871682092547 Adapter cache time: 0.019519280176609755 Engine time: 0.07593924645334482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.01930695120245,
    "estimated_duration": 3600.1207469295714,
    "input_throughput": 7381.726299781768,
    "output_throughput": 6471.79265303009,
    "total_throughput": 13853.518952811857,
    "itl": 121.31864771700164,
    "ttft": 2048826.4636962023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8242527639470114,
    "arrivals": 1852456,
    "finished_requests": 106860,
    "scheduler_time": 234.66890915489182
}
#Debug simulation 
Total elapsed time: 104.01946983207017. Arrivals time: 1.0809784019365907 Scheduler time: 102.73935458017513 Scheduler overhead time: 0.07559365592896938 Adapter cache time: 0.019766119308769703 Engine time: 0.07577678235247731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.24566160375252,
    "estimated_duration": 3600.1237357033165,
    "input_throughput": 7381.720171573023,
    "output_throughput": 6471.78728023588,
    "total_throughput": 13853.507451808902,
    "itl": 121.31873946328695,
    "ttft": 2048827.4275028608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8274575994163864,
    "arrivals": 1852456,
    "finished_requests": 106860,
    "scheduler_time": 234.66891930320992
}
#Debug simulation 
Total elapsed time: 105.24581490876153. Arrivals time: 0.584317590110004 Scheduler time: 104.46232245629653 Scheduler overhead time: 0.07538082078099251 Adapter cache time: 0.019603269640356302 Engine time: 0.07450877875089645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 102.70246411720291,
    "estimated_duration": 3600.027224207295,
    "input_throughput": 7373.047854060229,
    "output_throughput": 6484.161242736164,
    "total_throughput": 13857.209096796394,
    "itl": 121.3237418792273,
    "ttft": 2043327.2820146666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6945630124746736,
    "arrivals": 1852456,
    "finished_requests": 106796,
    "scheduler_time": 235.55409843326083
}
#Debug simulation 
Total elapsed time: 102.70262436103076. Arrivals time: 1.080260343849659 Scheduler time: 101.42524369014427 Scheduler overhead time: 0.07495125150308013 Adapter cache time: 0.0197944943793118 Engine time: 0.0747096398845315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.81474410835654,
    "estimated_duration": 3600.005073540444,
    "input_throughput": 7381.543763733104,
    "output_throughput": 6471.7111570865845,
    "total_throughput": 13853.254920819689,
    "itl": 121.31894119813086,
    "ttft": 2048800.7349960508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8505962961167144,
    "arrivals": 1852456,
    "finished_requests": 106854,
    "scheduler_time": 234.66023324846086
}
#Debug simulation 
Total elapsed time: 103.81490087229759. Arrivals time: 0.5802054069936275 Scheduler time: 103.03733276575804 Scheduler overhead time: 0.07470666524022818 Adapter cache time: 0.01964042102918029 Engine time: 0.07448146631941199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.05705131683499,
    "estimated_duration": 3600.0415100170007,
    "input_throughput": 7373.517479212245,
    "output_throughput": 6484.233010938188,
    "total_throughput": 13857.750490150434,
    "itl": 121.3199282849239,
    "ttft": 2043371.3168528755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6206072598369585,
    "arrivals": 1852456,
    "finished_requests": 106800,
    "scheduler_time": 235.5604617699127
}
#Debug simulation 
Total elapsed time: 103.0572193809785. Arrivals time: 0.5926230633631349 Scheduler time: 102.2656966005452 Scheduler overhead time: 0.07498346362262964 Adapter cache time: 0.01969498163089156 Engine time: 0.07557678828015924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.00327868433669,
    "estimated_duration": 3600.049380758424,
    "input_throughput": 7391.756108188137,
    "output_throughput": 6513.052050152808,
    "total_throughput": 13904.808158340946,
    "itl": 122.00581203083601,
    "ttft": 2042114.7153105326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 552,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8522588810324634,
    "arrivals": 1852456,
    "finished_requests": 107021,
    "scheduler_time": 234.72823738479744
}
#Debug simulation 
Total elapsed time: 104.0034389491193. Arrivals time: 0.5724778161384165 Scheduler time: 103.23198641370982 Scheduler overhead time: 0.07637458248063922 Adapter cache time: 0.019156206399202347 Engine time: 0.0744623327627778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.59664360806346,
    "estimated_duration": 3600.0960709731785,
    "input_throughput": 7325.034243564349,
    "output_throughput": 6485.634144115582,
    "total_throughput": 13810.66838767993,
    "itl": 122.16050458835038,
    "ttft": 2053970.5935416922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6710263081873056,
    "arrivals": 1850068,
    "finished_requests": 107017,
    "scheduler_time": 233.93605857518818
}
#Debug simulation 
Total elapsed time: 103.59681516699493. Arrivals time: 0.5907053025439382 Scheduler time: 102.80868902336806 Scheduler overhead time: 0.07435171399265528 Adapter cache time: 0.019657109398394823 Engine time: 0.07489758217707276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.70203039608896,
    "estimated_duration": 3600.0465083529866,
    "input_throughput": 7355.778859677862,
    "output_throughput": 6513.1325235926515,
    "total_throughput": 13868.911383270513,
    "itl": 122.87825528497959,
    "ttft": 2053018.037112175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7715088154072929,
    "arrivals": 1850068,
    "finished_requests": 107370,
    "scheduler_time": 232.45534665906195
}
#Debug simulation 
Total elapsed time: 103.70219914475456. Arrivals time: 0.5944789098575711 Scheduler time: 102.90943624125794 Scheduler overhead time: 0.07529611326754093 Adapter cache time: 0.019583437126129866 Engine time: 0.07608080608770251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.04241881100461,
    "estimated_duration": 3600.049603329421,
    "input_throughput": 7355.772535886598,
    "output_throughput": 6513.126924227671,
    "total_throughput": 13868.89946011427,
    "itl": 122.87835069149985,
    "ttft": 2053019.1322639908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7747143279016127,
    "arrivals": 1850068,
    "finished_requests": 107370,
    "scheduler_time": 232.45534922801025
}
#Debug simulation 
Total elapsed time: 103.04258518386632. Arrivals time: 0.592570052947849 Scheduler time: 102.25214488338679 Scheduler overhead time: 0.07467493088915944 Adapter cache time: 0.01924419542774558 Engine time: 0.07606814568862319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 108.13664574408904,
    "estimated_duration": 3600.01108419349,
    "input_throughput": 7330.963261717982,
    "output_throughput": 6483.908091974482,
    "total_throughput": 13814.871353692464,
    "itl": 121.6690483580446,
    "ttft": 2057516.9432378898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5854167036502558,
    "arrivals": 1850068,
    "finished_requests": 107018,
    "scheduler_time": 234.20527022782386
}
#Debug simulation 
Total elapsed time: 108.13681270508096. Arrivals time: 0.6076212027110159 Scheduler time: 107.32802829658613 Scheduler overhead time: 0.07660600543022156 Adapter cache time: 0.019825708121061325 Engine time: 0.07702095853164792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 104.0039394730702,
    "estimated_duration": 3600.0736275048944,
    "input_throughput": 7355.723449009933,
    "output_throughput": 6513.08346053212,
    "total_throughput": 13868.806909542052,
    "itl": 122.87907800736268,
    "ttft": 2053029.3431242052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7978530246019404,
    "arrivals": 1850068,
    "finished_requests": 107370,
    "scheduler_time": 232.45555607661723
}
#Debug simulation 
Total elapsed time: 104.00411006389186. Arrivals time: 0.594487345777452 Scheduler time: 103.21068462822586 Scheduler overhead time: 0.07522126007825136 Adapter cache time: 0.019731863867491484 Engine time: 0.07604297064244747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.43594030989334,
    "estimated_duration": 3600.0557888473277,
    "input_throughput": 7325.116205613986,
    "output_throughput": 6485.706713860647,
    "total_throughput": 13810.822919474633,
    "itl": 122.15931979325214,
    "ttft": 2053953.6719207831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6325674610165668,
    "arrivals": 1850068,
    "finished_requests": 107017,
    "scheduler_time": 233.93581876686628
}
#Debug simulation 
Total elapsed time: 103.43610398797318. Arrivals time: 0.7417140696197748 Scheduler time: 102.49734031269327 Scheduler overhead time: 0.07390831364318728 Adapter cache time: 0.019648943096399307 Engine time: 0.07549312431365252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.98725290503353,
    "estimated_duration": 3600.095936510161,
    "input_throughput": 7355.677867204319,
    "output_throughput": 6513.043100381783,
    "total_throughput": 13868.720967586103,
    "itl": 122.87972443230166,
    "ttft": 2053039.1258443147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8202371985837782,
    "arrivals": 1850068,
    "finished_requests": 107370,
    "scheduler_time": 232.45570711798737
}
#Debug simulation 
Total elapsed time: 102.98742213798687. Arrivals time: 0.5860009859316051 Scheduler time: 102.202925670892 Scheduler overhead time: 0.07493609748780727 Adapter cache time: 0.01951460260897875 Engine time: 0.07575275842100382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.43127964995801,
    "estimated_duration": 3600.05357178739,
    "input_throughput": 7285.659915048899,
    "output_throughput": 6479.336636209805,
    "total_throughput": 13764.996551258704,
    "itl": 122.1996377207068,
    "ttft": 2055576.648161309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4567921661120053,
    "arrivals": 1848950,
    "finished_requests": 106256,
    "scheduler_time": 234.29355620536998
}
#Debug simulation 
Total elapsed time: 104.43143899086863. Arrivals time: 0.5942257125861943 Scheduler time: 103.63896517083049 Scheduler overhead time: 0.07526802085340023 Adapter cache time: 0.019145012833178043 Engine time: 0.07612108020111918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.41313571343198,
    "estimated_duration": 3600.0776204599815,
    "input_throughput": 7283.519902731907,
    "output_throughput": 6477.323951982055,
    "total_throughput": 13760.843854713961,
    "itl": 121.70181766989539,
    "ttft": 2056659.0773587332,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.599014025884687,
    "arrivals": 1848950,
    "finished_requests": 106311,
    "scheduler_time": 234.48628667759138
}
#Debug simulation 
Total elapsed time: 103.41330086020753. Arrivals time: 0.6051465538330376 Scheduler time: 102.61088448716328 Scheduler overhead time: 0.07486726809293032 Adapter cache time: 0.01897124806419015 Engine time: 0.07577111339196563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.13959670206532,
    "estimated_duration": 3600.034485627287,
    "input_throughput": 7299.007302542945,
    "output_throughput": 6518.157838121721,
    "total_throughput": 13817.165140664667,
    "itl": 121.71563898564767,
    "ttft": 2048055.5622537918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5356667858176025,
    "arrivals": 1848950,
    "finished_requests": 106558,
    "scheduler_time": 234.13643719094722
}
#Debug simulation 
Total elapsed time: 106.13975445879623. Arrivals time: 0.5887503614649177 Scheduler time: 105.35244676750153 Scheduler overhead time: 0.07540396368131042 Adapter cache time: 0.01931946352124214 Engine time: 0.07582385558634996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 103.19348192587495,
    "estimated_duration": 3600.087933595562,
    "input_throughput": 7290.549143277836,
    "output_throughput": 6481.559459214417,
    "total_throughput": 13772.108602492253,
    "itl": 121.99505999464499,
    "ttft": 2055901.4077902553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5213998615019901,
    "arrivals": 1848950,
    "finished_requests": 106336,
    "scheduler_time": 234.02833820123587
}
#Debug simulation 
Total elapsed time: 103.19364222511649. Arrivals time: 0.5972285396419466 Scheduler time: 102.39811074687168 Scheduler overhead time: 0.07576207956299186 Adapter cache time: 0.01920945243909955 Engine time: 0.07554446114227176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 106.16722263582051,
    "estimated_duration": 3600.0118877765394,
    "input_throughput": 7298.865897975893,
    "output_throughput": 6517.916254574462,
    "total_throughput": 13816.782152550355,
    "itl": 121.71667768193024,
    "ttft": 2048068.504468199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5557873916439755,
    "arrivals": 1848950,
    "finished_requests": 106556,
    "scheduler_time": 234.13125978783026
}
#Debug simulation 
Total elapsed time: 106.1673818770796. Arrivals time: 0.5825046198442578 Scheduler time: 105.38597161043435 Scheduler overhead time: 0.07525225915014744 Adapter cache time: 0.0191032150760293 Engine time: 0.07618311326950788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.57038635900244,
    "estimated_duration": 3600.0191282331816,
    "input_throughput": 7285.729621351363,
    "output_throughput": 6479.3986279311575,
    "total_throughput": 13765.12824928252,
    "itl": 122.19875263144282,
    "ttft": 2055561.811378644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.423263940373422,
    "arrivals": 1848950,
    "finished_requests": 106256,
    "scheduler_time": 234.29309329695863
}
#Debug simulation 
Total elapsed time: 104.57054954534397. Arrivals time: 0.7270359275862575 Scheduler time: 103.64747918071225 Scheduler overhead time: 0.07415608735755086 Adapter cache time: 0.018945337738841772 Engine time: 0.07561995927244425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.77263654302806,
    "estimated_duration": 3600.032297676289,
    "input_throughput": 7298.8245180356735,
    "output_throughput": 6517.879302123391,
    "total_throughput": 13816.703820159066,
    "itl": 121.71725401173923,
    "ttft": 2048077.6449449768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5760337512567633,
    "arrivals": 1848950,
    "finished_requests": 106556,
    "scheduler_time": 234.13142332798736
}
#Debug simulation 
Total elapsed time: 106.77278967667371. Arrivals time: 0.5927748065441847 Scheduler time: 105.98403079714626 Scheduler overhead time: 0.07390841701999307 Adapter cache time: 0.018700798507779837 Engine time: 0.07498501753434539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.00283590285107,
    "estimated_duration": 3600.0874727318874,
    "input_throughput": 7282.058894004104,
    "output_throughput": 6429.113507743851,
    "total_throughput": 13711.172401747956,
    "itl": 117.81762644058534,
    "ttft": 2045975.1973426354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.903623376726203,
    "arrivals": 1692537,
    "finished_requests": 105811,
    "scheduler_time": 236.9954343866243
}
#Debug simulation 
Total elapsed time: 104.00299351895228. Arrivals time: 0.5888292505405843 Scheduler time: 103.21292977733538 Scheduler overhead time: 0.0762287057004869 Adapter cache time: 0.02039399743080139 Engine time: 0.07608048478141427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.52926745498553,
    "estimated_duration": 3600.1073396975767,
    "input_throughput": 7234.378462223252,
    "output_throughput": 6396.329005549706,
    "total_throughput": 13630.70746777296,
    "itl": 116.2337528648441,
    "ttft": 2044350.50147869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0481358329881965,
    "arrivals": 1692537,
    "finished_requests": 105116,
    "scheduler_time": 239.5484185961982
}
#Debug simulation 
Total elapsed time: 104.5294194468297. Arrivals time: 0.5893617779947817 Scheduler time: 103.73830129392445 Scheduler overhead time: 0.07560956012457609 Adapter cache time: 0.02072375314310193 Engine time: 0.07602169457823038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.24288974376395,
    "estimated_duration": 3600.111165706444,
    "input_throughput": 7234.370773906178,
    "output_throughput": 6396.3222078675335,
    "total_throughput": 13630.692981773711,
    "itl": 116.23389167489647,
    "ttft": 2044351.9077608453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.051962042246024,
    "arrivals": 1692537,
    "finished_requests": 105116,
    "scheduler_time": 239.5484183957813
}
#Debug simulation 
Total elapsed time: 103.2430429388769. Arrivals time: 0.5681613483466208 Scheduler time: 102.47505630087107 Scheduler overhead time: 0.07506264979019761 Adapter cache time: 0.020858592819422483 Engine time: 0.0754550825804472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.45503043103963,
    "estimated_duration": 3600.1319534840213,
    "input_throughput": 7281.9689218972835,
    "output_throughput": 6429.0340740430665,
    "total_throughput": 13711.00299594035,
    "itl": 117.81826227620792,
    "ttft": 2045994.7317987843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9468420862569353,
    "arrivals": 1692537,
    "finished_requests": 105811,
    "scheduler_time": 236.99613090399953
}
#Debug simulation 
Total elapsed time: 104.4552012742497. Arrivals time: 0.5856251791119576 Scheduler time: 103.67006534524262 Scheduler overhead time: 0.07502997620031238 Adapter cache time: 0.020515598822385073 Engine time: 0.0757125155068934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.30107027897611,
    "estimated_duration": 3600.0011794708794,
    "input_throughput": 7234.120685434809,
    "output_throughput": 6396.048460013083,
    "total_throughput": 13630.169145447891,
    "itl": 116.23443624002978,
    "ttft": 2044375.584848807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0783703373931384,
    "arrivals": 1692537,
    "finished_requests": 105109,
    "scheduler_time": 239.53993583846892
}
#Debug simulation 
Total elapsed time: 103.30123829422519. Arrivals time: 0.5890424461103976 Scheduler time: 102.5114715276286 Scheduler overhead time: 0.07563489908352494 Adapter cache time: 0.020560009870678186 Engine time: 0.07603046204894781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.25361095974222,
    "estimated_duration": 3600.041945127285,
    "input_throughput": 7282.150985902774,
    "output_throughput": 6429.194812945897,
    "total_throughput": 13711.345798848672,
    "itl": 117.81595266090291,
    "ttft": 2045956.587362296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.859811283429124,
    "arrivals": 1692537,
    "finished_requests": 105811,
    "scheduler_time": 236.9945106104411
}
#Debug simulation 
Total elapsed time: 104.25377407995984. Arrivals time: 0.5930123021826148 Scheduler time: 103.46151317795739 Scheduler overhead time: 0.07563946209847927 Adapter cache time: 0.020129121374338865 Engine time: 0.07545268349349499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.67678603203967,
    "estimated_duration": 3600.0267828719807,
    "input_throughput": 7234.069236347151,
    "output_throughput": 6396.002971297565,
    "total_throughput": 13630.072207644715,
    "itl": 116.2350314787233,
    "ttft": 2044386.029026174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.10440137118101,
    "arrivals": 1692537,
    "finished_requests": 105109,
    "scheduler_time": 239.54029994102294
}
#Debug simulation 
Total elapsed time: 103.67694808263332. Arrivals time: 0.5992354298941791 Scheduler time: 102.87760518258438 Scheduler overhead time: 0.07520526740700006 Adapter cache time: 0.020649629179388285 Engine time: 0.07595127075910568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.30786327971146,
    "estimated_duration": 3600.083521226828,
    "input_throughput": 7259.089919973397,
    "output_throughput": 6426.788118547715,
    "total_throughput": 13685.878038521112,
    "itl": 118.80900317792299,
    "ttft": 2033044.0254555722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6434819184919098,
    "arrivals": 1577546,
    "finished_requests": 105624,
    "scheduler_time": 238.56678270475376
}
#Debug simulation 
Total elapsed time: 105.30802940996364. Arrivals time: 0.7671325565315783 Scheduler time: 104.34166804794222 Scheduler overhead time: 0.07510611694306135 Adapter cache time: 0.019963175058364868 Engine time: 0.07605087757110596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.99121374683455,
    "estimated_duration": 3600.1382548460606,
    "input_throughput": 7280.416513093257,
    "output_throughput": 6420.4514837412435,
    "total_throughput": 13700.8679968345,
    "itl": 119.08815304071054,
    "ttft": 2034881.5314877024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.832814319513278,
    "arrivals": 1577546,
    "finished_requests": 105966,
    "scheduler_time": 237.42977531746084
}
#Debug simulation 
Total elapsed time: 104.99138541985303. Arrivals time: 0.7868778593838215 Scheduler time: 104.00329588493332 Scheduler overhead time: 0.07632344588637352 Adapter cache time: 0.020260490477085114 Engine time: 0.07655271189287305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.95521185500547,
    "estimated_duration": 3600.1419537930706,
    "input_throughput": 7280.409032867411,
    "output_throughput": 6420.444887081966,
    "total_throughput": 13700.853919949377,
    "itl": 119.08823981327781,
    "ttft": 2034883.2241220844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.83625090846793,
    "arrivals": 1577546,
    "finished_requests": 105966,
    "scheduler_time": 237.4298114654372
}
#Debug simulation 
Total elapsed time: 104.95537907583639. Arrivals time: 0.7993431417271495 Scheduler time: 103.95440065255389 Scheduler overhead time: 0.07643656991422176 Adapter cache time: 0.020113203674554825 Engine time: 0.07655657129362226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.86415166500956,
    "estimated_duration": 3600.062190024571,
    "input_throughput": 7280.570339208809,
    "output_throughput": 6420.587139868892,
    "total_throughput": 13701.157479077701,
    "itl": 119.08601339916557,
    "ttft": 2034850.5089810197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7576327809202394,
    "arrivals": 1577546,
    "finished_requests": 105966,
    "scheduler_time": 237.42923134963408
}
#Debug simulation 
Total elapsed time: 104.8643161370419. Arrivals time: 0.7900610556825995 Scheduler time: 103.87333426717669 Scheduler overhead time: 0.07590190134942532 Adapter cache time: 0.020086241886019707 Engine time: 0.07651720941066742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 104.95049646589905,
    "estimated_duration": 3600.02312918615,
    "input_throughput": 7280.289336897972,
    "output_throughput": 6420.456250020063,
    "total_throughput": 13700.745586918034,
    "itl": 119.08792932468684,
    "ttft": 2034868.2955738322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8593896051682575,
    "arrivals": 1577546,
    "finished_requests": 105961,
    "scheduler_time": 237.42107607166994
}
#Debug simulation 
Total elapsed time: 104.95066169602796. Arrivals time: 0.7980115818791091 Scheduler time: 103.94973556278273 Scheduler overhead time: 0.07700635166838765 Adapter cache time: 0.020421981811523438 Engine time: 0.0770697989501059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.06112795881927,
    "estimated_duration": 3600.045322633362,
    "input_throughput": 7259.166943177255,
    "output_throughput": 6426.856310541047,
    "total_throughput": 13686.023253718302,
    "itl": 118.80820346554955,
    "ttft": 2033027.5751382858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6056570083624482,
    "arrivals": 1577546,
    "finished_requests": 105624,
    "scheduler_time": 238.56652212636592
}
#Debug simulation 
Total elapsed time: 105.06129277776927. Arrivals time: 0.593594322912395 Scheduler time: 104.26783932046965 Scheduler overhead time: 0.0759059083648026 Adapter cache time: 0.01974403066560626 Engine time: 0.07578330021351576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.84004429494962,
    "estimated_duration": 3600.0461233940455,
    "input_throughput": 7280.242836247477,
    "output_throughput": 6420.415241293858,
    "total_throughput": 13700.658077541335,
    "itl": 119.08834673465606,
    "ttft": 2034877.570759056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8831570708006584,
    "arrivals": 1577546,
    "finished_requests": 105961,
    "scheduler_time": 237.42120765419645
}
#Debug simulation 
Total elapsed time: 104.840212889947. Arrivals time: 0.8081313371658325 Scheduler time: 103.83134357118979 Scheduler overhead time: 0.07613248331472278 Adapter cache time: 0.02021305076777935 Engine time: 0.07595137832686305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.39082858990878,
    "estimated_duration": 3600.009149646823,
    "input_throughput": 7296.790343595949,
    "output_throughput": 6460.321913982257,
    "total_throughput": 13757.112257578205,
    "itl": 120.49413202653461,
    "ttft": 2019318.7043188834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9831960580684573,
    "arrivals": 1558275,
    "finished_requests": 106116,
    "scheduler_time": 237.45913951407314
}
#Debug simulation 
Total elapsed time: 103.39099466102198. Arrivals time: 0.577439100947231 Scheduler time: 102.61300098523498 Scheduler overhead time: 0.07590124243870378 Adapter cache time: 0.020625189878046513 Engine time: 0.07553084893152118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.27795860776678,
    "estimated_duration": 3600.0164425163366,
    "input_throughput": 7333.483727520557,
    "output_throughput": 6465.6643578356025,
    "total_throughput": 13799.14808535616,
    "itl": 121.17451309640198,
    "ttft": 2034034.0750120834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7973423112928932,
    "arrivals": 1558275,
    "finished_requests": 106617,
    "scheduler_time": 234.9810248746104
}
#Debug simulation 
Total elapsed time: 108.27812396781519. Arrivals time: 0.6048619663342834 Scheduler time: 107.46996332146227 Scheduler overhead time: 0.07685808930546045 Adapter cache time: 0.020490055438131094 Engine time: 0.07731231860816479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.44544313196093,
    "estimated_duration": 3600.0192925038596,
    "input_throughput": 7333.477921902469,
    "output_throughput": 6465.659239234492,
    "total_throughput": 13799.137161136961,
    "itl": 121.1745843031403,
    "ttft": 2034035.40734467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8000659297779313,
    "arrivals": 1558275,
    "finished_requests": 106617,
    "scheduler_time": 234.98103813859396
}
#Debug simulation 
Total elapsed time: 108.44561104802415. Arrivals time: 0.616999579127878 Scheduler time: 107.62782473210245 Scheduler overhead time: 0.07587309461086988 Adapter cache time: 0.020086977630853653 Engine time: 0.07668067188933492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 103.3140311720781,
    "estimated_duration": 3600.051723969493,
    "input_throughput": 7296.7040515284,
    "output_throughput": 6460.245514016143,
    "total_throughput": 13756.949565544543,
    "itl": 120.49490669464458,
    "ttft": 2019334.9045087097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.025809179879711,
    "arrivals": 1558275,
    "finished_requests": 106116,
    "scheduler_time": 237.45944002994938
}
#Debug simulation 
Total elapsed time: 103.31419279333204. Arrivals time: 0.6111891944892704 Scheduler time: 102.50123238516971 Scheduler overhead time: 0.07545071467757225 Adapter cache time: 0.02137769479304552 Engine time: 0.07621356006711721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 108.23103304114193,
    "estimated_duration": 3600.0435384972575,
    "input_throughput": 7333.428531539442,
    "output_throughput": 6465.615693558017,
    "total_throughput": 13799.044225097457,
    "itl": 121.1751788516992,
    "ttft": 2034045.1263100517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.823707641623918,
    "arrivals": 1558275,
    "finished_requests": 106617,
    "scheduler_time": 234.98119000003982
}
#Debug simulation 
Total elapsed time: 108.23120104707778. Arrivals time: 0.7271137861534953 Scheduler time: 107.3020777311176 Scheduler overhead time: 0.07628105813637376 Adapter cache time: 0.02059392584487796 Engine time: 0.07703357888385653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.5295524476096,
    "estimated_duration": 3600.0886332749697,
    "input_throughput": 7306.981210645878,
    "output_throughput": 6456.180213223308,
    "total_throughput": 13763.161423869185,
    "itl": 120.72254270507125,
    "ttft": 2023337.7449718502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.946522741981284,
    "arrivals": 1558275,
    "finished_requests": 106254,
    "scheduler_time": 237.03829129713841
}
#Debug simulation 
Total elapsed time: 103.52971351100132. Arrivals time: 0.6041574985720217 Scheduler time: 102.72557818330824 Scheduler overhead time: 0.07474993960931897 Adapter cache time: 0.021188045386224985 Engine time: 0.07626446103677154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 540, 34560, 34560, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 34560, 8640, 34560, 34560, 540, 34560, 8640, 8640, 34560, 34560, 8640, 540, 540, 8640, 34560, 34560, 8640, 8640, 540, 540, 8640, 34560, 34560, 540, 34560, 8640, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 34560, 8640, 540, 540, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 540, 34560, 8640, 34560, 34560, 8640, 540, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 8640, 540, 34560, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 8640, 540, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 8640, 34560, 8640, 8640, 8640, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 8640, 540, 8640, 540, 540, 540, 34560, 34560, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 540, 8640, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 8640, 540, 8640, 540, 8640, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 34560, 540, 34560, 540, 540, 540, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 34560, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4679640 . Total input tokens: 1041849217 . Total output tokens: 935865325
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.08508251328021,
    "estimated_duration": 3600.066398655834,
    "input_throughput": 7333.381964804117,
    "output_throughput": 6465.574637370802,
    "total_throughput": 13798.956602174918,
    "itl": 121.17566557175644,
    "ttft": 2034054.4331713258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 550,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8470978458970746,
    "arrivals": 1558275,
    "finished_requests": 106617,
    "scheduler_time": 234.9814516895788
}
#Debug simulation 
Total elapsed time: 108.08525036042556. Arrivals time: 0.6117064408026636 Scheduler time: 107.27215207647532 Scheduler overhead time: 0.07659302884712815 Adapter cache time: 0.020188436843454838 Engine time: 0.07636694796383381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.68697056313977,
    "estimated_duration": 3600.0711274067326,
    "input_throughput": 7267.815571979377,
    "output_throughput": 6422.355331811148,
    "total_throughput": 13690.170903790524,
    "itl": 119.91513348132621,
    "ttft": 2036715.8093393375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6281794797722455,
    "arrivals": 1548789,
    "finished_requests": 105770,
    "scheduler_time": 237.80282876186885
}
#Debug simulation 
Total elapsed time: 105.68713363911957. Arrivals time: 0.5861273342743516 Scheduler time: 104.89964774576947 Scheduler overhead time: 0.07656743284314871 Adapter cache time: 0.01988384546712041 Engine time: 0.0768656893633306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.18656640360132,
    "estimated_duration": 3600.071352264513,
    "input_throughput": 7325.36786622621,
    "output_throughput": 6481.697921159844,
    "total_throughput": 13807.065787386053,
    "itl": 121.30912099550231,
    "ttft": 2030729.2938900748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7667545007728107,
    "arrivals": 1548789,
    "finished_requests": 106720,
    "scheduler_time": 235.14648708987025
}
#Debug simulation 
Total elapsed time: 105.18673252966255. Arrivals time: 0.6033416935242712 Scheduler time: 104.38238486507908 Scheduler overhead time: 0.07587812654674053 Adapter cache time: 0.02053882461041212 Engine time: 0.07642661267891526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.89842729782686,
    "estimated_duration": 3600.074241205623,
    "input_throughput": 7325.361987859555,
    "output_throughput": 6481.692719810557,
    "total_throughput": 13807.054707670111,
    "itl": 121.30919795992692,
    "ttft": 2030730.643756212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7696390326880027,
    "arrivals": 1548789,
    "finished_requests": 106720,
    "scheduler_time": 235.14649149904116
}
#Debug simulation 
Total elapsed time: 104.8985860128887. Arrivals time: 0.6081405756995082 Scheduler time: 104.09053436014801 Scheduler overhead time: 0.07537926128134131 Adapter cache time: 0.020075265783816576 Engine time: 0.07646653149276972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 105.24509118683636,
    "estimated_duration": 3600.0111963497648,
    "input_throughput": 7332.008863406746,
    "output_throughput": 6461.957680461568,
    "total_throughput": 13793.966543868315,
    "itl": 121.8736313140972,
    "ttft": 2036514.8649130426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6710512054338982,
    "arrivals": 1548789,
    "finished_requests": 106668,
    "scheduler_time": 234.94369928525762
}
#Debug simulation 
Total elapsed time: 105.2452542646788. Arrivals time: 0.7186108520254493 Scheduler time: 104.32593007385731 Scheduler overhead time: 0.07585080387070775 Adapter cache time: 0.01989592704921961 Engine time: 0.07630855310708284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 104.78797100111842,
    "estimated_duration": 3600.097863468467,
    "input_throughput": 7325.3139220477715,
    "output_throughput": 6481.650189786399,
    "total_throughput": 13806.964111834171,
    "itl": 121.30972491136572,
    "ttft": 2030740.505591352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.792400468029086,
    "arrivals": 1548789,
    "finished_requests": 106720,
    "scheduler_time": 235.14667369637445
}
#Debug simulation 
Total elapsed time: 104.7881259159185. Arrivals time: 0.6075143567286432 Scheduler time: 103.98095730692148 Scheduler overhead time: 0.07563351886346936 Adapter cache time: 0.01975533226504922 Engine time: 0.07655802322551608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.45296072913334,
    "estimated_duration": 3600.125079019791,
    "input_throughput": 7302.506280464561,
    "output_throughput": 6453.352172509971,
    "total_throughput": 13755.858452974533,
    "itl": 121.14015934582618,
    "ttft": 2035814.4734308312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6056570083624482,
    "arrivals": 1548789,
    "finished_requests": 106379,
    "scheduler_time": 235.73924241243213
}
#Debug simulation 
Total elapsed time: 106.45311874104664. Arrivals time: 0.5878384080715477 Scheduler time: 105.66529947565868 Scheduler overhead time: 0.07525335298851132 Adapter cache time: 0.019930201582610607 Engine time: 0.07649178290739655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 270, 34560, 34560, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 34560, 8640, 34560, 34560, 270, 34560, 8640, 8640, 34560, 34560, 8640, 270, 270, 8640, 34560, 34560, 8640, 8640, 270, 270, 8640, 34560, 34560, 270, 34560, 8640, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 34560, 8640, 270, 270, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 270, 34560, 8640, 34560, 34560, 8640, 270, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 8640, 270, 34560, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 8640, 270, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 8640, 34560, 8640, 8640, 8640, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 8640, 270, 8640, 270, 270, 270, 34560, 34560, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 270, 8640, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 8640, 270, 8640, 270, 8640, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 34560, 270, 34560, 270, 270, 270, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 34560, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4651020 . Total input tokens: 1035473495 . Total output tokens: 930081862
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.75308316899464,
    "estimated_duration": 3600.012065590221,
    "input_throughput": 7324.9804499409765,
    "output_throughput": 6481.638276446832,
    "total_throughput": 13806.618726387807,
    "itl": 121.31217197513674,
    "ttft": 2030712.9416735854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 541,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8155391647294128,
    "arrivals": 1548789,
    "finished_requests": 106715,
    "scheduler_time": 235.1391825175202
}
#Debug simulation 
Total elapsed time: 104.75323869287968. Arrivals time: 0.5954486476257443 Scheduler time: 103.95834957901388 Scheduler overhead time: 0.07463455758988857 Adapter cache time: 0.01972319232299924 Engine time: 0.07662293035537004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.28762700408697,
    "estimated_duration": 3600.0892973621367,
    "input_throughput": 7369.221929977959,
    "output_throughput": 6505.425856286516,
    "total_throughput": 13874.647786264475,
    "itl": 122.05311376964836,
    "ttft": 2030917.3348016336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6587843572115741,
    "arrivals": 1544103,
    "finished_requests": 107243,
    "scheduler_time": 233.1219353915572
}
#Debug simulation 
Total elapsed time: 105.2877872781828. Arrivals time: 0.6019750577397645 Scheduler time: 104.48747865576297 Scheduler overhead time: 0.07521423231810331 Adapter cache time: 0.01946492213755846 Engine time: 0.07535095326602459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.65520325209945,
    "estimated_duration": 3600.0759765625853,
    "input_throughput": 7344.535829837185,
    "output_throughput": 6486.422273314499,
    "total_throughput": 13830.958103151683,
    "itl": 121.72543617422195,
    "ttft": 2028691.7461031796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.73997393118451,
    "arrivals": 1544103,
    "finished_requests": 106737,
    "scheduler_time": 234.90074578293252
}
#Debug simulation 
Total elapsed time: 104.65535863908008. Arrivals time: 0.5799479107372463 Scheduler time: 103.87837881268933 Scheduler overhead time: 0.07529865065589547 Adapter cache time: 0.019045952707529068 Engine time: 0.07500159740447998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.22791529307142,
    "estimated_duration": 3600.0799020462705,
    "input_throughput": 7344.527821443938,
    "output_throughput": 6486.41520059792,
    "total_throughput": 13830.943022041858,
    "itl": 121.72552028925126,
    "ttft": 2028693.765812096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7429301494360077,
    "arrivals": 1544103,
    "finished_requests": 106737,
    "scheduler_time": 234.90081020809436
}
#Debug simulation 
Total elapsed time: 104.22807239089161. Arrivals time: 0.7010677652433515 Scheduler time: 103.3302908372134 Scheduler overhead time: 0.07459886744618416 Adapter cache time: 0.019135846756398678 Engine time: 0.0751380450092256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.03109653526917,
    "estimated_duration": 3600.007625758485,
    "input_throughput": 7368.812168671689,
    "output_throughput": 6505.115664877506,
    "total_throughput": 13873.927833549194,
    "itl": 122.05401124667976,
    "ttft": 2030945.8150565478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6957887984299957,
    "arrivals": 1544103,
    "finished_requests": 107237,
    "scheduler_time": 233.1140924602867
}
#Debug simulation 
Total elapsed time: 106.031256838236. Arrivals time: 0.5884735160507262 Scheduler time: 105.2450274922885 Scheduler overhead time: 0.07438118802383542 Adapter cache time: 0.01944311009719968 Engine time: 0.07611935818567872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.62105453992262,
    "estimated_duration": 3600.061501986989,
    "input_throughput": 7364.19280208614,
    "output_throughput": 6488.6985922621125,
    "total_throughput": 13852.891394348253,
    "itl": 121.87445285419695,
    "ttft": 2033124.0120723774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8891280036792193,
    "arrivals": 1544103,
    "finished_requests": 107081,
    "scheduler_time": 233.64465134663635
}
#Debug simulation 
Total elapsed time: 103.62121412390843. Arrivals time: 0.5813202117569745 Scheduler time: 102.84264245070517 Scheduler overhead time: 0.07460531778633595 Adapter cache time: 0.019749009516090155 Engine time: 0.07485288148745894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.54759727604687,
    "estimated_duration": 3600.0500186302834,
    "input_throughput": 7369.302332664216,
    "output_throughput": 6505.496834433064,
    "total_throughput": 13874.799167097279,
    "itl": 122.05223656580011,
    "ttft": 2030900.5421624046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6206072598369585,
    "arrivals": 1544103,
    "finished_requests": 107243,
    "scheduler_time": 233.1216254922137
}
#Debug simulation 
Total elapsed time: 105.54774919804186. Arrivals time: 0.5943190599791706 Scheduler time: 104.75451198685914 Scheduler overhead time: 0.07508765766397119 Adapter cache time: 0.01975033851340413 Engine time: 0.07571403635665774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 135, 34560, 34560, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 34560, 8640, 34560, 34560, 135, 34560, 8640, 8640, 34560, 34560, 8640, 135, 135, 8640, 34560, 34560, 8640, 8640, 135, 135, 8640, 34560, 34560, 135, 34560, 8640, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 34560, 8640, 135, 135, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 135, 34560, 8640, 34560, 34560, 8640, 135, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 8640, 135, 34560, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 8640, 135, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 8640, 34560, 8640, 8640, 8640, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 8640, 135, 8640, 135, 135, 135, 34560, 34560, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 135, 8640, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 8640, 135, 8640, 135, 8640, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 34560, 135, 34560, 135, 135, 135, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 34560, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4636710 . Total input tokens: 1032247703 . Total output tokens: 927267205
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.44170402502641,
    "estimated_duration": 3600.0863100905453,
    "input_throughput": 7364.142055620108,
    "output_throughput": 6488.653878804501,
    "total_throughput": 13852.79593442461,
    "itl": 121.87508617006266,
    "ttft": 2033133.94596523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9135242382436946,
    "arrivals": 1544103,
    "finished_requests": 107081,
    "scheduler_time": 233.64483700558972
}
#Debug simulation 
Total elapsed time: 103.44186332030222. Arrivals time: 0.5862919082865119 Scheduler time: 102.6581858615391 Scheduler overhead time: 0.07411506026983261 Adapter cache time: 0.01994900917634368 Engine time: 0.0752192847430706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.66734223999083,
    "estimated_duration": 3600.1128382794427,
    "input_throughput": 7367.505184275339,
    "output_throughput": 6525.490187476313,
    "total_throughput": 13892.995371751651,
    "itl": 122.35780583184547,
    "ttft": 2027423.2609150715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5424858229421254,
    "arrivals": 1541713,
    "finished_requests": 107443,
    "scheduler_time": 231.54254681328547
}
#Debug simulation 
Total elapsed time: 105.66749994968995. Arrivals time: 0.5972811528481543 Scheduler time: 104.87334041902795 Scheduler overhead time: 0.07358591770753264 Adapter cache time: 0.0191751248203218 Engine time: 0.0762088573537767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.67437000665814,
    "estimated_duration": 3600.027079156191,
    "input_throughput": 7383.011965073843,
    "output_throughput": 6531.7103129989555,
    "total_throughput": 13914.722278072799,
    "itl": 122.80461768378802,
    "ttft": 2028887.811935645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7008245650981613,
    "arrivals": 1541713,
    "finished_requests": 107686,
    "scheduler_time": 231.2192719903384
}
#Debug simulation 
Total elapsed time: 103.67453300580382. Arrivals time: 0.5846779812127352 Scheduler time: 102.89443420711905 Scheduler overhead time: 0.07410512818023562 Adapter cache time: 0.019016478210687637 Engine time: 0.07400123216211796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.92178887687624,
    "estimated_duration": 3600.0303556664685,
    "input_throughput": 7383.00524554312,
    "output_throughput": 6531.704368266868,
    "total_throughput": 13914.709613809988,
    "itl": 122.80468415012466,
    "ttft": 2028889.3895900873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7037099432945355,
    "arrivals": 1541713,
    "finished_requests": 107686,
    "scheduler_time": 231.21932380730064
}
#Debug simulation 
Total elapsed time: 103.92194491112605. Arrivals time: 0.5991189437918365 Scheduler time: 103.12485145544633 Scheduler overhead time: 0.07439396809786558 Adapter cache time: 0.019064318388700485 Engine time: 0.0762849161401391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 105.70255216490477,
    "estimated_duration": 3600.003992356081,
    "input_throughput": 7367.691829319645,
    "output_throughput": 6525.551374354247,
    "total_throughput": 13893.243203673892,
    "itl": 122.35876217092274,
    "ttft": 2027368.5897275163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5772637434024308,
    "arrivals": 1541713,
    "finished_requests": 107442,
    "scheduler_time": 231.53373434968597
}
#Debug simulation 
Total elapsed time: 105.70271251909435. Arrivals time: 0.6932680178433657 Scheduler time: 104.81310594175011 Scheduler overhead time: 0.0738067808561027 Adapter cache time: 0.01931866491213441 Engine time: 0.07505933241918683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.60344755090773,
    "estimated_duration": 3600.0533217172433,
    "input_throughput": 7382.9581466648015,
    "output_throughput": 6531.6627001467705,
    "total_throughput": 13914.620846811571,
    "itl": 122.80526775115821,
    "ttft": 2028898.6026391038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7257168559171299,
    "arrivals": 1541713,
    "finished_requests": 107686,
    "scheduler_time": 231.21949121025725
}
#Debug simulation 
Total elapsed time: 103.60359899373725. Arrivals time: 0.580788656603545 Scheduler time: 102.82781550381333 Scheduler overhead time: 0.07397460751235485 Adapter cache time: 0.018517944496124983 Engine time: 0.07510664919391274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.54384479904547,
    "estimated_duration": 3600.077474207433,
    "input_throughput": 7367.577556324478,
    "output_throughput": 6525.554288292626,
    "total_throughput": 13893.131844617104,
    "itl": 122.356882260782,
    "ttft": 2027408.8222375715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.50698534863068,
    "arrivals": 1541713,
    "finished_requests": 107443,
    "scheduler_time": 231.54234390041967
}
#Debug simulation 
Total elapsed time: 105.54400306660682. Arrivals time: 0.5873017231933773 Scheduler time: 104.75825468916446 Scheduler overhead time: 0.07494006771594286 Adapter cache time: 0.019316752441227436 Engine time: 0.0753443124704063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 66, 34560, 34560, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 34560, 8640, 34560, 34560, 66, 34560, 8640, 8640, 34560, 34560, 8640, 66, 66, 8640, 34560, 34560, 8640, 8640, 66, 66, 8640, 34560, 34560, 66, 34560, 8640, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 34560, 8640, 66, 66, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 66, 34560, 8640, 34560, 34560, 8640, 66, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 8640, 66, 34560, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 8640, 66, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 8640, 34560, 8640, 8640, 8640, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 8640, 66, 8640, 66, 66, 66, 34560, 34560, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 66, 8640, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 8640, 66, 8640, 66, 8640, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 34560, 66, 34560, 66, 66, 66, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 34560, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4629396 . Total input tokens: 1030606647 . Total output tokens: 925851877
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.86680264119059,
    "estimated_duration": 3600.075399978245,
    "input_throughput": 7382.912869036191,
    "output_throughput": 6531.6226432763315,
    "total_throughput": 13914.535512312523,
    "itl": 122.80588719113263,
    "ttft": 2028907.470822957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7477237685397238,
    "arrivals": 1541713,
    "finished_requests": 107686,
    "scheduler_time": 231.21956255865913
}
#Debug simulation 
Total elapsed time: 103.86704786587507. Arrivals time: 0.5869340957142413 Scheduler time: 103.08511065598577 Scheduler overhead time: 0.07393998885527253 Adapter cache time: 0.01852861326187849 Engine time: 0.0745159462094307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.8354348409921,
    "estimated_duration": 3600.0286935509425,
    "input_throughput": 7382.894210708017,
    "output_throughput": 6524.63021810846,
    "total_throughput": 13907.524428816478,
    "itl": 121.89023590349004,
    "ttft": 2030811.5758193345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4476107028802068,
    "arrivals": 1540502,
    "finished_requests": 107262,
    "scheduler_time": 231.88719741243418
}
#Debug simulation 
Total elapsed time: 103.8355967309326. Arrivals time: 0.5789787224493921 Scheduler time: 103.06158952321857 Scheduler overhead time: 0.07382855331525207 Adapter cache time: 0.01849237084388733 Engine time: 0.074884875677526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.9018495879136,
    "estimated_duration": 3600.1262444256317,
    "input_throughput": 7382.6941600044875,
    "output_throughput": 6524.453423368057,
    "total_throughput": 13907.147583372545,
    "itl": 121.89272380893948,
    "ttft": 2030850.8250608358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5446356960712067,
    "arrivals": 1540502,
    "finished_requests": 107262,
    "scheduler_time": 231.88794950396513
}
#Debug simulation 
Total elapsed time: 103.9020099658519. Arrivals time: 0.5870084702037275 Scheduler time: 103.11928310524672 Scheduler overhead time: 0.07459168462082744 Adapter cache time: 0.019007805734872818 Engine time: 0.07460901141166687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.24139458592981,
    "estimated_duration": 3600.128690012667,
    "input_throughput": 7382.689144900119,
    "output_throughput": 6524.448991271297,
    "total_throughput": 13907.138136171416,
    "itl": 121.89276791380736,
    "ttft": 2030851.988102225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.547166366223255,
    "arrivals": 1540502,
    "finished_requests": 107262,
    "scheduler_time": 231.8879775258546
}
#Debug simulation 
Total elapsed time: 103.24155302299187. Arrivals time: 0.6860092030838132 Scheduler time: 102.35881859250367 Scheduler overhead time: 0.07507229363545775 Adapter cache time: 0.01852034544572234 Engine time: 0.07557812752202153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 103.7743762889877,
    "estimated_duration": 3600.058745882685,
    "input_throughput": 7382.832580273155,
    "output_throughput": 6524.575752232859,
    "total_throughput": 13907.408332506013,
    "itl": 121.89107624079577,
    "ttft": 2030824.5924380075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4776260638469778,
    "arrivals": 1540502,
    "finished_requests": 107262,
    "scheduler_time": 231.8873474881909
}
#Debug simulation 
Total elapsed time: 103.774541774299. Arrivals time: 0.587315037380904 Scheduler time: 102.99142193654552 Scheduler overhead time: 0.07364134397357702 Adapter cache time: 0.018436310812830925 Engine time: 0.07522472878918052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.9874117942527,
    "estimated_duration": 3600.1208763974137,
    "input_throughput": 7382.705168110031,
    "output_throughput": 6524.463151777543,
    "total_throughput": 13907.168319887574,
    "itl": 121.89550306848271,
    "ttft": 2030838.3297955466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5677899871952872,
    "arrivals": 1540502,
    "finished_requests": 107262,
    "scheduler_time": 231.88396115946833
}
#Debug simulation 
Total elapsed time: 103.98757092095912. Arrivals time: 1.0235775909386575 Scheduler time: 102.76651766430587 Scheduler overhead time: 0.07518913084641099 Adapter cache time: 0.01917486870661378 Engine time: 0.07551667559891939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.03600900294259,
    "estimated_duration": 3600.138409570302,
    "input_throughput": 7383.083364056688,
    "output_throughput": 6524.908025078886,
    "total_throughput": 13907.991389135574,
    "itl": 121.88963837966186,
    "ttft": 2030821.07875891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4142937894887158,
    "arrivals": 1540502,
    "finished_requests": 107268,
    "scheduler_time": 231.8957582799336
}
#Debug simulation 
Total elapsed time: 104.03616990614682. Arrivals time: 0.5990512692369521 Scheduler time: 103.24453598214313 Scheduler overhead time: 0.07347702980041504 Adapter cache time: 0.01865475671365857 Engine time: 0.07340106507763267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 33, 34560, 34560, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 34560, 8640, 34560, 34560, 33, 34560, 8640, 8640, 34560, 34560, 8640, 33, 33, 8640, 34560, 34560, 8640, 8640, 33, 33, 8640, 34560, 34560, 33, 34560, 8640, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 34560, 33, 34560, 33, 34560, 8640, 33, 33, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 33, 8640, 8640, 33, 34560, 8640, 34560, 34560, 8640, 33, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 8640, 33, 34560, 33, 33, 33, 33, 34560, 8640, 8640, 34560, 8640, 8640, 33, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 8640, 34560, 8640, 8640, 8640, 33, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 8640, 33, 8640, 33, 33, 33, 34560, 34560, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 33, 8640, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 8640, 33, 8640, 33, 8640, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 34560, 33, 34560, 33, 33, 33, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 34560, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4625898 . Total input tokens: 1029861444 . Total output tokens: 925146967
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.73346074298024,
    "estimated_duration": 3600.14003110839,
    "input_throughput": 7382.6658880868945,
    "output_throughput": 6524.428438070613,
    "total_throughput": 13907.094326157507,
    "itl": 121.89596909936633,
    "ttft": 2030846.4241385814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 473,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5872818240895852,
    "arrivals": 1540502,
    "finished_requests": 107262,
    "scheduler_time": 231.88407645369583
}
#Debug simulation 
Total elapsed time: 103.73362040100619. Arrivals time: 0.7089285408146679 Scheduler time: 102.82751979632303 Scheduler overhead time: 0.07486383151262999 Adapter cache time: 0.018910960294306278 Engine time: 0.07623112620785832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.41293639782816,
    "estimated_duration": 3600.0854039799456,
    "input_throughput": 7231.379836494852,
    "output_throughput": 6438.896970158969,
    "total_throughput": 13670.276806653821,
    "itl": 119.88020682381551,
    "ttft": 2026498.6857014282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6373609430040441,
    "arrivals": 1423678,
    "finished_requests": 105367,
    "scheduler_time": 237.90247720857042
}
#Debug simulation 
Total elapsed time: 104.41310382308438. Arrivals time: 0.5912197129800916 Scheduler time: 103.62049708841369 Scheduler overhead time: 0.07569291908293962 Adapter cache time: 0.01981322607025504 Engine time: 0.07639153534546494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.92454347806051,
    "estimated_duration": 3600.0613831020974,
    "input_throughput": 7246.798102514498,
    "output_throughput": 6444.421228176054,
    "total_throughput": 13691.219330690552,
    "itl": 120.18549882526456,
    "ttft": 2030148.515354608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6762168551678822,
    "arrivals": 1423678,
    "finished_requests": 105598,
    "scheduler_time": 236.91707234863927
}
#Debug simulation 
Total elapsed time: 107.9247079002671. Arrivals time: 0.5748752770014107 Scheduler time: 107.14983856445178 Scheduler overhead time: 0.07578090950846672 Adapter cache time: 0.01999728474766016 Engine time: 0.0761219640262425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.98614643095061,
    "estimated_duration": 3600.0640881740046,
    "input_throughput": 7246.792657303112,
    "output_throughput": 6444.416385867029,
    "total_throughput": 13691.209043170142,
    "itl": 120.18554949831058,
    "ttft": 2030149.5207676017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6793700839020413,
    "arrivals": 1423678,
    "finished_requests": 105598,
    "scheduler_time": 236.91707661192672
}
#Debug simulation 
Total elapsed time: 107.98631244013086. Arrivals time: 0.5914661721326411 Scheduler time: 107.19586661923677 Scheduler overhead time: 0.07467454764991999 Adapter cache time: 0.02000336954370141 Engine time: 0.07576921675354242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 109.06579393008724,
    "estimated_duration": 3600.037732147481,
    "input_throughput": 7216.849081329476,
    "output_throughput": 6432.410358706579,
    "total_throughput": 13649.259440036056,
    "itl": 119.32548528546579,
    "ttft": 2023554.5272606504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5227555305231308,
    "arrivals": 1423678,
    "finished_requests": 105165,
    "scheduler_time": 238.7985790939951
}
#Debug simulation 
Total elapsed time: 109.06596048409119. Arrivals time: 0.5933644520118833 Scheduler time: 108.27174525568262 Scheduler overhead time: 0.0765336723998189 Adapter cache time: 0.019498911686241627 Engine time: 0.0761621086858213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 108.16002055676654,
    "estimated_duration": 3600.08553034851,
    "input_throughput": 7246.749495275029,
    "output_throughput": 6444.378002806525,
    "total_throughput": 13691.127498081554,
    "itl": 120.1859849445535,
    "ttft": 2030158.9498251611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6998679510876586,
    "arrivals": 1423678,
    "finished_requests": 105598,
    "scheduler_time": 236.9172291840357
}
#Debug simulation 
Total elapsed time: 108.16018736874685. Arrivals time: 1.0283796805888414 Scheduler time: 106.93318542139605 Scheduler overhead time: 0.07539753848686814 Adapter cache time: 0.019725192803889513 Engine time: 0.07528778910636902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.49629054497927,
    "estimated_duration": 3600.048479774595,
    "input_throughput": 7231.4540057610575,
    "output_throughput": 6438.96301125683,
    "total_throughput": 13670.417017017888,
    "itl": 119.87937959297383,
    "ttft": 2026484.103730551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.599676907772644,
    "arrivals": 1423678,
    "finished_requests": 105367,
    "scheduler_time": 237.90233219811435
}
#Debug simulation 
Total elapsed time: 104.49645451689139. Arrivals time: 0.5766232465393841 Scheduler time: 103.72097497060895 Scheduler overhead time: 0.07551654428243637 Adapter cache time: 0.01994739519432187 Engine time: 0.0754518611356616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 1080, 34560, 34560, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 4320, 1080, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 34560, 4320, 1080, 4320, 34560, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 34560, 1080, 34560, 1080, 34560, 4320, 1080, 1080, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 1080, 4320, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 4320, 4320, 34560, 4320, 4320, 1080, 4320, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 4320, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 4320, 1080, 4320, 1080, 1080, 1080, 34560, 34560, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 34560, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4274640 . Total input tokens: 951746907 . Total output tokens: 854754148
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.47215369995683,
    "estimated_duration": 3600.030772163332,
    "input_throughput": 7283.481353200604,
    "output_throughput": 6476.428251747786,
    "total_throughput": 13759.909604948389,
    "itl": 121.19829716672254,
    "ttft": 2025897.8582347184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6413366509228935,
    "arrivals": 1423678,
    "finished_requests": 106243,
    "scheduler_time": 234.24028250971975
}
#Debug simulation 
Total elapsed time: 106.47231644764543. Arrivals time: 0.5919221113435924 Scheduler time: 105.68194815097377 Scheduler overhead time: 0.07517867581918836 Adapter cache time: 0.01938327169045806 Engine time: 0.0758886132389307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.7813729532063,
    "estimated_duration": 3600.0007200256805,
    "input_throughput": 7305.248816675903,
    "output_throughput": 6496.871478357137,
    "total_throughput": 13802.120295033039,
    "itl": 121.8440653878382,
    "ttft": 2024603.122899814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.462913141599871,
    "arrivals": 1404624,
    "finished_requests": 106334,
    "scheduler_time": 234.5212973675484
}
#Debug simulation 
Total elapsed time: 107.78153779916465. Arrivals time: 0.5892744408920407 Scheduler time: 106.99404976703227 Scheduler overhead time: 0.07461172481998801 Adapter cache time: 0.019341038540005684 Engine time: 0.07589025935158134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.64536765823141,
    "estimated_duration": 3600.0054165941488,
    "input_throughput": 7271.277670677754,
    "output_throughput": 6456.219730354996,
    "total_throughput": 13727.49740103275,
    "itl": 121.75143223079394,
    "ttft": 2021532.3891982073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.561758807203737,
    "arrivals": 1404624,
    "finished_requests": 105884,
    "scheduler_time": 235.65142498005778
}
#Debug simulation 
Total elapsed time: 107.64552623825148. Arrivals time: 1.012710735667497 Scheduler time: 106.43277592537925 Scheduler overhead time: 0.07599035138264298 Adapter cache time: 0.01943929400295019 Engine time: 0.07599262800067663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.49618081795052,
    "estimated_duration": 3600.0086701230653,
    "input_throughput": 7271.27109921798,
    "output_throughput": 6456.213895508608,
    "total_throughput": 13727.484994726588,
    "itl": 121.75149484380171,
    "ttft": 2021533.8632180002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5647529843263421,
    "arrivals": 1404624,
    "finished_requests": 105884,
    "scheduler_time": 235.65145812178127
}
#Debug simulation 
Total elapsed time: 107.49634288623929. Arrivals time: 0.5850090612657368 Scheduler time: 106.71430539200082 Scheduler overhead time: 0.07525650458410382 Adapter cache time: 0.018885995727032423 Engine time: 0.07459523202851415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.55368898715824,
    "estimated_duration": 3600.063289815567,
    "input_throughput": 7271.637716497237,
    "output_throughput": 6456.441492502423,
    "total_throughput": 13728.07920899966,
    "itl": 121.75059057062101,
    "ttft": 2021497.7607644363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4992437234823546,
    "arrivals": 1404624,
    "finished_requests": 105887,
    "scheduler_time": 235.65917049101782
}
#Debug simulation 
Total elapsed time: 106.55384522117674. Arrivals time: 0.5864775129593909 Scheduler time: 105.76894506718963 Scheduler overhead time: 0.07574835792183876 Adapter cache time: 0.019298783969134092 Engine time: 0.07539087999612093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 106.69921980099753,
    "estimated_duration": 3600.027991420795,
    "input_throughput": 7271.23207441203,
    "output_throughput": 6456.179245102784,
    "total_throughput": 13727.411319514815,
    "itl": 121.75193679022934,
    "ttft": 2021542.1854702644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.583993313647812,
    "arrivals": 1404624,
    "finished_requests": 105884,
    "scheduler_time": 235.65153909019241
}
#Debug simulation 
Total elapsed time: 106.69937666598707. Arrivals time: 0.574598515406251 Scheduler time: 105.92432156903669 Scheduler overhead time: 0.07597927656024694 Adapter cache time: 0.019249613862484694 Engine time: 0.07672374788671732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.32623952301219,
    "estimated_duration": 3600.043642921069,
    "input_throughput": 7305.358381339106,
    "output_throughput": 6496.99040343351,
    "total_throughput": 13802.348784772616,
    "itl": 121.8424438564859,
    "ttft": 2024582.0340529915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.429244040963226,
    "arrivals": 1404624,
    "finished_requests": 106337,
    "scheduler_time": 234.5276609560392
}
#Debug simulation 
Total elapsed time: 107.3263966711238. Arrivals time: 0.6844636327587068 Scheduler time: 106.44304007664323 Scheduler overhead time: 0.07513442263007164 Adapter cache time: 0.019230710808187723 Engine time: 0.07624797755852342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.7334416010417,
    "estimated_duration": 3600.048344560651,
    "input_throughput": 7271.19096596315,
    "output_throughput": 6456.14274461542,
    "total_throughput": 13727.33371057857,
    "itl": 121.75243666988494,
    "ttft": 2021550.6321833776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6046169346198436,
    "arrivals": 1404624,
    "finished_requests": 105884,
    "scheduler_time": 235.6516079241794
}
#Debug simulation 
Total elapsed time: 106.7336031422019. Arrivals time: 0.5922861755825579 Scheduler time: 105.9412064445205 Scheduler overhead time: 0.07567577669396996 Adapter cache time: 0.019310482777655125 Engine time: 0.07664647186174989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.45802587503567,
    "estimated_duration": 3600.100248519101,
    "input_throughput": 7395.931824663113,
    "output_throughput": 6512.664198627413,
    "total_throughput": 13908.596023290525,
    "itl": 122.01936452546089,
    "ttft": 2014709.932832264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5026994822709983,
    "arrivals": 1395198,
    "finished_requests": 107898,
    "scheduler_time": 233.02137735168554
}
#Debug simulation 
Total elapsed time: 105.45818813005462. Arrivals time: 0.5977779477834702 Scheduler time: 104.66298323869705 Scheduler overhead time: 0.07487284066155553 Adapter cache time: 0.019185382407158613 Engine time: 0.0753105478361249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.88056733598933,
    "estimated_duration": 3600.086624290522,
    "input_throughput": 7343.352468695096,
    "output_throughput": 6455.915489139189,
    "total_throughput": 13799.267957834285,
    "itl": 120.80389673201176,
    "ttft": 2020240.6183675518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5601244259299758,
    "arrivals": 1395198,
    "finished_requests": 107041,
    "scheduler_time": 235.5962361745451
}
#Debug simulation 
Total elapsed time: 105.88073088601232. Arrivals time: 0.600809148978442 Scheduler time: 105.07929951604456 Scheduler overhead time: 0.0756157822906971 Adapter cache time: 0.019447607453912497 Engine time: 0.07673942903056741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.83835804089904,
    "estimated_duration": 3600.089329934346,
    "input_throughput": 7343.346949805304,
    "output_throughput": 6455.910637201843,
    "total_throughput": 13799.257587007147,
    "itl": 120.80397182307595,
    "ttft": 2020241.5742669876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5634039943479094,
    "arrivals": 1395198,
    "finished_requests": 107041,
    "scheduler_time": 235.59622777509958
}
#Debug simulation 
Total elapsed time: 105.83852170407772. Arrivals time: 0.5895028505474329 Scheduler time: 105.04859718354419 Scheduler overhead time: 0.07549085654318333 Adapter cache time: 0.0197635805234313 Engine time: 0.07692917948588729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 105.93148897821084,
    "estimated_duration": 3600.0211235757192,
    "input_throughput": 7343.486077587721,
    "output_throughput": 6456.032951527529,
    "total_throughput": 13799.51902911525,
    "itl": 120.80238173319398,
    "ttft": 2020211.8486707667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4955663656163911,
    "arrivals": 1395198,
    "finished_requests": 107041,
    "scheduler_time": 235.59518041500152
}
#Debug simulation 
Total elapsed time: 105.93165412684903. Arrivals time: 0.6059942059218884 Scheduler time: 105.12415112322196 Scheduler overhead time: 0.07617134135216475 Adapter cache time: 0.019202012568712234 Engine time: 0.07711166981607676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 105.99783467315137,
    "estimated_duration": 3600.1097824708136,
    "input_throughput": 7343.30523161326,
    "output_throughput": 6455.8739606125955,
    "total_throughput": 13799.179192225854,
    "itl": 120.80443862635579,
    "ttft": 2020250.7597492484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5832730926014533,
    "arrivals": 1395198,
    "finished_requests": 107041,
    "scheduler_time": 235.59635879319208
}
#Debug simulation 
Total elapsed time: 105.99799828091636. Arrivals time: 0.5897737103514373 Scheduler time: 105.20806819805875 Scheduler overhead time: 0.07664481224492192 Adapter cache time: 0.019240921828895807 Engine time: 0.07616713317111135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.79695941787213,
    "estimated_duration": 3600.0657851026704,
    "input_throughput": 7396.002625891085,
    "output_throughput": 6512.726544337671,
    "total_throughput": 13908.729170228757,
    "itl": 122.01855832265147,
    "ttft": 2014694.902503767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.468114694796953,
    "arrivals": 1395198,
    "finished_requests": 107898,
    "scheduler_time": 233.02115940755527
}
#Debug simulation 
Total elapsed time: 105.79712084401399. Arrivals time: 0.5864574159495533 Scheduler time: 105.01394506217912 Scheduler overhead time: 0.07471493072807789 Adapter cache time: 0.019108032807707787 Engine time: 0.0752559001557529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.9293442661874,
    "estimated_duration": 3600.1290244695297,
    "input_throughput": 7343.265983056089,
    "output_throughput": 6455.839455205257,
    "total_throughput": 13799.105438261346,
    "itl": 120.80480121768223,
    "ttft": 2020258.6898167487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6027649294957516,
    "arrivals": 1395198,
    "finished_requests": 107041,
    "scheduler_time": 235.5964482701156
}
#Debug simulation 
Total elapsed time: 105.92950279312208. Arrivals time: 0.5870591187849641 Scheduler time: 105.14421798009425 Scheduler overhead time: 0.07527181878685951 Adapter cache time: 0.01922515779733658 Engine time: 0.07567310519516468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.79414555383846,
    "estimated_duration": 3600.0156486249657,
    "input_throughput": 7381.419580814796,
    "output_throughput": 6547.639871788677,
    "total_throughput": 13929.059452603473,
    "itl": 122.3987799807855,
    "ttft": 2014249.0264188233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.508820457758864,
    "arrivals": 1390337,
    "finished_requests": 107449,
    "scheduler_time": 232.05043096907832
}
#Debug simulation 
Total elapsed time: 107.79431797284633. Arrivals time: 0.5916149257682264 Scheduler time: 107.00541746523231 Scheduler overhead time: 0.07488118996843696 Adapter cache time: 0.0190504495985806 Engine time: 0.07481845514848828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.80476628197357,
    "estimated_duration": 3600.0843849604817,
    "input_throughput": 7385.266054059967,
    "output_throughput": 6529.6166662654605,
    "total_throughput": 13914.882720325428,
    "itl": 123.22955993837007,
    "ttft": 2017291.703421868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5859579218155762,
    "arrivals": 1390337,
    "finished_requests": 107535,
    "scheduler_time": 231.15940465409147
}
#Debug simulation 
Total elapsed time: 102.80493552004918. Arrivals time: 0.5762010221369565 Scheduler time: 102.0338384192437 Scheduler overhead time: 0.07437173090875149 Adapter cache time: 0.018269330263137817 Engine time: 0.0751310046762228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.05969481915236,
    "estimated_duration": 3600.084859880223,
    "input_throughput": 7385.2650798027535,
    "output_throughput": 6529.615804884693,
    "total_throughput": 13914.880884687445,
    "itl": 123.22948935387595,
    "ttft": 2017291.2104729097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5887555962242281,
    "arrivals": 1390337,
    "finished_requests": 107535,
    "scheduler_time": 231.15934400003346
}
#Debug simulation 
Total elapsed time: 103.05987181607634. Arrivals time: 0.577251791022718 Scheduler time: 102.28764348430559 Scheduler overhead time: 0.0734719019383192 Adapter cache time: 0.018626708071678877 Engine time: 0.07443929696455598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.06268898909912,
    "estimated_duration": 3600.075940619335,
    "input_throughput": 7344.848952117126,
    "output_throughput": 6483.935446090693,
    "total_throughput": 13828.78439820782,
    "itl": 121.10378034009415,
    "ttft": 2019175.2953013277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 460,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4383468146948106,
    "arrivals": 1390337,
    "finished_requests": 106885,
    "scheduler_time": 233.96472907216625
}
#Debug simulation 
Total elapsed time: 106.06285782484338. Arrivals time: 0.5780279752798378 Scheduler time: 105.28851970238611 Scheduler overhead time: 0.07377539901062846 Adapter cache time: 0.019055369775742292 Engine time: 0.07532571628689766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.73890838027,
    "estimated_duration": 3600.1368043940283,
    "input_throughput": 7343.5731574789415,
    "output_throughput": 6493.931000473505,
    "total_throughput": 13837.504157952446,
    "itl": 121.3288414630364,
    "ttft": 2014892.3292286678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6593304774351463,
    "arrivals": 1390337,
    "finished_requests": 106850,
    "scheduler_time": 233.76650983552977
}
#Debug simulation 
Total elapsed time: 103.73907015100121. Arrivals time: 0.5812002732418478 Scheduler time: 102.96098582958803 Scheduler overhead time: 0.07464060094207525 Adapter cache time: 0.019155393820255995 Engine time: 0.07556595420464873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.50587939005345,
    "estimated_duration": 3600.067495755264,
    "input_throughput": 7381.313553518573,
    "output_throughput": 6547.555852159062,
    "total_throughput": 13928.869405677635,
    "itl": 122.39752186828088,
    "ttft": 2014304.6911981825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4740947953867571,
    "arrivals": 1390337,
    "finished_requests": 107450,
    "scheduler_time": 232.0569352164991
}
#Debug simulation 
Total elapsed time: 107.5060508060269. Arrivals time: 0.5797943295910954 Scheduler time: 106.72967776935548 Scheduler overhead time: 0.07507679425179958 Adapter cache time: 0.01906965533271432 Engine time: 0.07390550384297967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.00489769084379,
    "estimated_duration": 3600.0193312535043,
    "input_throughput": 7343.536955618192,
    "output_throughput": 6494.070405966308,
    "total_throughput": 13837.6073615845,
    "itl": 121.32925798195227,
    "ttft": 2014833.5714344548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680834374912081,
    "arrivals": 1390337,
    "finished_requests": 106848,
    "scheduler_time": 233.75793308160215
}
#Debug simulation 
Total elapsed time: 104.00506389886141. Arrivals time: 0.5850437446497381 Scheduler time: 103.22182773519307 Scheduler overhead time: 0.0756223420612514 Adapter cache time: 0.01899548340588808 Engine time: 0.07482513412833214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.42285068985075,
    "estimated_duration": 3600.1157682177486,
    "input_throughput": 7368.350827543597,
    "output_throughput": 6528.250621127938,
    "total_throughput": 13896.601448671534,
    "itl": 122.59105850475795,
    "ttft": 2016652.5654816742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3680380215379524,
    "arrivals": 1387991,
    "finished_requests": 107552,
    "scheduler_time": 231.38732073561349
}
#Debug simulation 
Total elapsed time: 108.42302411189303. Arrivals time: 0.5852778875268996 Scheduler time: 107.6427355427295 Scheduler overhead time: 0.07306430023163557 Adapter cache time: 0.018784099258482456 Engine time: 0.07512674434110522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.43831893103197,
    "estimated_duration": 3600.011974132801,
    "input_throughput": 7368.8299346254935,
    "output_throughput": 6545.575450669527,
    "total_throughput": 13914.40538529502,
    "itl": 123.09717708571223,
    "ttft": 2006618.077863222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.457775408332242,
    "arrivals": 1387991,
    "finished_requests": 107475,
    "scheduler_time": 231.68588978126024
}
#Debug simulation 
Total elapsed time: 107.43848673114553. Arrivals time: 0.6896179122850299 Scheduler time: 106.55468602664769 Scheduler overhead time: 0.07333568157628179 Adapter cache time: 0.018452844582498074 Engine time: 0.07509367354214191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.08832253096625,
    "estimated_duration": 3600.0146228162484,
    "input_throughput": 7368.824513064772,
    "output_throughput": 6545.570634812046,
    "total_throughput": 13914.395147876818,
    "itl": 123.09722886486301,
    "ttft": 2006619.3588509462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4599326448887673,
    "arrivals": 1387991,
    "finished_requests": 107475,
    "scheduler_time": 231.68592880801435
}
#Debug simulation 
Total elapsed time: 107.08849260909483. Arrivals time: 0.6045392761006951 Scheduler time: 106.28825357882306 Scheduler overhead time: 0.07473097695037723 Adapter cache time: 0.018673584796488285 Engine time: 0.07493956293910742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 107.28239666623995,
    "estimated_duration": 3600.007670513739,
    "input_throughput": 7368.85568808089,
    "output_throughput": 6545.889386018203,
    "total_throughput": 13914.745074099093,
    "itl": 123.09526442786766,
    "ttft": 2006583.2360979875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.394851729292419,
    "arrivals": 1387991,
    "finished_requests": 107478,
    "scheduler_time": 231.6913602934761
}
#Debug simulation 
Total elapsed time: 107.28256318997592. Arrivals time: 0.5890373499132693 Scheduler time: 106.4978303569369 Scheduler overhead time: 0.07424501469358802 Adapter cache time: 0.01864901976659894 Engine time: 0.07470141304656863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 107.17753535090014,
    "estimated_duration": 3600.032652645925,
    "input_throughput": 7368.787608218704,
    "output_throughput": 6545.537853019471,
    "total_throughput": 13914.325461238175,
    "itl": 123.09768734739575,
    "ttft": 2006626.518097733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4792987279966514,
    "arrivals": 1387991,
    "finished_requests": 107475,
    "scheduler_time": 231.685949814968
}
#Debug simulation 
Total elapsed time: 107.17770367208868. Arrivals time: 0.6848747041076422 Scheduler time: 106.297516672872 Scheduler overhead time: 0.07370099984109402 Adapter cache time: 0.018799324054270983 Engine time: 0.07488398905843496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.85706038493663,
    "estimated_duration": 3600.08557046775,
    "input_throughput": 7368.412633745654,
    "output_throughput": 6528.30538051527,
    "total_throughput": 13896.718014260925,
    "itl": 122.59023616198505,
    "ttft": 2016640.7510624751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 447,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.336552481821262,
    "arrivals": 1387991,
    "finished_requests": 107552,
    "scheduler_time": 231.38657263470262
}
#Debug simulation 
Total elapsed time: 108.85723321698606. Arrivals time: 0.604118934366852 Scheduler time: 108.0567099424079 Scheduler overhead time: 0.07427827036008239 Adapter cache time: 0.018598297610878944 Engine time: 0.07531662285327911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.81590654468164,
    "estimated_duration": 3600.0531313484003,
    "input_throughput": 7368.745691279279,
    "output_throughput": 6545.500619090598,
    "total_throughput": 13914.246310369877,
    "itl": 123.09807001091455,
    "ttft": 2006636.0254464005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4981617959588769,
    "arrivals": 1387991,
    "finished_requests": 107475,
    "scheduler_time": 231.6862081891161
}
#Debug simulation 
Total elapsed time: 107.8160685240291. Arrivals time: 0.5903928689658642 Scheduler time: 107.03082652855664 Scheduler overhead time: 0.07438950799405575 Adapter cache time: 0.018660076428204775 Engine time: 0.0744898933917284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.89919290039688,
    "estimated_duration": 3600.0295030740776,
    "input_throughput": 7359.919405486827,
    "output_throughput": 6541.126949068631,
    "total_throughput": 13901.046354555458,
    "itl": 123.22517600980667,
    "ttft": 2018671.9753381815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3190702176350266,
    "arrivals": 1386791,
    "finished_requests": 107537,
    "scheduler_time": 230.6730788421551
}
#Debug simulation 
Total elapsed time: 103.89935856917873. Arrivals time: 0.6022720504552126 Scheduler time: 103.10048371646553 Scheduler overhead time: 0.07501139491796494 Adapter cache time: 0.01870447862893343 Engine time: 0.07479865057393909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.69452334987,
    "estimated_duration": 3600.0828805108094,
    "input_throughput": 7339.119091683553,
    "output_throughput": 6518.793810844193,
    "total_throughput": 13857.912902527745,
    "itl": 122.3906040848003,
    "ttft": 2012616.0448527671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.740103814250329,
    "arrivals": 1386791,
    "finished_requests": 107186,
    "scheduler_time": 231.8617831424337
}
#Debug simulation 
Total elapsed time: 99.69467978691682. Arrivals time: 0.5925293839536607 Scheduler time: 98.90551075618714 Scheduler overhead time: 0.07405761629343033 Adapter cache time: 0.019868815317749977 Engine time: 0.07510350877419114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 100.33770131226629,
    "estimated_duration": 3600.0678096276547,
    "input_throughput": 7353.086219433708,
    "output_throughput": 6529.084795886407,
    "total_throughput": 13882.171015320115,
    "itl": 122.50410640889727,
    "ttft": 2014083.0075487543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7571360011957693,
    "arrivals": 1386791,
    "finished_requests": 107354,
    "scheduler_time": 231.27267999348146
}
#Debug simulation 
Total elapsed time: 100.33786912309006. Arrivals time: 0.5815251306630671 Scheduler time: 99.56105111259967 Scheduler overhead time: 0.07316655991598964 Adapter cache time: 0.01955383364111185 Engine time: 0.0752368625253439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 103.3149775089696,
    "estimated_duration": 3600.0588133859096,
    "input_throughput": 7359.8594838177605,
    "output_throughput": 6541.073693696831,
    "total_throughput": 13900.933177514591,
    "itl": 123.22597766579266,
    "ttft": 2018684.717491568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3471408076398048,
    "arrivals": 1386791,
    "finished_requests": 107537,
    "scheduler_time": 230.67352682871464
}
#Debug simulation 
Total elapsed time: 103.31513379374519. Arrivals time: 0.5833992920815945 Scheduler time: 102.53899154113606 Scheduler overhead time: 0.07214268017560244 Adapter cache time: 0.018084135837852955 Engine time: 0.07479881960898638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 100.20748534193262,
    "estimated_duration": 3600.089807028247,
    "input_throughput": 7353.0412903369825,
    "output_throughput": 6529.04490163336,
    "total_throughput": 13882.086191970342,
    "itl": 122.50467361181674,
    "ttft": 2014091.0908705115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.779017160031949,
    "arrivals": 1386791,
    "finished_requests": 107354,
    "scheduler_time": 231.27279623525982
}
#Debug simulation 
Total elapsed time: 100.20764242485166. Arrivals time: 0.5861095623113215 Scheduler time: 99.42932580551133 Scheduler overhead time: 0.07306792819872499 Adapter cache time: 0.01823965646326542 Engine time: 0.07368138758465648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.30912071280181,
    "estimated_duration": 3600.0041490939034,
    "input_throughput": 7378.284551890152,
    "output_throughput": 6560.861605102532,
    "total_throughput": 13939.146156992683,
    "itl": 123.30211587133235,
    "ttft": 2014461.8079162117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2857216268079268,
    "arrivals": 1386791,
    "finished_requests": 107770,
    "scheduler_time": 229.936160058159
}
#Debug simulation 
Total elapsed time: 106.30927404621616. Arrivals time: 0.9855411979369819 Scheduler time: 105.12913694465533 Scheduler overhead time: 0.07566732540726662 Adapter cache time: 0.017121315002441406 Engine time: 0.07398988166823983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 98.3072181576863,
    "estimated_duration": 3600.1131805613913,
    "input_throughput": 7352.9935511283265,
    "output_throughput": 6529.002512175096,
    "total_throughput": 13881.996063303422,
    "itl": 122.50521484936371,
    "ttft": 2014099.665061231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 538,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.801778595373032,
    "arrivals": 1386791,
    "finished_requests": 107354,
    "scheduler_time": 231.2729559129632
}
#Debug simulation 
Total elapsed time: 98.30742409499362. Arrivals time: 0.588639338966459 Scheduler time: 97.5355668719858 Scheduler overhead time: 0.07021699380129576 Adapter cache time: 0.016950068529695272 Engine time: 0.06953006749972701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.78928919695318,
    "estimated_duration": 3600.1009756276453,
    "input_throughput": 7251.754652645116,
    "output_throughput": 6433.94675782997,
    "total_throughput": 13685.701410475087,
    "itl": 123.20556090955911,
    "ttft": 2021313.914831032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.312949242147161,
    "arrivals": 1289387,
    "finished_requests": 105513,
    "scheduler_time": 236.72911070450826
}
#Debug simulation 
Total elapsed time: 108.78944821981713. Arrivals time: 0.4733148836530745 Scheduler time: 108.13095546606928 Scheduler overhead time: 0.0718685737811029 Adapter cache time: 0.016059755347669125 Engine time: 0.07061103219166398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.79692512843758,
    "estimated_duration": 3600.016968847803,
    "input_throughput": 7312.525531907553,
    "output_throughput": 6497.127708674654,
    "total_throughput": 13809.653240582207,
    "itl": 124.40932117105288,
    "ttft": 2019048.288285609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 450,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4681012282380892,
    "arrivals": 1289387,
    "finished_requests": 106583,
    "scheduler_time": 233.09584278625314
}
#Debug simulation 
Total elapsed time: 103.7970810001716. Arrivals time: 0.48842073744162917 Scheduler time: 103.12566951196641 Scheduler overhead time: 0.06969656143337488 Adapter cache time: 0.016156206838786602 Engine time: 0.07086505880579352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.17803112976253,
    "estimated_duration": 3600.079406439943,
    "input_throughput": 7317.326099217933,
    "output_throughput": 6499.408862522359,
    "total_throughput": 13816.734961740292,
    "itl": 124.25321983799448,
    "ttft": 2019750.5156900794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4961176235787659,
    "arrivals": 1289387,
    "finished_requests": 106677,
    "scheduler_time": 232.98615915004186
}
#Debug simulation 
Total elapsed time: 104.17819907609373. Arrivals time: 0.48128806753084064 Scheduler time: 103.51427050167695 Scheduler overhead time: 0.06884860759600997 Adapter cache time: 0.01619101082906127 Engine time: 0.0709763616323471 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 101.27823702478781,
    "estimated_duration": 3600.003665636184,
    "input_throughput": 7306.274782737441,
    "output_throughput": 6501.856990710487,
    "total_throughput": 13808.131773447927,
    "itl": 124.4561137751426,
    "ttft": 2019700.9371161577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4307323328312442,
    "arrivals": 1289387,
    "finished_requests": 106558,
    "scheduler_time": 232.97492114391937
}
#Debug simulation 
Total elapsed time: 101.27838771883398. Arrivals time: 0.484581109136343 Scheduler time: 100.61239806236699 Scheduler overhead time: 0.06948133837431669 Adapter cache time: 0.015781612135469913 Engine time: 0.06947783334180713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 103.99816370522603,
    "estimated_duration": 3600.0981324104005,
    "input_throughput": 7317.288038024231,
    "output_throughput": 6499.375055738801,
    "total_throughput": 13816.663093763033,
    "itl": 124.25357400911355,
    "ttft": 2019758.6128057993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5149806915409907,
    "arrivals": 1289387,
    "finished_requests": 106677,
    "scheduler_time": 232.9862482626025
}
#Debug simulation 
Total elapsed time: 103.99831866519526. Arrivals time: 0.48040473088622093 Scheduler time: 103.33528676023707 Scheduler overhead time: 0.07080751284956932 Adapter cache time: 0.016050560865551233 Engine time: 0.06947498396039009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 110.34319264395162,
    "estimated_duration": 3600.069996046464,
    "input_throughput": 7251.817055965667,
    "output_throughput": 6434.002123691223,
    "total_throughput": 13685.81917965689,
    "itl": 123.20496227987219,
    "ttft": 2021300.0994159598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2827315765130247,
    "arrivals": 1289387,
    "finished_requests": 105513,
    "scheduler_time": 236.7289143140488
}
#Debug simulation 
Total elapsed time: 110.34334046393633. Arrivals time: 0.48121112724766135 Scheduler time: 109.67620357731357 Scheduler overhead time: 0.07188549311831594 Adapter cache time: 0.01620618114247918 Engine time: 0.07107103895395994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 100.97584792785347,
    "estimated_duration": 3600.015588061382,
    "input_throughput": 7306.234474991259,
    "output_throughput": 6501.670180990593,
    "total_throughput": 13807.90465598185,
    "itl": 124.45916394004144,
    "ttft": 2019693.3178946213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 458,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5337580195814369,
    "arrivals": 1289387,
    "finished_requests": 106558,
    "scheduler_time": 232.9701034151675
}
#Debug simulation 
Total elapsed time: 100.97600404918194. Arrivals time: 0.48353838780894876 Scheduler time: 100.30901593575254 Scheduler overhead time: 0.07215594220906496 Adapter cache time: 0.01584882801398635 Engine time: 0.06864411011338234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.67189452797174,
    "estimated_duration": 3600.085454932336,
    "input_throughput": 7287.875615300673,
    "output_throughput": 6471.264999579815,
    "total_throughput": 13759.140614880487,
    "itl": 123.31492643061009,
    "ttft": 2014154.8420687574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3955824112333481,
    "arrivals": 1279697,
    "finished_requests": 106983,
    "scheduler_time": 234.42232326338066
}
#Debug simulation 
Total elapsed time: 99.67202359298244. Arrivals time: 0.5699634309858084 Scheduler time: 98.92037099646404 Scheduler overhead time: 0.06999030895531178 Adapter cache time: 0.01667105546221137 Engine time: 0.06893391674384475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 96.02145869378,
    "estimated_duration": 3600.116484821774,
    "input_throughput": 7343.04045756695,
    "output_throughput": 6523.003935846973,
    "total_throughput": 13866.044393413922,
    "itl": 124.55463708607749,
    "ttft": 2011437.9729706992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5583601615903941,
    "arrivals": 1279697,
    "finished_requests": 107736,
    "scheduler_time": 231.55923450236872
}
#Debug simulation 
Total elapsed time: 96.02159371692687. Arrivals time: 0.48165329406037927 Scheduler time: 95.35927923908457 Scheduler overhead time: 0.06965554412454367 Adapter cache time: 0.017046786844730377 Engine time: 0.06811132002621889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 96.32121097808704,
    "estimated_duration": 3600.1195028906777,
    "input_throughput": 7343.034301715166,
    "output_throughput": 6522.998467452015,
    "total_throughput": 13866.032769167181,
    "itl": 124.55472850462482,
    "ttft": 2011439.0480570192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5613722179830167,
    "arrivals": 1279697,
    "finished_requests": 107736,
    "scheduler_time": 231.55924051487452
}
#Debug simulation 
Total elapsed time: 96.32133982516825. Arrivals time: 0.4904465707950294 Scheduler time: 95.64669193327427 Scheduler overhead time: 0.07102768961340189 Adapter cache time: 0.0168549339286983 Engine time: 0.06968938978388906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 96.3276989236474,
    "estimated_duration": 3600.0819581022956,
    "input_throughput": 7343.110881268673,
    "output_throughput": 6523.066494958035,
    "total_throughput": 13866.177376226708,
    "itl": 124.55284916322091,
    "ttft": 2011430.7882708702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.496253673187452,
    "arrivals": 1279697,
    "finished_requests": 107736,
    "scheduler_time": 231.56325917719636
}
#Debug simulation 
Total elapsed time: 96.3278272850439. Arrivals time: 0.4773092777468264 Scheduler time: 95.66758395591751 Scheduler overhead time: 0.07074157195165753 Adapter cache time: 0.016363490372896194 Engine time: 0.06930520990863442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 96.45608681393787,
    "estimated_duration": 3600.140079155843,
    "input_throughput": 7342.992333286831,
    "output_throughput": 6522.96118586208,
    "total_throughput": 13865.95351914891,
    "itl": 124.55520224028196,
    "ttft": 2011447.6469580452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5804867935180713,
    "arrivals": 1279697,
    "finished_requests": 107736,
    "scheduler_time": 231.55979736425942
}
#Debug simulation 
Total elapsed time: 96.45622015884146. Arrivals time: 0.4789798418059945 Scheduler time: 95.79476315807551 Scheduler overhead time: 0.07027999870479107 Adapter cache time: 0.016763092018663883 Engine time: 0.06915301037952304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.37513668602332,
    "estimated_duration": 3600.0524718222946,
    "input_throughput": 7287.942385661735,
    "output_throughput": 6471.32428828387,
    "total_throughput": 13759.266673945605,
    "itl": 123.31423754135679,
    "ttft": 2014140.7967442248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3634629344753806,
    "arrivals": 1279697,
    "finished_requests": 106983,
    "scheduler_time": 234.42213826021134
}
#Debug simulation 
Total elapsed time: 99.37526303390041. Arrivals time: 0.4841340961866081 Scheduler time: 98.709476897493 Scheduler overhead time: 0.07023358484730124 Adapter cache time: 0.01625551888719201 Engine time: 0.06892762938514352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 96.79220842337236,
    "estimated_duration": 3600.0181051167333,
    "input_throughput": 7342.699183215042,
    "output_throughput": 6522.98719459872,
    "total_throughput": 13865.686377813761,
    "itl": 124.55611126868848,
    "ttft": 2011437.0255757205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6011104144901036,
    "arrivals": 1279697,
    "finished_requests": 107730,
    "scheduler_time": 231.55110624420976
}
#Debug simulation 
Total elapsed time: 96.79233678104356. Arrivals time: 0.48853992437943816 Scheduler time: 96.1197739513591 Scheduler overhead time: 0.07055994402617216 Adapter cache time: 0.0165906329639256 Engine time: 0.07044743979349732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 97.51855192473158,
    "estimated_duration": 3600.0779586780563,
    "input_throughput": 7376.450539352001,
    "output_throughput": 6498.001784547464,
    "total_throughput": 13874.452323899464,
    "itl": 123.86896777860102,
    "ttft": 2011744.0707142411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4384292396484082,
    "arrivals": 1274994,
    "finished_requests": 107162,
    "scheduler_time": 232.85708978287474
}
#Debug simulation 
Total elapsed time: 97.51867979066446. Arrivals time: 0.48862204514443874 Scheduler time: 96.84568738378584 Scheduler overhead time: 0.07128361659124494 Adapter cache time: 0.016865188255906105 Engine time: 0.0696073672734201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 95.95743116829544,
    "estimated_duration": 3600.1062466719463,
    "input_throughput": 7422.3134455272975,
    "output_throughput": 6536.782080182984,
    "total_throughput": 13959.095525710281,
    "itl": 124.30390941891966,
    "ttft": 2011826.1568206104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6119213007669952,
    "arrivals": 1274994,
    "finished_requests": 107775,
    "scheduler_time": 230.7885615304962
}
#Debug simulation 
Total elapsed time: 95.95756192924455. Arrivals time: 0.49185485299676657 Scheduler time: 95.28375691641122 Scheduler overhead time: 0.07008851272985339 Adapter cache time: 0.017033292911946774 Engine time: 0.06879017734900117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 96.06900306697935,
    "estimated_duration": 3600.108090869235,
    "input_throughput": 7422.30964336081,
    "output_throughput": 6536.77873164025,
    "total_throughput": 13959.08837500106,
    "itl": 124.30396266242654,
    "ttft": 2011826.6086414182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6147899844870068,
    "arrivals": 1274994,
    "finished_requests": 107775,
    "scheduler_time": 230.78855498933584
}
#Debug simulation 
Total elapsed time: 96.06912955129519. Arrivals time: 0.4898173101246357 Scheduler time: 95.39498493820429 Scheduler overhead time: 0.07076614908874035 Adapter cache time: 0.017150646541267633 Engine time: 0.0699798739515245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 99.97301446506754,
    "estimated_duration": 3600.061739226144,
    "input_throughput": 7395.363171111323,
    "output_throughput": 6522.260089085942,
    "total_throughput": 13917.623260197264,
    "itl": 124.20880399072274,
    "ttft": 2010991.7611013022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4674301270069505,
    "arrivals": 1274994,
    "finished_requests": 107521,
    "scheduler_time": 231.55008810071755
}
#Debug simulation 
Total elapsed time: 99.97314418200403. Arrivals time: 0.4904607506468892 Scheduler time: 99.29930011415854 Scheduler overhead time: 0.07065606256946921 Adapter cache time: 0.016176335979253054 Engine time: 0.07041239831596613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 99.69496756792068,
    "estimated_duration": 3600.089932095334,
    "input_throughput": 7395.305256861838,
    "output_throughput": 6522.2090122437,
    "total_throughput": 13917.514269105539,
    "itl": 124.21209316515906,
    "ttft": 2010970.9565716905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5553326817601965,
    "arrivals": 1274994,
    "finished_requests": 107521,
    "scheduler_time": 231.54317883088018
}
#Debug simulation 
Total elapsed time: 99.69509583292529. Arrivals time: 0.496058423537761 Scheduler time: 99.01643374422565 Scheduler overhead time: 0.07026886334642768 Adapter cache time: 0.01668913010507822 Engine time: 0.06935980217531323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 96.51517128292471,
    "estimated_duration": 3600.1425488297496,
    "input_throughput": 7412.216776992386,
    "output_throughput": 6528.380385282199,
    "total_throughput": 13940.597162274586,
    "itl": 124.19677315537795,
    "ttft": 2011170.448622605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5219356001051902,
    "arrivals": 1274994,
    "finished_requests": 107656,
    "scheduler_time": 231.1493144354459
}
#Debug simulation 
Total elapsed time: 96.51529812905937. Arrivals time: 0.5041125915013254 Scheduler time: 95.8289202018641 Scheduler overhead time: 0.0689797573722899 Adapter cache time: 0.017058574594557285 Engine time: 0.06974671268835664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.29757538903505,
    "estimated_duration": 3600.109252204536,
    "input_throughput": 7395.265569703717,
    "output_throughput": 6522.174010586382,
    "total_throughput": 13917.4395802901,
    "itl": 124.21252180146081,
    "ttft": 2010979.2848899958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5744472572952508,
    "arrivals": 1274994,
    "finished_requests": 107521,
    "scheduler_time": 231.54327125952312
}
#Debug simulation 
Total elapsed time: 99.29770556883886. Arrivals time: 0.5020577111281455 Scheduler time: 98.61003891704604 Scheduler overhead time: 0.0711066615767777 Adapter cache time: 0.01691484311595559 Engine time: 0.07137727178633213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.40680213319138,
    "estimated_duration": 3600.1011059538323,
    "input_throughput": 7350.86743987111,
    "output_throughput": 6527.401955777559,
    "total_throughput": 13878.26939564867,
    "itl": 124.85129034142935,
    "ttft": 2009492.5052190747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2486789995245708,
    "arrivals": 1272675,
    "finished_requests": 107280,
    "scheduler_time": 231.35119072183804
}
#Debug simulation 
Total elapsed time: 103.40693027712405. Arrivals time: 0.4952847082167864 Scheduler time: 102.72832455346361 Scheduler overhead time: 0.0710781174711883 Adapter cache time: 0.01603525783866644 Engine time: 0.06993615534156561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.72431608708575,
    "estimated_duration": 3600.0887773825216,
    "input_throughput": 7331.36615013969,
    "output_throughput": 6514.450184490015,
    "total_throughput": 13845.816334629704,
    "itl": 124.37223527828199,
    "ttft": 2007058.750983821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3079752352135319,
    "arrivals": 1272675,
    "finished_requests": 107035,
    "scheduler_time": 232.24298054563383
}
#Debug simulation 
Total elapsed time: 109.72444139420986. Arrivals time: 0.5041427290998399 Scheduler time: 109.03262205282226 Scheduler overhead time: 0.07285803509876132 Adapter cache time: 0.016164799220860004 Engine time: 0.07125757122412324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.61551797389984,
    "estimated_duration": 3600.090509373414,
    "input_throughput": 7331.362623045199,
    "output_throughput": 6514.447050410924,
    "total_throughput": 13845.809673456124,
    "itl": 124.3722633261883,
    "ttft": 2007059.6361572177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3098133530095295,
    "arrivals": 1272675,
    "finished_requests": 107035,
    "scheduler_time": 232.24298752375304
}
#Debug simulation 
Total elapsed time: 109.61563258711249. Arrivals time: 0.4994190065190196 Scheduler time: 108.92836262471974 Scheduler overhead time: 0.07316351216286421 Adapter cache time: 0.016018992755562067 Engine time: 0.07157516526058316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 109.34487420227379,
    "estimated_duration": 3600.0057958262328,
    "input_throughput": 7320.131826052204,
    "output_throughput": 6519.607281524747,
    "total_throughput": 13839.739107576952,
    "itl": 124.01710496484178,
    "ttft": 2005169.8226981745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2677651186985885,
    "arrivals": 1272675,
    "finished_requests": 106837,
    "scheduler_time": 233.82249746809148
}
#Debug simulation 
Total elapsed time: 109.34499090537429. Arrivals time: 0.4948584553785622 Scheduler time: 108.66269793175161 Scheduler overhead time: 0.07295216852799058 Adapter cache time: 0.016147800255566835 Engine time: 0.0717620556242764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 109.75592209398746,
    "estimated_duration": 3600.1069078948262,
    "input_throughput": 7331.329228618303,
    "output_throughput": 6514.417377042278,
    "total_throughput": 13845.74660566058,
    "itl": 124.37259201134025,
    "ttft": 2007066.188410907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.326790114175533,
    "arrivals": 1272675,
    "finished_requests": 107035,
    "scheduler_time": 232.24308791419125
}
#Debug simulation 
Total elapsed time: 109.75604079617187. Arrivals time: 0.4960978399030864 Scheduler time: 109.07468663575128 Scheduler overhead time: 0.07204324332997203 Adapter cache time: 0.015961870085448027 Engine time: 0.07029516343027353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.42972310399637,
    "estimated_duration": 3600.0720613317517,
    "input_throughput": 7350.9267451192045,
    "output_throughput": 6527.45461747981,
    "total_throughput": 13878.381362599015,
    "itl": 124.85066558412616,
    "ttft": 2009479.8946673565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2199405203200813,
    "arrivals": 1272675,
    "finished_requests": 107280,
    "scheduler_time": 231.35099768393172
}
#Debug simulation 
Total elapsed time: 103.42984579410404. Arrivals time: 0.5210721706971526 Scheduler time: 102.72458798531443 Scheduler overhead time: 0.07088628457859159 Adapter cache time: 0.016131514683365822 Engine time: 0.07061110390350223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.48593890992925,
    "estimated_duration": 3600.009944452513,
    "input_throughput": 7331.476970132061,
    "output_throughput": 6514.564504506289,
    "total_throughput": 13846.04147463835,
    "itl": 124.37303145201446,
    "ttft": 2007077.7248658948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3442698904871955,
    "arrivals": 1272675,
    "finished_requests": 107034,
    "scheduler_time": 232.23540602810846
}
#Debug simulation 
Total elapsed time: 109.48610220430419. Arrivals time: 0.5022989688441157 Scheduler time: 108.79532648297027 Scheduler overhead time: 0.07298093382269144 Adapter cache time: 0.016211302019655704 Engine time: 0.07244056882336736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 94.90845019416884,
    "estimated_duration": 3600.1056032498295,
    "input_throughput": 7409.22071172615,
    "output_throughput": 6543.637214067913,
    "total_throughput": 13952.857925794064,
    "itl": 124.5774381739785,
    "ttft": 2006296.0126633793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2394975362927723,
    "arrivals": 1271499,
    "finished_requests": 108186,
    "scheduler_time": 230.48383929988248
}
#Debug simulation 
Total elapsed time: 94.9085755799897. Arrivals time: 0.4752563307993114 Scheduler time: 94.25247473455966 Scheduler overhead time: 0.07044663466513157 Adapter cache time: 0.015943408478051424 Engine time: 0.06852699676528573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 100.64602001104504,
    "estimated_duration": 3600.005560504482,
    "input_throughput": 7367.128343069397,
    "output_throughput": 6513.420495026707,
    "total_throughput": 13880.548838096103,
    "itl": 124.44133910044292,
    "ttft": 2005338.4480491667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2752145650354276,
    "arrivals": 1271499,
    "finished_requests": 107576,
    "scheduler_time": 232.1087041346847
}
#Debug simulation 
Total elapsed time: 100.64615213731304. Arrivals time: 0.48703829012811184 Scheduler time: 99.97481673769653 Scheduler overhead time: 0.07115003280341625 Adapter cache time: 0.015787447802722454 Engine time: 0.07073645573109388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 100.67112491792068,
    "estimated_duration": 3600.0073820102843,
    "input_throughput": 7367.1246155028675,
    "output_throughput": 6513.417199413125,
    "total_throughput": 13880.541814915992,
    "itl": 124.44137055437562,
    "ttft": 2005339.2730204167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2770174320601,
    "arrivals": 1271499,
    "finished_requests": 107576,
    "scheduler_time": 232.1087227734526
}
#Debug simulation 
Total elapsed time: 100.67126034293324. Arrivals time: 0.48526750318706036 Scheduler time: 100.00189337041229 Scheduler overhead time: 0.07152678770944476 Adapter cache time: 0.016407574992626905 Engine time: 0.06948846811428666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.66096804011613,
    "estimated_duration": 3600.0949506665784,
    "input_throughput": 7367.518180343819,
    "output_throughput": 6513.469872692736,
    "total_throughput": 13880.988053036555,
    "itl": 124.43886549067413,
    "ttft": 2005380.328863796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.223322959593497,
    "arrivals": 1271499,
    "finished_requests": 107583,
    "scheduler_time": 232.11709730746077
}
#Debug simulation 
Total elapsed time: 106.66109891794622. Arrivals time: 0.4963901024311781 Scheduler time: 105.97937133675441 Scheduler overhead time: 0.07107184501364827 Adapter cache time: 0.01608792459592223 Engine time: 0.07126838760450482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 100.86856717895716,
    "estimated_duration": 3600.0235745085915,
    "input_throughput": 7367.091479010732,
    "output_throughput": 6513.3879028002575,
    "total_throughput": 13880.479381810988,
    "itl": 124.44167068196175,
    "ttft": 2005346.0547540088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2929881629347846,
    "arrivals": 1271499,
    "finished_requests": 107576,
    "scheduler_time": 232.10883143586116
}
#Debug simulation 
Total elapsed time: 100.8687028218992. Arrivals time: 0.5006509581580758 Scheduler time: 100.18232056498528 Scheduler overhead time: 0.0720676863566041 Adapter cache time: 0.016112581826746464 Engine time: 0.07054165564477444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 95.31674869079143,
    "estimated_duration": 3600.077441574102,
    "input_throughput": 7409.2786704991095,
    "output_throughput": 6543.688401797148,
    "total_throughput": 13952.967072296258,
    "itl": 124.5768638564858,
    "ttft": 2006284.3057504646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.210970369435375,
    "arrivals": 1271499,
    "finished_requests": 108186,
    "scheduler_time": 230.48363926579438
}
#Debug simulation 
Total elapsed time: 95.31688033696264. Arrivals time: 0.4920882638543844 Scheduler time: 94.64365437394008 Scheduler overhead time: 0.06964806653559208 Adapter cache time: 0.015758840832859278 Engine time: 0.0697759403847158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_32_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 100.78614040184766,
    "estimated_duration": 3600.124543948765,
    "input_throughput": 7377.749207216871,
    "output_throughput": 6525.055095520137,
    "total_throughput": 13902.804302737008,
    "itl": 124.51308877310646,
    "ttft": 2007662.5461828958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 397,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.334676332660021,
    "arrivals": 1271499,
    "finished_requests": 107705,
    "scheduler_time": 231.51546505224135
}
#Debug simulation 
Total elapsed time: 100.7862693099305. Arrivals time: 0.49911816976964474 Scheduler time: 100.10603020247072 Scheduler overhead time: 0.07007100665941834 Adapter cache time: 0.015702564269304276 Engine time: 0.06878229370340705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 91.58644730318338,
    "estimated_duration": 3600.012471582978,
    "input_throughput": 7313.766884930393,
    "output_throughput": 6516.634368681593,
    "total_throughput": 13830.401253611986,
    "itl": 125.0164006077871,
    "ttft": 2011079.057531409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.444550215136274,
    "arrivals": 1260602,
    "finished_requests": 106926,
    "scheduler_time": 231.92282956864128
}
#Debug simulation 
Total elapsed time: 91.58658177498728. Arrivals time: 0.4803090454079211 Scheduler time: 90.92645756993443 Scheduler overhead time: 0.0689648543484509 Adapter cache time: 0.016314283944666386 Engine time: 0.06883759191259742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.43400821788236,
    "estimated_duration": 3600.106847798642,
    "input_throughput": 7313.5751557206695,
    "output_throughput": 6516.463536171175,
    "total_throughput": 13830.038691891845,
    "itl": 125.01848602570293,
    "ttft": 2011118.4223324137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5391940738656609,
    "arrivals": 1260602,
    "finished_requests": 106926,
    "scheduler_time": 231.92414539598076
}
#Debug simulation 
Total elapsed time: 91.43413633527234. Arrivals time: 0.48758778255432844 Scheduler time: 90.76784685999155 Scheduler overhead time: 0.06872778898105025 Adapter cache time: 0.016220293939113617 Engine time: 0.06742743728682399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.38738486496732,
    "estimated_duration": 3600.10977854013,
    "input_throughput": 7313.5692019582975,
    "output_throughput": 6516.458231313486,
    "total_throughput": 13830.027433271784,
    "itl": 125.01857484811029,
    "ttft": 2011119.670494728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5420993624068888,
    "arrivals": 1260602,
    "finished_requests": 106926,
    "scheduler_time": 231.92417084892188
}
#Debug simulation 
Total elapsed time: 91.3875126936473. Arrivals time: 0.4831551956012845 Scheduler time: 90.72477921890095 Scheduler overhead time: 0.06934390217065811 Adapter cache time: 0.015896406956017017 Engine time: 0.06816131016239524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 91.34552539465949,
    "estimated_duration": 3600.042663750399,
    "input_throughput": 7313.705547192235,
    "output_throughput": 6516.579716185982,
    "total_throughput": 13830.285263378217,
    "itl": 125.0170247606025,
    "ttft": 2011091.521659217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.475453204188957,
    "arrivals": 1260602,
    "finished_requests": 106926,
    "scheduler_time": 231.92291048217325
}
#Debug simulation 
Total elapsed time: 91.3456490598619. Arrivals time: 0.4775415579788387 Scheduler time: 90.68906037462875 Scheduler overhead time: 0.06841593515127897 Adapter cache time: 0.016246269922703505 Engine time: 0.06801782455295324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_32_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 91.4785906621255,
    "estimated_duration": 3600.130198330212,
    "input_throughput": 7313.52771969526,
    "output_throughput": 6516.421270231016,
    "total_throughput": 13829.948989926277,
    "itl": 125.01921570468652,
    "ttft": 2011128.7344774895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5617169530876025,
    "arrivals": 1260602,
    "finished_requests": 106926,
    "scheduler_time": 231.9244075231701
}
#Debug simulation 
Total elapsed time: 91.47871362511069. Arrivals time: 0.4671420189552009 Scheduler time: 90.83163171401247 Scheduler overhead time: 0.06897387374192476 Adapter cache time: 0.016273089218884706 Engine time: 0.06850890582427382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_32_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 91.86937550315633,
    "estimated_duration": 3600.115256494818,
    "input_throughput": 7313.826398334895,
    "output_throughput": 6516.489425630634,
    "total_throughput": 13830.31582396553,
    "itl": 125.01509699423019,
    "ttft": 2011104.0075865497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4113037391938137,
    "arrivals": 1260602,
    "finished_requests": 106929,
    "scheduler_time": 231.93072277291245
}
#Debug simulation 
Total elapsed time: 91.86949490802363. Arrivals time: 0.4744432885199785 Scheduler time: 91.21527038048953 Scheduler overhead time: 0.06881361734122038 Adapter cache time: 0.016008808743208647 Engine time: 0.06869756057858467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_32_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 91.35139283910394,
    "estimated_duration": 3600.01035223205,
    "input_throughput": 7313.0509148888705,
    "output_throughput": 6516.081540003289,
    "total_throughput": 13829.13245489216,
    "itl": 125.0198355454806,
    "ttft": 2011070.931598599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 472,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.581460297554731,
    "arrivals": 1260602,
    "finished_requests": 106919,
    "scheduler_time": 231.91578388975995
}
#Debug simulation 
Total elapsed time: 91.35151222813874. Arrivals time: 0.4682452632114291 Scheduler time: 90.70538241555914 Scheduler overhead time: 0.06865132926031947 Adapter cache time: 0.01625535823404789 Engine time: 0.06721556140109897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_32_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.04861991340294,
    "estimated_duration": 3600.0542053859667,
    "input_throughput": 7368.611550435242,
    "output_throughput": 6514.114416642727,
    "total_throughput": 13882.725967077968,
    "itl": 124.22639868892755,
    "ttft": 2006815.3740172344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3251911931228924,
    "arrivals": 1256018,
    "finished_requests": 107346,
    "scheduler_time": 232.1628019709629
}
#Debug simulation 
Total elapsed time: 108.04878446832299. Arrivals time: 0.49018974136561155 Scheduler time: 107.37283421354368 Scheduler overhead time: 0.07190221594646573 Adapter cache time: 0.016455958131700754 Engine time: 0.0703790420666337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_32_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.12902786023915,
    "estimated_duration": 3600.1010410284666,
    "input_throughput": 7383.192776280143,
    "output_throughput": 6527.700676225042,
    "total_throughput": 13910.893452505186,
    "itl": 124.3154399655906,
    "ttft": 2007226.6385934893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4063871288136636,
    "arrivals": 1256018,
    "finished_requests": 107559,
    "scheduler_time": 231.36908773630384
}
#Debug simulation 
Total elapsed time: 104.1291509498842. Arrivals time: 0.48146776715293527 Scheduler time: 103.46182799618691 Scheduler overhead time: 0.0716376481577754 Adapter cache time: 0.01646495284512639 Engine time: 0.07138157030567527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_32_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.97001200122759,
    "estimated_duration": 3600.1035454177413,
    "input_throughput": 7383.187640208759,
    "output_throughput": 6527.696135271329,
    "total_throughput": 13910.883775480088,
    "itl": 124.31550033519879,
    "ttft": 2007227.5739626782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.408883902244278,
    "arrivals": 1256018,
    "finished_requests": 107559,
    "scheduler_time": 231.36909535214448
}
#Debug simulation 
Total elapsed time: 103.97013014229015. Arrivals time: 0.4871154287829995 Scheduler time: 103.29565854370594 Scheduler overhead time: 0.07247171364724636 Adapter cache time: 0.016679235734045506 Engine time: 0.07134054508060217 
