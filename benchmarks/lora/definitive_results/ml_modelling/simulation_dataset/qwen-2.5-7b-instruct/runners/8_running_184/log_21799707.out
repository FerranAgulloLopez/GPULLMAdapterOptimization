INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7757951528765261,
    "estimated_duration": 3599.9718899613163,
    "input_throughput": 1284.4203069734765,
    "output_throughput": 1164.5296486037419,
    "total_throughput": 2448.949955577218,
    "itl": 21.981392374681626,
    "ttft": 6366.08252910983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.098988328054347,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.00026705982050897895
}
#Debug simulation 
Total elapsed time: 1.775947346817702. Arrivals time: 0.05962604330852628 Scheduler time: 1.3270749640651047 Scheduler overhead time: 0.13972110813483596 Adapter cache time: 0.03839927911758423 Engine time: 0.14223438873887062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7616239772178233,
    "estimated_duration": 3599.9608167939587,
    "input_throughput": 1284.424257738982,
    "output_throughput": 1164.5332305959769,
    "total_throughput": 2448.9574883349587,
    "itl": 21.978438510713485,
    "ttft": 6366.0268144161255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.661615772391508,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0002637558668518291
}
#Debug simulation 
Total elapsed time: 1.7617340204305947. Arrivals time: 0.05854335427284241 Scheduler time: 1.3188434620387852 Scheduler overhead time: 0.1382095697335899 Adapter cache time: 0.0379893365316093 Engine time: 0.13930874038487673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.755445420742035,
    "estimated_duration": 3599.970068154179,
    "input_throughput": 1284.4209569694592,
    "output_throughput": 1164.5302379276488,
    "total_throughput": 2448.951194897108,
    "itl": 21.982655763268323,
    "ttft": 6366.162056158577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.239285796023564,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0002621810264587033
}
#Debug simulation 
Total elapsed time: 1.7555388025939465. Arrivals time: 0.05798456771299243 Scheduler time: 1.314635707065463 Scheduler overhead time: 0.13741694809868932 Adapter cache time: 0.038082231767475605 Engine time: 0.13908241363242269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7560807201080024,
    "estimated_duration": 3599.9683576258017,
    "input_throughput": 1284.4215672632943,
    "output_throughput": 1164.530791255295,
    "total_throughput": 2448.9523585185893,
    "itl": 21.97580386461646,
    "ttft": 6365.963973829021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2773,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.291409467763561,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.00025711596915857374
}
#Debug simulation 
Total elapsed time: 1.7561720479279757. Arrivals time: 0.0580350742675364 Scheduler time: 1.312562317121774 Scheduler overhead time: 0.13897263538092375 Adapter cache time: 0.03790688142180443 Engine time: 0.13953682780265808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7650126130320132,
    "estimated_duration": 3599.9599336343326,
    "input_throughput": 1284.4245728401688,
    "output_throughput": 1164.5335162849153,
    "total_throughput": 2448.9580891250844,
    "itl": 21.983186138800416,
    "ttft": 6366.1795956712685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2772,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.346431765853907,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.00026607576024437034
}
#Debug simulation 
Total elapsed time: 1.7651073862798512. Arrivals time: 0.05924046225845814 Scheduler time: 1.3219915176741779 Scheduler overhead time: 0.13831585040315986 Adapter cache time: 0.038115310948342085 Engine time: 0.13866062043234706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7237501796334982,
    "estimated_duration": 3599.9001122027266,
    "input_throughput": 1267.1179360054202,
    "output_throughput": 1126.8676556466503,
    "total_throughput": 2393.9855916520705,
    "itl": 21.673658360718086,
    "ttft": 5894.574689034752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1985,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.0750681717066914,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.002626705483815514
}
#Debug simulation 
Total elapsed time: 1.7238487186841667. Arrivals time: 0.05809184815734625 Scheduler time: 1.275633888784796 Scheduler overhead time: 0.14014150062575936 Adapter cache time: 0.03645242936909199 Engine time: 0.14299941854551435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7330780159682035,
    "estimated_duration": 3599.897456610785,
    "input_throughput": 1267.1188707398733,
    "output_throughput": 1126.8684869205135,
    "total_throughput": 2393.987357660387,
    "itl": 21.676380350913828,
    "ttft": 5894.931532528609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.53276502012718,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.0024059302460816266
}
#Debug simulation 
Total elapsed time: 1.733237239997834. Arrivals time: 0.05721931019797921 Scheduler time: 1.2811593827791512 Scheduler overhead time: 0.14631605288013816 Adapter cache time: 0.03636857820674777 Engine time: 0.14301688922569156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7101160772144794,
    "estimated_duration": 3599.900490791938,
    "input_throughput": 1267.1178027469646,
    "output_throughput": 1126.8675371378365,
    "total_throughput": 2393.9853398848013,
    "itl": 21.676438586956394,
    "ttft": 5894.927524864122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5337496740370895,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.002409975054122876
}
#Debug simulation 
Total elapsed time: 1.7102242391556501. Arrivals time: 0.057213252410292625 Scheduler time: 1.270283015910536 Scheduler overhead time: 0.13849300425499678 Adapter cache time: 0.035986210219562054 Engine time: 0.1395348128862679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7746857292950153,
    "estimated_duration": 3599.9009154464966,
    "input_throughput": 1267.117653274142,
    "output_throughput": 1126.8674042093344,
    "total_throughput": 2393.9850574834763,
    "itl": 21.67380877825252,
    "ttft": 5894.62622656163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.190102377142572,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.0026183364728582345
}
#Debug simulation 
Total elapsed time: 1.774814559146762. Arrivals time: 0.05913713341578841 Scheduler time: 1.3187620807439089 Scheduler overhead time: 0.14733565878123045 Adapter cache time: 0.036578720435500145 Engine time: 0.14288722816854715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7718155630864203,
    "estimated_duration": 3599.9046860728563,
    "input_throughput": 1267.1163260647736,
    "output_throughput": 1126.866223901435,
    "total_throughput": 2393.9825499662084,
    "itl": 21.677032583752762,
    "ttft": 5894.738080480881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.640414312891545,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.0026226606757742644
}
#Debug simulation 
Total elapsed time: 1.7719108927994967. Arrivals time: 0.058919322676956654 Scheduler time: 1.323586996179074 Scheduler overhead time: 0.13882141839712858 Adapter cache time: 0.036478616297245026 Engine time: 0.14459296548739076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7549403789453208,
    "estimated_duration": 3599.9037737849435,
    "input_throughput": 1267.116647177498,
    "output_throughput": 1126.8665094719668,
    "total_throughput": 2393.983156649465,
    "itl": 21.672371749346365,
    "ttft": 5894.599492038666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1983,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.92926973479084,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.002626705483815514
}
#Debug simulation 
Total elapsed time: 1.7550351326353848. Arrivals time: 0.05861018784344196 Scheduler time: 1.3109498643316329 Scheduler overhead time: 0.13891742378473282 Adapter cache time: 0.03648123890161514 Engine time: 0.14083816157653928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.757477339822799,
    "estimated_duration": 3599.8946913901377,
    "input_throughput": 1267.1198440636965,
    "output_throughput": 1126.8693525125027,
    "total_throughput": 2393.989196576199,
    "itl": 21.678107012070353,
    "ttft": 5894.517180213048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.716107250228335,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.0026183364728582345
}
#Debug simulation 
Total elapsed time: 1.7575755040161312. Arrivals time: 0.05885286023840308 Scheduler time: 1.3102465313859284 Scheduler overhead time: 0.14085720293223858 Adapter cache time: 0.03630905831232667 Engine time: 0.14118826994672418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7324904408305883,
    "estimated_duration": 3599.976378419206,
    "input_throughput": 1244.5726107701332,
    "output_throughput": 1110.715899129264,
    "total_throughput": 2355.288509899397,
    "itl": 21.560573809025783,
    "ttft": 6150.297023809266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.013078924561989,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0005073945812286741
}
#Debug simulation 
Total elapsed time: 1.7325944476760924. Arrivals time: 0.057690557558089495 Scheduler time: 1.2870637536980212 Scheduler overhead time: 0.14091703575104475 Adapter cache time: 0.035643949173390865 Engine time: 0.14140725694596767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7681460231542587,
    "estimated_duration": 3599.974658679915,
    "input_throughput": 1244.5732053133236,
    "output_throughput": 1110.716429727936,
    "total_throughput": 2355.2896350412593,
    "itl": 21.562331212292488,
    "ttft": 6150.409495485355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.415243822326763,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0005073945812286741
}
#Debug simulation 
Total elapsed time: 1.7683174828998744. Arrivals time: 0.05776450177654624 Scheduler time: 1.3175595067441463 Scheduler overhead time: 0.14160886267200112 Adapter cache time: 0.03565486427396536 Engine time: 0.14531644759699702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7687544408254325,
    "estimated_duration": 3599.9730489643425,
    "input_throughput": 1244.5737618199537,
    "output_throughput": 1110.716926380969,
    "total_throughput": 2355.2906882009224,
    "itl": 21.562280584574875,
    "ttft": 6150.394143235936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.413604775145617,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0005073945812286741
}
#Debug simulation 
Total elapsed time: 1.7688494669273496. Arrivals time: 0.058759842067956924 Scheduler time: 1.3197767613455653 Scheduler overhead time: 0.13983917888253927 Adapter cache time: 0.035732217598706484 Engine time: 0.14486328605562449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7254913989454508,
    "estimated_duration": 3599.9784346246292,
    "input_throughput": 1244.5718999056103,
    "output_throughput": 1110.7152647198927,
    "total_throughput": 2355.287164625503,
    "itl": 21.560985739614036,
    "ttft": 6150.325002151445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.115873336975812,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0004976369931281227
}
#Debug simulation 
Total elapsed time: 1.7255975883454084. Arrivals time: 0.05482834344729781 Scheduler time: 1.284303103107959 Scheduler overhead time: 0.1404847325757146 Adapter cache time: 0.03536202339455485 Engine time: 0.14080052869394422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7451800219714642,
    "estimated_duration": 3599.959785221709,
    "input_throughput": 1244.5783473450845,
    "output_throughput": 1110.7210187220865,
    "total_throughput": 2355.299366067171,
    "itl": 21.56345407910824,
    "ttft": 6150.516127860137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1639,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.503281810749259,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0005082285672377005
}
#Debug simulation 
Total elapsed time: 1.7452884227968752. Arrivals time: 0.05869365856051445 Scheduler time: 1.2996468637138605 Scheduler overhead time: 0.13843337167054415 Adapter cache time: 0.03550326358526945 Engine time: 0.14312674337998033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7514541959390044,
    "estimated_duration": 3599.9615367528627,
    "input_throughput": 1244.577741805907,
    "output_throughput": 1110.7204783100715,
    "total_throughput": 2355.2982201159784,
    "itl": 21.559306536596626,
    "ttft": 6150.324394033605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8977023830496265,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0005033497731874247
}
#Debug simulation 
Total elapsed time: 1.751570404972881. Arrivals time: 0.05779227474704385 Scheduler time: 1.3099752757698298 Scheduler overhead time: 0.14004008285701275 Adapter cache time: 0.03480476280674338 Engine time: 0.14004012197256088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7370028928853571,
    "estimated_duration": 3599.964368587753,
    "input_throughput": 1244.5767627854743,
    "output_throughput": 1110.7196045855894,
    "total_throughput": 2355.2963673710638,
    "itl": 21.563434481837188,
    "ttft": 6150.481097352876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.56449847675852,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0004993049651461754
}
#Debug simulation 
Total elapsed time: 1.737100434023887. Arrivals time: 0.05792306549847126 Scheduler time: 1.2965278644114733 Scheduler overhead time: 0.1369080818258226 Adapter cache time: 0.03497891779989004 Engine time: 0.14221539488062263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7441008472815156,
    "estimated_duration": 3599.8639941360957,
    "input_throughput": 1244.1458919824618,
    "output_throughput": 1110.000268484847,
    "total_throughput": 2354.1461604673086,
    "itl": 21.549098152084344,
    "ttft": 4199.77100582877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.223473086627311,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7441934761591256. Arrivals time: 0.057123873848468065 Scheduler time: 1.301527213305235 Scheduler overhead time: 0.14084162190556526 Adapter cache time: 0.033943640533834696 Engine time: 0.14085580268874764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7322644819505513,
    "estimated_duration": 3599.8520552110695,
    "input_throughput": 1244.1500181977333,
    "output_throughput": 1110.003949805574,
    "total_throughput": 2354.1539680033075,
    "itl": 21.551347583235724,
    "ttft": 4199.756940214835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.568090829264807,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7323586638085544. Arrivals time: 0.05700796516612172 Scheduler time: 1.2924285302869976 Scheduler overhead time: 0.1387973935343325 Adapter cache time: 0.03423061966896057 Engine time: 0.14098434336483479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7339713401161134,
    "estimated_duration": 3599.8593282970523,
    "input_throughput": 1244.1475045411617,
    "output_throughput": 1110.0017071751176,
    "total_throughput": 2354.1492117162793,
    "itl": 21.55141794448417,
    "ttft": 4199.792432943752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.565303339287574,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7340637748129666. Arrivals time: 0.05637976108118892 Scheduler time: 1.296009968034923 Scheduler overhead time: 0.13915244676172733 Adapter cache time: 0.03417319990694523 Engine time: 0.1394928265362978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7308670720085502,
    "estimated_duration": 3599.8536482601303,
    "input_throughput": 1244.1494676220123,
    "output_throughput": 1110.0034585937296,
    "total_throughput": 2354.152926215742,
    "itl": 21.549571066988396,
    "ttft": 4199.650081333938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.296932367007179,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7309582028537989. Arrivals time: 0.05679036537185311 Scheduler time: 1.2921440820209682 Scheduler overhead time: 0.13829618599265814 Adapter cache time: 0.03421689011156559 Engine time: 0.13993980269879103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7581387548707426,
    "estimated_duration": 3599.8563160872054,
    "input_throughput": 1244.14854559198,
    "output_throughput": 1110.0026359783194,
    "total_throughput": 2354.1511815702993,
    "itl": 21.55284656144053,
    "ttft": 4199.7731729217985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.6363979862816445,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.758232087828219. Arrivals time: 0.05674120644107461 Scheduler time: 1.3189886421896517 Scheduler overhead time: 0.13773167552426457 Adapter cache time: 0.03400952648371458 Engine time: 0.14270778791978955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7425294248387218,
    "estimated_duration": 3599.861361117013,
    "input_throughput": 1244.1468019785827,
    "output_throughput": 1110.00108036386,
    "total_throughput": 2354.1478823424427,
    "itl": 21.549172624803376,
    "ttft": 4199.798315529409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1202893063750885,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7426234688609838. Arrivals time: 0.05564140109345317 Scheduler time: 1.3055080086924136 Scheduler overhead time: 0.13871318567544222 Adapter cache time: 0.03400505194440484 Engine time: 0.14041381748393178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7362197111360729,
    "estimated_duration": 3599.8539729696718,
    "input_throughput": 1244.1493553987927,
    "output_throughput": 1110.0033584705811,
    "total_throughput": 2354.1527138693737,
    "itl": 21.55252273772873,
    "ttft": 4199.829917100065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.696856385767464,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7363209230825305. Arrivals time: 0.0566990808583796 Scheduler time: 1.3007678515277803 Scheduler overhead time: 0.13763822801411152 Adapter cache time: 0.03409930691123009 Engine time: 0.13919834652915597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6526120542548597,
    "estimated_duration": 3599.7949512262508,
    "input_throughput": 1196.2645257150216,
    "output_throughput": 1062.5016290711521,
    "total_throughput": 2258.7661547861735,
    "itl": 21.272835895021892,
    "ttft": 3937.445609498635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.53792383198635,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6527129979804158. Arrivals time: 0.05438700318336487 Scheduler time: 1.2240428538061678 Scheduler overhead time: 0.13662681262940168 Adapter cache time: 0.03284494671970606 Engine time: 0.1365246050991118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6550781009718776,
    "estimated_duration": 3599.78936657227,
    "input_throughput": 1196.2663815801195,
    "output_throughput": 1062.5032774186936,
    "total_throughput": 2258.769658998813,
    "itl": 21.274362852858665,
    "ttft": 3937.5659988211482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7942576400702923,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6551696411333978. Arrivals time: 0.05568476393818855 Scheduler time: 1.219610053114593 Scheduler overhead time: 0.13732096320018172 Adapter cache time: 0.03308273060247302 Engine time: 0.14056829502806067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.670365888159722,
    "estimated_duration": 3599.7922167570255,
    "input_throughput": 1196.2654344198395,
    "output_throughput": 1062.502436167182,
    "total_throughput": 2258.7678705870217,
    "itl": 21.275294145837947,
    "ttft": 3937.611076080083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7951962735875844,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6704592979513109. Arrivals time: 0.055125484708696604 Scheduler time: 1.238505408167839 Scheduler overhead time: 0.13803019933402538 Adapter cache time: 0.03289436083287001 Engine time: 0.13733272440731525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6767423702403903,
    "estimated_duration": 3599.7874775363834,
    "input_throughput": 1196.2670093366576,
    "output_throughput": 1062.5038349812812,
    "total_throughput": 2258.770844317939,
    "itl": 21.27390436351101,
    "ttft": 3937.4921999005373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5909260006737425,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6768449321389198. Arrivals time: 0.05545421410351992 Scheduler time: 1.242869992274791 Scheduler overhead time: 0.13814019737765193 Adapter cache time: 0.032837656792253256 Engine time: 0.13843872770667076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.714208414312452,
    "estimated_duration": 3599.792529629065,
    "input_throughput": 1196.2653304477346,
    "output_throughput": 1062.502343820942,
    "total_throughput": 2258.7676742686767,
    "itl": 21.275322919927383,
    "ttft": 3937.6930335282136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.858853117488336,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7143088290467858. Arrivals time: 0.056117985397577286 Scheduler time: 1.2711600665934384 Scheduler overhead time: 0.14446666138246655 Adapter cache time: 0.033563781064003706 Engine time: 0.13822751538828015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6553012449294329,
    "estimated_duration": 3599.8034739323643,
    "input_throughput": 1196.261693501802,
    "output_throughput": 1062.4991135479588,
    "total_throughput": 2258.760807049761,
    "itl": 21.27299043346517,
    "ttft": 3937.436194717527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4594881912017312,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6553956288844347. Arrivals time: 0.05554365552961826 Scheduler time: 1.2207249896600842 Scheduler overhead time: 0.1376053006388247 Adapter cache time: 0.032975610345602036 Engine time: 0.13999736309051514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6641832133755088,
    "estimated_duration": 3599.796448591822,
    "input_throughput": 1196.2640281187435,
    "output_throughput": 1062.5011871146744,
    "total_throughput": 2258.765215233418,
    "itl": 21.275522979700682,
    "ttft": 3937.543786386476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8968453468755495,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.664272922091186. Arrivals time: 0.05469025485217571 Scheduler time: 1.2300988123752177 Scheduler overhead time: 0.13737157685682178 Adapter cache time: 0.0331660988740623 Engine time: 0.14019131194800138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.669568964280188,
    "estimated_duration": 3599.8294626606767,
    "input_throughput": 1174.0053365962374,
    "output_throughput": 1063.4081529991743,
    "total_throughput": 2237.4134895954116,
    "itl": 21.251650841513165,
    "ttft": 4403.469135354914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8921609180165166,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6696640043519437. Arrivals time: 0.05389905069023371 Scheduler time: 1.2344450447708368 Scheduler overhead time: 0.13886424247175455 Adapter cache time: 0.03244004864245653 Engine time: 0.14048572210595012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6449661049991846,
    "estimated_duration": 3599.822129474336,
    "input_throughput": 1174.007728158817,
    "output_throughput": 1063.410319264579,
    "total_throughput": 2237.418047423396,
    "itl": 21.252836006733055,
    "ttft": 4403.357862271397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1058939171326463,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6450656089000404. Arrivals time: 0.054004902485758066 Scheduler time: 1.215737126301974 Scheduler overhead time: 0.1377145959995687 Adapter cache time: 0.032438864931464195 Engine time: 0.13637073058634996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6344813080504537,
    "estimated_duration": 3599.82575779402,
    "input_throughput": 1174.006544858392,
    "output_throughput": 1063.4092474369813,
    "total_throughput": 2237.4157922953736,
    "itl": 21.253073067788677,
    "ttft": 4403.446374830722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1074770933389333,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6345870029181242. Arrivals time: 0.05427381582558155 Scheduler time: 1.2044083247892559 Scheduler overhead time: 0.1378098833374679 Adapter cache time: 0.03228622768074274 Engine time: 0.13695161463692784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6530985534191132,
    "estimated_duration": 3599.828470405078,
    "input_throughput": 1174.0056601987028,
    "output_throughput": 1063.4084461166665,
    "total_throughput": 2237.4141063153693,
    "itl": 21.252310515906633,
    "ttft": 4403.283039375092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.945724552303986,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6531911012716591. Arrivals time: 0.05429945420473814 Scheduler time: 1.2228427212685347 Scheduler overhead time: 0.13737604022026062 Adapter cache time: 0.03207835787907243 Engine time: 0.1377413826994598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6551870349794626,
    "estimated_duration": 3599.8181526183926,
    "input_throughput": 1174.0090251297788,
    "output_throughput": 1063.411494054379,
    "total_throughput": 2237.420519184158,
    "itl": 21.253246565289963,
    "ttft": 4403.441421059608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1600275901705106,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6552851940505207. Arrivals time: 0.05363211128860712 Scheduler time: 1.2245314791798592 Scheduler overhead time: 0.13727966975420713 Adapter cache time: 0.03223472787067294 Engine time: 0.13884492870420218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.637312474194914,
    "estimated_duration": 3599.8230420762425,
    "input_throughput": 1174.0074305326063,
    "output_throughput": 1063.4100496762483,
    "total_throughput": 2237.4174802088546,
    "itl": 21.250997643573413,
    "ttft": 4403.359904225766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 945,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8255975286824926,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6374023598618805. Arrivals time: 0.052489545196294785 Scheduler time: 1.211015765555203 Scheduler overhead time: 0.13676705211400986 Adapter cache time: 0.03205773467198014 Engine time: 0.1364816091954708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.64859069744125,
    "estimated_duration": 3599.8266824717384,
    "input_throughput": 1174.0062432945142,
    "output_throughput": 1063.4089742819315,
    "total_throughput": 2237.4152175764457,
    "itl": 21.25355660318484,
    "ttft": 4403.389264997845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1902376706898568,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.648690007161349. Arrivals time: 0.05389635590836406 Scheduler time: 1.2204075469635427 Scheduler overhead time: 0.13750263582915068 Adapter cache time: 0.03185109840705991 Engine time: 0.13599415589123964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6151001690886915,
    "estimated_duration": 3599.890552055794,
    "input_throughput": 1174.7587708145566,
    "output_throughput": 1035.083691050574,
    "total_throughput": 2209.8424618651306,
    "itl": 21.08853416709832,
    "ttft": 5271.374775918812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3229101976450046,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6151937209069729. Arrivals time: 0.053087832406163216 Scheduler time: 1.1857755072414875 Scheduler overhead time: 0.13801049115136266 Adapter cache time: 0.03172078588977456 Engine time: 0.13768785493448377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6098297219723463,
    "estimated_duration": 3599.9061327135337,
    "input_throughput": 1174.753686372446,
    "output_throughput": 1035.079211132452,
    "total_throughput": 2209.832897504898,
    "itl": 21.089732936702248,
    "ttft": 5271.616085950426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.49841038134416,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6099214400164783. Arrivals time: 0.052718209102749825 Scheduler time: 1.1837559039704502 Scheduler overhead time: 0.13755800994113088 Adapter cache time: 0.031717652920633554 Engine time: 0.13521854672580957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.612346276640892,
    "estimated_duration": 3599.906438979131,
    "input_throughput": 1174.7535864291156,
    "output_throughput": 1035.0791230720652,
    "total_throughput": 2209.8327095011805,
    "itl": 21.089635649025798,
    "ttft": 5271.613025042643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.497861077878616,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.612437391653657. Arrivals time: 0.05279382178559899 Scheduler time: 1.1826728004962206 Scheduler overhead time: 0.1374268918298185 Adapter cache time: 0.03187643736600876 Engine time: 0.13827672274783254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6058957786299288,
    "estimated_duration": 3599.9029172694964,
    "input_throughput": 1174.7547356659475,
    "output_throughput": 1035.0801356682946,
    "total_throughput": 2209.834871334242,
    "itl": 21.088366755932046,
    "ttft": 5271.505954320323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.35389752168206,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.605992749799043. Arrivals time: 0.052374839782714844 Scheduler time: 1.178561920300126 Scheduler overhead time: 0.13855855632573366 Adapter cache time: 0.03183385729789734 Engine time: 0.13535447604954243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.613374658394605,
    "estimated_duration": 3599.8976808322886,
    "input_throughput": 1174.7564444726838,
    "output_throughput": 1035.0816413033476,
    "total_throughput": 2209.8380857760317,
    "itl": 21.089993312440008,
    "ttft": 5271.566037622123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5502712350338737,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6134688491001725. Arrivals time: 0.05318856704980135 Scheduler time: 1.1839797301217914 Scheduler overhead time: 0.13767084665596485 Adapter cache time: 0.03181270929053426 Engine time: 0.13780261110514402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.611225982196629,
    "estimated_duration": 3599.8927727843325,
    "input_throughput": 1174.758046120658,
    "output_throughput": 1035.083052520474,
    "total_throughput": 2209.841098641132,
    "itl": 21.08788361092727,
    "ttft": 5271.661840684484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2634680732409036,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.611313661094755. Arrivals time: 0.05278014577925205 Scheduler time: 1.1820727065205574 Scheduler overhead time: 0.13723860401660204 Adapter cache time: 0.03178849071264267 Engine time: 0.13821314740926027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6039882581681013,
    "estimated_duration": 3599.885927240941,
    "input_throughput": 1174.7602800406603,
    "output_throughput": 1035.0850208344964,
    "total_throughput": 2209.8453008751567,
    "itl": 21.090357508126363,
    "ttft": 5271.616486378452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5736760251969235,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6040791482664645. Arrivals time: 0.052536734845489264 Scheduler time: 1.1750997216440737 Scheduler overhead time: 0.13673337828367949 Adapter cache time: 0.03194673312827945 Engine time: 0.13814690290018916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5928795165382326,
    "estimated_duration": 3599.5670166880786,
    "input_throughput": 1131.9094716421741,
    "output_throughput": 1038.0095668944666,
    "total_throughput": 2169.919038536641,
    "itl": 21.073300239669283,
    "ttft": 5172.192766474753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.768961915993157,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.9181678207607294e-05
}
#Debug simulation 
Total elapsed time: 1.5929713496007025. Arrivals time: 0.05108645558357239 Scheduler time: 1.168435706757009 Scheduler overhead time: 0.1375124421902001 Adapter cache time: 0.030286386609077454 Engine time: 0.13703363249078393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6049096900969744,
    "estimated_duration": 3599.5508012955834,
    "input_throughput": 1131.9145707107427,
    "output_throughput": 1038.0142429591954,
    "total_throughput": 2169.928813669938,
    "itl": 21.074031251975356,
    "ttft": 5172.271104204225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8945473650586864,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 2.0849650225660102e-05
}
#Debug simulation 
Total elapsed time: 1.6050488431937993. Arrivals time: 0.05185557156801224 Scheduler time: 1.1776776583865285 Scheduler overhead time: 0.1376460469327867 Adapter cache time: 0.030625395942479372 Engine time: 0.13792927423492074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.611042516771704,
    "estimated_duration": 3599.551114848125,
    "input_throughput": 1131.9144721110342,
    "output_throughput": 1038.0141525390309,
    "total_throughput": 2169.928624650065,
    "itl": 21.07401366398624,
    "ttft": 5172.262518409853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8964136248640835,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 2.0849650225660102e-05
}
#Debug simulation 
Total elapsed time: 1.6111363600939512. Arrivals time: 0.051756443455815315 Scheduler time: 1.184022564906627 Scheduler overhead time: 0.13819775078445673 Adapter cache time: 0.03035166673362255 Engine time: 0.13774635270237923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6213515140116215,
    "estimated_duration": 3599.557221453362,
    "input_throughput": 1131.9125518318392,
    "output_throughput": 1038.012391560591,
    "total_throughput": 2169.92494339243,
    "itl": 21.07306939632318,
    "ttft": 5172.237292349353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7981188699067447,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.7513706189554486e-05
}
#Debug simulation 
Total elapsed time: 1.6214514300227165. Arrivals time: 0.051460432820022106 Scheduler time: 1.1972409882582724 Scheduler overhead time: 0.13757339073345065 Adapter cache time: 0.030499667394906282 Engine time: 0.13560947263613343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6012365147471428,
    "estimated_duration": 3599.564959733082,
    "input_throughput": 1131.9101184666847,
    "output_throughput": 1038.0101600603045,
    "total_throughput": 2169.920278526989,
    "itl": 21.074238075396018,
    "ttft": 5172.145206087469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9260915184579808,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 2.0849650225660102e-05
}
#Debug simulation 
Total elapsed time: 1.6013394896872342. Arrivals time: 0.05321563361212611 Scheduler time: 1.1728595779277384 Scheduler overhead time: 0.1374350329861045 Adapter cache time: 0.03049751976504922 Engine time: 0.13831492559984326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5913700070232153,
    "estimated_duration": 3599.564930943937,
    "input_throughput": 1131.9101275196467,
    "output_throughput": 1038.0101683622593,
    "total_throughput": 2169.920295881906,
    "itl": 21.072612895025674,
    "ttft": 5172.092355475635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.728249070453433,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 2.0849650225660102e-05
}
#Debug simulation 
Total elapsed time: 1.5914656380191445. Arrivals time: 0.05056167067959905 Scheduler time: 1.167694736737758 Scheduler overhead time: 0.1388071463443339 Adapter cache time: 0.030404991004616022 Engine time: 0.1349860499612987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6000305623747408,
    "estimated_duration": 3599.5637726706373,
    "input_throughput": 1131.9104917474701,
    "output_throughput": 1038.010502374806,
    "total_throughput": 2169.920994122276,
    "itl": 21.074161403620522,
    "ttft": 5172.243860684355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9475954159349151,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.7513706189554486e-05
}
#Debug simulation 
Total elapsed time: 1.6001364812254906. Arrivals time: 0.05173245770856738 Scheduler time: 1.1740040862932801 Scheduler overhead time: 0.1377582559362054 Adapter cache time: 0.030542111955583096 Engine time: 0.13727478124201298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5876749879680574,
    "estimated_duration": 3599.907788390757,
    "input_throughput": 1143.6690165445714,
    "output_throughput": 1011.2059013676225,
    "total_throughput": 2154.8749179121937,
    "itl": 20.898153727320995,
    "ttft": 6077.362221009301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.202771683365578,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.587767472025007. Arrivals time: 0.053148194681853056 Scheduler time: 1.1553113833069801 Scheduler overhead time: 0.13988484954461455 Adapter cache time: 0.03030398953706026 Engine time: 0.1390120079740882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5938375731930137,
    "estimated_duration": 3599.90057335547,
    "input_throughput": 1143.6713087224089,
    "output_throughput": 1011.2079280586692,
    "total_throughput": 2154.879236781078,
    "itl": 20.89845431656872,
    "ttft": 6077.336115764646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2956253848364652,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5939865908585489. Arrivals time: 0.05153474910184741 Scheduler time: 1.1677000457420945 Scheduler overhead time: 0.1374090015888214 Adapter cache time: 0.029970888048410416 Engine time: 0.13797967601567507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5878775310702622,
    "estimated_duration": 3599.900729098426,
    "input_throughput": 1143.6712592436138,
    "output_throughput": 1011.207884310654,
    "total_throughput": 2154.8791435542676,
    "itl": 20.89844663293343,
    "ttft": 6077.328046987397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2955909184552805,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5879744128324091. Arrivals time: 0.05242309719324112 Scheduler time: 1.15603118063882 Scheduler overhead time: 0.14026319608092308 Adapter cache time: 0.030333922244608402 Engine time: 0.13919195579364896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5779341580346227,
    "estimated_duration": 3599.905272265051,
    "input_throughput": 1143.6698159031084,
    "output_throughput": 1011.2066081420986,
    "total_throughput": 2154.876424045207,
    "itl": 20.898078608178345,
    "ttft": 6077.361914945237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2208524415618727,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5780313350260258. Arrivals time: 0.051378322299569845 Scheduler time: 1.1472172257490456 Scheduler overhead time: 0.14192288322374225 Adapter cache time: 0.03044694196432829 Engine time: 0.1370947896502912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5808250471018255,
    "estimated_duration": 3599.885923043445,
    "input_throughput": 1143.6759630758759,
    "output_throughput": 1011.2120433312042,
    "total_throughput": 2154.88800640708,
    "itl": 20.89863615965526,
    "ttft": 6077.334604394748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3186038613691966,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.580921872984618. Arrivals time: 0.05209669703617692 Scheduler time: 1.151229356881231 Scheduler overhead time: 0.13879635045304894 Adapter cache time: 0.030612161848694086 Engine time: 0.1387658347375691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5734088700264692,
    "estimated_duration": 3599.9042902514643,
    "input_throughput": 1143.6701278834298,
    "output_throughput": 1011.20688398794,
    "total_throughput": 2154.87701187137,
    "itl": 20.89746429590521,
    "ttft": 6077.440562010592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1750897658965502,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5734999729320407. Arrivals time: 0.05136920977383852 Scheduler time: 1.148114119656384 Scheduler overhead time: 0.1389654790982604 Adapter cache time: 0.03013070998713374 Engine time: 0.13593452097848058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5861706850118935,
    "estimated_duration": 3599.900029651499,
    "input_throughput": 1143.6714814546033,
    "output_throughput": 1011.2080807845119,
    "total_throughput": 2154.8795622391153,
    "itl": 20.898895953621277,
    "ttft": 6077.378793493081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3326882854476587,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5862603532150388. Arrivals time: 0.0513912751339376 Scheduler time: 1.1592805455438793 Scheduler overhead time: 0.1379084810614586 Adapter cache time: 0.030307205393910408 Engine time: 0.1379997506737709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5613084509968758,
    "estimated_duration": 3599.921882602278,
    "input_throughput": 1109.8338048135379,
    "output_throughput": 1013.0744829839748,
    "total_throughput": 2122.9082877975125,
    "itl": 20.877094610786944,
    "ttft": 5069.109711024001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7865453501907167,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5613982700742781. Arrivals time: 0.05068631190806627 Scheduler time: 1.137829214334488 Scheduler overhead time: 0.13961354596540332 Adapter cache time: 0.028745906427502632 Engine time: 0.13479393580928445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5821359902620316,
    "estimated_duration": 3599.9198783307006,
    "input_throughput": 1109.8344227184984,
    "output_throughput": 1013.0750470177479,
    "total_throughput": 2122.909469736246,
    "itl": 20.877313701486877,
    "ttft": 5069.187567144115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8379041299247223,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5822552791796625. Arrivals time: 0.051874399185180664 Scheduler time: 1.1532636280171573 Scheduler overhead time: 0.13914169510826468 Adapter cache time: 0.029468550346791744 Engine time: 0.13853798201307654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.587774126790464,
    "estimated_duration": 3599.920428491394,
    "input_throughput": 1109.8342531071728,
    "output_throughput": 1013.0748921937508,
    "total_throughput": 2122.9091453009237,
    "itl": 20.87724256531437,
    "ttft": 5069.18169285549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8395164182037156,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5878590606153011. Arrivals time: 0.05103906383737922 Scheduler time: 1.1579284919425845 Scheduler overhead time: 0.14083715621381998 Adapter cache time: 0.02932532364502549 Engine time: 0.13892137119546533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.571732325013727,
    "estimated_duration": 3599.935201414539,
    "input_throughput": 1109.8296987207166,
    "output_throughput": 1013.0707348751645,
    "total_throughput": 2122.900433595881,
    "itl": 20.877070918660102,
    "ttft": 5069.102704174688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7925500495778416,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5718308207578957. Arrivals time: 0.05162821803241968 Scheduler time: 1.144378441851586 Scheduler overhead time: 0.13881391938775778 Adapter cache time: 0.029226714745163918 Engine time: 0.13844901183620095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5891342367976904,
    "estimated_duration": 3599.919074496992,
    "input_throughput": 1109.8346705358247,
    "output_throughput": 1013.0752732294642,
    "total_throughput": 2122.909943765289,
    "itl": 20.877555070840195,
    "ttft": 5069.2019513987625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8534750884957653,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5892589511349797. Arrivals time: 0.05059765186160803 Scheduler time: 1.162774599622935 Scheduler overhead time: 0.13979990035295486 Adapter cache time: 0.028682764153927565 Engine time: 0.13792357128113508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5679499749094248,
    "estimated_duration": 3599.9376395222416,
    "input_throughput": 1109.8289470731581,
    "output_throughput": 1013.0700487589564,
    "total_throughput": 2122.898995832115,
    "itl": 20.877066686050547,
    "ttft": 5069.197653791449,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7684429257898602,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5680385120213032. Arrivals time: 0.05024966597557068 Scheduler time: 1.1433971016667783 Scheduler overhead time: 0.1387138282880187 Adapter cache time: 0.029464202467352152 Engine time: 0.1369629204273224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.583036803174764,
    "estimated_duration": 3599.923683703606,
    "input_throughput": 1109.833249545339,
    "output_throughput": 1013.0739761260642,
    "total_throughput": 2122.907225671403,
    "itl": 20.877515670578184,
    "ttft": 5069.208748654806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8608945618942422,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5831559840589762. Arrivals time: 0.051615254022181034 Scheduler time: 1.1542209098115563 Scheduler overhead time: 0.1393507458269596 Adapter cache time: 0.02911528293043375 Engine time: 0.13943012384697795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9906416540034115,
    "estimated_duration": 3599.5680527524437,
    "input_throughput": 468.5053804470971,
    "output_throughput": 423.1204904809022,
    "total_throughput": 891.6258709279992,
    "itl": 19.38778327245393,
    "ttft": 7315.39538198861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.376554955144092,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9907545372843742. Arrivals time: 0.029764859471470118 Scheduler time: 0.5648496206849813 Scheduler overhead time: 0.14358238643035293 Adapter cache time: 0.03865355299785733 Engine time: 0.14091096026822925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9925034712068737,
    "estimated_duration": 3599.5471569359725,
    "input_throughput": 468.5081001787796,
    "output_throughput": 423.12294674768486,
    "total_throughput": 891.6310469264645,
    "itl": 19.392558687337157,
    "ttft": 7315.550568511207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.984614481290144,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.992595927324146. Arrivals time: 0.03033496718853712 Scheduler time: 0.5620397585444152 Scheduler overhead time: 0.14368985872715712 Adapter cache time: 0.03864121017977595 Engine time: 0.1448331749998033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9985694079659879,
    "estimated_duration": 3599.54789340731,
    "input_throughput": 468.5080043215227,
    "output_throughput": 423.1228601762788,
    "total_throughput": 891.6308644978016,
    "itl": 19.392201599832866,
    "ttft": 7315.511469766829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.991453425865455,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9986497885547578. Arrivals time: 0.030328750610351562 Scheduler time: 0.5710920300334692 Scheduler overhead time: 0.14349650824442506 Adapter cache time: 0.038557513151317835 Engine time: 0.14219631720334291 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9833403970114887,
    "estimated_duration": 3599.5473147674375,
    "input_throughput": 468.5080796358298,
    "output_throughput": 423.12292819476454,
    "total_throughput": 891.6310078305944,
    "itl": 19.388842358689644,
    "ttft": 7315.463699159288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.586382874997609,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9834155701100826. Arrivals time: 0.03014906821772456 Scheduler time: 0.5567298610694706 Scheduler overhead time: 0.1425821641460061 Adapter cache time: 0.038299615029245615 Engine time: 0.14307083236053586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9890776090323925,
    "estimated_duration": 3599.559226441767,
    "input_throughput": 468.5065292472088,
    "output_throughput": 423.1215279948498,
    "total_throughput": 891.6280572420586,
    "itl": 19.39258340091904,
    "ttft": 7315.418459228819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.105078280642331,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.989159788005054. Arrivals time: 0.030203976668417454 Scheduler time: 0.5597908794879913 Scheduler overhead time: 0.14304230082780123 Adapter cache time: 0.03831193735823035 Engine time: 0.14506443915888667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.980992732103914,
    "estimated_duration": 3599.5481185088115,
    "input_throughput": 468.50797502288526,
    "output_throughput": 423.12283371584874,
    "total_throughput": 891.630808738734,
    "itl": 19.387768196027903,
    "ttft": 7315.300750691744,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2735,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.177787556557249,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9810617147013545. Arrivals time: 0.02985229156911373 Scheduler time: 0.5537417107261717 Scheduler overhead time: 0.1430934020318091 Adapter cache time: 0.038169614505022764 Engine time: 0.1429732427932322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9847978018224239,
    "estimated_duration": 3599.551521298744,
    "input_throughput": 468.50753212487115,
    "output_throughput": 423.1224337220967,
    "total_throughput": 891.6299658469678,
    "itl": 19.39241238792195,
    "ttft": 7315.544921950146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.237593599743704,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9848860488273203. Arrivals time: 0.02987008076161146 Scheduler time: 0.5563277406617999 Scheduler overhead time: 0.14286734722554684 Adapter cache time: 0.038455089554190636 Engine time: 0.14423425821587443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9575455170124769,
    "estimated_duration": 3599.640939166527,
    "input_throughput": 436.96997188953037,
    "output_throughput": 401.20057094760955,
    "total_throughput": 838.1705428371399,
    "itl": 19.08709352213146,
    "ttft": 7287.741896307168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.6871657204932635,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.957726432941854. Arrivals time: 0.02913760207593441 Scheduler time: 0.5325450319796801 Scheduler overhead time: 0.14411992952227592 Adapter cache time: 0.03658390650525689 Engine time: 0.1423853044398129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.960124240256846,
    "estimated_duration": 3599.6411815794945,
    "input_throughput": 436.9699424623785,
    "output_throughput": 401.2005439292996,
    "total_throughput": 838.1704863916782,
    "itl": 19.09187348272325,
    "ttft": 7287.846497908452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.178729560551873,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9601916358806193. Arrivals time: 0.02896892512217164 Scheduler time: 0.5328018674626946 Scheduler overhead time: 0.14402884943410754 Adapter cache time: 0.036811491940170527 Engine time: 0.14389609266072512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.958904042840004,
    "estimated_duration": 3599.6414215713976,
    "input_throughput": 436.96991332913,
    "output_throughput": 401.20051718083477,
    "total_throughput": 838.1704305099648,
    "itl": 19.091806325759975,
    "ttft": 7287.750692582522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2184,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.1903508794121445,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9589898479171097. Arrivals time: 0.02898342115804553 Scheduler time: 0.5330795641057193 Scheduler overhead time: 0.14370598923414946 Adapter cache time: 0.03665425581857562 Engine time: 0.14328832691535354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9649084210395813,
    "estimated_duration": 3599.6352772874984,
    "input_throughput": 436.97065920114096,
    "output_throughput": 401.2012019974032,
    "total_throughput": 838.1718611985441,
    "itl": 19.08705502715433,
    "ttft": 7287.889943957579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.855122068347177,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9649955127388239. Arrivals time: 0.028983235359191895 Scheduler time: 0.5366911147721112 Scheduler overhead time: 0.14358397154137492 Adapter cache time: 0.03710322314873338 Engine time: 0.14550426974892616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9613841222599149,
    "estimated_duration": 3599.651377651333,
    "input_throughput": 436.9687047378166,
    "output_throughput": 401.19940752214836,
    "total_throughput": 838.168112259965,
    "itl": 19.197892040903117,
    "ttft": 7288.091007442182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2158,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.201316307894754,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9614645093679428. Arrivals time: 0.028865720611065626 Scheduler time: 0.5381997982040048 Scheduler overhead time: 0.14293822599574924 Adapter cache time: 0.03592468425631523 Engine time: 0.14279690338298678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9574080910533667,
    "estimated_duration": 3599.6476778197825,
    "input_throughput": 436.9691538680496,
    "output_throughput": 401.19981988756825,
    "total_throughput": 838.1689737556178,
    "itl": 19.08660615122165,
    "ttft": 7287.800059603748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2182,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.524289743476352,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9574941690079868. Arrivals time: 0.028791451826691628 Scheduler time: 0.532215443905443 Scheduler overhead time: 0.14307003701105714 Adapter cache time: 0.036951232235878706 Engine time: 0.14335079304873943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9597991080954671,
    "estimated_duration": 3599.6373817362046,
    "input_throughput": 436.9704037358702,
    "output_throughput": 401.20096744395767,
    "total_throughput": 838.1713711798278,
    "itl": 19.197352660653866,
    "ttft": 7288.040926629013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.287084134034565,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9598711910657585. Arrivals time: 0.02882357034832239 Scheduler time: 0.5355664151720703 Scheduler overhead time: 0.14260785933583975 Adapter cache time: 0.036207460798323154 Engine time: 0.1438804599456489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9610038460232317,
    "estimated_duration": 3600.0068433662864,
    "input_throughput": 427.7025202986089,
    "output_throughput": 380.04788866474763,
    "total_throughput": 807.7504089633566,
    "itl": 19.069315610726413,
    "ttft": 5797.800929922758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.524180377798777,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9611686267890036. Arrivals time: 0.028735946398228407 Scheduler time: 0.5325375981628895 Scheduler overhead time: 0.1435852856375277 Adapter cache time: 0.03634518850594759 Engine time: 0.14629033161327243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.953448239248246,
    "estimated_duration": 3600.0089211584223,
    "input_throughput": 427.70227344451695,
    "output_throughput": 380.04766931514837,
    "total_throughput": 807.7499427596653,
    "itl": 19.07170209960287,
    "ttft": 5797.935239100542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.965396870248777,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9535124818794429. Arrivals time: 0.028723136987537146 Scheduler time: 0.5263165244832635 Scheduler overhead time: 0.1436298592016101 Adapter cache time: 0.03605792485177517 Engine time: 0.1448674169369042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9423428140580654,
    "estimated_duration": 3600.0086543015773,
    "input_throughput": 427.70230514868496,
    "output_throughput": 380.04769748683674,
    "total_throughput": 807.7500026355217,
    "itl": 19.071301464473507,
    "ttft": 5798.01442578047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.962662786934509,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9424293888732791. Arrivals time: 0.028487267438322306 Scheduler time: 0.5150091079995036 Scheduler overhead time: 0.14371071988716722 Adapter cache time: 0.036041497718542814 Engine time: 0.14544393774122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9426847849972546,
    "estimated_duration": 3600.011064589208,
    "input_throughput": 427.7020187924607,
    "output_throughput": 380.04744303643423,
    "total_throughput": 807.7494618288949,
    "itl": 19.06896405801534,
    "ttft": 5797.9058549207075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.6833172713381535,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9427616279572248. Arrivals time: 0.028477127198129892 Scheduler time: 0.5147742037661374 Scheduler overhead time: 0.1439888090826571 Adapter cache time: 0.036008549854159355 Engine time: 0.1459369990043342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9392471658065915,
    "estimated_duration": 3600.0041648735432,
    "input_throughput": 427.7028385199343,
    "output_throughput": 380.04817142984047,
    "total_throughput": 807.7510099497748,
    "itl": 19.07144230079159,
    "ttft": 5797.8874757013955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.054951480273093,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9393252218142152. Arrivals time: 0.027987695299088955 Scheduler time: 0.5123343653976917 Scheduler overhead time: 0.14390903990715742 Adapter cache time: 0.03684169193729758 Engine time: 0.1445078570395708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9332332401536405,
    "estimated_duration": 3600.017939168678,
    "input_throughput": 427.7012020544424,
    "output_throughput": 380.04671729939804,
    "total_throughput": 807.7479193538404,
    "itl": 19.06800216347979,
    "ttft": 5797.8131745083565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.400030832593174,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9333107471466064. Arrivals time: 0.028348980471491814 Scheduler time: 0.5078813475556672 Scheduler overhead time: 0.14328391710296273 Adapter cache time: 0.035878390073776245 Engine time: 0.14469585102051497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9339087312109768,
    "estimated_duration": 3600.020374920634,
    "input_throughput": 427.70091267440256,
    "output_throughput": 380.04646016209364,
    "total_throughput": 807.7473728364962,
    "itl": 19.07232384188034,
    "ttft": 5797.975069221079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.141092823967205,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.933979538269341. Arrivals time: 0.02811511978507042 Scheduler time: 0.5094577600248158 Scheduler overhead time: 0.14412442361935973 Adapter cache time: 0.0361673329025507 Engine time: 0.14287321455776691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.931129521690309,
    "estimated_duration": 3599.75044526439,
    "input_throughput": 422.48512032291706,
    "output_throughput": 373.7981341929306,
    "total_throughput": 796.2832545158476,
    "itl": 18.909319351219228,
    "ttft": 2966.2800989442785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.795784294742756,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9312175358645618. Arrivals time: 0.027979419101029634 Scheduler time: 0.5060339514166117 Scheduler overhead time: 0.1438591885380447 Adapter cache time: 0.03550373902544379 Engine time: 0.14403717825189233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9543965449556708,
    "estimated_duration": 3599.751459737998,
    "input_throughput": 422.48500125914023,
    "output_throughput": 373.79802885000726,
    "total_throughput": 796.2830301091475,
    "itl": 18.91133720397172,
    "ttft": 2966.2440599575193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.187293746222178,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9545385637320578. Arrivals time: 0.028538126964122057 Scheduler time: 0.524308143183589 Scheduler overhead time: 0.14411479840055108 Adapter cache time: 0.036190327256917953 Engine time: 0.14737208234146237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9320367476902902,
    "estimated_duration": 3599.751406100189,
    "input_throughput": 422.48500755434435,
    "output_throughput": 373.798034419755,
    "total_throughput": 796.2830419740994,
    "itl": 18.911589510787504,
    "ttft": 2966.290918916422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.184016745705125,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9321242589503527. Arrivals time: 0.0283736540004611 Scheduler time: 0.50675511918962 Scheduler overhead time: 0.14290094003081322 Adapter cache time: 0.035045354161411524 Engine time: 0.14582652132958174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9375649006105959,
    "estimated_duration": 3599.75105114268,
    "input_throughput": 422.4850492139546,
    "output_throughput": 373.79807127853144,
    "total_throughput": 796.2831204924861,
    "itl": 18.91072937392318,
    "ttft": 2966.0098570382925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.925384147101908,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.937642449978739. Arrivals time: 0.028098882175982 Scheduler time: 0.5091449413448572 Scheduler overhead time: 0.14492609445005655 Adapter cache time: 0.035314994398504496 Engine time: 0.14459874108433723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9376727980561554,
    "estimated_duration": 3599.751531853975,
    "input_throughput": 422.4849927952453,
    "output_throughput": 373.79802136148766,
    "total_throughput": 796.283014156733,
    "itl": 18.91260608005806,
    "ttft": 2966.3055671089473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.271049207989084,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9377504638396204. Arrivals time: 0.02813856629654765 Scheduler time: 0.5117617067880929 Scheduler overhead time: 0.14420183189213276 Adapter cache time: 0.03527254890650511 Engine time: 0.1446796553209424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9398836991749704,
    "estimated_duration": 3599.7502339520433,
    "input_throughput": 422.48514512361606,
    "output_throughput": 373.79815613560874,
    "total_throughput": 796.2833012592248,
    "itl": 18.90941491013366,
    "ttft": 2966.1391405604395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1569,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.691388912701384,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9399634031578898. Arrivals time: 0.02809809986501932 Scheduler time: 0.5119196642190218 Scheduler overhead time: 0.1444914094172418 Adapter cache time: 0.03598637832328677 Engine time: 0.14564654929563403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9421877642162144,
    "estimated_duration": 3599.751783361547,
    "input_throughput": 422.48496327705044,
    "output_throughput": 373.7979952449556,
    "total_throughput": 796.2829585220061,
    "itl": 18.912952412149156,
    "ttft": 2966.2737206819834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.337099117636624,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9422611221671104. Arrivals time: 0.028264997992664576 Scheduler time: 0.518242702819407 Scheduler overhead time: 0.14410621160641313 Adapter cache time: 0.03556166961789131 Engine time: 0.14282712899148464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8961921841837466,
    "estimated_duration": 3598.9084419851883,
    "input_throughput": 362.57743730768976,
    "output_throughput": 336.21555521777844,
    "total_throughput": 698.7929925254682,
    "itl": 18.74124547701178,
    "ttft": 4010.4538087338615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.569308201691724,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8963760021142662. Arrivals time: 0.026449183002114296 Scheduler time: 0.46806926699355245 Scheduler overhead time: 0.14409544132649899 Adapter cache time: 0.034588334150612354 Engine time: 0.14705380843952298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8918107021600008,
    "estimated_duration": 3598.905159756259,
    "input_throughput": 362.5777679810754,
    "output_throughput": 336.21586184892675,
    "total_throughput": 698.7936298300021,
    "itl": 18.742781639654755,
    "ttft": 4010.609765991784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.892501813201165,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8918815772049129. Arrivals time: 0.026415395084768534 Scheduler time: 0.4682781626470387 Scheduler overhead time: 0.14446066785603762 Adapter cache time: 0.03458666941151023 Engine time: 0.1441072290763259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8963720300234854,
    "estimated_duration": 3598.9105858721678,
    "input_throughput": 362.5772213187041,
    "output_throughput": 336.2153549326827,
    "total_throughput": 698.7925762513868,
    "itl": 18.74311941904087,
    "ttft": 4010.603935299236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.896380690205782,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8964329371228814. Arrivals time: 0.026778775732964277 Scheduler time: 0.47056498005986214 Scheduler overhead time: 0.14498361852020025 Adapter cache time: 0.03425300354138017 Engine time: 0.14601336512714624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9001467432826757,
    "estimated_duration": 3598.908293255485,
    "input_throughput": 362.57745229168773,
    "output_throughput": 336.2155691123363,
    "total_throughput": 698.7930214040241,
    "itl": 18.7426222897012,
    "ttft": 4010.523984032837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.688463920112613,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9002224351279438. Arrivals time: 0.026740341912955046 Scheduler time: 0.47418344765901566 Scheduler overhead time: 0.14391335705295205 Adapter cache time: 0.03447364829480648 Engine time: 0.1471909899264574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9008635547943413,
    "estimated_duration": 3598.9101179994254,
    "input_throughput": 362.57726845519636,
    "output_throughput": 336.2153986420266,
    "total_throughput": 698.792667097223,
    "itl": 18.743861304601616,
    "ttft": 4010.6757364768564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.961269643995867,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9009242299944162. Arrivals time: 0.026704223826527596 Scheduler time: 0.4726926130242646 Scheduler overhead time: 0.14482164569199085 Adapter cache time: 0.034672534093260765 Engine time: 0.14763655653223395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8872626628726721,
    "estimated_duration": 3598.9045063708695,
    "input_throughput": 362.57783380750004,
    "output_throughput": 336.21592288931595,
    "total_throughput": 698.793756696816,
    "itl": 18.741010617472785,
    "ttft": 4010.489985659615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.458164989699022,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8873442406766117. Arrivals time: 0.026186954230070114 Scheduler time: 0.463798048440367 Scheduler overhead time: 0.14408744033426046 Adapter cache time: 0.03403042024001479 Engine time: 0.145357814617455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.900175167247653,
    "estimated_duration": 3598.9065659129246,
    "input_throughput": 362.57762631550673,
    "output_throughput": 336.21573048342265,
    "total_throughput": 698.7933567989294,
    "itl": 18.743695750717432,
    "ttft": 4010.606915716093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.026550445035064,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9002386080101132. Arrivals time: 0.0264564654789865 Scheduler time: 0.4733719010837376 Scheduler overhead time: 0.1470594247803092 Adapter cache time: 0.03446678491309285 Engine time: 0.14476613467559218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8718175441026688,
    "estimated_duration": 3599.682282514952,
    "input_throughput": 358.38579595382424,
    "output_throughput": 317.21438459902663,
    "total_throughput": 675.6001805528509,
    "itl": 18.804052983724837,
    "ttft": 6933.566861709032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5134399300348873,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8718933989293873. Arrivals time: 0.026148705277591944 Scheduler time: 0.4478214466944337 Scheduler overhead time: 0.14482578681781888 Adapter cache time: 0.03303264360874891 Engine time: 0.1462070569396019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8732224958948791,
    "estimated_duration": 3599.681789057671,
    "input_throughput": 358.38584508263364,
    "output_throughput": 317.2144280839114,
    "total_throughput": 675.6002731665451,
    "itl": 18.700148393056352,
    "ttft": 6933.393904098945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8685272574215372,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8732842248864472. Arrivals time: 0.025994232390075922 Scheduler time: 0.44904954405501485 Scheduler overhead time: 0.1454521119594574 Adapter cache time: 0.033218867145478725 Engine time: 0.1453119246289134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8767659589648247,
    "estimated_duration": 3599.6817349120947,
    "input_throughput": 358.38585047339024,
    "output_throughput": 317.2144328553771,
    "total_throughput": 675.6002833287673,
    "itl": 18.700104839346984,
    "ttft": 6933.376915790284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8681743947788383,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8768515181727707. Arrivals time: 0.026212798431515694 Scheduler time: 0.44914148980751634 Scheduler overhead time: 0.1453603864647448 Adapter cache time: 0.03330824989825487 Engine time: 0.14629510045051575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8748212452046573,
    "estimated_duration": 3599.6830391106582,
    "input_throughput": 358.3857206268715,
    "output_throughput": 317.2143179256449,
    "total_throughput": 675.6000385525164,
    "itl": 18.80508015522736,
    "ttft": 6933.654547113083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.602553391018846,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.874886014033109. Arrivals time: 0.025855241809040308 Scheduler time: 0.4525869684293866 Scheduler overhead time: 0.14446859573945403 Adapter cache time: 0.03285329369828105 Engine time: 0.14534836541861296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8768440918065608,
    "estimated_duration": 3599.682739309077,
    "input_throughput": 358.38575047522573,
    "output_throughput": 317.214344345016,
    "total_throughput": 675.6000948202418,
    "itl": 18.70072600119811,
    "ttft": 6933.478730704425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9266353195719406,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8769299280829728. Arrivals time: 0.026198803447186947 Scheduler time: 0.45124277379363775 Scheduler overhead time: 0.14443040173500776 Adapter cache time: 0.03336647758260369 Engine time: 0.14740788843482733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8786330078728497,
    "estimated_duration": 3599.680948771781,
    "input_throughput": 358.38592874187265,
    "output_throughput": 317.21450213236506,
    "total_throughput": 675.6004308742376,
    "itl": 18.803890766820473,
    "ttft": 6933.554973110961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4385578391374167,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8787006726488471. Arrivals time: 0.026540149468928576 Scheduler time: 0.4541296293027699 Scheduler overhead time: 0.14407484093680978 Adapter cache time: 0.032864919397979975 Engine time: 0.14669532189145684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8766302671283484,
    "estimated_duration": 3599.6835170557006,
    "input_throughput": 358.3856730424998,
    "output_throughput": 317.21427580777265,
    "total_throughput": 675.5999488502724,
    "itl": 18.699950283341263,
    "ttft": 6933.448895390494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.982847262099452,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8767159800045192. Arrivals time: 0.025868498254567385 Scheduler time: 0.45000380324199796 Scheduler overhead time: 0.14488175278529525 Adapter cache time: 0.03326245630159974 Engine time: 0.14616315672174096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8800430158153176,
    "estimated_duration": 3599.3945385177576,
    "input_throughput": 345.13332359268713,
    "output_throughput": 313.4988365195112,
    "total_throughput": 658.6321601121983,
    "itl": 18.69879618179673,
    "ttft": 5674.094615936461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0237618910056296,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8802435081452131. Arrivals time: 0.02558532217517495 Scheduler time: 0.4533404423855245 Scheduler overhead time: 0.14535992732271552 Adapter cache time: 0.032943397760391235 Engine time: 0.14841227000579238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8712943359278142,
    "estimated_duration": 3599.377467410579,
    "input_throughput": 345.1349604890703,
    "output_throughput": 313.5003233800273,
    "total_throughput": 658.6352838690975,
    "itl": 18.70050415131172,
    "ttft": 5674.1513077674535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.26347634742271,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8713830998167396. Arrivals time: 0.02568315528333187 Scheduler time: 0.4462720607407391 Scheduler overhead time: 0.14495054306462407 Adapter cache time: 0.032875089440494776 Engine time: 0.1473269579000771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8731980379670858,
    "estimated_duration": 3599.3774311442726,
    "input_throughput": 345.1349639665523,
    "output_throughput": 313.50032653876764,
    "total_throughput": 658.6352905053199,
    "itl": 18.700462979750657,
    "ttft": 5674.11938473542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.262292975950943,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8732663081027567. Arrivals time: 0.025963629595935345 Scheduler time: 0.44735360611230135 Scheduler overhead time: 0.14585792319849133 Adapter cache time: 0.03309957170858979 Engine time: 0.14661888498812914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8713777191005647,
    "estimated_duration": 3599.3951867747473,
    "input_throughput": 345.13326143360825,
    "output_throughput": 313.4987800578554,
    "total_throughput": 658.6320414914636,
    "itl": 18.698793250674818,
    "ttft": 5673.872746056757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1033069825940482,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8714616452343762. Arrivals time: 0.025729860179126263 Scheduler time: 0.4499281202442944 Scheduler overhead time: 0.14465214777737856 Adapter cache time: 0.032874143216758966 Engine time: 0.14451159164309502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.871009930036962,
    "estimated_duration": 3599.378128561345,
    "input_throughput": 345.13489709305145,
    "output_throughput": 313.50026579480794,
    "total_throughput": 658.6351628878595,
    "itl": 18.69987793722621,
    "ttft": 5674.1273824505415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3115884602256127,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.871077872812748. Arrivals time: 0.026020606979727745 Scheduler time: 0.4457535482943058 Scheduler overhead time: 0.1447249287739396 Adapter cache time: 0.03314012801274657 Engine time: 0.14689983520656824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8631993546150625,
    "estimated_duration": 3599.3935523934742,
    "input_throughput": 345.1334181487134,
    "output_throughput": 313.49892240865086,
    "total_throughput": 658.6323405573643,
    "itl": 18.697455621877207,
    "ttft": 5674.035971725872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9541696913632816,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8632682696916163. Arrivals time: 0.025410898961126804 Scheduler time: 0.4408064312301576 Scheduler overhead time: 0.14464350324124098 Adapter cache time: 0.032900862861424685 Engine time: 0.14542999165132642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8696973798796535,
    "estimated_duration": 3599.378631576489,
    "input_throughput": 345.1348488602597,
    "output_throughput": 313.5002219829733,
    "total_throughput": 658.635070843233,
    "itl": 18.701443387037582,
    "ttft": 5674.112434572378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3574885922670803,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8697765618562698. Arrivals time: 0.025875695049762726 Scheduler time: 0.4444858259521425 Scheduler overhead time: 0.14573420770466328 Adapter cache time: 0.032985924277454615 Engine time: 0.14597090473398566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8472894439473748,
    "estimated_duration": 3598.8779492882622,
    "input_throughput": 305.4274180699527,
    "output_throughput": 288.64552080890655,
    "total_throughput": 594.0729388788592,
    "itl": 18.5356531553892,
    "ttft": 5396.270515423783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3014867834374746,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8474933439865708. Arrivals time: 0.024847049731761217 Scheduler time: 0.4222821434959769 Scheduler overhead time: 0.14564729062840343 Adapter cache time: 0.03224835870787501 Engine time: 0.14771877694875002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8489336878992617,
    "estimated_duration": 3598.8646447165847,
    "input_throughput": 305.4285471985466,
    "output_throughput": 288.6465878968357,
    "total_throughput": 594.0751350953823,
    "itl": 18.537216024380953,
    "ttft": 5396.196957773921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4579973370605224,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8490219376981258. Arrivals time: 0.024861429817974567 Scheduler time: 0.42542033502832055 Scheduler overhead time: 0.14473990816622972 Adapter cache time: 0.03176423767581582 Engine time: 0.14748843666166067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8398011848330498,
    "estimated_duration": 3598.864946463848,
    "input_throughput": 305.4285215898534,
    "output_throughput": 288.6465636952279,
    "total_throughput": 594.0750852850813,
    "itl": 18.537196161263832,
    "ttft": 5396.192378331791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4610513525828654,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.839863384142518. Arrivals time: 0.025031563360244036 Scheduler time: 0.4168847044929862 Scheduler overhead time: 0.1451909514144063 Adapter cache time: 0.03164561511948705 Engine time: 0.14669094793498516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8551986366510391,
    "estimated_duration": 3598.8807659066865,
    "input_throughput": 305.4271790310545,
    "output_throughput": 288.6452949041476,
    "total_throughput": 594.0724739352021,
    "itl": 18.535968319976803,
    "ttft": 5396.194737745363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3502580560580637,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8552836738526821. Arrivals time: 0.02520624501630664 Scheduler time: 0.4313836907967925 Scheduler overhead time: 0.14536269241943955 Adapter cache time: 0.03181388974189758 Engine time: 0.14658712735399604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8687919308431447,
    "estimated_duration": 3598.866476283229,
    "input_throughput": 305.4283917571755,
    "output_throughput": 288.64644099628634,
    "total_throughput": 594.0748327534619,
    "itl": 18.537824197636716,
    "ttft": 5396.2028760336225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4951306287013018,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8688591499812901. Arrivals time: 0.02554099727421999 Scheduler time: 0.44224031269550323 Scheduler overhead time: 0.14542143745347857 Adapter cache time: 0.03179572243243456 Engine time: 0.14824990928173065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8508550110273063,
    "estimated_duration": 3598.8756848033563,
    "input_throughput": 305.42761025102214,
    "output_throughput": 288.64570243046904,
    "total_throughput": 594.0733126814912,
    "itl": 18.53500594874299,
    "ttft": 5396.247362856346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2485178217663933,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8509362023323774. Arrivals time: 0.02587114553898573 Scheduler time: 0.4251455604098737 Scheduler overhead time: 0.14658431056886911 Adapter cache time: 0.031887445133179426 Engine time: 0.14656304521486163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8424617690034211,
    "estimated_duration": 3598.868166554786,
    "input_throughput": 305.4282483073743,
    "output_throughput": 288.6463054284226,
    "total_throughput": 594.0745537357968,
    "itl": 18.537716363875404,
    "ttft": 5396.3169415199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.526443321518613,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8425367074087262. Arrivals time: 0.025553131010383368 Scheduler time: 0.41680811904370785 Scheduler overhead time: 0.14601730927824974 Adapter cache time: 0.03180125588551164 Engine time: 0.14712146297097206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.84113516099751,
    "estimated_duration": 3598.2602497168023,
    "input_throughput": 302.4075315524054,
    "output_throughput": 283.17740499181383,
    "total_throughput": 585.5849365442192,
    "itl": 18.530591851822425,
    "ttft": 7909.950267917654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7138731366023656,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8412572178058326. Arrivals time: 0.024939774069935083 Scheduler time: 0.41706233425065875 Scheduler overhead time: 0.1456736153922975 Adapter cache time: 0.031442211009562016 Engine time: 0.14723929716274142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8483114913105965,
    "estimated_duration": 3598.265373120576,
    "input_throughput": 302.40710096829673,
    "output_throughput": 283.17700178859366,
    "total_throughput": 585.5841027568904,
    "itl": 18.531260791571288,
    "ttft": 7910.066463546369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.841543650387329,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8483845861628652. Arrivals time: 0.025799556635320187 Scheduler time: 0.4202974336221814 Scheduler overhead time: 0.14691879926249385 Adapter cache time: 0.03157109720632434 Engine time: 0.1477911351248622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8552592867054045,
    "estimated_duration": 3598.265211868637,
    "input_throughput": 302.4071145203082,
    "output_throughput": 283.1770144788313,
    "total_throughput": 585.5841289991396,
    "itl": 18.531254653657346,
    "ttft": 7910.071866058978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8423047805763897,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.855353303719312. Arrivals time: 0.025455689523369074 Scheduler time: 0.4294210700318217 Scheduler overhead time: 0.14570204494521022 Adapter cache time: 0.031282362062484026 Engine time: 0.14836630458012223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.845221534371376,
    "estimated_duration": 3598.262554945138,
    "input_throughput": 302.40733781490013,
    "output_throughput": 283.17722357409673,
    "total_throughput": 585.5845613889969,
    "itl": 18.53014127341729,
    "ttft": 7909.963680302651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7474368440802126,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8452960583381355. Arrivals time: 0.025576444808393717 Scheduler time: 0.41877530748024583 Scheduler overhead time: 0.1459647947922349 Adapter cache time: 0.031346299685537815 Engine time: 0.14861488435417414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8423841563053429,
    "estimated_duration": 3598.2659663913532,
    "input_throughput": 302.4070511083649,
    "output_throughput": 283.1769550992601,
    "total_throughput": 585.5840062076251,
    "itl": 18.53101612654499,
    "ttft": 7910.169649824578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8702221211604806,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8424925589933991. Arrivals time: 0.0253987074829638 Scheduler time: 0.416669599711895 Scheduler overhead time: 0.1459727198816836 Adapter cache time: 0.031200944911688566 Engine time: 0.14815606828778982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8372410372830927,
    "estimated_duration": 3598.2587003764006,
    "input_throughput": 302.40766176322273,
    "output_throughput": 283.1775269225117,
    "total_throughput": 585.5851886857344,
    "itl": 18.53037323245293,
    "ttft": 7910.113451209384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6744281651451958,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8373174862936139. Arrivals time: 0.025072943419218063 Scheduler time: 0.41468794737011194 Scheduler overhead time: 0.1452299845404923 Adapter cache time: 0.03123268811032176 Engine time: 0.14641851652413607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8432110268622637,
    "estimated_duration": 3598.267193314089,
    "input_throughput": 302.4069479948198,
    "output_throughput": 283.1768585427161,
    "total_throughput": 585.5838065375359,
    "itl": 18.530765080208102,
    "ttft": 7910.194804517866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8902315590903114,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.843301807064563. Arrivals time: 0.025388660840690136 Scheduler time: 0.4180044922977686 Scheduler overhead time: 0.1454031364992261 Adapter cache time: 0.031373603735119104 Engine time: 0.1481001847423613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8218674352392554,
    "estimated_duration": 3599.031320163037,
    "input_throughput": 291.49315653982023,
    "output_throughput": 262.4197779854875,
    "total_throughput": 553.9129345253077,
    "itl": 18.519866085049465,
    "ttft": 5072.378784913858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9732351025706144,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.821949107106775. Arrivals time: 0.02467120671644807 Scheduler time: 0.3977081626653671 Scheduler overhead time: 0.14693028759211302 Adapter cache time: 0.030328665394335985 Engine time: 0.14702619798481464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8220237977802753,
    "estimated_duration": 3599.0315878834576,
    "input_throughput": 291.4931348565789,
    "output_throughput": 262.41975846492153,
    "total_throughput": 553.9128933215004,
    "itl": 18.520237114486886,
    "ttft": 5072.614366278866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0423613451095357,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.822124847676605. Arrivals time: 0.02487039752304554 Scheduler time: 0.39795032190158963 Scheduler overhead time: 0.1460756277665496 Adapter cache time: 0.030560435261577368 Engine time: 0.14715274842455983 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8155952552333474,
    "estimated_duration": 3599.0316234727416,
    "input_throughput": 291.493131974128,
    "output_throughput": 262.41975586996483,
    "total_throughput": 553.9128878440928,
    "itl": 18.520245829661402,
    "ttft": 5072.584893378235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.043382432684308,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8156737401150167. Arrivals time: 0.024406138341873884 Scheduler time: 0.3922959011979401 Scheduler overhead time: 0.14642191817983985 Adapter cache time: 0.030232334975153208 Engine time: 0.14702302543446422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8198427869938314,
    "estimated_duration": 3599.0311792881394,
    "input_throughput": 291.4931679495765,
    "output_throughput": 262.4197882572405,
    "total_throughput": 553.912956206817,
    "itl": 18.51998301255706,
    "ttft": 5072.51028429015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.990878334986049,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.81991619290784. Arrivals time: 0.02466831309720874 Scheduler time: 0.39558487432077527 Scheduler overhead time: 0.14616170059889555 Adapter cache time: 0.03038892289623618 Engine time: 0.1480383798480034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8248955830931664,
    "estimated_duration": 3599.0317492265276,
    "input_throughput": 291.493121789065,
    "output_throughput": 262.41974670075484,
    "total_throughput": 553.9128684898199,
    "itl": 18.52015923296001,
    "ttft": 5072.577558972061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.055846643429255,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.82499462319538. Arrivals time: 0.025279864203184843 Scheduler time: 0.39921394223347306 Scheduler overhead time: 0.1459956830367446 Adapter cache time: 0.030538744758814573 Engine time: 0.1490032165311277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8164166598580778,
    "estimated_duration": 3599.0311792881394,
    "input_throughput": 291.4931679495765,
    "output_throughput": 262.4197882572405,
    "total_throughput": 553.912956206817,
    "itl": 18.519690982319595,
    "ttft": 5072.568784349431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9508359937788932,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8164843139238656. Arrivals time: 0.02418931992724538 Scheduler time: 0.3928604992106557 Scheduler overhead time: 0.14590955851599574 Adapter cache time: 0.030446422286331654 Engine time: 0.1486600930802524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8088133558630943,
    "estimated_duration": 3599.0317492265276,
    "input_throughput": 291.493121789065,
    "output_throughput": 262.41974670075484,
    "total_throughput": 553.9128684898199,
    "itl": 18.520250376794905,
    "ttft": 5072.486399850284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.068044760711496,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8088953848928213. Arrivals time: 0.0236527007073164 Scheduler time: 0.39005608344450593 Scheduler overhead time: 0.14475360698997974 Adapter cache time: 0.030009312089532614 Engine time: 0.1459603412076831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7446283036842942,
    "estimated_duration": 3599.408934498196,
    "input_throughput": 224.0770678401516,
    "output_throughput": 200.2059263378653,
    "total_throughput": 424.2829941780169,
    "itl": 18.189957484067556,
    "ttft": 3297.1061017497723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.975573579368749,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7447113008238375. Arrivals time: 0.021741691045463085 Scheduler time: 0.3275520303286612 Scheduler overhead time: 0.14423057064414024 Adapter cache time: 0.03095137607306242 Engine time: 0.1460208287462592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7523674331605434,
    "estimated_duration": 3599.4113580113562,
    "input_throughput": 224.07691696722577,
    "output_throughput": 200.20579153757464,
    "total_throughput": 424.2827085048004,
    "itl": 18.191691980077362,
    "ttft": 3297.0099481972948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.270476621256666,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7524373698979616. Arrivals time: 0.021779240109026432 Scheduler time: 0.33386729238554835 Scheduler overhead time: 0.14450829103589058 Adapter cache time: 0.031232720240950584 Engine time: 0.14699156396090984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7455654907971621,
    "estimated_duration": 3599.411428851413,
    "input_throughput": 224.07691255716546,
    "output_throughput": 200.2057875973222,
    "total_throughput": 424.28270015448766,
    "itl": 18.191694399417464,
    "ttft": 3297.0537384007725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.271884327996454,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7456402620300651. Arrivals time: 0.021713257301598787 Scheduler time: 0.3296842076815665 Scheduler overhead time: 0.14425197802484035 Adapter cache time: 0.030962318181991577 Engine time: 0.14492858480662107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.746058794669807,
    "estimated_duration": 3599.409723630083,
    "input_throughput": 224.07701871366336,
    "output_throughput": 200.20588244486822,
    "total_throughput": 424.28290115853156,
    "itl": 18.190090183594926,
    "ttft": 3296.98014672923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0792540122265475,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7461275728419423. Arrivals time: 0.021606148220598698 Scheduler time: 0.3280706871300936 Scheduler overhead time: 0.14467470115050673 Adapter cache time: 0.03087368980050087 Engine time: 0.1468876670114696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7483608853071928,
    "estimated_duration": 3599.411931866557,
    "input_throughput": 224.07688124258334,
    "output_throughput": 200.20575961871208,
    "total_throughput": 424.2826408612954,
    "itl": 18.19156879258678,
    "ttft": 3297.0276414369946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.330737100038663,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7484225053340197. Arrivals time: 0.021771392319351435 Scheduler time: 0.3302431288175285 Scheduler overhead time: 0.14500807598233223 Adapter cache time: 0.03112407447770238 Engine time: 0.1454021674580872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.74326366558671,
    "estimated_duration": 3599.40808924881,
    "input_throughput": 224.07712046019336,
    "output_throughput": 200.20597335224434,
    "total_throughput": 424.2830938124377,
    "itl": 18.188676669526348,
    "ttft": 3296.926287301256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.884075333077825,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7433263976126909. Arrivals time: 0.021603409200906754 Scheduler time: 0.3275581821799278 Scheduler overhead time: 0.1438175654038787 Adapter cache time: 0.030979829374700785 Engine time: 0.14525443548336625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7457021810114384,
    "estimated_duration": 3599.4124348817013,
    "input_throughput": 224.07684992800998,
    "output_throughput": 200.20573164010978,
    "total_throughput": 424.2825815681198,
    "itl": 18.191967858094905,
    "ttft": 3296.882596086975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.391727686449912,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7457691379822791. Arrivals time: 0.021638269536197186 Scheduler time: 0.32780966395512223 Scheduler overhead time: 0.14448950393125415 Adapter cache time: 0.03115969430655241 Engine time: 0.14589069597423077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7350950599648058,
    "estimated_duration": 3592.378093519243,
    "input_throughput": 208.30268432767673,
    "output_throughput": 187.69238160548542,
    "total_throughput": 395.99506593316215,
    "itl": 18.12865938223118,
    "ttft": 4665.507742523539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.19514920466587,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7351809362880886. Arrivals time: 0.02087507164105773 Scheduler time: 0.31343109952285886 Scheduler overhead time: 0.15096431877464056 Adapter cache time: 0.03008646797388792 Engine time: 0.14596440270543098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7390723759308457,
    "estimated_duration": 3592.380052029011,
    "input_throughput": 208.30257076429086,
    "output_throughput": 187.69227927851628,
    "total_throughput": 395.9948500428072,
    "itl": 18.12893900606845,
    "ttft": 4665.442588515447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.439908260942917,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7391347191296518. Arrivals time: 0.0215473179705441 Scheduler time: 0.32326669758185744 Scheduler overhead time: 0.14333843486383557 Adapter cache time: 0.029911968857049942 Engine time: 0.14707938907667994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7255740943364799,
    "estimated_duration": 3592.379998221946,
    "input_throughput": 208.3025738842698,
    "output_throughput": 187.692282089792,
    "total_throughput": 395.9948559740618,
    "itl": 18.128946156146004,
    "ttft": 4665.390658661522,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4401494763604803,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7256563561968505. Arrivals time: 0.021212392952293158 Scheduler time: 0.3142651249654591 Scheduler overhead time: 0.14236805029213428 Adapter cache time: 0.03009491367265582 Engine time: 0.14448629738762975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.727539696265012,
    "estimated_duration": 3592.3792348383745,
    "input_throughput": 208.3026181487398,
    "output_throughput": 187.69232197455787,
    "total_throughput": 395.9949401232977,
    "itl": 18.129044544700903,
    "ttft": 4665.403461885959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.281781872706458,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7276131520047784. Arrivals time: 0.021244667004793882 Scheduler time: 0.31487474078312516 Scheduler overhead time: 0.14276590524241328 Adapter cache time: 0.030011094640940428 Engine time: 0.1454602968879044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7426311988383532,
    "estimated_duration": 3592.3802497295183,
    "input_throughput": 208.3025593007149,
    "output_throughput": 187.69226894919248,
    "total_throughput": 395.9948282499074,
    "itl": 18.129217083778194,
    "ttft": 4665.4745092887115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4888161917030796,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7426929669454694. Arrivals time: 0.02171708969399333 Scheduler time: 0.32829725788906217 Scheduler overhead time: 0.14314846182242036 Adapter cache time: 0.030084338039159775 Engine time: 0.14499976206570864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7325676279142499,
    "estimated_duration": 3592.3776004571014,
    "input_throughput": 208.30271291770234,
    "output_throughput": 187.69240736669929,
    "total_throughput": 395.99512028440165,
    "itl": 18.128253272496107,
    "ttft": 4665.426032595493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1216125078777974,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.732650846708566. Arrivals time: 0.021150341257452965 Scheduler time: 0.3186307861469686 Scheduler overhead time: 0.14327934803441167 Adapter cache time: 0.02996669663116336 Engine time: 0.14573023188859224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7310698297806084,
    "estimated_duration": 3592.3807527446625,
    "input_throughput": 208.3025301336112,
    "output_throughput": 187.69224266799898,
    "total_throughput": 395.99477280161017,
    "itl": 18.12949381021838,
    "ttft": 4665.42356919939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.538111675977757,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7311390428803861. Arrivals time: 0.02154611423611641 Scheduler time: 0.3195782545953989 Scheduler overhead time: 0.14270657440647483 Adapter cache time: 0.029909877572208643 Engine time: 0.14355373196303844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7279130490496755,
    "estimated_duration": 3597.3263028965894,
    "input_throughput": 197.79495661182284,
    "output_throughput": 184.18318056565982,
    "total_throughput": 381.97813717748267,
    "itl": 18.130001108141958,
    "ttft": 7252.266894881558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.705471165636612,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7279787678271532. Arrivals time: 0.020941968075931072 Scheduler time: 0.3127238224260509 Scheduler overhead time: 0.14351083431392908 Adapter cache time: 0.0297669623978436 Engine time: 0.14641368202865124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7258500410243869,
    "estimated_duration": 3597.3275850906184,
    "input_throughput": 197.79488611184576,
    "output_throughput": 184.1831149173226,
    "total_throughput": 381.97800102916835,
    "itl": 18.130793439038808,
    "ttft": 7252.347533444181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.923092253825178,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7259404780343175. Arrivals time: 0.021105478517711163 Scheduler time: 0.3110790252685547 Scheduler overhead time: 0.14389248192310333 Adapter cache time: 0.030014834832400084 Engine time: 0.14594813622534275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.737672118935734,
    "estimated_duration": 3597.327567042093,
    "input_throughput": 197.794887104223,
    "output_throughput": 184.18311584140682,
    "total_throughput": 381.97800294562984,
    "itl": 18.130788370632438,
    "ttft": 7252.319939832514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9214851960725805,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.737742634024471. Arrivals time: 0.0211213119328022 Scheduler time: 0.32037241850048304 Scheduler overhead time: 0.14408706035465002 Adapter cache time: 0.029855663422495127 Engine time: 0.1482056025415659 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7311152191832662,
    "estimated_duration": 3597.326767899982,
    "input_throughput": 197.79493104413558,
    "output_throughput": 184.18315675747965,
    "total_throughput": 381.97808780161523,
    "itl": 18.130371751459478,
    "ttft": 7252.358554999271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.780901083007899,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7311824611388147. Arrivals time: 0.021161599550396204 Scheduler time: 0.3170197973959148 Scheduler overhead time: 0.1431359862908721 Adapter cache time: 0.029957071412354708 Engine time: 0.14585202280431986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7286758697591722,
    "estimated_duration": 3597.327818549665,
    "input_throughput": 197.7948732753716,
    "output_throughput": 184.1831029642239,
    "total_throughput": 381.97797623959553,
    "itl": 18.131043490319634,
    "ttft": 7252.30090224132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9652475137449796,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7287749126553535. Arrivals time: 0.020877650938928127 Scheduler time: 0.3149156025610864 Scheduler overhead time: 0.14382869144901633 Adapter cache time: 0.029656601138412952 Engine time: 0.14545261021703482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7300625364296138,
    "estimated_duration": 3597.3259507093453,
    "input_throughput": 197.7949759764458,
    "output_throughput": 184.18319859765572,
    "total_throughput": 381.9781745741015,
    "itl": 18.129743419574087,
    "ttft": 7252.264686045547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6461945109883684,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7301286570727825. Arrivals time: 0.020992359146475792 Scheduler time: 0.31291719572618604 Scheduler overhead time: 0.1439971891231835 Adapter cache time: 0.029648824594914913 Engine time: 0.14830117486417294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7302249222993851,
    "estimated_duration": 3597.3280700572373,
    "input_throughput": 197.79485944652214,
    "output_throughput": 184.1830900870428,
    "total_throughput": 381.977949533565,
    "itl": 18.131249071211133,
    "ttft": 7252.282561830276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0076265397668185,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7302853860892355. Arrivals time: 0.02081461437046528 Scheduler time: 0.3134806933812797 Scheduler overhead time: 0.14638515887781978 Adapter cache time: 0.02984087448567152 Engine time: 0.14540691254660487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6788710057735443,
    "estimated_duration": 3599.386916598902,
    "input_throughput": 178.15922957400116,
    "output_throughput": 154.39490470924758,
    "total_throughput": 332.55413428324874,
    "itl": 17.970840578136652,
    "ttft": 6923.984892151063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2372165408148845,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6789316688664258. Arrivals time: 0.01982231205329299 Scheduler time: 0.27756840363144875 Scheduler overhead time: 0.13932596845552325 Adapter cache time: 0.0282521047629416 Engine time: 0.14213749254122376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6730879568494856,
    "estimated_duration": 3599.3875224771923,
    "input_throughput": 178.1591995847853,
    "output_throughput": 154.39487872023687,
    "total_throughput": 332.5540783050222,
    "itl": 17.971687908612175,
    "ttft": 6923.975982483809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4018736890284447,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6731692869216204. Arrivals time: 0.019565953873097897 Scheduler time: 0.2740361001342535 Scheduler overhead time: 0.13940341025590897 Adapter cache time: 0.028006555046886206 Engine time: 0.14044398441910744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6850792430341244,
    "estimated_duration": 3599.3875401872065,
    "input_throughput": 178.15919870819118,
    "output_throughput": 154.39487796057,
    "total_throughput": 332.5540766687612,
    "itl": 17.97169813353216,
    "ttft": 6923.995194725559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4032162030599973,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6851427969522774. Arrivals time: 0.019678812939673662 Scheduler time: 0.2831677976064384 Scheduler overhead time: 0.14020402962341905 Adapter cache time: 0.02823528368026018 Engine time: 0.14094964694231749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6816670666448772,
    "estimated_duration": 3599.3867052865558,
    "input_throughput": 178.15924003335104,
    "output_throughput": 154.39491377344442,
    "total_throughput": 332.55415380679545,
    "itl": 17.97121223707545,
    "ttft": 6924.0920608535325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2964560968708088,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6817340096458793. Arrivals time: 0.01974971778690815 Scheduler time: 0.27841336326673627 Scheduler overhead time: 0.14007748709991574 Adapter cache time: 0.028595675714313984 Engine time: 0.14258436067029834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6793685690499842,
    "estimated_duration": 3599.3877916947786,
    "input_throughput": 178.15918625929984,
    "output_throughput": 154.39486717221288,
    "total_throughput": 332.5540534315127,
    "itl": 17.97184383388969,
    "ttft": 6923.995330526001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.43566067995504,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6794312242418528. Arrivals time: 0.01983892312273383 Scheduler time: 0.2767269145697355 Scheduler overhead time: 0.1395964059047401 Adapter cache time: 0.028360112570226192 Engine time: 0.14278684416785836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6790185570716858,
    "estimated_duration": 3599.3867052865558,
    "input_throughput": 178.15924003335104,
    "output_throughput": 154.39491377344442,
    "total_throughput": 332.55415380679545,
    "itl": 17.970634682981466,
    "ttft": 6923.802030728163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.18572676557345,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6790885762311518. Arrivals time: 0.019384799525141716 Scheduler time: 0.2764891991391778 Scheduler overhead time: 0.14000697853043675 Adapter cache time: 0.028000036720186472 Engine time: 0.14327410189434886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6778588220477104,
    "estimated_duration": 3599.3877916947786,
    "input_throughput": 178.15918625929984,
    "output_throughput": 154.39486717221288,
    "total_throughput": 332.5540534315127,
    "itl": 17.972089219268764,
    "ttft": 6924.056402042036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.469739956073474,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.677925004158169. Arrivals time: 0.019511929247528315 Scheduler time: 0.2770174043253064 Scheduler overhead time: 0.13920037494972348 Adapter cache time: 0.028063167817890644 Engine time: 0.142041121609509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6831212439574301,
    "estimated_duration": 3599.2542096059287,
    "input_throughput": 170.560611796079,
    "output_throughput": 157.56208563609368,
    "total_throughput": 328.1226974321727,
    "itl": 18.085477153995352,
    "ttft": 4288.715916901965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7628409405052914,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6831840509548783. Arrivals time: 0.019680814817547798 Scheduler time: 0.2801652140915394 Scheduler overhead time: 0.14083802560344338 Adapter cache time: 0.027715079952031374 Engine time: 0.14246866153553128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6783131598494947,
    "estimated_duration": 3599.25413916848,
    "input_throughput": 170.56061513395233,
    "output_throughput": 157.5620887195857,
    "total_throughput": 328.122703853538,
    "itl": 18.08621671459297,
    "ttft": 4288.623868550674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8971477661561316,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6783886929042637. Arrivals time: 0.019668211694806814 Scheduler time: 0.27937143482267857 Scheduler overhead time: 0.13930625701323152 Adapter cache time: 0.027765450533479452 Engine time: 0.14038213714957237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6804883349686861,
    "estimated_duration": 3599.2541926370336,
    "input_throughput": 170.56061260019703,
    "output_throughput": 157.56208637892937,
    "total_throughput": 328.1226989791264,
    "itl": 18.086155631928083,
    "ttft": 4288.68158486278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8974087845534207,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6805617590434849. Arrivals time: 0.019632866140455008 Scheduler time: 0.2797042359597981 Scheduler overhead time: 0.13940174411982298 Adapter cache time: 0.027758280746638775 Engine time: 0.14192069601267576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6917844377458096,
    "estimated_duration": 3599.25413916848,
    "input_throughput": 170.56061513395233,
    "output_throughput": 157.5620887195857,
    "total_throughput": 328.122703853538,
    "itl": 18.085748957834493,
    "ttft": 4288.6952130426425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8084825820545583,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6918489979580045. Arrivals time: 0.019476014655083418 Scheduler time: 0.28086921386420727 Scheduler overhead time: 0.13938336446881294 Adapter cache time: 0.029325192794203758 Engine time: 0.14560193056240678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6774376411922276,
    "estimated_duration": 3599.2541926370336,
    "input_throughput": 170.56061260019703,
    "output_throughput": 157.56208637892937,
    "total_throughput": 328.1226989791264,
    "itl": 18.086428587381018,
    "ttft": 4288.601532862813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9246973562054366,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6774994661100209. Arrivals time: 0.01934563461691141 Scheduler time: 0.27830850193277 Scheduler overhead time: 0.13923367345705628 Adapter cache time: 0.027849629521369934 Engine time: 0.14036589488387108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6816841340623796,
    "estimated_duration": 3599.25413916848,
    "input_throughput": 170.56061513395233,
    "output_throughput": 157.5620887195857,
    "total_throughput": 328.122703853538,
    "itl": 18.084592011142288,
    "ttft": 4288.733549201882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7222689698636289,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6817614687606692. Arrivals time: 0.019553130492568016 Scheduler time: 0.2809188715182245 Scheduler overhead time: 0.1401673569343984 Adapter cache time: 0.027808649465441704 Engine time: 0.14158603502437472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6885671759955585,
    "estimated_duration": 3599.2541926370336,
    "input_throughput": 170.56061260019703,
    "output_throughput": 157.56208637892937,
    "total_throughput": 328.1226989791264,
    "itl": 18.086589620449672,
    "ttft": 4288.650464633712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9512314051389634,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6886450028978288. Arrivals time: 0.019715452566742897 Scheduler time: 0.2853631917387247 Scheduler overhead time: 0.14006904466077685 Adapter cache time: 0.027814585715532303 Engine time: 0.1431165342219174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6595932291820645,
    "estimated_duration": 3598.9145162312484,
    "input_throughput": 151.1889203108368,
    "output_throughput": 141.7474623804655,
    "total_throughput": 292.9363826913023,
    "itl": 17.9997133861285,
    "ttft": 4808.079564801048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1048360755597264,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6596541563048959. Arrivals time: 0.018606831319630146 Scheduler time: 0.26084290398284793 Scheduler overhead time: 0.14442538283765316 Adapter cache time: 0.026591744739562273 Engine time: 0.13840345479547977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6520788730122149,
    "estimated_duration": 3598.9148560224244,
    "input_throughput": 151.18890603635043,
    "output_throughput": 141.7474489973934,
    "total_throughput": 292.93635503374384,
    "itl": 18.00022400181266,
    "ttft": 4808.177237831537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1885031064832647,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.652162364218384. Arrivals time: 0.01845688372850418 Scheduler time: 0.2617313042283058 Scheduler overhead time: 0.13661955576390028 Adapter cache time: 0.026431043166667223 Engine time: 0.1379745677113533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6517261839471757,
    "estimated_duration": 3598.9148381431546,
    "input_throughput": 151.1889067874511,
    "output_throughput": 141.74744970158923,
    "total_throughput": 292.93635648904035,
    "itl": 18.000222091471322,
    "ttft": 4808.189251629388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1887553854473003,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6517993430607021. Arrivals time: 0.01867238851264119 Scheduler time: 0.2600420149974525 Scheduler overhead time: 0.13699179841205478 Adapter cache time: 0.02619306370615959 Engine time: 0.13926576357334852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6457351562567055,
    "estimated_duration": 3598.9144457937996,
    "input_throughput": 151.18892326988515,
    "output_throughput": 141.74746515472694,
    "total_throughput": 292.93638842461206,
    "itl": 17.999889913057192,
    "ttft": 4808.027942032844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1292567853094095,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6458021532744169. Arrivals time: 0.0185228711925447 Scheduler time: 0.2581102787517011 Scheduler overhead time: 0.13627726025879383 Adapter cache time: 0.026254144497215748 Engine time: 0.13684025779366493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6547918170690536,
    "estimated_duration": 3598.9149638969407,
    "input_throughput": 151.18890150458734,
    "output_throughput": 141.7474447486302,
    "total_throughput": 292.9363462532175,
    "itl": 18.000254899296422,
    "ttft": 4808.180406513144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2069896844774535,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6548597128130496. Arrivals time: 0.018561762291938066 Scheduler time: 0.2631825115531683 Scheduler overhead time: 0.1363805504515767 Adapter cache time: 0.026369331404566765 Engine time: 0.13978271512314677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.65436050016433,
    "estimated_duration": 3598.9144457937996,
    "input_throughput": 151.18892326988515,
    "output_throughput": 141.74746515472694,
    "total_throughput": 292.93638842461206,
    "itl": 17.99953280558267,
    "ttft": 4808.089231603145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.079408156459684,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.654437888879329. Arrivals time: 0.018443549517542124 Scheduler time: 0.2641607327386737 Scheduler overhead time: 0.13660477520897985 Adapter cache time: 0.02655968815088272 Engine time: 0.1376167144626379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_32_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6483318950049579,
    "estimated_duration": 3598.9149638969407,
    "input_throughput": 151.18890150458734,
    "output_throughput": 141.7474447486302,
    "total_throughput": 292.9363462532175,
    "itl": 18.00033209769727,
    "ttft": 4808.226720783009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2223316464200649,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6484348559752107. Arrivals time: 0.018492959439754486 Scheduler time: 0.2587325763888657 Scheduler overhead time: 0.1365080322138965 Adapter cache time: 0.026255352422595024 Engine time: 0.13812580844387412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5529868029989302,
    "estimated_duration": 3595.988684389557,
    "input_throughput": 110.39133735966904,
    "output_throughput": 95.99279371998306,
    "total_throughput": 206.3841310796521,
    "itl": 17.78810622576202,
    "ttft": 8772.110133682974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.992377521300256,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.553069160785526. Arrivals time: 0.016042133793234825 Scheduler time: 0.20071559958159924 Scheduler overhead time: 0.12330523366108537 Adapter cache time: 0.02387986145913601 Engine time: 0.12521169614046812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5626230118796229,
    "estimated_duration": 3595.9889521099776,
    "input_throughput": 110.39132914106334,
    "output_throughput": 95.9927865733451,
    "total_throughput": 206.38411571440844,
    "itl": 17.788822226334663,
    "ttft": 8772.325002997182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.136928160374528,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5626848000101745. Arrivals time: 0.016484209802001715 Scheduler time: 0.20617958856746554 Scheduler overhead time: 0.12441424326971173 Adapter cache time: 0.023976103402674198 Engine time: 0.1266103987582028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5623662588186562,
    "estimated_duration": 3595.9889876992615,
    "input_throughput": 110.39132804852709,
    "output_throughput": 95.99278562331034,
    "total_throughput": 206.38411367183744,
    "itl": 17.788826033437143,
    "ttft": 8772.268729512907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1384881030023166,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5624315510503948. Arrivals time: 0.016284119803458452 Scheduler time: 0.20408699940890074 Scheduler overhead time: 0.12767558824270964 Adapter cache time: 0.023850081954151392 Engine time: 0.1260083601810038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_32_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5546617819927633,
    "estimated_duration": 3595.9889521099776,
    "input_throughput": 110.39132914106334,
    "output_throughput": 95.9927865733451,
    "total_throughput": 206.38411571440844,
    "itl": 17.78832705210159,
    "ttft": 8772.177322674841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.043359832451666,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5547430948354304. Arrivals time: 0.016041279304772615 Scheduler time: 0.201388543471694 Scheduler overhead time: 0.1245232978835702 Adapter cache time: 0.023846608120948076 Engine time: 0.1250045602209866 
