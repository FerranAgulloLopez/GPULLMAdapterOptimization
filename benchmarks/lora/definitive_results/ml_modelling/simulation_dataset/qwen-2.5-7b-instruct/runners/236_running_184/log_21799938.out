INFO 06-01 00:47:28 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:29 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.2919573858380318,
    "estimated_duration": 3600.112837375972,
    "input_throughput": 2962.782690937661,
    "output_throughput": 2610.7431696087233,
    "total_throughput": 5573.525860546384,
    "itl": 327.03535800583575,
    "ttft": 2236471.5476033795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.985534534866593,
    "arrivals": 241330,
    "finished_requests": 43094,
    "scheduler_time": 37.63937599499341
}
#Debug simulation 
Total elapsed time: 3.292061557993293. Arrivals time: 0.16244409000501037 Scheduler time: 2.9699490629136562 Scheduler overhead time: 0.017469212412834167 Adapter cache time: 0.11592092551290989 Engine time: 0.01810477999970317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.4885125760920346,
    "estimated_duration": 3600.1029321862857,
    "input_throughput": 2969.1142729379317,
    "output_throughput": 2632.0339108319945,
    "total_throughput": 5601.148183769927,
    "itl": 192.82223020117536,
    "ttft": 2246073.1738011953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.299687131692074,
    "arrivals": 241330,
    "finished_requests": 43193,
    "scheduler_time": 36.95898858652682
}
#Debug simulation 
Total elapsed time: 3.4886531811207533. Arrivals time: 0.16622941521927714 Scheduler time: 3.0585271744057536 Scheduler overhead time: 0.028056584764271975 Adapter cache time: 0.1934856059961021 Engine time: 0.02907129656523466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.480567751917988,
    "estimated_duration": 3600.13054986559,
    "input_throughput": 2972.884136215445,
    "output_throughput": 2635.2844344364703,
    "total_throughput": 5608.168570651915,
    "itl": 192.65538074606474,
    "ttft": 2245514.5821137493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.074272398978818,
    "arrivals": 241330,
    "finished_requests": 43251,
    "scheduler_time": 37.00457393796553
}
#Debug simulation 
Total elapsed time: 3.4806541996076703. Arrivals time: 0.17670995462685823 Scheduler time: 3.039248310495168 Scheduler overhead time: 0.027999903075397015 Adapter cache time: 0.19462279556319118 Engine time: 0.02891350956633687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 1080, 270, 4320, 4320, 270, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 270, 270, 1080, 270, 4320, 270, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 4320, 4320, 270, 1080, 1080, 1080, 4320, 1080, 270, 1080, 270, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 4320, 4320, 1080, 270, 270, 4320, 1080, 1080, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 270, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 270, 270, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 1080, 270, 4320, 1080, 1080, 270, 4320, 4320, 4320, 270, 1080, 4320, 270, 4320, 1080, 1080, 4320, 4320, 270, 1080, 4320, 270, 1080, 1080, 270, 1080, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 1080, 1080, 1080, 270, 270, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 4320, 4320, 270, 270, 4320, 270, 270, 270, 1080, 270, 1080, 4320, 4320, 1080, 1080, 270, 4320, 1080, 4320, 270, 1080, 1080, 270, 270, 1080, 270, 4320, 4320, 270, 4320, 4320, 270, 1080, 4320, 270, 270, 1080, 1080, 270, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 4320, 1080, 1080, 1080, 4320, 270, 1080, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 1080, 270, 4320, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 270, 4320, 4320, 1080, 270, 4320, 1080, 1080, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 1080, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 4320, 270, 270, 270, 1080, 270, 1080, 1080, 270, 4320, 1080, 4320, 270, 4320, 270, 1080, 1080, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 1080, 1080, 1080, 270, 1080, 270, 270, 4320, 270, 1080, 270, 270, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 725760 . Total input tokens: 161737649 . Total output tokens: 145027066
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.720912178978324,
    "estimated_duration": 3600.079436881147,
    "input_throughput": 2972.851623871913,
    "output_throughput": 2635.183797004977,
    "total_throughput": 5608.0354208768895,
    "itl": 192.55251181357906,
    "ttft": 2245471.6823231434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.87378198069041,
    "arrivals": 241330,
    "finished_requests": 43250,
    "scheduler_time": 37.00267032329521
}
#Debug simulation 
Total elapsed time: 3.720973940100521. Arrivals time: 0.16972843371331692 Scheduler time: 3.2862979667261243 Scheduler overhead time: 0.028149615973234177 Adapter cache time: 0.1944385697133839 Engine time: 0.02915847161784768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4963262430392206,
    "estimated_duration": 3600.15518614812,
    "input_throughput": 3133.966847710158,
    "output_throughput": 2751.514167531901,
    "total_throughput": 5885.481015242059,
    "itl": 309.405117904535,
    "ttft": 2199937.236281475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.616717021062559,
    "arrivals": 235580,
    "finished_requests": 45514,
    "scheduler_time": 39.63793402757484
}
#Debug simulation 
Total elapsed time: 3.4964384520426393. Arrivals time: 0.17901463760063052 Scheduler time: 3.1696296515874565 Scheduler overhead time: 0.018582304008305073 Adapter cache time: 0.10111383395269513 Engine time: 0.019389125518500805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5757412519305944,
    "estimated_duration": 3600.000285179428,
    "input_throughput": 3082.574755809193,
    "output_throughput": 2722.3506176782244,
    "total_throughput": 5804.925373487417,
    "itl": 185.7617022706347,
    "ttft": 2219168.745728809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.757708620242778,
    "arrivals": 235580,
    "finished_requests": 44779,
    "scheduler_time": 38.21620768969133
}
#Debug simulation 
Total elapsed time: 3.5758391078561544. Arrivals time: 0.17193610593676567 Scheduler time: 3.1561319176107645 Scheduler overhead time: 0.028974940534681082 Adapter cache time: 0.17480229958891869 Engine time: 0.030327672138810158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5647715502418578,
    "estimated_duration": 3600.1201948974763,
    "input_throughput": 3088.23383612519,
    "output_throughput": 2727.30616436533,
    "total_throughput": 5815.54000049052,
    "itl": 185.66348318901987,
    "ttft": 2218098.0182038033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 849,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.643970292529528,
    "arrivals": 235580,
    "finished_requests": 44859,
    "scheduler_time": 38.283433481392116
}
#Debug simulation 
Total elapsed time: 3.5648629842326045. Arrivals time: 0.1697287173010409 Scheduler time: 3.1486919899471104 Scheduler overhead time: 0.02897436497732997 Adapter cache time: 0.17370683746412396 Engine time: 0.03005010448396206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 1080, 135, 4320, 4320, 135, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 135, 135, 1080, 135, 4320, 135, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 4320, 4320, 135, 1080, 1080, 1080, 4320, 1080, 135, 1080, 135, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 4320, 4320, 1080, 135, 135, 4320, 1080, 1080, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 135, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 135, 135, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 1080, 135, 4320, 1080, 1080, 135, 4320, 4320, 4320, 135, 1080, 4320, 135, 4320, 1080, 1080, 4320, 4320, 135, 1080, 4320, 135, 1080, 1080, 135, 1080, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 1080, 1080, 1080, 135, 135, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 4320, 4320, 135, 135, 4320, 135, 135, 135, 1080, 135, 1080, 4320, 4320, 1080, 1080, 135, 4320, 1080, 4320, 135, 1080, 1080, 135, 135, 1080, 135, 4320, 4320, 135, 4320, 4320, 135, 1080, 4320, 135, 135, 1080, 1080, 135, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 4320, 1080, 1080, 1080, 4320, 135, 1080, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 1080, 135, 4320, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 135, 4320, 4320, 1080, 135, 4320, 1080, 1080, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 1080, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 4320, 135, 135, 135, 1080, 135, 1080, 1080, 135, 4320, 1080, 4320, 135, 4320, 135, 1080, 1080, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 1080, 1080, 1080, 135, 1080, 135, 135, 4320, 135, 1080, 135, 135, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 708480 . Total input tokens: 157845104 . Total output tokens: 141621177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6292985011823475,
    "estimated_duration": 3600.1230350262317,
    "input_throughput": 3092.4845877993384,
    "output_throughput": 2731.538312531129,
    "total_throughput": 5824.022900330468,
    "itl": 185.4831820541822,
    "ttft": 2217995.496896975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.541542750666796,
    "arrivals": 235580,
    "finished_requests": 44927,
    "scheduler_time": 38.330541528335104
}
#Debug simulation 
Total elapsed time: 3.629389408044517. Arrivals time: 0.1690175672993064 Scheduler time: 3.208570359274745 Scheduler overhead time: 0.029431185219436884 Adapter cache time: 0.1780067142099142 Engine time: 0.030615899711847305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.516896214336157,
    "estimated_duration": 3600.238479946341,
    "input_throughput": 3209.1174138475953,
    "output_throughput": 2823.0768757717083,
    "total_throughput": 6032.194289619303,
    "itl": 301.48406391166264,
    "ttft": 2172673.9730253033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.747538501785627,
    "arrivals": 232701,
    "finished_requests": 46959,
    "scheduler_time": 40.672321582205726
}
#Debug simulation 
Total elapsed time: 3.517006469424814. Arrivals time: 0.18598344642668962 Scheduler time: 3.195908053778112 Scheduler overhead time: 0.018988332711160183 Adapter cache time: 0.08786203432828188 Engine time: 0.019523049239069223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.6335862679407,
    "estimated_duration": 3600.1983037851764,
    "input_throughput": 3140.745049546778,
    "output_throughput": 2778.3597335411823,
    "total_throughput": 5919.104783087961,
    "itl": 181.72837919668018,
    "ttft": 2198371.3865786046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8420631826506055,
    "arrivals": 232701,
    "finished_requests": 45950,
    "scheduler_time": 38.9879000528605
}
#Debug simulation 
Total elapsed time: 3.633679903112352. Arrivals time: 0.17236320208758116 Scheduler time: 3.2213657274842262 Scheduler overhead time: 0.029659763909876347 Adapter cache time: 0.1655414579436183 Engine time: 0.030831892509013414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.6170529327355325,
    "estimated_duration": 3600.0141515351856,
    "input_throughput": 3140.933486380348,
    "output_throughput": 2778.388244872498,
    "total_throughput": 5919.321731252846,
    "itl": 183.24389115709326,
    "ttft": 2198200.495999995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7623870955547207,
    "arrivals": 232701,
    "finished_requests": 45950,
    "scheduler_time": 39.00009532737943
}
#Debug simulation 
Total elapsed time: 3.6171457478776574. Arrivals time: 0.17197315953671932 Scheduler time: 3.2063909228891134 Scheduler overhead time: 0.029211372137069702 Adapter cache time: 0.1652542082592845 Engine time: 0.030555326025933027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 1080, 66, 4320, 4320, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 1080, 1080, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 66, 66, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 1080, 66, 4320, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 4320, 66, 4320, 1080, 1080, 4320, 4320, 66, 1080, 4320, 66, 1080, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 4320, 4320, 66, 66, 4320, 66, 66, 66, 1080, 66, 1080, 4320, 4320, 1080, 1080, 66, 4320, 1080, 4320, 66, 1080, 1080, 66, 66, 1080, 66, 4320, 4320, 66, 4320, 4320, 66, 1080, 4320, 66, 66, 1080, 1080, 66, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 4320, 1080, 1080, 1080, 4320, 66, 1080, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 1080, 66, 4320, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 66, 4320, 4320, 1080, 66, 4320, 1080, 1080, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 1080, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 4320, 66, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 1080, 1080, 1080, 66, 1080, 66, 66, 4320, 66, 1080, 66, 66, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 699648 . Total input tokens: 155898747 . Total output tokens: 139865162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.614698893856257,
    "estimated_duration": 3600.114553984046,
    "input_throughput": 3143.294145314618,
    "output_throughput": 2780.3868043373263,
    "total_throughput": 5923.6809496519445,
    "itl": 183.08343614435108,
    "ttft": 2197863.5704552475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6893784166197061,
    "arrivals": 232701,
    "finished_requests": 45987,
    "scheduler_time": 39.03391949644251
}
#Debug simulation 
Total elapsed time: 3.614789156243205. Arrivals time: 0.17212760588154197 Scheduler time: 3.201115515548736 Scheduler overhead time: 0.0293841022066772 Adapter cache time: 0.1677406458184123 Engine time: 0.030625592451542616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5610765600576997,
    "estimated_duration": 3600.310746684618,
    "input_throughput": 3212.2724436077942,
    "output_throughput": 2849.319606494129,
    "total_throughput": 6061.592050101923,
    "itl": 300.4045635123737,
    "ttft": 2168537.557315683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2639814382442351,
    "arrivals": 231176,
    "finished_requests": 47115,
    "scheduler_time": 41.03129018077338
}
#Debug simulation 
Total elapsed time: 3.561181439086795. Arrivals time: 0.1798028126358986 Scheduler time: 3.2522443565540016 Scheduler overhead time: 0.019126360304653645 Adapter cache time: 0.08086991729214787 Engine time: 0.020251070149242878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.635321500711143,
    "estimated_duration": 3600.139177091311,
    "input_throughput": 3125.500833856959,
    "output_throughput": 2788.203040558564,
    "total_throughput": 5913.703874415523,
    "itl": 182.51639821675204,
    "ttft": 2196047.2926685615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.322108296051161,
    "arrivals": 231176,
    "finished_requests": 45873,
    "scheduler_time": 39.15576226936238
}
#Debug simulation 
Total elapsed time: 3.6354135889559984. Arrivals time: 0.1721442504785955 Scheduler time: 3.22948262328282 Scheduler overhead time: 0.02927251346409321 Adapter cache time: 0.16011670185253024 Engine time: 0.030667705927044153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.6368321999907494,
    "estimated_duration": 3600.1453157995475,
    "input_throughput": 3125.7579938827575,
    "output_throughput": 2788.3841121481382,
    "total_throughput": 5914.142106030896,
    "itl": 182.51139969386642,
    "ttft": 2195988.1814795006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2677651186985883,
    "arrivals": 231176,
    "finished_requests": 45876,
    "scheduler_time": 39.15662096437531
}
#Debug simulation 
Total elapsed time: 3.6369253378361464. Arrivals time: 0.17313854908570647 Scheduler time: 3.229707872029394 Scheduler overhead time: 0.02942242380231619 Adapter cache time: 0.16029060818254948 Engine time: 0.030585345812141895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 1080, 33, 4320, 4320, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 1080, 1080, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 33, 33, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 1080, 33, 4320, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 4320, 33, 4320, 1080, 1080, 4320, 4320, 33, 1080, 4320, 33, 1080, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 4320, 4320, 33, 33, 4320, 33, 33, 33, 1080, 33, 1080, 4320, 4320, 1080, 1080, 33, 4320, 1080, 4320, 33, 1080, 1080, 33, 33, 1080, 33, 4320, 4320, 33, 4320, 4320, 33, 1080, 4320, 33, 33, 1080, 1080, 33, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 4320, 1080, 1080, 1080, 4320, 33, 1080, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 1080, 33, 4320, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 33, 4320, 4320, 1080, 33, 4320, 1080, 1080, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 1080, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 4320, 33, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 1080, 1080, 1080, 33, 1080, 33, 33, 4320, 33, 1080, 33, 33, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 695424 . Total input tokens: 154965070 . Total output tokens: 139036309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.621065493207425,
    "estimated_duration": 3600.2032909843633,
    "input_throughput": 3126.031807199101,
    "output_throughput": 2788.49531223419,
    "total_throughput": 5914.527119433291,
    "itl": 182.49939805676897,
    "ttft": 2195900.209748616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.210970369435375,
    "arrivals": 231176,
    "finished_requests": 45879,
    "scheduler_time": 39.155991590110524
}
#Debug simulation 
Total elapsed time: 3.62115584500134. Arrivals time: 0.17348605953156948 Scheduler time: 3.2138480986468494 Scheduler overhead time: 0.02935297042131424 Adapter cache time: 0.15984442131593823 Engine time: 0.0308690145611763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5367796579375863,
    "estimated_duration": 3600.247778810905,
    "input_throughput": 3183.03925286635,
    "output_throughput": 2795.3267714601325,
    "total_throughput": 5978.366024326483,
    "itl": 304.0069494021922,
    "ttft": 2173987.9895756207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.664962814019688,
    "arrivals": 218283,
    "finished_requests": 46327,
    "scheduler_time": 40.295311747648555
}
#Debug simulation 
Total elapsed time: 3.5368772479705513. Arrivals time: 0.19764573825523257 Scheduler time: 3.1696434691548347 Scheduler overhead time: 0.018766924738883972 Adapter cache time: 0.12253828532993793 Engine time: 0.019497087690979242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7150364089757204,
    "estimated_duration": 3600.143153412104,
    "input_throughput": 3196.3073438048896,
    "output_throughput": 2825.3604277817612,
    "total_throughput": 6021.667771586651,
    "itl": 179.29273772853605,
    "ttft": 2179619.221960514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.014850370338939,
    "arrivals": 218283,
    "finished_requests": 46529,
    "scheduler_time": 39.66144534442204
}
#Debug simulation 
Total elapsed time: 3.715127113740891. Arrivals time: 0.16955178743228316 Scheduler time: 3.285108986310661 Scheduler overhead time: 0.030177328269928694 Adapter cache time: 0.1848427732475102 Engine time: 0.03127615246921778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7199181630276144,
    "estimated_duration": 3600.061652019119,
    "input_throughput": 3186.6032054106267,
    "output_throughput": 2815.2162322875065,
    "total_throughput": 6001.819437698133,
    "itl": 179.49783066166057,
    "ttft": 2181958.0623005345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1835,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.733533863483302,
    "arrivals": 218283,
    "finished_requests": 46374,
    "scheduler_time": 39.50572798749078
}
#Debug simulation 
Total elapsed time: 3.7200384410098195. Arrivals time: 0.1728968103416264 Scheduler time: 3.2874830937944353 Scheduler overhead time: 0.030033460818231106 Adapter cache time: 0.1842578793875873 Engine time: 0.03118078550323844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 4320, 540, 270, 4320, 4320, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 270, 4320, 270, 4320, 540, 540, 540, 270, 270, 540, 270, 4320, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 540, 270, 270, 270, 540, 270, 540, 270, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 4320, 4320, 540, 270, 270, 4320, 540, 540, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 270, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 270, 270, 540, 540, 4320, 270, 270, 4320, 270, 4320, 540, 270, 4320, 540, 540, 270, 4320, 4320, 4320, 270, 540, 4320, 270, 4320, 540, 540, 4320, 4320, 270, 540, 4320, 270, 540, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 4320, 270, 4320, 540, 540, 540, 540, 540, 270, 270, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 270, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 270, 270, 270, 270, 270, 540, 270, 270, 540, 4320, 4320, 270, 270, 4320, 270, 270, 270, 540, 270, 540, 4320, 4320, 540, 540, 270, 4320, 540, 4320, 270, 540, 540, 270, 270, 540, 270, 4320, 4320, 270, 4320, 4320, 270, 540, 4320, 270, 270, 540, 540, 270, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 4320, 540, 540, 540, 4320, 270, 540, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 270, 270, 540, 270, 4320, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 270, 4320, 4320, 540, 270, 4320, 540, 540, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 270, 4320, 270, 540, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 4320, 270, 270, 270, 540, 270, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 540, 540, 540, 540, 270, 540, 4320, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 540, 540, 540, 270, 540, 270, 270, 4320, 270, 540, 270, 270, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 656640 . Total input tokens: 146385497 . Total output tokens: 131206172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7044878848828375,
    "estimated_duration": 3600.0954046474008,
    "input_throughput": 3191.4854215162986,
    "output_throughput": 2819.7138850530628,
    "total_throughput": 6011.199306569361,
    "itl": 178.61275720016755,
    "ttft": 2181127.126172768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.510662693504551,
    "arrivals": 218283,
    "finished_requests": 46450,
    "scheduler_time": 39.56477443383285
}
#Debug simulation 
Total elapsed time: 3.7045762431807816. Arrivals time: 0.17528567975386977 Scheduler time: 3.2706592180766165 Scheduler overhead time: 0.030147785786539316 Adapter cache time: 0.1828882321715355 Engine time: 0.03144631581380963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.652857984881848,
    "estimated_duration": 3600.2401250295857,
    "input_throughput": 3314.126998654555,
    "output_throughput": 2935.8388976660663,
    "total_throughput": 6249.965896320621,
    "itl": 291.0600154861783,
    "ttft": 2133243.0778007964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4246857854608344,
    "arrivals": 212473,
    "finished_requests": 48278,
    "scheduler_time": 42.28501818681977
}
#Debug simulation 
Total elapsed time: 3.652951166033745. Arrivals time: 0.1821539681404829 Scheduler time: 3.3173765880055726 Scheduler overhead time: 0.019554731901735067 Adapter cache time: 0.10407084599137306 Engine time: 0.02063254453241825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7707228511571884,
    "estimated_duration": 3600.097279793488,
    "input_throughput": 3280.1113642899622,
    "output_throughput": 2921.9213211381366,
    "total_throughput": 6202.032685428099,
    "itl": 172.55611165032622,
    "ttft": 2149023.8859604984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5552375981258253,
    "arrivals": 212473,
    "finished_requests": 47777,
    "scheduler_time": 40.989185551288124
}
#Debug simulation 
Total elapsed time: 3.7708119130693376. Arrivals time: 0.1763224401511252 Scheduler time: 3.353800195734948 Scheduler overhead time: 0.030974172987043858 Adapter cache time: 0.16287117032334208 Engine time: 0.032286436296999454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.785255596973002,
    "estimated_duration": 3600.0120273303532,
    "input_throughput": 3282.3034785143736,
    "output_throughput": 2924.1166196342847,
    "total_throughput": 6206.420098148658,
    "itl": 173.28900089328113,
    "ttft": 2148372.939742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.398615708097307,
    "arrivals": 212473,
    "finished_requests": 47807,
    "scheduler_time": 41.02258490597768
}
#Debug simulation 
Total elapsed time: 3.7853703503496945. Arrivals time: 0.17638295702636242 Scheduler time: 3.3669051588512957 Scheduler overhead time: 0.03134371852502227 Adapter cache time: 0.16403092630207539 Engine time: 0.03219666052609682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 540, 135, 4320, 4320, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 135, 4320, 135, 4320, 540, 540, 540, 135, 135, 540, 135, 4320, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 540, 135, 135, 135, 540, 135, 540, 135, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 4320, 4320, 540, 135, 135, 4320, 540, 540, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 135, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 135, 135, 540, 540, 4320, 135, 135, 4320, 135, 4320, 540, 135, 4320, 540, 540, 135, 4320, 4320, 4320, 135, 540, 4320, 135, 4320, 540, 540, 4320, 4320, 135, 540, 4320, 135, 540, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 4320, 135, 4320, 540, 540, 540, 540, 540, 135, 135, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 135, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 135, 135, 135, 135, 135, 540, 135, 135, 540, 4320, 4320, 135, 135, 4320, 135, 135, 135, 540, 135, 540, 4320, 4320, 540, 540, 135, 4320, 540, 4320, 135, 540, 540, 135, 135, 540, 135, 4320, 4320, 135, 4320, 4320, 135, 540, 4320, 135, 135, 540, 540, 135, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 4320, 540, 540, 540, 4320, 135, 540, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 540, 135, 4320, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 135, 4320, 4320, 540, 135, 4320, 540, 540, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 540, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 4320, 135, 135, 135, 540, 135, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 540, 540, 540, 540, 135, 540, 4320, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 540, 540, 540, 135, 540, 135, 135, 4320, 135, 540, 135, 135, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 639360 . Total input tokens: 142592364 . Total output tokens: 127777710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7851303089410067,
    "estimated_duration": 3600.0456209030335,
    "input_throughput": 3282.2384059222086,
    "output_throughput": 2924.162388075344,
    "total_throughput": 6206.400793997553,
    "itl": 173.2240057930495,
    "ttft": 2148348.38526916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2561647711483905,
    "arrivals": 212473,
    "finished_requests": 47806,
    "scheduler_time": 41.023362786422105
}
#Debug simulation 
Total elapsed time: 3.7852207948453724. Arrivals time: 0.17709801997989416 Scheduler time: 3.366960808634758 Scheduler overhead time: 0.03094905149191618 Adapter cache time: 0.1633633174933493 Engine time: 0.032310509122908115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7708778800442815,
    "estimated_duration": 3600.122284269839,
    "input_throughput": 3474.6886389546853,
    "output_throughput": 3050.6935967113955,
    "total_throughput": 6525.382235666081,
    "itl": 278.9322501877686,
    "ttft": 2094772.5078057756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 641,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9617726438609273,
    "arrivals": 209565,
    "finished_requests": 50494,
    "scheduler_time": 43.84833471890884
}
#Debug simulation 
Total elapsed time: 3.7709725429303944. Arrivals time: 0.1900654500350356 Scheduler time: 3.435198366176337 Scheduler overhead time: 0.02035071048885584 Adapter cache time: 0.09416612237691879 Engine time: 0.02166955964639783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8610227652825415,
    "estimated_duration": 3600.110198777495,
    "input_throughput": 3391.778397268635,
    "output_throughput": 2998.0221171188305,
    "total_throughput": 6389.800514387466,
    "itl": 169.12112265134402,
    "ttft": 2119512.094593267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.043919996737973,
    "arrivals": 209565,
    "finished_requests": 49323,
    "scheduler_time": 42.01979332417789
}
#Debug simulation 
Total elapsed time: 3.8611161201260984. Arrivals time: 0.18635581387206912 Scheduler time: 3.4436774346977472 Scheduler overhead time: 0.031635841354727745 Adapter cache time: 0.15158703876659274 Engine time: 0.03300455957651138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.065459736157209,
    "estimated_duration": 3600.0452923534326,
    "input_throughput": 3392.015379900157,
    "output_throughput": 2998.272000334687,
    "total_throughput": 6390.287380234844,
    "itl": 169.21135409501676,
    "ttft": 2119402.523418226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.956072003273278,
    "arrivals": 209565,
    "finished_requests": 49325,
    "scheduler_time": 42.02410141623159
}
#Debug simulation 
Total elapsed time: 4.0655283741652966. Arrivals time: 0.4054896836169064 Scheduler time: 3.4284291355870664 Scheduler overhead time: 0.03151799598708749 Adapter cache time: 0.152234080247581 Engine time: 0.033076995983719826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 540, 66, 4320, 4320, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 66, 4320, 66, 4320, 540, 540, 540, 66, 66, 540, 66, 4320, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 540, 66, 66, 66, 540, 66, 540, 66, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 4320, 4320, 540, 66, 66, 4320, 540, 540, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 66, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 66, 66, 540, 540, 4320, 66, 66, 4320, 66, 4320, 540, 66, 4320, 540, 540, 66, 4320, 4320, 4320, 66, 540, 4320, 66, 4320, 540, 540, 4320, 4320, 66, 540, 4320, 66, 540, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 4320, 66, 4320, 540, 540, 540, 540, 540, 66, 66, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 66, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 66, 66, 66, 66, 66, 540, 66, 66, 540, 4320, 4320, 66, 66, 4320, 66, 66, 66, 540, 66, 540, 4320, 4320, 540, 540, 66, 4320, 540, 4320, 66, 540, 540, 66, 66, 540, 66, 4320, 4320, 66, 4320, 4320, 66, 540, 4320, 66, 66, 540, 540, 66, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 4320, 540, 540, 540, 4320, 66, 540, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 540, 66, 4320, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 66, 4320, 4320, 540, 66, 4320, 540, 540, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 540, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 4320, 66, 66, 66, 540, 66, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 540, 540, 540, 540, 66, 540, 4320, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 540, 540, 540, 66, 540, 66, 66, 4320, 66, 540, 66, 66, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 630528 . Total input tokens: 140630688 . Total output tokens: 125979895
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.892562183085829,
    "estimated_duration": 3600.0030868480294,
    "input_throughput": 3392.41820225571,
    "output_throughput": 2998.470762271232,
    "total_throughput": 6390.888964526943,
    "itl": 169.2037333463555,
    "ttft": 2119264.6401467677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8747615349036344,
    "arrivals": 209565,
    "finished_requests": 49328,
    "scheduler_time": 42.02472578729009
}
#Debug simulation 
Total elapsed time: 3.8926544040441513. Arrivals time: 0.18471939116716385 Scheduler time: 3.475532868411392 Scheduler overhead time: 0.031851623207330704 Adapter cache time: 0.15229456452652812 Engine time: 0.03324846178293228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.80537221301347,
    "estimated_duration": 3600.1771362330746,
    "input_throughput": 3511.3019503331475,
    "output_throughput": 3101.5282241593327,
    "total_throughput": 6612.83017449248,
    "itl": 275.849923528659,
    "ttft": 2085835.1050686652,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 462,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4139453376969453,
    "arrivals": 208142,
    "finished_requests": 51093,
    "scheduler_time": 44.59310669678426
}
#Debug simulation 
Total elapsed time: 3.8054931801743805. Arrivals time: 0.18129780096933246 Scheduler time: 3.4854191122576594 Scheduler overhead time: 0.020412294659763575 Adapter cache time: 0.08736857073381543 Engine time: 0.02143119042739272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9024816351011395,
    "estimated_duration": 3600.0624440974007,
    "input_throughput": 3423.3536754915694,
    "output_throughput": 3035.3456834940266,
    "total_throughput": 6458.6993589855965,
    "itl": 166.97235988552254,
    "ttft": 2114739.622353714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4732641381910119,
    "arrivals": 208142,
    "finished_requests": 49789,
    "scheduler_time": 42.546268321252114
}
#Debug simulation 
Total elapsed time: 3.902570472098887. Arrivals time: 0.18046737276017666 Scheduler time: 3.4915287224575877 Scheduler overhead time: 0.03214459400624037 Adapter cache time: 0.14986048312857747 Engine time: 0.033481255173683167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.934527999255806,
    "estimated_duration": 3600.121447763228,
    "input_throughput": 3419.3438134283756,
    "output_throughput": 3032.615471009532,
    "total_throughput": 6451.959284437908,
    "itl": 167.21986712948618,
    "ttft": 2115377.2659174544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4119748404249501,
    "arrivals": 208142,
    "finished_requests": 49742,
    "scheduler_time": 42.490294136101646
}
#Debug simulation 
Total elapsed time: 3.9346174700185657. Arrivals time: 0.1813904196023941 Scheduler time: 3.5252588046714664 Scheduler overhead time: 0.03222327586263418 Adapter cache time: 0.14713618019595742 Engine time: 0.033441856037825346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 540, 33, 4320, 4320, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 33, 4320, 33, 4320, 540, 540, 540, 33, 33, 540, 33, 4320, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 540, 33, 33, 33, 540, 33, 540, 33, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 4320, 4320, 540, 33, 33, 4320, 540, 540, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 4320, 4320, 33, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 33, 33, 540, 540, 4320, 33, 33, 4320, 33, 4320, 540, 33, 4320, 540, 540, 33, 4320, 4320, 4320, 33, 540, 4320, 33, 4320, 540, 540, 4320, 4320, 33, 540, 4320, 33, 540, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 4320, 33, 4320, 540, 540, 540, 540, 540, 33, 33, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 33, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 33, 33, 33, 33, 33, 540, 33, 33, 540, 4320, 4320, 33, 33, 4320, 33, 33, 33, 540, 33, 540, 4320, 4320, 540, 540, 33, 4320, 540, 4320, 33, 540, 540, 33, 33, 540, 33, 4320, 4320, 33, 4320, 4320, 33, 540, 4320, 33, 33, 540, 540, 33, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 4320, 540, 540, 540, 4320, 33, 540, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 540, 33, 4320, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 33, 4320, 4320, 540, 33, 4320, 540, 540, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 540, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 4320, 33, 33, 33, 540, 33, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 540, 540, 540, 540, 33, 540, 4320, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 540, 540, 540, 33, 540, 33, 33, 4320, 33, 540, 33, 33, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 626304 . Total input tokens: 139684315 . Total output tokens: 125137764
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.91939365491271,
    "estimated_duration": 3600.0938725195356,
    "input_throughput": 3411.9657528272814,
    "output_throughput": 3026.1424801058106,
    "total_throughput": 6438.108232933092,
    "itl": 167.23204675170615,
    "ttft": 2116868.4512722064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3515027332957723,
    "arrivals": 208142,
    "finished_requests": 49632,
    "scheduler_time": 42.39483872215978
}
#Debug simulation 
Total elapsed time: 3.919492485933006. Arrivals time: 0.19276145193725824 Scheduler time: 3.4990011430345476 Scheduler overhead time: 0.03218322666361928 Adapter cache time: 0.14686049427837133 Engine time: 0.033551770728081465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.9636126994155347,
    "estimated_duration": 3600.021374342817,
    "input_throughput": 3636.787573904345,
    "output_throughput": 3190.940221041613,
    "total_throughput": 6827.727794945958,
    "itl": 267.049766078077,
    "ttft": 2050282.8926269964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1257,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.847033094123569,
    "arrivals": 200966,
    "finished_requests": 52594,
    "scheduler_time": 45.84090304210082
}
#Debug simulation 
Total elapsed time: 3.963713332079351. Arrivals time: 0.1900245943106711 Scheduler time: 3.6227931352332234 Scheduler overhead time: 0.021423697005957365 Adapter cache time: 0.09715145640075207 Engine time: 0.022325297817587852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.9833525139838457,
    "estimated_duration": 3600.1765795488277,
    "input_throughput": 3545.393598888303,
    "output_throughput": 3124.966443009831,
    "total_throughput": 6670.360041898134,
    "itl": 161.66340840601518,
    "ttft": 2080155.8615170002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9819435010780615,
    "arrivals": 200966,
    "finished_requests": 51252,
    "scheduler_time": 43.7817898245522
}
#Debug simulation 
Total elapsed time: 3.9834427358582616. Arrivals time: 0.1841050712391734 Scheduler time: 3.577415809966624 Scheduler overhead time: 0.03303150832653046 Adapter cache time: 0.13898511044681072 Engine time: 0.03438553446903825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.024906147271395,
    "estimated_duration": 3600.126246434872,
    "input_throughput": 3545.6584370175146,
    "output_throughput": 3125.337065927126,
    "total_throughput": 6670.995502944641,
    "itl": 161.68301691266058,
    "ttft": 2080046.2124245774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8235384005889768,
    "arrivals": 200966,
    "finished_requests": 51255,
    "scheduler_time": 43.78440910457934
}
#Debug simulation 
Total elapsed time: 4.0249967579729855. Arrivals time: 0.18442306201905012 Scheduler time: 3.617275091819465 Scheduler overhead time: 0.03317584889009595 Adapter cache time: 0.14015137078240514 Engine time: 0.034372054506093264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 4320, 270, 135, 4320, 4320, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 135, 4320, 135, 4320, 270, 270, 270, 135, 135, 270, 135, 4320, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 270, 135, 135, 135, 270, 135, 270, 135, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 4320, 4320, 270, 135, 135, 4320, 270, 270, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 135, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 135, 135, 270, 270, 4320, 135, 135, 4320, 135, 4320, 270, 135, 4320, 270, 270, 135, 4320, 4320, 4320, 135, 270, 4320, 135, 4320, 270, 270, 4320, 4320, 135, 270, 4320, 135, 270, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 4320, 135, 4320, 270, 270, 270, 270, 270, 135, 135, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 135, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 135, 135, 135, 135, 135, 270, 135, 135, 270, 4320, 4320, 135, 135, 4320, 135, 135, 135, 270, 135, 270, 4320, 4320, 270, 270, 135, 4320, 270, 4320, 135, 270, 270, 135, 135, 270, 135, 4320, 4320, 135, 4320, 4320, 135, 270, 4320, 135, 135, 270, 270, 135, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 4320, 270, 270, 270, 4320, 135, 270, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 135, 135, 270, 135, 4320, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 135, 4320, 4320, 270, 135, 4320, 270, 270, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 135, 4320, 135, 270, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 4320, 135, 135, 135, 270, 135, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 270, 270, 270, 270, 135, 270, 4320, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 270, 270, 270, 135, 270, 135, 135, 4320, 135, 270, 135, 135, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 604800 . Total input tokens: 134855028 . Total output tokens: 120795858
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.004829515237361,
    "estimated_duration": 3600.0763791014538,
    "input_throughput": 3545.8703248918646,
    "output_throughput": 3125.564520052895,
    "total_throughput": 6671.43484494476,
    "itl": 161.66715128447012,
    "ttft": 2080062.5364103925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6538414603703657,
    "arrivals": 200966,
    "finished_requests": 51257,
    "scheduler_time": 43.786453463158814
}
#Debug simulation 
Total elapsed time: 4.0049362210556865. Arrivals time: 0.19394991220906377 Scheduler time: 3.5879180151969194 Scheduler overhead time: 0.03304353868588805 Adapter cache time: 0.13999050902202725 Engine time: 0.03448720509186387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.001031141728163,
    "estimated_duration": 3600.0068637368504,
    "input_throughput": 3740.3295353784265,
    "output_throughput": 3295.670938717203,
    "total_throughput": 7036.000474095629,
    "itl": 259.10250751641,
    "ttft": 2013567.4803135921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3688175138039975,
    "arrivals": 198105,
    "finished_requests": 54434,
    "scheduler_time": 47.319523974881335
}
#Debug simulation 
Total elapsed time: 4.0011292127892375. Arrivals time: 0.18978119315579534 Scheduler time: 3.6732549625448883 Scheduler overhead time: 0.021724712569266558 Adapter cache time: 0.08365451358258724 Engine time: 0.022562773898243904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.082025741692632,
    "estimated_duration": 3600.1475076433935,
    "input_throughput": 3614.403291080072,
    "output_throughput": 3194.816872247806,
    "total_throughput": 6809.220163327877,
    "itl": 158.6357512631293,
    "ttft": 2052325.5789425294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.446686551210008,
    "arrivals": 198105,
    "finished_requests": 52548,
    "scheduler_time": 44.75319456368549
}
#Debug simulation 
Total elapsed time: 4.082113825716078. Arrivals time: 0.18567585526034236 Scheduler time: 3.6834977525286376 Scheduler overhead time: 0.03382122935727239 Adapter cache time: 0.12798140803351998 Engine time: 0.03524326719343662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.036171744111925,
    "estimated_duration": 3600.1609046394333,
    "input_throughput": 3613.789867901199,
    "output_throughput": 3193.7291983763575,
    "total_throughput": 6807.519066277557,
    "itl": 158.27143166356515,
    "ttft": 2052564.5384143086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.346580698192098,
    "arrivals": 198105,
    "finished_requests": 52532,
    "scheduler_time": 44.728215193162434
}
#Debug simulation 
Total elapsed time: 4.036264406051487. Arrivals time: 0.18440695479512215 Scheduler time: 3.6421302394010127 Scheduler overhead time: 0.03349389415234327 Adapter cache time: 0.12557873642072082 Engine time: 0.03485910315066576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 270, 66, 4320, 4320, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 66, 4320, 66, 4320, 270, 270, 270, 66, 66, 270, 66, 4320, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 270, 66, 66, 66, 270, 66, 270, 66, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 4320, 4320, 270, 66, 66, 4320, 270, 270, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 66, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 66, 66, 270, 270, 4320, 66, 66, 4320, 66, 4320, 270, 66, 4320, 270, 270, 66, 4320, 4320, 4320, 66, 270, 4320, 66, 4320, 270, 270, 4320, 4320, 66, 270, 4320, 66, 270, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 4320, 66, 4320, 270, 270, 270, 270, 270, 66, 66, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 66, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 66, 66, 66, 66, 66, 270, 66, 66, 270, 4320, 4320, 66, 66, 4320, 66, 66, 66, 270, 66, 270, 4320, 4320, 270, 270, 66, 4320, 270, 4320, 66, 270, 270, 66, 66, 270, 66, 4320, 4320, 66, 4320, 4320, 66, 270, 4320, 66, 66, 270, 270, 66, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 4320, 270, 270, 270, 4320, 66, 270, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 270, 66, 4320, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 66, 4320, 4320, 270, 66, 4320, 270, 270, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 270, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 4320, 66, 66, 66, 270, 66, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 270, 270, 270, 270, 66, 270, 4320, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 270, 270, 270, 66, 270, 66, 66, 4320, 66, 270, 66, 66, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 595968 . Total input tokens: 132907362 . Total output tokens: 119020776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.070697207935154,
    "estimated_duration": 3600.110907020561,
    "input_throughput": 3613.64645034412,
    "output_throughput": 3193.862993936462,
    "total_throughput": 6807.509444280581,
    "itl": 158.27415752221273,
    "ttft": 2052624.678885078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2485178217663933,
    "arrivals": 198105,
    "finished_requests": 52532,
    "scheduler_time": 44.72889958618041
}
#Debug simulation 
Total elapsed time: 4.070798920001835. Arrivals time: 0.19504811894148588 Scheduler time: 3.6642653541639447 Scheduler overhead time: 0.03380761528387666 Adapter cache time: 0.1268608747050166 Engine time: 0.03496023965999484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.320322670973837,
    "estimated_duration": 3600.267396496241,
    "input_throughput": 3855.573342554778,
    "output_throughput": 3377.54801541522,
    "total_throughput": 7233.121357969998,
    "itl": 252.0282718954478,
    "ttft": 1988987.033882598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.487397043551334,
    "arrivals": 196756,
    "finished_requests": 56148,
    "scheduler_time": 48.516258998696074
}
#Debug simulation 
Total elapsed time: 4.320385462138802. Arrivals time: 0.19916126085445285 Scheduler time: 3.9902940378524363 Scheduler overhead time: 0.022355535998940468 Adapter cache time: 0.07492851093411446 Engine time: 0.02321675233542919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.128583513665944,
    "estimated_duration": 3600.1596660401788,
    "input_throughput": 3695.211666718209,
    "output_throughput": 3251.889662126264,
    "total_throughput": 6947.101328844473,
    "itl": 156.6094120727693,
    "ttft": 2032139.4157655393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.566383238772401,
    "arrivals": 196756,
    "finished_requests": 53779,
    "scheduler_time": 45.559433346966316
}
#Debug simulation 
Total elapsed time: 4.1286739856004715. Arrivals time: 0.19148353720083833 Scheduler time: 3.735838552005589 Scheduler overhead time: 0.0341163189150393 Adapter cache time: 0.1156545514240861 Engine time: 0.035519120283424854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.127295997925103,
    "estimated_duration": 3600.095159059304,
    "input_throughput": 3694.6631720355845,
    "output_throughput": 3251.050731408514,
    "total_throughput": 6945.713903444098,
    "itl": 156.35156249220864,
    "ttft": 2032305.839948353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4989650112297326,
    "arrivals": 196756,
    "finished_requests": 53764,
    "scheduler_time": 45.54082250901551
}
#Debug simulation 
Total elapsed time: 4.1273886510171. Arrivals time: 0.19173583947122097 Scheduler time: 3.731399410869926 Scheduler overhead time: 0.03398919990286231 Adapter cache time: 0.11887729493901134 Engine time: 0.03535880008712411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 270, 33, 4320, 4320, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 33, 4320, 33, 4320, 270, 270, 270, 33, 33, 270, 33, 4320, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 270, 33, 33, 33, 270, 33, 270, 33, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 4320, 4320, 270, 33, 33, 4320, 270, 270, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 4320, 4320, 33, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 33, 33, 270, 270, 4320, 33, 33, 4320, 33, 4320, 270, 33, 4320, 270, 270, 33, 4320, 4320, 4320, 33, 270, 4320, 33, 4320, 270, 270, 4320, 4320, 33, 270, 4320, 33, 270, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 4320, 33, 4320, 270, 270, 270, 270, 270, 33, 33, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 33, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 33, 33, 33, 33, 33, 270, 33, 33, 270, 4320, 4320, 33, 33, 4320, 33, 33, 33, 270, 33, 270, 4320, 4320, 270, 270, 33, 4320, 270, 4320, 33, 270, 270, 33, 33, 270, 33, 4320, 4320, 33, 4320, 4320, 33, 270, 4320, 33, 33, 270, 270, 33, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 4320, 270, 270, 270, 4320, 33, 270, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 270, 33, 4320, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 33, 4320, 4320, 270, 33, 4320, 270, 270, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 270, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 4320, 33, 33, 33, 270, 33, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 270, 270, 270, 270, 33, 270, 4320, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 270, 270, 270, 33, 270, 33, 33, 4320, 33, 270, 33, 33, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 591744 . Total input tokens: 131952871 . Total output tokens: 118169411
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.15855587599799,
    "estimated_duration": 3600.0424308736233,
    "input_throughput": 3694.635898158645,
    "output_throughput": 3250.9036281441645,
    "total_throughput": 6945.5395263028095,
    "itl": 156.35268011360264,
    "ttft": 2032365.838379091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4352241415530302,
    "arrivals": 196756,
    "finished_requests": 53762,
    "scheduler_time": 45.540592190324396
}
#Debug simulation 
Total elapsed time: 4.158645691350102. Arrivals time: 0.19055679766461253 Scheduler time: 3.7659929213114083 Scheduler overhead time: 0.034319848753511906 Adapter cache time: 0.11583853140473366 Engine time: 0.03579004015773535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.29197106231004,
    "estimated_duration": 3600.170064150934,
    "input_throughput": 4013.893439061207,
    "output_throughput": 3544.6236629406612,
    "total_throughput": 7558.517102001869,
    "itl": 241.66273411169942,
    "ttft": 1949252.6241808138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 832,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5463258029521034,
    "arrivals": 192504,
    "finished_requests": 58468,
    "scheduler_time": 50.83244648089773
}
#Debug simulation 
Total elapsed time: 4.2920970669947565. Arrivals time: 0.20837685139849782 Scheduler time: 3.955682954750955 Scheduler overhead time: 0.023401040583848953 Adapter cache time: 0.06963218469172716 Engine time: 0.024084150325506926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.231232051271945,
    "estimated_duration": 3600.1270875630726,
    "input_throughput": 3807.0578250829262,
    "output_throughput": 3371.1148814513554,
    "total_throughput": 7178.172706534281,
    "itl": 150.7245481408841,
    "ttft": 2004604.2904740062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6161912904377114,
    "arrivals": 192504,
    "finished_requests": 55459,
    "scheduler_time": 47.1704766921141
}
#Debug simulation 
Total elapsed time: 4.231319491285831. Arrivals time: 0.19585347967222333 Scheduler time: 3.846183913294226 Scheduler overhead time: 0.03533581690862775 Adapter cache time: 0.10086060222238302 Engine time: 0.03643682412803173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.20877170516178,
    "estimated_duration": 3600.1084946190617,
    "input_throughput": 3807.4683083823033,
    "output_throughput": 3371.534224077418,
    "total_throughput": 7179.002532459722,
    "itl": 150.72576754123645,
    "ttft": 2004532.7859037016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 805,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5132252701907176,
    "arrivals": 192504,
    "finished_requests": 55463,
    "scheduler_time": 47.171181624785575
}
#Debug simulation 
Total elapsed time: 4.208866632077843. Arrivals time: 0.19250620529055595 Scheduler time: 3.829062181059271 Scheduler overhead time: 0.035062686540186405 Adapter cache time: 0.09941526362672448 Engine time: 0.036314351949840784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 4320, 135, 66, 4320, 4320, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 66, 4320, 66, 4320, 135, 135, 135, 66, 66, 135, 66, 4320, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 135, 66, 66, 66, 135, 66, 135, 66, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 4320, 4320, 135, 66, 66, 4320, 135, 135, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 66, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 66, 66, 135, 135, 4320, 66, 66, 4320, 66, 4320, 135, 66, 4320, 135, 135, 66, 4320, 4320, 4320, 66, 135, 4320, 66, 4320, 135, 135, 4320, 4320, 66, 135, 4320, 66, 135, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 4320, 66, 4320, 135, 135, 135, 135, 135, 66, 66, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 66, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 66, 66, 66, 66, 66, 135, 66, 66, 135, 4320, 4320, 66, 66, 4320, 66, 66, 66, 135, 66, 135, 4320, 4320, 135, 135, 66, 4320, 135, 4320, 66, 135, 135, 66, 66, 135, 66, 4320, 4320, 66, 4320, 4320, 66, 135, 4320, 66, 66, 135, 135, 66, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 4320, 135, 135, 135, 4320, 66, 135, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 66, 66, 135, 66, 4320, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 66, 4320, 4320, 135, 66, 4320, 135, 135, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 66, 4320, 66, 135, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 4320, 66, 66, 66, 135, 66, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 135, 135, 135, 135, 66, 135, 4320, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 135, 135, 135, 66, 135, 66, 66, 4320, 66, 135, 66, 66, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 578688 . Total input tokens: 129047464 . Total output tokens: 115563730
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.255316446069628,
    "estimated_duration": 3600.097668048185,
    "input_throughput": 3807.490591618176,
    "output_throughput": 3371.5754735567193,
    "total_throughput": 7179.066065174896,
    "itl": 150.7213690045812,
    "ttft": 2004446.994901397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.404000437101301,
    "arrivals": 192504,
    "finished_requests": 55464,
    "scheduler_time": 47.171659672584966
}
#Debug simulation 
Total elapsed time: 4.25540631916374. Arrivals time: 0.1919955089688301 Scheduler time: 3.872824707068503 Scheduler overhead time: 0.036276796367019415 Adapter cache time: 0.10054528340697289 Engine time: 0.03692101687192917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.309494595043361,
    "estimated_duration": 3600.1383078092313,
    "input_throughput": 4092.5436025722624,
    "output_throughput": 3616.538279031563,
    "total_throughput": 7709.081881603825,
    "itl": 236.47728662831966,
    "ttft": 1932781.613283764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6220585042843798,
    "arrivals": 191087,
    "finished_requests": 59677,
    "scheduler_time": 51.860822856136025
}
#Debug simulation 
Total elapsed time: 4.309611739125103. Arrivals time: 0.1991803776472807 Scheduler time: 3.98999343207106 Scheduler overhead time: 0.02374513214454055 Adapter cache time: 0.06105886306613684 Engine time: 0.024567618500441313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.275462142657489,
    "estimated_duration": 3600.100025793338,
    "input_throughput": 3836.984500717025,
    "output_throughput": 3408.6839010246003,
    "total_throughput": 7245.6684017416255,
    "itl": 148.26422111635526,
    "ttft": 1994529.2638002909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.658963860969532,
    "arrivals": 191087,
    "finished_requests": 55972,
    "scheduler_time": 47.6945699113353
}
#Debug simulation 
Total elapsed time: 4.275552697014064. Arrivals time: 0.2019098256714642 Scheduler time: 3.895115717779845 Scheduler overhead time: 0.035770771093666553 Adapter cache time: 0.08893342223018408 Engine time: 0.03702551452443004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.481523355003446,
    "estimated_duration": 3600.0233064694185,
    "input_throughput": 3844.350111603247,
    "output_throughput": 3414.0287308454976,
    "total_throughput": 7258.378842448745,
    "itl": 148.85021449145913,
    "ttft": 1994438.3112393343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5875895633082766,
    "arrivals": 191087,
    "finished_requests": 56070,
    "scheduler_time": 47.76531068269544
}
#Debug simulation 
Total elapsed time: 4.481596481055021. Arrivals time: 0.4244166826829314 Scheduler time: 3.878052869811654 Scheduler overhead time: 0.03540942678228021 Adapter cache time: 0.09042227920144796 Engine time: 0.03660047613084316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 135, 33, 4320, 4320, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 33, 4320, 33, 4320, 135, 135, 135, 33, 33, 135, 33, 4320, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 135, 33, 33, 33, 135, 33, 135, 33, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 4320, 4320, 135, 33, 33, 4320, 135, 135, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 4320, 4320, 33, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 33, 33, 135, 135, 4320, 33, 33, 4320, 33, 4320, 135, 33, 4320, 135, 135, 33, 4320, 4320, 4320, 33, 135, 4320, 33, 4320, 135, 135, 4320, 4320, 33, 135, 4320, 33, 135, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 4320, 33, 4320, 135, 135, 135, 135, 135, 33, 33, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 33, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 33, 33, 33, 33, 33, 135, 33, 33, 135, 4320, 4320, 33, 33, 4320, 33, 33, 33, 135, 33, 135, 4320, 4320, 135, 135, 33, 4320, 135, 4320, 33, 135, 135, 33, 33, 135, 33, 4320, 4320, 33, 4320, 4320, 33, 135, 4320, 33, 33, 135, 135, 33, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 4320, 135, 135, 135, 4320, 33, 135, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 135, 33, 4320, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 33, 4320, 4320, 135, 33, 4320, 135, 135, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 135, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 4320, 33, 33, 33, 135, 33, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 135, 135, 135, 135, 33, 135, 4320, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 135, 135, 135, 33, 135, 33, 33, 4320, 33, 135, 33, 33, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 574464 . Total input tokens: 128075419 . Total output tokens: 114736704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.263216434977949,
    "estimated_duration": 3600.0652144651685,
    "input_throughput": 3844.4528572397357,
    "output_throughput": 3414.2345395890393,
    "total_throughput": 7258.6873968287755,
    "itl": 148.84829296280589,
    "ttft": 1994335.6126319137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5189455498102882,
    "arrivals": 191087,
    "finished_requests": 56072,
    "scheduler_time": 47.766856046806936
}
#Debug simulation 
Total elapsed time: 4.263332951813936. Arrivals time: 0.20021819416433573 Scheduler time: 3.881833663210273 Scheduler overhead time: 0.03602377464994788 Adapter cache time: 0.0912872045300901 Engine time: 0.037260961253196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.511166080832481,
    "estimated_duration": 3600.0565587710566,
    "input_throughput": 4290.211208590686,
    "output_throughput": 3790.896830981677,
    "total_throughput": 8081.108039572363,
    "itl": 225.91703870064677,
    "ttft": 1879801.7438836037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6771472836751713,
    "arrivals": 188115,
    "finished_requests": 62523,
    "scheduler_time": 54.326419334152746
}
#Debug simulation 
Total elapsed time: 4.511260150931776. Arrivals time: 0.20574043411761522 Scheduler time: 4.197783072013408 Scheduler overhead time: 0.024651221465319395 Adapter cache time: 0.046013711020350456 Engine time: 0.02550667431205511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.4059442318975925,
    "estimated_duration": 3600.0412970765833,
    "input_throughput": 3959.1973602009466,
    "output_throughput": 3515.044955255358,
    "total_throughput": 7474.242315456305,
    "itl": 144.46093107214836,
    "ttft": 1954416.737777631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.68912413005019,
    "arrivals": 188115,
    "finished_requests": 57676,
    "scheduler_time": 49.21316932768994
}
#Debug simulation 
Total elapsed time: 4.406030626967549. Arrivals time: 0.19774072617292404 Scheduler time: 4.045527612790465 Scheduler overhead time: 0.036681768484413624 Adapter cache time: 0.07074592215940356 Engine time: 0.038011953700333834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.356145138852298,
    "estimated_duration": 3600.1157237275074,
    "input_throughput": 3960.245473786647,
    "output_throughput": 3516.013364952067,
    "total_throughput": 7476.258838738714,
    "itl": 144.6015595636747,
    "ttft": 1954063.384445259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.62088871187064,
    "arrivals": 188115,
    "finished_requests": 57694,
    "scheduler_time": 49.23275511013143
}
#Debug simulation 
Total elapsed time: 4.356233151629567. Arrivals time: 0.2042316454462707 Scheduler time: 3.989551142323762 Scheduler overhead time: 0.036580391228199005 Adapter cache time: 0.0710206888616085 Engine time: 0.03764255344867706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 4320, 66, 33, 4320, 4320, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 33, 4320, 33, 4320, 66, 66, 66, 33, 33, 66, 33, 4320, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 66, 33, 33, 33, 66, 33, 66, 33, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 4320, 4320, 66, 33, 33, 4320, 66, 66, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 4320, 4320, 33, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 33, 33, 66, 66, 4320, 33, 33, 4320, 33, 4320, 66, 33, 4320, 66, 66, 33, 4320, 4320, 4320, 33, 66, 4320, 33, 4320, 66, 66, 4320, 4320, 33, 66, 4320, 33, 66, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 4320, 33, 4320, 66, 66, 66, 66, 66, 33, 33, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 33, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 33, 33, 33, 33, 33, 66, 33, 33, 66, 4320, 4320, 33, 33, 4320, 33, 33, 33, 66, 33, 66, 4320, 4320, 66, 66, 33, 4320, 66, 4320, 33, 66, 66, 33, 33, 66, 33, 4320, 4320, 33, 4320, 4320, 33, 66, 4320, 33, 33, 66, 66, 33, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 4320, 66, 66, 66, 4320, 33, 66, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 33, 33, 66, 33, 4320, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 33, 4320, 4320, 66, 33, 4320, 66, 66, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 33, 4320, 33, 66, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 4320, 33, 33, 33, 66, 33, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 66, 66, 66, 66, 33, 66, 4320, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 66, 66, 66, 33, 66, 33, 33, 4320, 33, 66, 33, 33, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 565632 . Total input tokens: 126102881 . Total output tokens: 112978603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.40425036707893,
    "estimated_duration": 3600.010580589354,
    "input_throughput": 3960.192527452529,
    "output_throughput": 3516.04911059117,
    "total_throughput": 7476.241638043699,
    "itl": 144.60109037225348,
    "ttft": 1953979.225835406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.551836103054211,
    "arrivals": 188115,
    "finished_requests": 57693,
    "scheduler_time": 49.23270048190931
}
#Debug simulation 
Total elapsed time: 4.404342240188271. Arrivals time: 0.20272450475022197 Scheduler time: 4.0382727342657745 Scheduler overhead time: 0.036650354973971844 Adapter cache time: 0.07128289761021733 Engine time: 0.03811889607459307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.1237144167535007,
    "estimated_duration": 3600.3555357805208,
    "input_throughput": 2598.271728175866,
    "output_throughput": 2268.1507197954165,
    "total_throughput": 4866.422447971282,
    "itl": 370.03266109153935,
    "ttft": 2006622.0569344768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3320,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.160819309856432,
    "arrivals": 80883,
    "finished_requests": 37707,
    "scheduler_time": 32.552143779029386
}
#Debug simulation 
Total elapsed time: 3.1238051396794617. Arrivals time: 0.1481883260421455 Scheduler time: 2.8028595969080925 Scheduler overhead time: 0.016664776019752026 Adapter cache time: 0.13159903651103377 Engine time: 0.01683680061250925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.1929516079835594,
    "estimated_duration": 3600.016468757551,
    "input_throughput": 2603.803921829028,
    "output_throughput": 2288.247309836066,
    "total_throughput": 4892.051231665094,
    "itl": 218.66070496142115,
    "ttft": 2014647.6698053933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.70571461323932,
    "arrivals": 80883,
    "finished_requests": 37776,
    "scheduler_time": 31.81081927040851
}
#Debug simulation 
Total elapsed time: 3.1930412189103663. Arrivals time: 0.1474863919429481 Scheduler time: 2.7374738384969532 Scheduler overhead time: 0.02527061617001891 Adapter cache time: 0.24449785659089684 Engine time: 0.026428373530507088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.192740507889539,
    "estimated_duration": 3600.090363293877,
    "input_throughput": 2601.536087952765,
    "output_throughput": 2286.1984476605035,
    "total_throughput": 4887.734535613268,
    "itl": 218.49200750649504,
    "ttft": 2015776.0283039887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.129262403404022,
    "arrivals": 80883,
    "finished_requests": 37743,
    "scheduler_time": 31.78424116637815
}
#Debug simulation 
Total elapsed time: 3.192849279846996. Arrivals time: 0.14854343235492706 Scheduler time: 2.7362701180391014 Scheduler overhead time: 0.02536860154941678 Adapter cache time: 0.24428240954875946 Engine time: 0.026364262215793133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 1080, 540, 270, 1080, 1080, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 270, 1080, 270, 1080, 540, 540, 540, 270, 270, 540, 270, 1080, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 540, 270, 270, 270, 540, 270, 540, 270, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 1080, 1080, 540, 270, 270, 1080, 540, 540, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 270, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 270, 270, 540, 540, 1080, 270, 270, 1080, 270, 1080, 540, 270, 1080, 540, 540, 270, 1080, 1080, 1080, 270, 540, 1080, 270, 1080, 540, 540, 1080, 1080, 270, 540, 1080, 270, 540, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 1080, 270, 1080, 540, 540, 540, 540, 540, 270, 270, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 270, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 270, 270, 270, 270, 270, 540, 270, 270, 540, 1080, 1080, 270, 270, 1080, 270, 270, 270, 540, 270, 540, 1080, 1080, 540, 540, 270, 1080, 540, 1080, 270, 540, 540, 270, 270, 540, 270, 1080, 1080, 270, 1080, 1080, 270, 540, 1080, 270, 270, 540, 540, 270, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 1080, 540, 540, 540, 1080, 270, 540, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 270, 270, 540, 270, 1080, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 270, 1080, 1080, 540, 270, 1080, 540, 540, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 270, 1080, 270, 540, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 1080, 270, 270, 270, 540, 270, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 540, 540, 540, 540, 270, 540, 1080, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 540, 540, 540, 270, 540, 270, 270, 1080, 270, 540, 270, 270, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 241920 . Total input tokens: 53925975 . Total output tokens: 48373036
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.182639366015792,
    "estimated_duration": 3600.097770145072,
    "input_throughput": 2601.7757288915395,
    "output_throughput": 2286.275964018701,
    "total_throughput": 4888.0516929102405,
    "itl": 218.4683289210623,
    "ttft": 2015632.667259414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.60737524481094,
    "arrivals": 80883,
    "finished_requests": 37745,
    "scheduler_time": 31.787532947445417
}
#Debug simulation 
Total elapsed time: 3.1827236963436007. Arrivals time: 0.15117664076387882 Scheduler time: 2.7250981680117548 Scheduler overhead time: 0.025234988890588284 Adapter cache time: 0.24276857497170568 Engine time: 0.02644882071763277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.0848960955627263,
    "estimated_duration": 3600.03096507915,
    "input_throughput": 2731.0262315434943,
    "output_throughput": 2375.185125612386,
    "total_throughput": 5106.21135715588,
    "itl": 351.6379210582075,
    "ttft": 1907322.8893373602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2283,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.987093519398684,
    "arrivals": 75147,
    "finished_requests": 39420,
    "scheduler_time": 34.02056228080811
}
#Debug simulation 
Total elapsed time: 3.0849847039207816. Arrivals time: 0.1468229377642274 Scheduler time: 2.775803857948631 Scheduler overhead time: 0.01695972913876176 Adapter cache time: 0.12014310341328382 Engine time: 0.017427673563361168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.3043535090982914,
    "estimated_duration": 3600.22672649266,
    "input_throughput": 2734.6052757047305,
    "output_throughput": 2395.77828155362,
    "total_throughput": 5130.38355725835,
    "itl": 208.43884164498658,
    "ttft": 1914538.173786329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.473294140121124,
    "arrivals": 75147,
    "finished_requests": 39459,
    "scheduler_time": 33.18097605929258
}
#Debug simulation 
Total elapsed time: 3.304445161949843. Arrivals time: 0.15134216099977493 Scheduler time: 2.8619197625666857 Scheduler overhead time: 0.0265029389411211 Adapter cache time: 0.22395506547763944 Engine time: 0.02818617830052972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.2938787671737373,
    "estimated_duration": 3600.1971880427627,
    "input_throughput": 2736.6678782826084,
    "output_throughput": 2397.9247660857454,
    "total_throughput": 5134.592644368354,
    "itl": 209.0494961044075,
    "ttft": 1912435.1916714304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.157969491230075,
    "arrivals": 75147,
    "finished_requests": 39494,
    "scheduler_time": 33.22360304227324
}
#Debug simulation 
Total elapsed time: 3.293993087951094. Arrivals time: 0.1504330555908382 Scheduler time: 2.852608574088663 Scheduler overhead time: 0.026387842372059822 Adapter cache time: 0.22421491332352161 Engine time: 0.027832799591124058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 540, 135, 1080, 1080, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 135, 1080, 135, 1080, 540, 540, 540, 135, 135, 540, 135, 1080, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 540, 135, 135, 135, 540, 135, 540, 135, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 1080, 1080, 540, 135, 135, 1080, 540, 540, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 135, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 135, 135, 540, 540, 1080, 135, 135, 1080, 135, 1080, 540, 135, 1080, 540, 540, 135, 1080, 1080, 1080, 135, 540, 1080, 135, 1080, 540, 540, 1080, 1080, 135, 540, 1080, 135, 540, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 1080, 135, 1080, 540, 540, 540, 540, 540, 135, 135, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 135, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 135, 135, 135, 135, 135, 540, 135, 135, 540, 1080, 1080, 135, 135, 1080, 135, 135, 135, 540, 135, 540, 1080, 1080, 540, 540, 135, 1080, 540, 1080, 135, 540, 540, 135, 135, 540, 135, 1080, 1080, 135, 1080, 1080, 135, 540, 1080, 135, 135, 540, 540, 135, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 1080, 540, 540, 540, 1080, 135, 540, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 540, 135, 1080, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 135, 1080, 1080, 540, 135, 1080, 540, 540, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 540, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 1080, 135, 135, 135, 540, 135, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 540, 540, 540, 540, 135, 540, 1080, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 540, 540, 540, 135, 540, 135, 135, 1080, 135, 540, 135, 135, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 224640 . Total input tokens: 50059495 . Total output tokens: 44930825
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.284947069827467,
    "estimated_duration": 3600.020456320301,
    "input_throughput": 2733.418078978961,
    "output_throughput": 2394.309172567963,
    "total_throughput": 5127.727251546924,
    "itl": 208.3510733634974,
    "ttft": 1915093.6531015157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8830957788646,
    "arrivals": 75147,
    "finished_requests": 39437,
    "scheduler_time": 33.14557508638059
}
#Debug simulation 
Total elapsed time: 3.2850377722643316. Arrivals time: 0.16347608109936118 Scheduler time: 2.8335156831890345 Scheduler overhead time: 0.026395180728286505 Adapter cache time: 0.2214898057281971 Engine time: 0.027728023007512093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.190599831286818,
    "estimated_duration": 3600.143501472003,
    "input_throughput": 2878.3858187216724,
    "output_throughput": 2519.3756849668553,
    "total_throughput": 5397.761503688527,
    "itl": 333.0932559220553,
    "ttft": 1809564.316156993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5960730991210745,
    "arrivals": 72240,
    "finished_requests": 41915,
    "scheduler_time": 35.95201301153758
}
#Debug simulation 
Total elapsed time: 3.1906873220577836. Arrivals time: 0.14783389773219824 Scheduler time: 2.9003718863241374 Scheduler overhead time: 0.01747259497642517 Adapter cache time: 0.09847082104533911 Engine time: 0.018312813248485327 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.3732931171543896,
    "estimated_duration": 3600.078913118625,
    "input_throughput": 2845.650400236778,
    "output_throughput": 2504.5064893284193,
    "total_throughput": 5350.156889565197,
    "itl": 201.39613472208222,
    "ttft": 1833856.1860612507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1140,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7069319186499343,
    "arrivals": 72240,
    "finished_requests": 41413,
    "scheduler_time": 34.60370539887861
}
#Debug simulation 
Total elapsed time: 3.3733843499794602. Arrivals time: 0.1536643779836595 Scheduler time: 2.9541163840331137 Scheduler overhead time: 0.02718477789312601 Adapter cache time: 0.19695591507479548 Engine time: 0.02860668208450079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.3778959568589926,
    "estimated_duration": 3600.077875055631,
    "input_throughput": 2839.895789710386,
    "output_throughput": 2500.211471081278,
    "total_throughput": 5340.107260791664,
    "itl": 201.7901678781942,
    "ttft": 1835386.7554965906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5644430894590458,
    "arrivals": 72240,
    "finished_requests": 41332,
    "scheduler_time": 34.53880372566916
}
#Debug simulation 
Total elapsed time: 3.3780036456882954. Arrivals time: 0.15499003836885095 Scheduler time: 2.955556293949485 Scheduler overhead time: 0.027250342071056366 Adapter cache time: 0.19864952331408858 Engine time: 0.028633676934987307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 540, 66, 1080, 1080, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 66, 1080, 66, 1080, 540, 540, 540, 66, 66, 540, 66, 1080, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 540, 66, 66, 66, 540, 66, 540, 66, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 1080, 1080, 540, 66, 66, 1080, 540, 540, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 66, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 66, 66, 540, 540, 1080, 66, 66, 1080, 66, 1080, 540, 66, 1080, 540, 540, 66, 1080, 1080, 1080, 66, 540, 1080, 66, 1080, 540, 540, 1080, 1080, 66, 540, 1080, 66, 540, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 1080, 66, 1080, 540, 540, 540, 540, 540, 66, 66, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 66, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 66, 66, 66, 66, 66, 540, 66, 66, 540, 1080, 1080, 66, 66, 1080, 66, 66, 66, 540, 66, 540, 1080, 1080, 540, 540, 66, 1080, 540, 1080, 66, 540, 540, 66, 66, 540, 66, 1080, 1080, 66, 1080, 1080, 66, 540, 1080, 66, 66, 540, 540, 66, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 1080, 540, 540, 540, 1080, 66, 540, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 540, 66, 1080, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 66, 1080, 1080, 540, 66, 1080, 540, 540, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 540, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 1080, 66, 66, 66, 540, 66, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 540, 540, 540, 540, 66, 540, 1080, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 540, 540, 540, 66, 540, 66, 66, 1080, 66, 540, 66, 66, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 215808 . Total input tokens: 48083984 . Total output tokens: 43180710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.3512683459557593,
    "estimated_duration": 3600.0573549905744,
    "input_throughput": 2840.1639173403587,
    "output_throughput": 2500.3693309279424,
    "total_throughput": 5340.533248268301,
    "itl": 201.9859290251846,
    "ttft": 1835108.1981041292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4206175373680043,
    "arrivals": 72240,
    "finished_requests": 41335,
    "scheduler_time": 34.547158274731686
}
#Debug simulation 
Total elapsed time: 3.3513569277711213. Arrivals time: 0.15185825154185295 Scheduler time: 2.932339201681316 Scheduler overhead time: 0.027043407317250967 Adapter cache time: 0.19865555688738823 Engine time: 0.028609345201402903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.2751279519870877,
    "estimated_duration": 3600.123072749189,
    "input_throughput": 2975.459111685285,
    "output_throughput": 2615.413642736867,
    "total_throughput": 5590.872754422152,
    "itl": 321.023280694061,
    "ttft": 1760190.9231701302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2617004427663474,
    "arrivals": 70816,
    "finished_requests": 43194,
    "scheduler_time": 37.24072104019677
}
#Debug simulation 
Total elapsed time: 3.275219523347914. Arrivals time: 0.1531455428339541 Scheduler time: 2.9913663170300424 Scheduler overhead time: 0.017997201066464186 Adapter cache time: 0.0850329464301467 Engine time: 0.019178118091076612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.418005451094359,
    "estimated_duration": 3600.1914134594113,
    "input_throughput": 2898.1895131997912,
    "output_throughput": 2562.4356986995535,
    "total_throughput": 5460.625211899345,
    "itl": 195.71584835268843,
    "ttft": 1803302.9554402558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3652678856765896,
    "arrivals": 70816,
    "finished_requests": 42085,
    "scheduler_time": 35.32255284465543
}
#Debug simulation 
Total elapsed time: 3.418093916028738. Arrivals time: 0.15457106987014413 Scheduler time: 3.0097076655365527 Scheduler overhead time: 0.02803705120459199 Adapter cache time: 0.18309961399063468 Engine time: 0.02945967996492982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.423050579149276,
    "estimated_duration": 3600.003445574904,
    "input_throughput": 2899.1800029605943,
    "output_throughput": 2563.4375465233115,
    "total_throughput": 5462.617549483905,
    "itl": 196.22077589170152,
    "ttft": 1802670.2871698167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2643448420217984,
    "arrivals": 70816,
    "finished_requests": 42098,
    "scheduler_time": 35.3374472680749
}
#Debug simulation 
Total elapsed time: 3.4231387791223824. Arrivals time: 0.15786722162738442 Scheduler time: 3.011448284611106 Scheduler overhead time: 0.027753274887800217 Adapter cache time: 0.1834910809993744 Engine time: 0.02938272198662162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 540, 33, 1080, 1080, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 33, 1080, 33, 1080, 540, 540, 540, 33, 33, 540, 33, 1080, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 540, 33, 33, 33, 540, 33, 540, 33, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 1080, 1080, 540, 33, 33, 1080, 540, 540, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 1080, 1080, 33, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 33, 33, 540, 540, 1080, 33, 33, 1080, 33, 1080, 540, 33, 1080, 540, 540, 33, 1080, 1080, 1080, 33, 540, 1080, 33, 1080, 540, 540, 1080, 1080, 33, 540, 1080, 33, 540, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 1080, 33, 1080, 540, 540, 540, 540, 540, 33, 33, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 33, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 33, 33, 33, 33, 33, 540, 33, 33, 540, 1080, 1080, 33, 33, 1080, 33, 33, 33, 540, 33, 540, 1080, 1080, 540, 540, 33, 1080, 540, 1080, 33, 540, 540, 33, 33, 540, 33, 1080, 1080, 33, 1080, 1080, 33, 540, 1080, 33, 33, 540, 540, 33, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 1080, 540, 540, 540, 1080, 33, 540, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 540, 33, 1080, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 33, 1080, 1080, 540, 33, 1080, 540, 540, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 540, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 1080, 33, 33, 33, 540, 33, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 540, 540, 540, 540, 33, 540, 1080, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 540, 540, 540, 33, 540, 33, 33, 1080, 33, 540, 33, 33, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 211584 . Total input tokens: 47166834 . Total output tokens: 42349164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4083873806521297,
    "estimated_duration": 3600.0060389388063,
    "input_throughput": 2899.504858352109,
    "output_throughput": 2563.5387552628695,
    "total_throughput": 5463.043613614978,
    "itl": 196.207081124759,
    "ttft": 1802684.6411383294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 726,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1707765140989395,
    "arrivals": 70816,
    "finished_requests": 42100,
    "scheduler_time": 35.33871793961088
}
#Debug simulation 
Total elapsed time: 3.4084730739705265. Arrivals time: 0.153363230638206 Scheduler time: 3.0035737133584917 Scheduler overhead time: 0.0278320643119514 Adapter cache time: 0.18129664845764637 Engine time: 0.029251362197101116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.1455596298910677,
    "estimated_duration": 3600.169789287426,
    "input_throughput": 2836.789262103503,
    "output_throughput": 2461.721673897541,
    "total_throughput": 5298.510936001044,
    "itl": 338.87402077656867,
    "ttft": 1658896.568331477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.938905207761803,
    "arrivals": 63706,
    "finished_requests": 40852,
    "scheduler_time": 34.98158395171993
}
#Debug simulation 
Total elapsed time: 3.1456498466432095. Arrivals time: 0.1394781805574894 Scheduler time: 2.828124189283699 Scheduler overhead time: 0.017254774924367666 Adapter cache time: 0.13468250539153814 Engine time: 0.01799436006695032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.4276724071241915,
    "estimated_duration": 3600.0447934183208,
    "input_throughput": 2886.4393629205997,
    "output_throughput": 2518.8144926913214,
    "total_throughput": 5405.253855611921,
    "itl": 198.63049009862274,
    "ttft": 1634654.7769097988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.609851542580634,
    "arrivals": 63706,
    "finished_requests": 41550,
    "scheduler_time": 34.522961616658826
}
#Debug simulation 
Total elapsed time: 3.4277595789171755. Arrivals time: 0.1486967382952571 Scheduler time: 2.984318716917187 Scheduler overhead time: 0.02772219805046916 Adapter cache time: 0.22461597621440887 Engine time: 0.029216321650892496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.417697297874838,
    "estimated_duration": 3600.14511252484,
    "input_throughput": 2886.4336506458812,
    "output_throughput": 2518.899576700724,
    "total_throughput": 5405.333227346605,
    "itl": 198.43785394327884,
    "ttft": 1634708.4040935885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.214369166572329,
    "arrivals": 63706,
    "finished_requests": 41551,
    "scheduler_time": 34.52178265415137
}
#Debug simulation 
Total elapsed time: 3.41778567712754. Arrivals time: 0.1444631484337151 Scheduler time: 2.9772185967303813 Scheduler overhead time: 0.027614854276180267 Adapter cache time: 0.2262902739457786 Engine time: 0.02914145542308688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 1080, 270, 135, 1080, 1080, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 135, 1080, 135, 1080, 270, 270, 270, 135, 135, 270, 135, 1080, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 270, 135, 135, 135, 270, 135, 270, 135, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 1080, 1080, 270, 135, 135, 1080, 270, 270, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 135, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 135, 135, 270, 270, 1080, 135, 135, 1080, 135, 1080, 270, 135, 1080, 270, 270, 135, 1080, 1080, 1080, 135, 270, 1080, 135, 1080, 270, 270, 1080, 1080, 135, 270, 1080, 135, 270, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 1080, 135, 1080, 270, 270, 270, 270, 270, 135, 135, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 135, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 135, 135, 135, 135, 135, 270, 135, 135, 270, 1080, 1080, 135, 135, 1080, 135, 135, 135, 270, 135, 270, 1080, 1080, 270, 270, 135, 1080, 270, 1080, 135, 270, 270, 135, 135, 270, 135, 1080, 1080, 135, 1080, 1080, 135, 270, 1080, 135, 135, 270, 270, 135, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 1080, 270, 270, 270, 1080, 135, 270, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 135, 135, 270, 135, 1080, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 135, 1080, 1080, 270, 135, 1080, 270, 270, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 1080, 135, 270, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 1080, 135, 135, 135, 270, 135, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 270, 270, 270, 270, 135, 270, 1080, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 270, 270, 270, 135, 270, 135, 135, 1080, 135, 270, 135, 135, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 190080 . Total input tokens: 42435601 . Total output tokens: 38009403
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.394414234906435,
    "estimated_duration": 3600.091652125755,
    "input_throughput": 2887.423433751206,
    "output_throughput": 2519.4964118883386,
    "total_throughput": 5406.919845639544,
    "itl": 198.58048094555602,
    "ttft": 1633961.0868367057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8847626276567935,
    "arrivals": 63706,
    "finished_requests": 41563,
    "scheduler_time": 34.5291912595474
}
#Debug simulation 
Total elapsed time: 3.3944963049143553. Arrivals time: 0.14408513437956572 Scheduler time: 2.956251110881567 Scheduler overhead time: 0.02760416455566883 Adapter cache time: 0.2242967849597335 Engine time: 0.02916924888268113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.2822552397847176,
    "estimated_duration": 3600.28957148171,
    "input_throughput": 2964.135741894786,
    "output_throughput": 2599.6192290022154,
    "total_throughput": 5563.754970897002,
    "itl": 320.2009788337972,
    "ttft": 1374601.1270587947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.899840878036473,
    "arrivals": 60894,
    "finished_requests": 43067,
    "scheduler_time": 36.85289338950821
}
#Debug simulation 
Total elapsed time: 3.282369275111705. Arrivals time: 0.13219198770821095 Scheduler time: 2.9822493619285524 Scheduler overhead time: 0.018244726583361626 Adapter cache time: 0.12183626601472497 Engine time: 0.019255083985626698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.4873281349428,
    "estimated_duration": 3600.165842946169,
    "input_throughput": 2969.5393119032638,
    "output_throughput": 2622.7580650209466,
    "total_throughput": 5592.297376924211,
    "itl": 191.2150600618867,
    "ttft": 1389040.3285313663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.197319167973371,
    "arrivals": 60894,
    "finished_requests": 43147,
    "scheduler_time": 35.797305654980455
}
#Debug simulation 
Total elapsed time: 3.4874428040347993. Arrivals time: 0.13764386624097824 Scheduler time: 3.0764331677928567 Scheduler overhead time: 0.02861288283020258 Adapter cache time: 0.20083954744040966 Engine time: 0.030253279488533735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.472977382130921,
    "estimated_duration": 3600.2040629835674,
    "input_throughput": 2969.818880527385,
    "output_throughput": 2622.8129947097113,
    "total_throughput": 5592.631875237096,
    "itl": 191.18169386890213,
    "ttft": 1388876.1348179735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.9840324117475,
    "arrivals": 60894,
    "finished_requests": 43150,
    "scheduler_time": 35.798505397189764
}
#Debug simulation 
Total elapsed time: 3.4730668631382287. Arrivals time: 0.1407443480566144 Scheduler time: 3.0595591319724917 Scheduler overhead time: 0.028517677448689938 Adapter cache time: 0.19996838876977563 Engine time: 0.030792301055043936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 270, 66, 1080, 1080, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 66, 1080, 66, 1080, 270, 270, 270, 66, 66, 270, 66, 1080, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 270, 66, 66, 66, 270, 66, 270, 66, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 1080, 1080, 270, 66, 66, 1080, 270, 270, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 66, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 66, 66, 270, 270, 1080, 66, 66, 1080, 66, 1080, 270, 66, 1080, 270, 270, 66, 1080, 1080, 1080, 66, 270, 1080, 66, 1080, 270, 270, 1080, 1080, 66, 270, 1080, 66, 270, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 1080, 66, 1080, 270, 270, 270, 270, 270, 66, 66, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 66, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 66, 66, 66, 66, 66, 270, 66, 66, 270, 1080, 1080, 66, 66, 1080, 66, 66, 66, 270, 66, 270, 1080, 1080, 270, 270, 66, 1080, 270, 1080, 66, 270, 270, 66, 66, 270, 66, 1080, 1080, 66, 1080, 1080, 66, 270, 1080, 66, 66, 270, 270, 66, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 1080, 270, 270, 270, 1080, 66, 270, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 270, 66, 1080, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 66, 1080, 1080, 270, 66, 1080, 270, 270, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 270, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 1080, 66, 66, 66, 270, 66, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 270, 270, 270, 270, 66, 270, 1080, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 270, 270, 270, 66, 270, 66, 66, 1080, 66, 270, 66, 66, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 181248 . Total input tokens: 40496111 . Total output tokens: 36247495
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4961820309981704,
    "estimated_duration": 3600.01460606227,
    "input_throughput": 2969.975450098232,
    "output_throughput": 2622.951580279413,
    "total_throughput": 5592.927030377645,
    "itl": 191.1701320004275,
    "ttft": 1388516.5923977152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.778100371253544,
    "arrivals": 60894,
    "finished_requests": 43151,
    "scheduler_time": 35.798455660697094
}
#Debug simulation 
Total elapsed time: 3.4962728316895664. Arrivals time: 0.13919347850605845 Scheduler time: 3.083711967803538 Scheduler overhead time: 0.028567438945174217 Adapter cache time: 0.20079358154907823 Engine time: 0.030473127495497465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.411806335207075,
    "estimated_duration": 3600.229226901196,
    "input_throughput": 3114.7116734152733,
    "output_throughput": 2727.077744560915,
    "total_throughput": 5841.789417976188,
    "itl": 306.2017676216804,
    "ttft": 1152093.3480259762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 877,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.684047751429082,
    "arrivals": 59412,
    "finished_requests": 45042,
    "scheduler_time": 38.51468158894318
}
#Debug simulation 
Total elapsed time: 3.411907154135406. Arrivals time: 0.13178064860403538 Scheduler time: 3.1266298480331898 Scheduler overhead time: 0.019017357379198074 Adapter cache time: 0.10550658870488405 Engine time: 0.020057459827512503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5591947571374476,
    "estimated_duration": 3600.0206278132646,
    "input_throughput": 3073.1910018860794,
    "output_throughput": 2703.5625642822984,
    "total_throughput": 5776.753566168378,
    "itl": 183.5501658895276,
    "ttft": 1219039.1085845537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 865,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.815615478735419,
    "arrivals": 59412,
    "finished_requests": 44423,
    "scheduler_time": 36.78182729627825
}
#Debug simulation 
Total elapsed time: 3.5592832169495523. Arrivals time: 0.14003085112199187 Scheduler time: 3.16237706085667 Scheduler overhead time: 0.029538127593696117 Adapter cache time: 0.18161495588719845 Engine time: 0.031734473537653685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.568610608112067,
    "estimated_duration": 3600.2084438703405,
    "input_throughput": 3076.6571360219045,
    "output_throughput": 2707.4382364153594,
    "total_throughput": 5784.095372437264,
    "itl": 183.68123741478544,
    "ttft": 1214720.0049948387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6912726188637026,
    "arrivals": 59412,
    "finished_requests": 44482,
    "scheduler_time": 36.83607497752017
}
#Debug simulation 
Total elapsed time: 3.5686986190266907. Arrivals time: 0.1361213638447225 Scheduler time: 3.172056366223842 Scheduler overhead time: 0.029618918430060148 Adapter cache time: 0.18547105696052313 Engine time: 0.031410181894898415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 270, 33, 1080, 1080, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 33, 1080, 33, 1080, 270, 270, 270, 33, 33, 270, 33, 1080, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 270, 33, 33, 33, 270, 33, 270, 33, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 1080, 1080, 270, 33, 33, 1080, 270, 270, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 1080, 1080, 33, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 33, 33, 270, 270, 1080, 33, 33, 1080, 33, 1080, 270, 33, 1080, 270, 270, 33, 1080, 1080, 1080, 33, 270, 1080, 33, 1080, 270, 270, 1080, 1080, 33, 270, 1080, 33, 270, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 1080, 33, 1080, 270, 270, 270, 270, 270, 33, 33, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 33, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 33, 33, 33, 33, 33, 270, 33, 33, 270, 1080, 1080, 33, 33, 1080, 33, 33, 33, 270, 33, 270, 1080, 1080, 270, 270, 33, 1080, 270, 1080, 33, 270, 270, 33, 33, 270, 33, 1080, 1080, 33, 1080, 1080, 33, 270, 1080, 33, 33, 270, 270, 33, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 1080, 270, 270, 270, 1080, 33, 270, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 270, 33, 1080, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 33, 1080, 1080, 270, 33, 1080, 270, 270, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 270, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 1080, 33, 33, 33, 270, 33, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 270, 270, 270, 270, 33, 270, 1080, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 270, 270, 270, 33, 270, 33, 33, 1080, 33, 270, 33, 33, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 177024 . Total input tokens: 39529967 . Total output tokens: 35428185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5720411189831793,
    "estimated_duration": 3600.0876209593002,
    "input_throughput": 3083.590503567219,
    "output_throughput": 2713.4592344719035,
    "total_throughput": 5797.0497380391225,
    "itl": 184.33811720909895,
    "ttft": 1207871.725165434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.583403454795425,
    "arrivals": 59412,
    "finished_requests": 44577,
    "scheduler_time": 36.91917258246284
}
#Debug simulation 
Total elapsed time: 3.572126713115722. Arrivals time: 0.13619748828932643 Scheduler time: 3.178126959130168 Scheduler overhead time: 0.029562138952314854 Adapter cache time: 0.1828156393021345 Engine time: 0.03143752785399556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5226520942524076,
    "estimated_duration": 3600.1023813225165,
    "input_throughput": 3192.0947747542673,
    "output_throughput": 2783.006131153256,
    "total_throughput": 5975.100905907523,
    "itl": 295.95249923659776,
    "ttft": 798799.6977649287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.383397941577865,
    "arrivals": 55057,
    "finished_requests": 45965,
    "scheduler_time": 39.16236755373756
}
#Debug simulation 
Total elapsed time: 3.522738281171769. Arrivals time: 0.12425462855026126 Scheduler time: 3.2223070194013417 Scheduler overhead time: 0.019844884984195232 Adapter cache time: 0.12607115926221013 Engine time: 0.020946061704307795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.68239836813882,
    "estimated_duration": 3600.1416290216193,
    "input_throughput": 3205.014188048964,
    "output_throughput": 2811.302454995506,
    "total_throughput": 6016.316643044471,
    "itl": 177.20690370308375,
    "ttft": 805051.0600639192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.804821649882784,
    "arrivals": 55057,
    "finished_requests": 46155,
    "scheduler_time": 38.03971915075683
}
#Debug simulation 
Total elapsed time: 3.682485460303724. Arrivals time: 0.12735204305499792 Scheduler time: 3.2911232179030776 Scheduler overhead time: 0.030780442990362644 Adapter cache time: 0.18635467626154423 Engine time: 0.03234541229903698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.679655957967043,
    "estimated_duration": 3600.1494988507266,
    "input_throughput": 3204.631642014588,
    "output_throughput": 2811.1532599495613,
    "total_throughput": 6015.78490196415,
    "itl": 176.96145624064528,
    "ttft": 805249.6803668838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.561558606223984,
    "arrivals": 55057,
    "finished_requests": 46152,
    "scheduler_time": 38.0343624031204
}
#Debug simulation 
Total elapsed time: 3.6797398230992258. Arrivals time: 0.12681501917541027 Scheduler time: 3.2898967983201146 Scheduler overhead time: 0.030761311296373606 Adapter cache time: 0.1856436119414866 Engine time: 0.0321472492069006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 1080, 135, 66, 1080, 1080, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 66, 1080, 66, 1080, 135, 135, 135, 66, 66, 135, 66, 1080, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 66, 1080, 135, 135, 66, 66, 66, 135, 66, 135, 66, 1080, 66, 135, 1080, 66, 1080, 135, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 1080, 1080, 135, 66, 66, 1080, 135, 135, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 66, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 66, 66, 135, 135, 1080, 66, 66, 1080, 66, 1080, 135, 66, 1080, 135, 135, 66, 1080, 1080, 1080, 66, 135, 1080, 66, 1080, 135, 135, 1080, 1080, 66, 135, 1080, 66, 135, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 1080, 66, 1080, 135, 135, 135, 135, 135, 66, 66, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 66, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 66, 66, 66, 66, 66, 135, 66, 66, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66, 135, 1080, 1080, 135, 135, 66, 1080, 135, 1080, 66, 135, 135, 66, 66, 135, 66, 1080, 1080, 66, 1080, 1080, 66, 135, 1080, 66, 66, 135, 135, 66, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 1080, 135, 135, 135, 1080, 66, 135, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 66, 66, 135, 66, 1080, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 66, 1080, 1080, 135, 66, 1080, 135, 135, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 1080, 66, 135, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 1080, 66, 66, 66, 135, 66, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 135, 135, 135, 135, 66, 135, 1080, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 135, 135, 135, 66, 135, 66, 66, 1080, 66, 135, 66, 66, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 163968 . Total input tokens: 36634820 . Total output tokens: 32787314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6760070961900055,
    "estimated_duration": 3600.0643646899393,
    "input_throughput": 3197.1583933031466,
    "output_throughput": 2803.115716201684,
    "total_throughput": 6000.27410950483,
    "itl": 177.2626119137691,
    "ttft": 815519.9756226502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1791,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.355180078169643,
    "arrivals": 55057,
    "finished_requests": 46036,
    "scheduler_time": 37.92792266943912
}
#Debug simulation 
Total elapsed time: 3.6760961622931063. Arrivals time: 0.12826982280239463 Scheduler time: 3.285447498783469 Scheduler overhead time: 0.030876305419951677 Adapter cache time: 0.1845137532800436 Engine time: 0.032426970545202494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.646588373929262,
    "estimated_duration": 3600.1488614275427,
    "input_throughput": 3383.251767864472,
    "output_throughput": 2929.4874756423355,
    "total_throughput": 6312.739243506808,
    "itl": 273.259501036969,
    "ttft": 428881.1243114195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.253298471800594,
    "arrivals": 53529,
    "finished_requests": 48601,
    "scheduler_time": 40.88318874471576
}
#Debug simulation 
Total elapsed time: 3.646675483789295. Arrivals time: 0.11626516189426184 Scheduler time: 3.3627368258312345 Scheduler overhead time: 0.021567415911704302 Adapter cache time: 0.11348935309797525 Engine time: 0.022507195360958576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7744721486233175,
    "estimated_duration": 3600.044128304044,
    "input_throughput": 3344.454837466686,
    "output_throughput": 2912.468188255075,
    "total_throughput": 6256.923025721761,
    "itl": 169.3951419849161,
    "ttft": 498164.0299377401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4836062741139937,
    "arrivals": 53529,
    "finished_requests": 48048,
    "scheduler_time": 39.17715096684659
}
#Debug simulation 
Total elapsed time: 3.77456259354949. Arrivals time: 0.13274929113686085 Scheduler time: 3.3942650062963367 Scheduler overhead time: 0.03223507246002555 Adapter cache time: 0.16645157895982265 Engine time: 0.0337671316228807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.768653750885278,
    "estimated_duration": 3600.1214418167874,
    "input_throughput": 3344.6180065313406,
    "output_throughput": 2912.6056355222327,
    "total_throughput": 6257.223642053574,
    "itl": 169.38528910603478,
    "ttft": 498079.39648152894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.34018931734139,
    "arrivals": 53529,
    "finished_requests": 48051,
    "scheduler_time": 39.179614100745205
}
#Debug simulation 
Total elapsed time: 3.7687313528731465. Arrivals time: 0.12350318348035216 Scheduler time: 3.3967541893944144 Scheduler overhead time: 0.03212659666314721 Adapter cache time: 0.1677586087025702 Engine time: 0.033441783394664526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 135, 33, 1080, 1080, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 33, 1080, 33, 1080, 135, 135, 135, 33, 33, 135, 33, 1080, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 33, 1080, 135, 135, 33, 33, 33, 135, 33, 135, 33, 1080, 33, 135, 1080, 33, 1080, 135, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 1080, 1080, 135, 33, 33, 1080, 135, 135, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 135, 1080, 1080, 33, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 1080, 33, 33, 1080, 33, 1080, 135, 33, 1080, 135, 135, 33, 1080, 1080, 1080, 33, 135, 1080, 33, 1080, 135, 135, 1080, 1080, 33, 135, 1080, 33, 135, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 1080, 33, 1080, 135, 135, 135, 135, 135, 33, 33, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 33, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 33, 33, 33, 33, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33, 135, 1080, 1080, 135, 135, 33, 1080, 135, 1080, 33, 135, 135, 33, 33, 135, 33, 1080, 1080, 33, 1080, 1080, 33, 135, 1080, 33, 33, 135, 135, 33, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 1080, 135, 135, 135, 1080, 33, 135, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 135, 33, 1080, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 33, 1080, 1080, 135, 33, 1080, 135, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 135, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 1080, 33, 33, 33, 135, 33, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 135, 135, 135, 135, 33, 135, 1080, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 135, 135, 135, 33, 135, 33, 33, 1080, 33, 135, 33, 33, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 159744 . Total input tokens: 35685722 . Total output tokens: 31942819
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7610355648212135,
    "estimated_duration": 3600.021696046054,
    "input_throughput": 3344.732342370295,
    "output_throughput": 2912.634113154484,
    "total_throughput": 6257.366455524779,
    "itl": 169.38356456244728,
    "ttft": 497785.60658723966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1068,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.193373714955447,
    "arrivals": 53529,
    "finished_requests": 48051,
    "scheduler_time": 39.17815847429298
}
#Debug simulation 
Total elapsed time: 3.7611213410273194. Arrivals time: 0.12457157485187054 Scheduler time: 3.386483880225569 Scheduler overhead time: 0.032183550763875246 Adapter cache time: 0.16901301452890038 Engine time: 0.0336487777531147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.8093388699926436,
    "estimated_duration": 3600.0049980101653,
    "input_throughput": 3470.8196257800632,
    "output_throughput": 3061.3335276177527,
    "total_throughput": 6532.153153397816,
    "itl": 139.44695114502198,
    "ttft": 35658.43427111376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.53792383198635,
    "arrivals": 50610,
    "finished_requests": 50110,
    "scheduler_time": 40.19628238656597
}
#Debug simulation 
Total elapsed time: 3.809421533718705. Arrivals time: 0.11572470422834158 Scheduler time: 3.454419052693993 Scheduler overhead time: 0.036732704378664494 Adapter cache time: 0.14803105872124434 Engine time: 0.037558685056865215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.8501587323844433,
    "estimated_duration": 3600.073262121871,
    "input_throughput": 3470.8518661187745,
    "output_throughput": 3061.2843677254364,
    "total_throughput": 6532.136233844211,
    "itl": 139.48348493556355,
    "ttft": 35820.422300933045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.759545984123835,
    "arrivals": 50610,
    "finished_requests": 50111,
    "scheduler_time": 40.205638960483185
}
#Debug simulation 
Total elapsed time: 3.850277820136398. Arrivals time: 0.11719172680750489 Scheduler time: 3.489168233703822 Scheduler overhead time: 0.037559923715889454 Adapter cache time: 0.15108148660510778 Engine time: 0.03816787526011467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.872960016131401,
    "estimated_duration": 3600.039235249858,
    "input_throughput": 3470.8846719368526,
    "output_throughput": 3061.313302391024,
    "total_throughput": 6532.197974327876,
    "itl": 139.51230607784382,
    "ttft": 35682.10495330544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6022367865242537,
    "arrivals": 50610,
    "finished_requests": 50111,
    "scheduler_time": 40.20567975050723
}
#Debug simulation 
Total elapsed time: 3.873047035187483. Arrivals time: 0.11574641615152359 Scheduler time: 3.5127015970647335 Scheduler overhead time: 0.03804359305649996 Adapter cache time: 0.15045644715428352 Engine time: 0.03861168259754777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 1080, 66, 33, 1080, 1080, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 33, 1080, 33, 1080, 66, 66, 66, 33, 33, 66, 33, 1080, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 33, 1080, 66, 66, 33, 33, 33, 66, 33, 66, 33, 1080, 33, 66, 1080, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 1080, 1080, 66, 33, 33, 1080, 66, 66, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 66, 1080, 1080, 33, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 1080, 33, 33, 1080, 33, 1080, 66, 33, 1080, 66, 66, 33, 1080, 1080, 1080, 33, 66, 1080, 33, 1080, 66, 66, 1080, 1080, 33, 66, 1080, 33, 66, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 1080, 33, 1080, 66, 66, 66, 66, 66, 33, 33, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 33, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 33, 33, 33, 33, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33, 66, 1080, 1080, 66, 66, 33, 1080, 66, 1080, 33, 66, 66, 33, 33, 66, 33, 1080, 1080, 33, 1080, 1080, 33, 66, 1080, 33, 33, 66, 66, 33, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 33, 33, 66, 33, 1080, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 33, 1080, 1080, 66, 33, 1080, 66, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 33, 1080, 33, 66, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 1080, 33, 33, 33, 66, 33, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 66, 66, 66, 66, 33, 66, 1080, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 66, 66, 66, 33, 66, 33, 33, 1080, 33, 66, 33, 33, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 150912 . Total input tokens: 33712521 . Total output tokens: 30175123
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.8322415077127516,
    "estimated_duration": 3600.101329632918,
    "input_throughput": 3470.864527380981,
    "output_throughput": 3061.261056539132,
    "total_throughput": 6532.125583920113,
    "itl": 139.35200739583811,
    "ttft": 35743.71288116385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.453508090611927,
    "arrivals": 50610,
    "finished_requests": 50112,
    "scheduler_time": 40.20087417957452
}
#Debug simulation 
Total elapsed time: 3.8323251949623227. Arrivals time: 0.11494900938123465 Scheduler time: 3.4790031323209405 Scheduler overhead time: 0.03744169883430004 Adapter cache time: 0.14580020448192954 Engine time: 0.037957790307700634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.045247814618051,
    "estimated_duration": 3600.0777401601867,
    "input_throughput": 2638.9746793571385,
    "output_throughput": 2265.6124641455876,
    "total_throughput": 4904.587143502727,
    "itl": 296.5149718626874,
    "ttft": 259583.3406139906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.33604660352631,
    "arrivals": 40507,
    "finished_requests": 37970,
    "scheduler_time": 31.014344474555042
}
#Debug simulation 
Total elapsed time: 3.0453282967209816. Arrivals time: 0.0907808649353683 Scheduler time: 2.705190775450319 Scheduler overhead time: 0.02305604750290513 Adapter cache time: 0.1929423389956355 Engine time: 0.02290209336206317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.230961026158184,
    "estimated_duration": 3600.1118237314345,
    "input_throughput": 2643.231228894706,
    "output_throughput": 2288.2691992221157,
    "total_throughput": 4931.500428116821,
    "itl": 196.5291390634977,
    "ttft": 269236.86396025354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.225650553717879,
    "arrivals": 40507,
    "finished_requests": 38056,
    "scheduler_time": 30.276032021486582
}
#Debug simulation 
Total elapsed time: 3.2310605123639107. Arrivals time: 0.09652946889400482 Scheduler time: 2.781780675519258 Scheduler overhead time: 0.02924689371138811 Adapter cache time: 0.279922844376415 Engine time: 0.029989127535372972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.156772645190358,
    "estimated_duration": 3600.061021296379,
    "input_throughput": 2643.462136809301,
    "output_throughput": 2288.394544221746,
    "total_throughput": 4931.856681031047,
    "itl": 196.80342032967454,
    "ttft": 269286.88760596974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.640060417690107,
    "arrivals": 40507,
    "finished_requests": 38057,
    "scheduler_time": 30.283925986398987
}
#Debug simulation 
Total elapsed time: 3.156865790951997. Arrivals time: 0.09511821391060948 Scheduler time: 2.7173060532659292 Scheduler overhead time: 0.028674828354269266 Adapter cache time: 0.27293813740834594 Engine time: 0.02940618759021163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 540, 270, 135, 540, 540, 135, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 135, 540, 135, 540, 270, 270, 270, 135, 135, 270, 135, 540, 135, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 540, 540, 540, 135, 270, 270, 270, 540, 270, 135, 270, 135, 540, 270, 540, 540, 270, 540, 540, 135, 135, 540, 270, 270, 135, 135, 135, 270, 135, 270, 135, 540, 135, 270, 540, 135, 540, 270, 135, 540, 540, 540, 540, 270, 135, 270, 540, 540, 270, 135, 135, 540, 270, 270, 135, 135, 540, 270, 540, 270, 540, 540, 270, 540, 540, 135, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 135, 135, 270, 270, 540, 135, 135, 540, 135, 540, 270, 135, 540, 270, 270, 135, 540, 540, 540, 135, 270, 540, 135, 540, 270, 270, 540, 540, 135, 270, 540, 135, 270, 270, 135, 270, 135, 270, 540, 540, 270, 135, 540, 135, 540, 270, 270, 270, 270, 270, 135, 135, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 135, 270, 270, 270, 270, 270, 270, 270, 270, 540, 135, 135, 135, 135, 135, 270, 135, 135, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135, 270, 540, 540, 270, 270, 135, 540, 270, 540, 135, 270, 270, 135, 135, 270, 135, 540, 540, 135, 540, 540, 135, 270, 540, 135, 135, 270, 270, 135, 135, 540, 540, 540, 540, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 135, 540, 540, 135, 540, 135, 135, 270, 135, 540, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 135, 540, 540, 270, 135, 540, 270, 270, 540, 540, 540, 135, 540, 135, 540, 540, 135, 135, 540, 135, 270, 540, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 540, 135, 135, 135, 270, 135, 270, 270, 135, 540, 270, 540, 135, 540, 135, 270, 270, 270, 270, 135, 270, 540, 540, 135, 540, 540, 135, 540, 270, 540, 270, 270, 270, 135, 270, 135, 135, 540, 135, 270, 135, 135, 270, 540, 270, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 120960 . Total input tokens: 27012138 . Total output tokens: 24203683
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.179586499929428,
    "estimated_duration": 3600.0125972933934,
    "input_throughput": 2644.506857325344,
    "output_throughput": 2289.1703229582818,
    "total_throughput": 4933.677180283626,
    "itl": 196.28433025407924,
    "ttft": 267553.62335247913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4060,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.139604197303667,
    "arrivals": 40507,
    "finished_requests": 38067,
    "scheduler_time": 30.278562438383506
}
#Debug simulation 
Total elapsed time: 3.1796735445968807. Arrivals time: 0.09408097434788942 Scheduler time: 2.7383405207656324 Scheduler overhead time: 0.028931715060025454 Adapter cache time: 0.2752612130716443 Engine time: 0.029554944019764662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.2989328065887094,
    "estimated_duration": 3600.1242705162426,
    "input_throughput": 2570.066560139387,
    "output_throughput": 2307.899776695365,
    "total_throughput": 4877.966336834752,
    "itl": 79.27387746555847,
    "ttft": 30967.09929818531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.442326700978635,
    "arrivals": 37708,
    "finished_requests": 37385,
    "scheduler_time": 25.437685120582007
}
#Debug simulation 
Total elapsed time: 3.299019186757505. Arrivals time: 0.09440430486574769 Scheduler time: 2.6635331376455724 Scheduler overhead time: 0.0547221596352756 Adapter cache time: 0.406071366276592 Engine time: 0.05485513946041465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.2933587352745235,
    "estimated_duration": 3600.043084225422,
    "input_throughput": 2569.8811885165464,
    "output_throughput": 2307.8107138230484,
    "total_throughput": 4877.691902339595,
    "itl": 79.34043211938372,
    "ttft": 30968.9388044742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.859811557621908,
    "arrivals": 37708,
    "finished_requests": 37383,
    "scheduler_time": 25.44413725640381
}
#Debug simulation 
Total elapsed time: 3.2934421952813864. Arrivals time: 0.09590329974889755 Scheduler time: 2.659057345241308 Scheduler overhead time: 0.05477840453386307 Adapter cache time: 0.4040916468948126 Engine time: 0.05415849247947335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.289263646584004,
    "estimated_duration": 3600.042206410459,
    "input_throughput": 2569.8818151425776,
    "output_throughput": 2307.811276547222,
    "total_throughput": 4877.6930916898,
    "itl": 79.29000783799457,
    "ttft": 30968.53662872288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.553254131846851,
    "arrivals": 37708,
    "finished_requests": 37383,
    "scheduler_time": 25.43889746758251
}
#Debug simulation 
Total elapsed time: 3.289347119629383. Arrivals time: 0.09450657432898879 Scheduler time: 2.6557763875462115 Scheduler overhead time: 0.054741072934120893 Adapter cache time: 0.404670137912035 Engine time: 0.05425896821543574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 270, 66, 540, 540, 66, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 66, 540, 66, 540, 270, 270, 270, 66, 66, 270, 66, 540, 66, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 540, 540, 540, 66, 270, 270, 270, 540, 270, 66, 270, 66, 540, 270, 540, 540, 270, 540, 540, 66, 66, 540, 270, 270, 66, 66, 66, 270, 66, 270, 66, 540, 66, 270, 540, 66, 540, 270, 66, 540, 540, 540, 540, 270, 66, 270, 540, 540, 270, 66, 66, 540, 270, 270, 66, 66, 540, 270, 540, 270, 540, 540, 270, 540, 540, 66, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 66, 66, 270, 270, 540, 66, 66, 540, 66, 540, 270, 66, 540, 270, 270, 66, 540, 540, 540, 66, 270, 540, 66, 540, 270, 270, 540, 540, 66, 270, 540, 66, 270, 270, 66, 270, 66, 270, 540, 540, 270, 66, 540, 66, 540, 270, 270, 270, 270, 270, 66, 66, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 66, 270, 270, 270, 270, 270, 270, 270, 270, 540, 66, 66, 66, 66, 66, 270, 66, 66, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66, 270, 540, 540, 270, 270, 66, 540, 270, 540, 66, 270, 270, 66, 66, 270, 66, 540, 540, 66, 540, 540, 66, 270, 540, 66, 66, 270, 270, 66, 66, 540, 540, 540, 540, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 66, 540, 540, 66, 540, 66, 66, 270, 66, 540, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 66, 540, 540, 270, 66, 540, 270, 270, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 270, 540, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 540, 66, 66, 66, 270, 66, 270, 270, 66, 540, 270, 540, 66, 540, 66, 270, 270, 270, 270, 66, 270, 540, 540, 66, 540, 540, 66, 540, 270, 540, 270, 270, 270, 66, 270, 66, 66, 540, 66, 270, 66, 66, 270, 540, 270, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 112128 . Total input tokens: 25003147 . Total output tokens: 22451802
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.310910030733794,
    "estimated_duration": 3600.0945867402634,
    "input_throughput": 2570.0877510492883,
    "output_throughput": 2307.9188059675976,
    "total_throughput": 4878.006557016885,
    "itl": 79.25251996287167,
    "ttft": 30872.392505152242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.291065820473991,
    "arrivals": 37708,
    "finished_requests": 37385,
    "scheduler_time": 25.435360399188408
}
#Debug simulation 
Total elapsed time: 3.3110219347290695. Arrivals time: 0.09403763758018613 Scheduler time: 2.6746751735918224 Scheduler overhead time: 0.054692336823791265 Adapter cache time: 0.40779133001342416 Engine time: 0.05451646912842989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.173016460146755,
    "estimated_duration": 3600.0075269285476,
    "input_throughput": 2480.369814009344,
    "output_throughput": 2185.0643203269415,
    "total_throughput": 4665.434134336286,
    "itl": 56.04490977937986,
    "ttft": 8453.64954300537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.277782373752057,
    "arrivals": 36171,
    "finished_requests": 36084,
    "scheduler_time": 20.06854999198586
}
#Debug simulation 
Total elapsed time: 3.173097377177328. Arrivals time: 0.09356112079694867 Scheduler time: 2.47821850143373 Scheduler overhead time: 0.07074496569111943 Adapter cache time: 0.4286359422840178 Engine time: 0.06916193943470716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.2086326382122934,
    "estimated_duration": 3600.0304770782177,
    "input_throughput": 2480.354001682523,
    "output_throughput": 2185.0503905689825,
    "total_throughput": 4665.404392251506,
    "itl": 56.05938584083818,
    "ttft": 8552.791149166656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4897162577696177,
    "arrivals": 36171,
    "finished_requests": 36084,
    "scheduler_time": 20.07161642255561
}
#Debug simulation 
Total elapsed time: 3.208763266913593. Arrivals time: 0.09594874689355493 Scheduler time: 2.5023433794267476 Scheduler overhead time: 0.07398778898641467 Adapter cache time: 0.43205835903063416 Engine time: 0.07126368163153529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.1892632292583585,
    "estimated_duration": 3600.015732578994,
    "input_throughput": 2480.364160409698,
    "output_throughput": 2185.059339828147,
    "total_throughput": 4665.423500237845,
    "itl": 56.05045725127517,
    "ttft": 8453.79763597284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.34343913376793,
    "arrivals": 36171,
    "finished_requests": 36084,
    "scheduler_time": 20.069573210752885
}
#Debug simulation 
Total elapsed time: 3.1893498999997973. Arrivals time: 0.09441800694912672 Scheduler time: 2.4918353967368603 Scheduler overhead time: 0.0711065772920847 Adapter cache time: 0.42845264449715614 Engine time: 0.07049882551655173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 270, 33, 540, 540, 33, 270, 540, 540, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 33, 540, 33, 540, 270, 270, 270, 33, 33, 270, 33, 540, 33, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 540, 540, 540, 33, 270, 270, 270, 540, 270, 33, 270, 33, 540, 270, 540, 540, 270, 540, 540, 33, 33, 540, 270, 270, 33, 33, 33, 270, 33, 270, 33, 540, 33, 270, 540, 33, 540, 270, 33, 540, 540, 540, 540, 270, 33, 270, 540, 540, 270, 33, 33, 540, 270, 270, 33, 33, 540, 270, 540, 270, 540, 540, 270, 540, 540, 33, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 33, 33, 270, 270, 540, 33, 33, 540, 33, 540, 270, 33, 540, 270, 270, 33, 540, 540, 540, 33, 270, 540, 33, 540, 270, 270, 540, 540, 33, 270, 540, 33, 270, 270, 33, 270, 33, 270, 540, 540, 270, 33, 540, 33, 540, 270, 270, 270, 270, 270, 33, 33, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 33, 270, 270, 270, 270, 270, 270, 270, 270, 540, 33, 33, 33, 33, 33, 270, 33, 33, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33, 270, 540, 540, 270, 270, 33, 540, 270, 540, 33, 270, 270, 33, 33, 270, 33, 540, 540, 33, 540, 540, 33, 270, 540, 33, 33, 270, 270, 33, 33, 540, 540, 540, 540, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 33, 540, 540, 33, 540, 33, 33, 270, 33, 540, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 33, 540, 540, 270, 33, 540, 270, 270, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 270, 540, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 540, 33, 33, 33, 270, 33, 270, 270, 33, 540, 270, 540, 33, 540, 33, 270, 270, 270, 270, 33, 270, 540, 540, 33, 540, 540, 33, 540, 270, 540, 270, 270, 270, 33, 270, 33, 33, 540, 33, 270, 33, 33, 270, 540, 270, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 107904 . Total input tokens: 24035451 . Total output tokens: 21614343
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.200185399968177,
    "estimated_duration": 3600.008234821863,
    "input_throughput": 2480.369326277901,
    "output_throughput": 2185.0638906633612,
    "total_throughput": 4665.433216941263,
    "itl": 56.04272277452463,
    "ttft": 8453.775899773735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2053339161350554,
    "arrivals": 36171,
    "finished_requests": 36084,
    "scheduler_time": 20.06780504216941
}
#Debug simulation 
Total elapsed time: 3.2002641363069415. Arrivals time: 0.09421462984755635 Scheduler time: 2.5027331984601915 Scheduler overhead time: 0.07071913732215762 Adapter cache time: 0.42955586267635226 Engine time: 0.07002108730375767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.950822797603905,
    "estimated_duration": 3599.744385644942,
    "input_throughput": 2206.129143966197,
    "output_throughput": 1937.3942293823434,
    "total_throughput": 4143.52337334854,
    "itl": 41.59027352612742,
    "ttft": 8442.268029384679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.393358897075709,
    "arrivals": 31815,
    "finished_requests": 31741,
    "scheduler_time": 12.518053919985642
}
#Debug simulation 
Total elapsed time: 2.950901636853814. Arrivals time: 0.08596240496262908 Scheduler time: 2.2276529907248914 Scheduler overhead time: 0.0881522037088871 Adapter cache time: 0.4232081980444491 Engine time: 0.08481346536427736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.9574461900629103,
    "estimated_duration": 3599.7470011430596,
    "input_throughput": 2206.1275410405965,
    "output_throughput": 1937.392821713705,
    "total_throughput": 4143.5203627543015,
    "itl": 41.23857059388379,
    "ttft": 8441.651094538678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.796054481605291,
    "arrivals": 31815,
    "finished_requests": 31741,
    "scheduler_time": 12.383336337385948
}
#Debug simulation 
Total elapsed time: 2.9575264281593263. Arrivals time: 0.08697028178721666 Scheduler time: 2.2274513505399227 Scheduler overhead time: 0.08948586555197835 Adapter cache time: 0.4249364910647273 Engine time: 0.08729201415553689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.9398496500216424,
    "estimated_duration": 3599.7611037209053,
    "input_throughput": 2206.1188982211183,
    "output_throughput": 1937.3852317008407,
    "total_throughput": 4143.504129921959,
    "itl": 41.22911392590355,
    "ttft": 8441.62772254829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.506620166962763,
    "arrivals": 31815,
    "finished_requests": 31741,
    "scheduler_time": 12.379947997599452
}
#Debug simulation 
Total elapsed time: 2.939929698128253. Arrivals time: 0.08749717706814408 Scheduler time: 2.210918068420142 Scheduler overhead time: 0.08956500282511115 Adapter cache time: 0.42196164513006806 Engine time: 0.0884147621691227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.968056085985154,
    "estimated_duration": 3599.75622434518,
    "input_throughput": 2206.121888557777,
    "output_throughput": 1937.3878577760195,
    "total_throughput": 4143.509746333796,
    "itl": 41.587385908042116,
    "ttft": 8442.491165979623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.252195166640264,
    "arrivals": 31815,
    "finished_requests": 31741,
    "scheduler_time": 12.516862369585477
}
#Debug simulation 
Total elapsed time: 2.968135990668088. Arrivals time: 0.0864682225510478 Scheduler time: 2.2343809017911553 Scheduler overhead time: 0.08944437839090824 Adapter cache time: 0.43007016042247415 Engine time: 0.08642777986824512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.876797678414732,
    "estimated_duration": 3599.9550470644685,
    "input_throughput": 2099.1881568527456,
    "output_throughput": 1836.7587688051447,
    "total_throughput": 3935.94692565789,
    "itl": 37.27181716060086,
    "ttft": 5264.79658600588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.715432121134456,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.243814208586674
}
#Debug simulation 
Total elapsed time: 2.8768808213062584. Arrivals time: 0.08417081320658326 Scheduler time: 2.148366437293589 Scheduler overhead time: 0.09714702749624848 Adapter cache time: 0.4072962673380971 Engine time: 0.0949781951494515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.857064299751073,
    "estimated_duration": 3599.939581143264,
    "input_throughput": 2099.197175303721,
    "output_throughput": 1836.7666598171324,
    "total_throughput": 3935.963835120853,
    "itl": 37.278234775232235,
    "ttft": 5264.702461651664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9576145034004035,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.24629997243799
}
#Debug simulation 
Total elapsed time: 2.8571508997119963. Arrivals time: 0.08446573652327061 Scheduler time: 2.12916288850829 Scheduler overhead time: 0.09650203539058566 Adapter cache time: 0.4065381051041186 Engine time: 0.09537623124197125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.84135092003271,
    "estimated_duration": 3599.947868176467,
    "input_throughput": 2099.1923429791073,
    "output_throughput": 1836.7624316041545,
    "total_throughput": 3935.9547745832615,
    "itl": 37.2740444578865,
    "ttft": 5264.6732857451225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.786004469655406,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.244548699405426
}
#Debug simulation 
Total elapsed time: 2.8414390049874783. Arrivals time: 0.08469062019139528 Scheduler time: 2.1147884046658874 Scheduler overhead time: 0.0966028431430459 Adapter cache time: 0.4068981190212071 Engine time: 0.093418522272259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.833690118044615,
    "estimated_duration": 3599.9312360540334,
    "input_throughput": 2099.202041504376,
    "output_throughput": 1836.7709176711487,
    "total_throughput": 3935.9729591755254,
    "itl": 37.27047573753981,
    "ttft": 5264.871332189756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.629921058011149,
    "arrivals": 30443,
    "finished_requests": 30399,
    "scheduler_time": 9.24288878153123
}
#Debug simulation 
Total elapsed time: 2.8337779068388045. Arrivals time: 0.08494297042489052 Scheduler time: 2.1056430120952427 Scheduler overhead time: 0.09662648383527994 Adapter cache time: 0.40536873787641525 Engine time: 0.09591867588460445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.6449142578057945,
    "estimated_duration": 3600.003551088855,
    "input_throughput": 1870.4306549818186,
    "output_throughput": 1691.3722204963772,
    "total_throughput": 3561.802875478196,
    "itl": 33.1817654118689,
    "ttft": 4896.435155044469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5807706604014102,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.210402768425602
}
#Debug simulation 
Total elapsed time: 2.6450097379274666. Arrivals time: 0.07893349602818489 Scheduler time: 1.9463470769114792 Scheduler overhead time: 0.10493623372167349 Adapter cache time: 0.3649885756894946 Engine time: 0.10088507970795035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.6485072979703546,
    "estimated_duration": 3600.0156525652096,
    "input_throughput": 1870.4243675168382,
    "output_throughput": 1691.366534937505,
    "total_throughput": 3561.7909024543433,
    "itl": 33.18585528572201,
    "ttft": 4896.491235512675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.811342858960855,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.212351073295476
}
#Debug simulation 
Total elapsed time: 2.648587079718709. Arrivals time: 0.07738135661929846 Scheduler time: 1.9521040646359324 Scheduler overhead time: 0.10605454770848155 Adapter cache time: 0.36378601752221584 Engine time: 0.10028100619092584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.6458156630396843,
    "estimated_duration": 3600.0159161652928,
    "input_throughput": 1870.424230560772,
    "output_throughput": 1691.3664110923974,
    "total_throughput": 3561.790641653169,
    "itl": 33.18304817895438,
    "ttft": 4896.397010826786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.647087540947786,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.211029838793998
}
#Debug simulation 
Total elapsed time: 2.645930716767907. Arrivals time: 0.07769085187464952 Scheduler time: 1.9443531609140337 Scheduler overhead time: 0.10580823430791497 Adapter cache time: 0.36576115200296044 Engine time: 0.10299133230000734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.643585043027997,
    "estimated_duration": 3600.006912652302,
    "input_throughput": 1870.4289084375835,
    "output_throughput": 1691.3706411507899,
    "total_throughput": 3561.7995495883733,
    "itl": 33.18067902400252,
    "ttft": 4896.386038398191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.498358845035458,
    "arrivals": 27512,
    "finished_requests": 27475,
    "scheduler_time": 5.209614281101574
}
#Debug simulation 
Total elapsed time: 2.6436709370464087. Arrivals time: 0.07854999974370003 Scheduler time: 1.9435344249941409 Scheduler overhead time: 0.10587720153853297 Adapter cache time: 0.3644320899620652 Engine time: 0.10209989827126265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.1518742493353784,
    "estimated_duration": 3599.95146439907,
    "input_throughput": 1401.6811198431844,
    "output_throughput": 1225.0645720125501,
    "total_throughput": 2626.7456918557345,
    "itl": 26.661120409900583,
    "ttft": 7324.042877039229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.552504259760218,
    "arrivals": 20275,
    "finished_requests": 20234,
    "scheduler_time": 0.09064376326775352
}
#Debug simulation 
Total elapsed time: 2.1519934269599617. Arrivals time: 0.06255184579640627 Scheduler time: 1.4484687084332108 Scheduler overhead time: 0.12249437347054482 Adapter cache time: 0.33832245459780097 Engine time: 0.1218485995195806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.1558172455988824,
    "estimated_duration": 3599.93964195021,
    "input_throughput": 1401.685723060184,
    "output_throughput": 1225.0685952086849,
    "total_throughput": 2626.754318268869,
    "itl": 26.66582986964718,
    "ttft": 7324.114436813955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2142,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.973861010267602,
    "arrivals": 20275,
    "finished_requests": 20234,
    "scheduler_time": 0.0907709454110543
}
#Debug simulation 
Total elapsed time: 2.155909625813365. Arrivals time: 0.06232751766219735 Scheduler time: 1.4487460004165769 Scheduler overhead time: 0.1248314194381237 Adapter cache time: 0.3414693991653621 Engine time: 0.11966412421315908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.141208700835705,
    "estimated_duration": 3599.9269542477396,
    "input_throughput": 1401.6906632080363,
    "output_throughput": 1225.0729128812486,
    "total_throughput": 2626.763576089285,
    "itl": 26.662483513432115,
    "ttft": 7324.108466177785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.6746393541034905,
    "arrivals": 20275,
    "finished_requests": 20234,
    "scheduler_time": 0.09066161047193656
}
#Debug simulation 
Total elapsed time: 2.1412869771011174. Arrivals time: 0.06275972165167332 Scheduler time: 1.4388521751388907 Scheduler overhead time: 0.12252661772072315 Adapter cache time: 0.337198032066226 Engine time: 0.12100707227364182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.1389680532738566,
    "estimated_duration": 3599.945876801796,
    "input_throughput": 1401.6832954396716,
    "output_throughput": 1225.0664734765435,
    "total_throughput": 2626.749768916215,
    "itl": 26.658664944721394,
    "ttft": 7324.10597154656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2141,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.401697681385367,
    "arrivals": 20275,
    "finished_requests": 20234,
    "scheduler_time": 0.09056024002689757
}
#Debug simulation 
Total elapsed time: 2.139053888153285. Arrivals time: 0.06243272311985493 Scheduler time: 1.4392432956956327 Scheduler overhead time: 0.12199123157188296 Adapter cache time: 0.33846187498420477 Engine time: 0.11887342529371381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.041355905123055,
    "estimated_duration": 3598.9692261511063,
    "input_throughput": 1267.8330136431186,
    "output_throughput": 1156.886802406125,
    "total_throughput": 2424.719816049244,
    "itl": 25.773208333822875,
    "ttft": 9947.276152837958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6021940746089403,
    "arrivals": 18900,
    "finished_requests": 18848,
    "scheduler_time": 0.01920438189075045
}
#Debug simulation 
Total elapsed time: 2.041436809115112. Arrivals time: 0.05850990256294608 Scheduler time: 1.3616746892221272 Scheduler overhead time: 0.12491921801120043 Adapter cache time: 0.31325023574754596 Engine time: 0.12361277220770717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.0262789642438293,
    "estimated_duration": 3598.9501054075627,
    "input_throughput": 1267.839749471402,
    "output_throughput": 1156.892948791935,
    "total_throughput": 2424.7326982633367,
    "itl": 25.775673648848212,
    "ttft": 9947.34162578547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8277786625223236,
    "arrivals": 18900,
    "finished_requests": 18848,
    "scheduler_time": 0.01926100920332795
}
#Debug simulation 
Total elapsed time: 2.0263557210564613. Arrivals time: 0.05852971551939845 Scheduler time: 1.3482765494845808 Scheduler overhead time: 0.1252056760713458 Adapter cache time: 0.31289152381941676 Engine time: 0.12184677505865693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.0520058451220393,
    "estimated_duration": 3598.952119596615,
    "input_throughput": 1267.8390399123807,
    "output_throughput": 1156.892301325385,
    "total_throughput": 2424.7313412377657,
    "itl": 25.773689066428815,
    "ttft": 9947.289651631854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.664749130464576,
    "arrivals": 18900,
    "finished_requests": 18848,
    "scheduler_time": 0.019249458521205454
}
#Debug simulation 
Total elapsed time: 2.0520852031186223. Arrivals time: 0.05859597260132432 Scheduler time: 1.3733581369742751 Scheduler overhead time: 0.12531756004318595 Adapter cache time: 0.3133964268490672 Engine time: 0.12173381447792053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.053831631783396,
    "estimated_duration": 3598.955073979178,
    "input_throughput": 1267.837999143192,
    "output_throughput": 1156.8913516323846,
    "total_throughput": 2424.7293507755767,
    "itl": 25.772568499779233,
    "ttft": 9947.251585994385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5192891970997726,
    "arrivals": 18900,
    "finished_requests": 18848,
    "scheduler_time": 0.019189745508599632
}
#Debug simulation 
Total elapsed time: 2.0539116766303778. Arrivals time: 0.05871352180838585 Scheduler time: 1.371204364579171 Scheduler overhead time: 0.12500109523534775 Adapter cache time: 0.3166773496195674 Engine time: 0.12268437119200826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.8399995593354106,
    "estimated_duration": 3599.927392323423,
    "input_throughput": 1096.9382350379428,
    "output_throughput": 1001.5418665633126,
    "total_throughput": 2098.4801016012557,
    "itl": 24.07068700742937,
    "ttft": 5628.408646159581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5562867584499473,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8401029668748379. Arrivals time: 0.05252801859751344 Scheduler time: 1.1941442261449993 Scheduler overhead time: 0.13210999453440309 Adapter cache time: 0.2675940403714776 Engine time: 0.13040717877447605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8298179502598941,
    "estimated_duration": 3599.947220893577,
    "input_throughput": 1096.9321930835993,
    "output_throughput": 1001.5363500537794,
    "total_throughput": 2098.4685431373787,
    "itl": 24.072082904223027,
    "ttft": 5628.306989618004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.777207573640626,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8298970479518175. Arrivals time: 0.05255388654768467 Scheduler time: 1.185782347805798 Scheduler overhead time: 0.13189947418868542 Adapter cache time: 0.2669258862733841 Engine time: 0.12990552745759487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.8327215928584337,
    "estimated_duration": 3599.9336957613855,
    "input_throughput": 1096.9363143130915,
    "output_throughput": 1001.5401128762851,
    "total_throughput": 2098.4764271893764,
    "itl": 24.07057837264692,
    "ttft": 5628.420959096073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.617855399448843,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8327960120514035. Arrivals time: 0.051933106034994125 Scheduler time: 1.1905664359219372 Scheduler overhead time: 0.13174239872023463 Adapter cache time: 0.2666935524903238 Engine time: 0.12887931428849697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.8335044411942363,
    "estimated_duration": 3599.94265280613,
    "input_throughput": 1096.9335850174896,
    "output_throughput": 1001.5376209366989,
    "total_throughput": 2098.4712059541885,
    "itl": 24.06909656013197,
    "ttft": 5628.403335558795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4744384426762416,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8336124899797142. Arrivals time: 0.05190659826621413 Scheduler time: 1.1915197162888944 Scheduler overhead time: 0.13178176386281848 Adapter cache time: 0.2660822896286845 Engine time: 0.12885617138817906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.3951033321209252,
    "estimated_duration": 3599.8954854722533,
    "input_throughput": 679.4675039514708,
    "output_throughput": 621.0666418018798,
    "total_throughput": 1300.5341457533505,
    "itl": 20.845065098729773,
    "ttft": 5693.474191256368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.626677976560403,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3951630368828773. Arrivals time: 0.0387909566052258 Scheduler time: 0.8041913248598576 Scheduler overhead time: 0.14431432308629155 Adapter cache time: 0.19330809451639652 Engine time: 0.14366078469902277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.3775611617602408,
    "estimated_duration": 3599.9123005278097,
    "input_throughput": 679.4643301842026,
    "output_throughput": 621.0637408228519,
    "total_throughput": 1300.5280710070545,
    "itl": 20.846865008874403,
    "ttft": 5693.548816939303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8631397337978743,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3776408676058054. Arrivals time: 0.039032661356031895 Scheduler time: 0.7897244431078434 Scheduler overhead time: 0.14488201076164842 Adapter cache time: 0.19354922138154507 Engine time: 0.140569812618196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.3818603260442615,
    "estimated_duration": 3599.90782897379,
    "input_throughput": 679.465174167327,
    "output_throughput": 621.0645122648439,
    "total_throughput": 1300.5296864321708,
    "itl": 20.84586121961784,
    "ttft": 5693.535042539114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6935726766450796,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3819327647797763. Arrivals time: 0.03911922359839082 Scheduler time: 0.7937773782759905 Scheduler overhead time: 0.1431045439094305 Adapter cache time: 0.1936685750260949 Engine time: 0.1421999866142869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 320,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_320_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.3853314206935465,
    "estimated_duration": 3599.9056345737126,
    "input_throughput": 679.4655883499701,
    "output_throughput": 621.0648908481047,
    "total_throughput": 1300.5304791980748,
    "itl": 20.844879137951224,
    "ttft": 5693.56745831718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.543209599458989,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.385407380759716. Arrivals time: 0.03915503202006221 Scheduler time: 0.7970613613724709 Scheduler overhead time: 0.14401916274800897 Adapter cache time: 0.19328084820881486 Engine time: 0.14198941318318248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.036092844326049,
    "estimated_duration": 3600.1120120518194,
    "input_throughput": 2564.368822162947,
    "output_throughput": 2258.0077988648404,
    "total_throughput": 4822.376621027787,
    "itl": 369.69247021442794,
    "ttft": 2480405.539894592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 2579962,
    "finished_requests": 37630,
    "scheduler_time": 22.78106398041881
}
#Debug simulation 
Total elapsed time: 3.0361561230383813. Arrivals time: 0.1866351393982768 Scheduler time: 2.665538809262216 Scheduler overhead time: 0.01576135354116559 Adapter cache time: 0.14445231389254332 Engine time: 0.016549091786146164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.449961008038372,
    "estimated_duration": 3600.0796697984365,
    "input_throughput": 2625.6930032132436,
    "output_throughput": 2334.9294379561984,
    "total_throughput": 4960.622441169442,
    "itl": 144.1242545906194,
    "ttft": 2489868.9682136024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631698,
    "arrivals": 2579962,
    "finished_requests": 38508,
    "scheduler_time": 6.423651317943442
}
#Debug simulation 
Total elapsed time: 3.4500294481404126. Arrivals time: 0.18945854483172297 Scheduler time: 2.8023513103835285 Scheduler overhead time: 0.03548858733847737 Adapter cache time: 0.3687151335179806 Engine time: 0.03731373092159629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.471421331167221,
    "estimated_duration": 3600.0275915178318,
    "input_throughput": 2625.7309866935166,
    "output_throughput": 2334.963215228003,
    "total_throughput": 4960.694201921519,
    "itl": 144.12185412971832,
    "ttft": 2489838.204373111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027997,
    "arrivals": 2579962,
    "finished_requests": 38508,
    "scheduler_time": 6.423873238098982
}
#Debug simulation 
Total elapsed time: 3.4715114571154118. Arrivals time: 0.19509717961773276 Scheduler time: 2.8183157802559435 Scheduler overhead time: 0.03582002827897668 Adapter cache time: 0.3676444753073156 Engine time: 0.0377609864808619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4368349560536444,
    "estimated_duration": 3600.032868019076,
    "input_throughput": 2613.22391902955,
    "output_throughput": 2324.371278477911,
    "total_throughput": 4937.59519750746,
    "itl": 143.47382410405206,
    "ttft": 2492227.788622437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 2579962,
    "finished_requests": 38339,
    "scheduler_time": 6.135339482127968
}
#Debug simulation 
Total elapsed time: 3.436895551159978. Arrivals time: 0.18934520334005356 Scheduler time: 2.7896930747665465 Scheduler overhead time: 0.036024336237460375 Adapter cache time: 0.36726903822273016 Engine time: 0.037801400292664766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.098744098097086,
    "estimated_duration": 3600.0347580839652,
    "input_throughput": 2716.267385486151,
    "output_throughput": 2388.458328268022,
    "total_throughput": 5104.725713754173,
    "itl": 351.8078307644879,
    "ttft": 2453132.5812272634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 2395765,
    "finished_requests": 39828,
    "scheduler_time": 24.184180343995877
}
#Debug simulation 
Total elapsed time: 3.0988375549204648. Arrivals time: 0.1895853355526924 Scheduler time: 2.7425260404124856 Scheduler overhead time: 0.016480830498039722 Adapter cache time: 0.1253970074467361 Engine time: 0.017252390272915363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.534452462103218,
    "estimated_duration": 3600.0232404352664,
    "input_throughput": 2722.6743677396125,
    "output_throughput": 2420.6963172122055,
    "total_throughput": 5143.3706849518185,
    "itl": 140.6006147264577,
    "ttft": 2470108.4848215496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.25277971476317,
    "arrivals": 2395765,
    "finished_requests": 39929,
    "scheduler_time": 6.9511102395701165
}
#Debug simulation 
Total elapsed time: 3.534515650011599. Arrivals time: 0.20675282273441553 Scheduler time: 2.8960289754904807 Scheduler overhead time: 0.0364939346909523 Adapter cache time: 0.3397908410988748 Engine time: 0.03825801610946655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.700681447982788,
    "estimated_duration": 3600.1304993350955,
    "input_throughput": 2722.694358387934,
    "output_throughput": 2420.7089164155414,
    "total_throughput": 5143.403274803475,
    "itl": 140.59759123509485,
    "ttft": 2470108.468992531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 2395765,
    "finished_requests": 39932,
    "scheduler_time": 6.951703552699978
}
#Debug simulation 
Total elapsed time: 3.700744401663542. Arrivals time: 0.1936893193051219 Scheduler time: 3.0722567262127995 Scheduler overhead time: 0.03651455510407686 Adapter cache time: 0.3430404528044164 Engine time: 0.03805948793888092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5122876460663974,
    "estimated_duration": 3600.0125635328704,
    "input_throughput": 2720.814115822895,
    "output_throughput": 2418.6051704929,
    "total_throughput": 5139.419286315795,
    "itl": 139.89766279447034,
    "ttft": 2470941.007861512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 2395765,
    "finished_requests": 39890,
    "scheduler_time": 6.77140875564183
}
#Debug simulation 
Total elapsed time: 3.5124051230959594. Arrivals time: 0.19214332988485694 Scheduler time: 2.885280089918524 Scheduler overhead time: 0.03678347868844867 Adapter cache time: 0.3426620000973344 Engine time: 0.038289204239845276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.3053741310723126,
    "estimated_duration": 3600.3467291784073,
    "input_throughput": 2995.661476877038,
    "output_throughput": 2634.9481629411994,
    "total_throughput": 5630.609639818237,
    "itl": 317.7512148581034,
    "ttft": 2417816.8131990354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 2257312,
    "finished_requests": 43524,
    "scheduler_time": 26.457622992129142
}
#Debug simulation 
Total elapsed time: 3.3054417348466814. Arrivals time: 0.19946996727958322 Scheduler time: 2.9754144209437072 Scheduler overhead time: 0.0177664952352643 Adapter cache time: 0.0859501357190311 Engine time: 0.01854813192039728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.764658560976386,
    "estimated_duration": 3600.038923447183,
    "input_throughput": 2853.924143176208,
    "output_throughput": 2530.499306734413,
    "total_throughput": 5384.4234499106215,
    "itl": 132.99791408947064,
    "ttft": 2455062.484223677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.25277971476317,
    "arrivals": 2257312,
    "finished_requests": 41446,
    "scheduler_time": 6.896126581255342
}
#Debug simulation 
Total elapsed time: 3.7647510659880936. Arrivals time: 0.36230758810415864 Scheduler time: 3.000781959388405 Scheduler overhead time: 0.03821924142539501 Adapter cache time: 0.30551734659820795 Engine time: 0.03997319098562002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.6267730789259076,
    "estimated_duration": 3600.134534720745,
    "input_throughput": 2853.8669599459727,
    "output_throughput": 2530.5540423940492,
    "total_throughput": 5384.421002340022,
    "itl": 132.99630132521537,
    "ttft": 2455030.935772345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 2257312,
    "finished_requests": 41447,
    "scheduler_time": 6.896598649651051
}
#Debug simulation 
Total elapsed time: 3.6268391208723187. Arrivals time: 0.20419338066130877 Scheduler time: 3.021231911610812 Scheduler overhead time: 0.038365719839930534 Adapter cache time: 0.30490252329036593 Engine time: 0.04009036859497428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.60469800978899,
    "estimated_duration": 3600.1133380320584,
    "input_throughput": 2851.1135723329267,
    "output_throughput": 2528.4598414826187,
    "total_throughput": 5379.573413815546,
    "itl": 132.48720551205207,
    "ttft": 2455203.279124799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 2257312,
    "finished_requests": 41415,
    "scheduler_time": 6.752093023674038
}
#Debug simulation 
Total elapsed time: 3.60476547293365. Arrivals time: 0.19378937082365155 Scheduler time: 3.0067125596106052 Scheduler overhead time: 0.038625120650976896 Adapter cache time: 0.307239324785769 Engine time: 0.040284490678459406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.3552184905856848,
    "estimated_duration": 3600.012895029822,
    "input_throughput": 3044.937148734628,
    "output_throughput": 2704.3214243596067,
    "total_throughput": 5749.258573094235,
    "itl": 311.9887342222105,
    "ttft": 2413784.9477774086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1721668059262493,
    "arrivals": 2233996,
    "finished_requests": 44592,
    "scheduler_time": 27.22429767368698
}
#Debug simulation 
Total elapsed time: 3.355299924965948. Arrivals time: 0.19946877285838127 Scheduler time: 3.035825530067086 Scheduler overhead time: 0.018066414166241884 Adapter cache time: 0.07473425660282373 Engine time: 0.018857876770198345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.6022633919492364,
    "estimated_duration": 3600.1386289581433,
    "input_throughput": 2853.6020578110474,
    "output_throughput": 2558.333705795495,
    "total_throughput": 5411.935763606542,
    "itl": 132.54180863384815,
    "ttft": 2457264.669301264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.249381069149827,
    "arrivals": 2233996,
    "finished_requests": 41803,
    "scheduler_time": 7.196006474034779
}
#Debug simulation 
Total elapsed time: 3.6023252429440618. Arrivals time: 0.19508543703705072 Scheduler time: 3.02497375337407 Scheduler overhead time: 0.038497989531606436 Adapter cache time: 0.28547109523788095 Engine time: 0.040259554516524076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.760124208871275,
    "estimated_duration": 3600.0865288379105,
    "input_throughput": 2853.6433548768587,
    "output_throughput": 2558.370729764947,
    "total_throughput": 5412.014084641806,
    "itl": 132.53971032743144,
    "ttft": 2457235.571081376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1970808683894565,
    "arrivals": 2233996,
    "finished_requests": 41803,
    "scheduler_time": 7.19620655455906
}
#Debug simulation 
Total elapsed time: 3.760196811053902. Arrivals time: 0.3641854473389685 Scheduler time: 3.012930728495121 Scheduler overhead time: 0.038578472565859556 Adapter cache time: 0.28641037875786424 Engine time: 0.04005645355209708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5909150051884353,
    "estimated_duration": 3600.1068867808435,
    "input_throughput": 2853.6633280870137,
    "output_throughput": 2558.418760792947,
    "total_throughput": 5412.082088879961,
    "itl": 132.40941002798436,
    "ttft": 2457217.660617128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1451892629475295,
    "arrivals": 2233996,
    "finished_requests": 41804,
    "scheduler_time": 7.165339705380567
}
#Debug simulation 
Total elapsed time: 3.5909809269942343. Arrivals time: 0.19347989931702614 Scheduler time: 3.0128446868620813 Scheduler overhead time: 0.03853600099682808 Adapter cache time: 0.2879923996515572 Engine time: 0.040129989851266146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.399024625774473,
    "estimated_duration": 3600.328795301991,
    "input_throughput": 3128.387611347384,
    "output_throughput": 2729.420438717387,
    "total_throughput": 5857.808050064771,
    "itl": 306.25879902559996,
    "ttft": 2394452.795865386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 367,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1231990020233236,
    "arrivals": 2222461,
    "finished_requests": 45443,
    "scheduler_time": 27.441759109302026
}
#Debug simulation 
Total elapsed time: 3.399095444008708. Arrivals time: 0.20251852506771684 Scheduler time: 3.0809319745749235 Scheduler overhead time: 0.01844603940844536 Adapter cache time: 0.06933204550296068 Engine time: 0.01922992616891861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.807779551949352,
    "estimated_duration": 3600.04237787886,
    "input_throughput": 2932.215483035408,
    "output_throughput": 2579.576023066607,
    "total_throughput": 5511.791506102015,
    "itl": 130.1522300246553,
    "ttft": 2439250.3114888817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1808696784987165,
    "arrivals": 2222461,
    "finished_requests": 42599,
    "scheduler_time": 7.025134461323523
}
#Debug simulation 
Total elapsed time: 3.8078726707026362. Arrivals time: 0.3684123051352799 Scheduler time: 3.0581796634942293 Scheduler overhead time: 0.03916630754247308 Adapter cache time: 0.2829533414915204 Engine time: 0.040796182584017515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.6331545277498662,
    "estimated_duration": 3600.1139318144747,
    "input_throughput": 2928.1414976461483,
    "output_throughput": 2575.849313559415,
    "total_throughput": 5503.990811205563,
    "itl": 129.9144951435735,
    "ttft": 2439912.952437598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1318382402858702,
    "arrivals": 2222461,
    "finished_requests": 42540,
    "scheduler_time": 6.9162475005979465
}
#Debug simulation 
Total elapsed time: 3.633218800649047. Arrivals time: 0.1963473823852837 Scheduler time: 3.056296646595001 Scheduler overhead time: 0.03926184680312872 Adapter cache time: 0.2820503222756088 Engine time: 0.040839490946382284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.627330433111638,
    "estimated_duration": 3600.1171957365036,
    "input_throughput": 2934.3150307746764,
    "output_throughput": 2581.0231986348062,
    "total_throughput": 5515.338229409483,
    "itl": 130.50218250763072,
    "ttft": 2438935.2478403794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.082398206754586,
    "arrivals": 2222461,
    "finished_requests": 42625,
    "scheduler_time": 7.12595572631497
}
#Debug simulation 
Total elapsed time: 3.6274315398186445. Arrivals time: 0.19697584910318255 Scheduler time: 3.0507145887240767 Scheduler overhead time: 0.03888142295181751 Adapter cache time: 0.2819991665892303 Engine time: 0.04061895050108433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.604300491977483,
    "estimated_duration": 3600.085841569556,
    "input_throughput": 3131.0022860693,
    "output_throughput": 2739.516065455866,
    "total_throughput": 5870.518351525166,
    "itl": 304.84846349078686,
    "ttft": 2401304.503330916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0222029064735392,
    "arrivals": 2216625,
    "finished_requests": 45405,
    "scheduler_time": 27.50005894796394
}
#Debug simulation 
Total elapsed time: 3.6043698051944375. Arrivals time: 0.3776248195208609 Scheduler time: 3.1157020833343267 Scheduler overhead time: 0.01843613898381591 Adapter cache time: 0.06466090539470315 Engine time: 0.019377806689590216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7726447442546487,
    "estimated_duration": 3600.049341622818,
    "input_throughput": 2913.5992328571137,
    "output_throughput": 2572.8472365394687,
    "total_throughput": 5486.446469396583,
    "itl": 131.02057984837893,
    "ttft": 2447378.777603382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0842220492381656,
    "arrivals": 2216625,
    "finished_requests": 42243,
    "scheduler_time": 7.075016554414482
}
#Debug simulation 
Total elapsed time: 3.7727341651916504. Arrivals time: 0.3666644971817732 Scheduler time: 3.0358069352805614 Scheduler overhead time: 0.03888692241162062 Adapter cache time: 0.2723714616149664 Engine time: 0.04074432281777263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.133541657123715,
    "estimated_duration": 3600.003779560353,
    "input_throughput": 2913.636107704579,
    "output_throughput": 2572.8797987904222,
    "total_throughput": 5486.515906495001,
    "itl": 131.01885258183145,
    "ttft": 2447353.197958469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0384593735728445,
    "arrivals": 2216625,
    "finished_requests": 42243,
    "scheduler_time": 7.075217167612696
}
#Debug simulation 
Total elapsed time: 4.133603009860963. Arrivals time: 0.7214183658361435 Scheduler time: 3.0418836129829288 Scheduler overhead time: 0.03873769100755453 Adapter cache time: 0.27297125896438956 Engine time: 0.040325567591935396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7849545311182737,
    "estimated_duration": 3600.0981267260436,
    "input_throughput": 2913.7394678570763,
    "output_throughput": 2572.9179244410266,
    "total_throughput": 5486.657392298103,
    "itl": 131.01450665978678,
    "ttft": 2447458.144124867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9926966979075237,
    "arrivals": 2216625,
    "finished_requests": 42247,
    "scheduler_time": 7.0756354184079155
}
#Debug simulation 
Total elapsed time: 3.785018772352487. Arrivals time: 0.36910054832696915 Scheduler time: 3.044750310946256 Scheduler overhead time: 0.0390538671053946 Adapter cache time: 0.27336249500513077 Engine time: 0.04046917799860239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4024709197692573,
    "estimated_duration": 3600.2832589228533,
    "input_throughput": 3111.434905083405,
    "output_throughput": 2754.5407643750355,
    "total_throughput": 5865.97566945844,
    "itl": 305.69596424717,
    "ttft": 2400443.4343230547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9242672986676904,
    "arrivals": 2213766,
    "finished_requests": 45543,
    "scheduler_time": 27.74629863802091
}
#Debug simulation 
Total elapsed time: 3.402555631007999. Arrivals time: 0.20465893065556884 Scheduler time: 3.0918304813094437 Scheduler overhead time: 0.01850869646295905 Adapter cache time: 0.059724846854805946 Engine time: 0.01929279137402773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.607336011249572,
    "estimated_duration": 3600.025819987427,
    "input_throughput": 2880.999892394167,
    "output_throughput": 2571.8226654364207,
    "total_throughput": 5452.822557830587,
    "itl": 130.78589263359288,
    "ttft": 2448516.476486855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9783255568402874,
    "arrivals": 2213766,
    "finished_requests": 42203,
    "scheduler_time": 7.000752266231335
}
#Debug simulation 
Total elapsed time: 3.607398385182023. Arrivals time: 0.19769963342696428 Scheduler time: 3.0459844921715558 Scheduler overhead time: 0.039049901999533176 Adapter cache time: 0.2655610949732363 Engine time: 0.040730906650424004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.615490878932178,
    "estimated_duration": 3600.130064885357,
    "input_throughput": 2880.916470535982,
    "output_throughput": 2571.7481960738082,
    "total_throughput": 5452.66466660979,
    "itl": 130.78439237241764,
    "ttft": 2448459.073798285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9370574296778098,
    "arrivals": 2213766,
    "finished_requests": 42203,
    "scheduler_time": 7.001243505028219
}
#Debug simulation 
Total elapsed time: 3.6155857988633215. Arrivals time: 0.19644039496779442 Scheduler time: 3.0561507581733167 Scheduler overhead time: 0.03907803352922201 Adapter cache time: 0.2648831680417061 Engine time: 0.04064942291006446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.641057045198977,
    "estimated_duration": 3600.100528362197,
    "input_throughput": 2885.497479351188,
    "output_throughput": 2576.957206309055,
    "total_throughput": 5462.454685660243,
    "itl": 131.26083289823504,
    "ttft": 2447854.6012662253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8970150884706539,
    "arrivals": 2213766,
    "finished_requests": 42275,
    "scheduler_time": 7.171199505898228
}
#Debug simulation 
Total elapsed time: 3.6411252291873097. Arrivals time: 0.20744061237201095 Scheduler time: 3.072564204223454 Scheduler overhead time: 0.038948905654251575 Adapter cache time: 0.2632018360309303 Engine time: 0.04068457102403045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.433247716166079,
    "estimated_duration": 3600.0288908509865,
    "input_throughput": 3155.7435633008226,
    "output_throughput": 2763.6155991093174,
    "total_throughput": 5919.35916241014,
    "itl": 304.17338089084853,
    "ttft": 2392237.7034231992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8508155928133044,
    "arrivals": 2212338,
    "finished_requests": 46175,
    "scheduler_time": 27.855079325325097
}
#Debug simulation 
Total elapsed time: 3.433311221189797. Arrivals time: 0.20432611601427197 Scheduler time: 3.127086668740958 Scheduler overhead time: 0.01842932403087616 Adapter cache time: 0.05571721214801073 Engine time: 0.01914969552308321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.5964249237440526,
    "estimated_duration": 3600.038073662374,
    "input_throughput": 2921.261882461495,
    "output_throughput": 2588.050406511838,
    "total_throughput": 5509.312288973333,
    "itl": 130.95975658865606,
    "ttft": 2441383.1169312205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9046512562362523,
    "arrivals": 2212338,
    "finished_requests": 42855,
    "scheduler_time": 7.31494875888066
}
#Debug simulation 
Total elapsed time: 3.596504784654826. Arrivals time: 0.1972705884836614 Scheduler time: 3.0473182797431946 Scheduler overhead time: 0.03975129034370184 Adapter cache time: 0.2532899035140872 Engine time: 0.04053598828613758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.568112939130515,
    "estimated_duration": 3600.1418551500815,
    "input_throughput": 2916.9078393335217,
    "output_throughput": 2584.459828073114,
    "total_throughput": 5501.3676674066355,
    "itl": 130.88998770291647,
    "ttft": 2441718.6309763743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8674690822581785,
    "arrivals": 2212338,
    "finished_requests": 42793,
    "scheduler_time": 7.2481034194911516
}
#Debug simulation 
Total elapsed time: 3.5681768101640046. Arrivals time: 0.19416284328326583 Scheduler time: 3.0286902775987983 Scheduler overhead time: 0.038579387590289116 Adapter cache time: 0.2488711173646152 Engine time: 0.039849638007581234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_384_slots_384_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.7487859721295536,
    "estimated_duration": 3600.1028620404722,
    "input_throughput": 2916.9394326827833,
    "output_throughput": 2584.4878206414423,
    "total_throughput": 5501.427253324226,
    "itl": 130.88846081769842,
    "ttft": 2441695.0663133357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8282439316879038,
    "arrivals": 2212338,
    "finished_requests": 42793,
    "scheduler_time": 7.248335460451423
}
#Debug simulation 
Total elapsed time: 3.7488678647205234. Arrivals time: 0.3683533235453069 Scheduler time: 3.0360372052527964 Scheduler overhead time: 0.03861925844103098 Adapter cache time: 0.24766143690794706 Engine time: 0.04003332369029522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.184786376077682,
    "estimated_duration": 3600.034646124273,
    "input_throughput": 2819.4539769019816,
    "output_throughput": 2486.016352546807,
    "total_throughput": 5305.470329448789,
    "itl": 336.8053056637675,
    "ttft": 2440594.975136335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 2026382,
    "finished_requests": 41210,
    "scheduler_time": 25.045686315770396
}
#Debug simulation 
Total elapsed time: 3.18485061917454. Arrivals time: 0.19066079147160053 Scheduler time: 2.8132547587156296 Scheduler overhead time: 0.016805716790258884 Adapter cache time: 0.1388163841329515 Engine time: 0.017521526664495468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.621607253793627,
    "estimated_duration": 3600.0055628163386,
    "input_throughput": 2852.3922590738157,
    "output_throughput": 2537.789411873221,
    "total_throughput": 5390.181670947037,
    "itl": 131.984351778504,
    "ttft": 2453604.0302558783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631694,
    "arrivals": 2026382,
    "finished_requests": 41678,
    "scheduler_time": 6.812086805102134
}
#Debug simulation 
Total elapsed time: 3.6216986631043255. Arrivals time: 0.19573424570262432 Scheduler time: 3.0049954946152866 Scheduler overhead time: 0.038374120369553566 Adapter cache time: 0.3245994923636317 Engine time: 0.03990169940516353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.5882799020037055,
    "estimated_duration": 3600.103014925382,
    "input_throughput": 2852.47893113771,
    "output_throughput": 2537.7754364591046,
    "total_throughput": 5390.2543675968145,
    "itl": 131.9816811414132,
    "ttft": 2453619.668492813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 2026382,
    "finished_requests": 41681,
    "scheduler_time": 6.81256769482604
}
#Debug simulation 
Total elapsed time: 3.5883454950526357. Arrivals time: 0.1846775310114026 Scheduler time: 2.983706041239202 Scheduler overhead time: 0.03827081574127078 Adapter cache time: 0.3235247195698321 Engine time: 0.040185640566051006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5657163448631763,
    "estimated_duration": 3600.0986155954915,
    "input_throughput": 2854.9992923735153,
    "output_throughput": 2539.6732079484013,
    "total_throughput": 5394.672500321916,
    "itl": 132.70698444666604,
    "ttft": 2453026.0999769457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 2026382,
    "finished_requests": 41718,
    "scheduler_time": 7.019510893124428
}
#Debug simulation 
Total elapsed time: 3.5657794177532196. Arrivals time: 0.17799310153350234 Scheduler time: 2.972160177771002 Scheduler overhead time: 0.03799453051760793 Adapter cache time: 0.32072488171979785 Engine time: 0.03911799378693104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4137684609740973,
    "estimated_duration": 3600.124207538546,
    "input_throughput": 3115.1833529843348,
    "output_throughput": 2736.7241883958,
    "total_throughput": 5851.907541380135,
    "itl": 306.54879961763925,
    "ttft": 2389261.9261989854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1752272936701822,
    "arrivals": 1888011,
    "finished_requests": 45431,
    "scheduler_time": 27.58004679355885
}
#Debug simulation 
Total elapsed time: 3.4138598991557956. Arrivals time: 0.19222399266436696 Scheduler time: 3.0679363179951906 Scheduler overhead time: 0.018169849645346403 Adapter cache time: 0.10839464329183102 Engine time: 0.01867094961926341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.667436467949301,
    "estimated_duration": 3600.0390878077283,
    "input_throughput": 3006.1554155486433,
    "output_throughput": 2661.0244406634174,
    "total_throughput": 5667.179856212061,
    "itl": 127.09663931910298,
    "ttft": 2421851.9453602945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2527797147631696,
    "arrivals": 1888011,
    "finished_requests": 43835,
    "scheduler_time": 7.399316071701677
}
#Debug simulation 
Total elapsed time: 3.667531260289252. Arrivals time: 0.18522255821153522 Scheduler time: 3.101114565040916 Scheduler overhead time: 0.03963174810633063 Adapter cache time: 0.28197395661845803 Engine time: 0.040982821490615606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.681792858056724,
    "estimated_duration": 3600.093204942547,
    "input_throughput": 3011.7348031751953,
    "output_throughput": 2666.158194688512,
    "total_throughput": 5677.892997863707,
    "itl": 126.81955926305655,
    "ttft": 2420465.9042300615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2004795140027995,
    "arrivals": 1888011,
    "finished_requests": 43921,
    "scheduler_time": 7.4104337714595445
}
#Debug simulation 
Total elapsed time: 3.6818835851736367. Arrivals time: 0.18384326063096523 Scheduler time: 3.1144388373941183 Scheduler overhead time: 0.03974627936258912 Adapter cache time: 0.2840009550563991 Engine time: 0.041215839330106974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.831075308844447,
    "estimated_duration": 3600.041124121498,
    "input_throughput": 3011.7783731278496,
    "output_throughput": 2666.1967652778576,
    "total_throughput": 5677.975138405707,
    "itl": 126.8174519343358,
    "ttft": 2420434.493922317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1481793132424316,
    "arrivals": 1888011,
    "finished_requests": 43921,
    "scheduler_time": 7.410653151170173
}
#Debug simulation 
Total elapsed time: 3.831164280883968. Arrivals time: 0.3294529551640153 Scheduler time: 3.1209133421070874 Scheduler overhead time: 0.040315630845725536 Adapter cache time: 0.2805382367223501 Engine time: 0.04123765975236893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.4764352161437273,
    "estimated_duration": 3600.008151983502,
    "input_throughput": 3218.9265998231845,
    "output_throughput": 2821.6797215870724,
    "total_throughput": 6040.606321410257,
    "itl": 298.1523484190648,
    "ttft": 2377504.336739029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1660458304383836,
    "arrivals": 1864865,
    "finished_requests": 46924,
    "scheduler_time": 28.408510282326663
}
#Debug simulation 
Total elapsed time: 3.4765283479355276. Arrivals time: 0.18808436207473278 Scheduler time: 3.1474314872175455 Scheduler overhead time: 0.01858093310147524 Adapter cache time: 0.09458712628111243 Engine time: 0.019070768263190985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.14036811562255,
    "estimated_duration": 3600.080226102743,
    "input_throughput": 3064.2872678263384,
    "output_throughput": 2704.275846246698,
    "total_throughput": 5768.563114073037,
    "itl": 124.24518200810277,
    "ttft": 2413454.8027060684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2438095638784639,
    "arrivals": 1864865,
    "finished_requests": 44610,
    "scheduler_time": 7.401631088803936
}
#Debug simulation 
Total elapsed time: 4.140429679770023. Arrivals time: 0.6320791896432638 Scheduler time: 3.1378295104950666 Scheduler overhead time: 0.04021660517901182 Adapter cache time: 0.26984403608366847 Engine time: 0.041557914577424526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7014148733578622,
    "estimated_duration": 3600.0514080427643,
    "input_throughput": 3062.1784942769486,
    "output_throughput": 2702.7455714278008,
    "total_throughput": 5764.924065704749,
    "itl": 124.45133736101552,
    "ttft": 2413707.188548986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.191509363118094,
    "arrivals": 1864865,
    "finished_requests": 44577,
    "scheduler_time": 7.42689413349261
}
#Debug simulation 
Total elapsed time: 3.7014762121252716. Arrivals time: 0.18560909386724234 Scheduler time: 3.147436023224145 Scheduler overhead time: 0.040188007056713104 Adapter cache time: 0.2677978998981416 Engine time: 0.041598889511078596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.840985480695963,
    "estimated_duration": 3600.042464553189,
    "input_throughput": 3067.958255700964,
    "output_throughput": 2707.043901830624,
    "total_throughput": 5775.002157531588,
    "itl": 124.51437262819049,
    "ttft": 2412823.040958108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 381,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1392091623577254,
    "arrivals": 1864865,
    "finished_requests": 44661,
    "scheduler_time": 7.515943347875057
}
#Debug simulation 
Total elapsed time: 3.8410769519396126. Arrivals time: 0.3274137335829437 Scheduler time: 3.145565167069435 Scheduler overhead time: 0.040094018913805485 Adapter cache time: 0.2676870566792786 Engine time: 0.04147523641586304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_384_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.5006995578296483,
    "estimated_duration": 3600.1891725884025,
    "input_throughput": 3288.955505492746,
    "output_throughput": 2863.103994224041,
    "total_throughput": 6152.059499716786,
    "itl": 292.5159947919385,
    "ttft": 2373050.376854876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1446224162308536,
    "arrivals": 1853406,
    "finished_requests": 47618,
    "scheduler_time": 28.796983859427215
}
#Debug simulation 
Total elapsed time: 3.5008003157563508. Arrivals time: 0.1930309603922069 Scheduler time: 3.1751411333680153 Scheduler overhead time: 0.018912966828793287 Adapter cache time: 0.08553543873131275 Engine time: 0.01935757789760828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_384_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.7117304261773825,
    "estimated_duration": 3600.096622323613,
    "input_throughput": 3107.582427268072,
    "output_throughput": 2723.4563481442733,
    "total_throughput": 5831.038775412346,
    "itl": 123.91790076059216,
    "ttft": 2412555.7387601766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2196104492666253,
    "arrivals": 1853406,
    "finished_requests": 44990,
    "scheduler_time": 7.565564398920662
}
#Debug simulation 
Total elapsed time: 3.7118199272081256. Arrivals time: 0.1865786644630134 Scheduler time: 3.1702416418120265 Scheduler overhead time: 0.04054127121344209 Adapter cache time: 0.2537094634026289 Engine time: 0.04166213795542717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_384_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.7087147077545524,
    "estimated_duration": 3600.0465673106683,
    "input_throughput": 3107.6256350643366,
    "output_throughput": 2723.494215055218,
    "total_throughput": 5831.119850119554,
    "itl": 123.91609527727087,
    "ttft": 2412528.1476723324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169353225098457,
    "arrivals": 1853406,
    "finished_requests": 44990,
    "scheduler_time": 7.565766610140675
}
#Debug simulation 
Total elapsed time: 3.708802070003003. Arrivals time: 0.18820823449641466 Scheduler time: 3.165187441278249 Scheduler overhead time: 0.04040712909772992 Adapter cache time: 0.25430450215935707 Engine time: 0.04170084558427334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 384,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 165664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_384_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.6851787427440286,
    "estimated_duration": 3600.134245942267,
    "input_throughput": 3107.689945898594,
    "output_throughput": 2723.55149285098,
    "total_throughput": 5831.241438749575,
    "itl": 123.91484817892638,
    "ttft": 2412495.187068227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 374,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.118278810293411,
    "arrivals": 1853406,
    "finished_requests": 44992,
    "scheduler_time": 7.566234674715266
}
#Debug simulation 
Total elapsed time: 3.6852680817246437. Arrivals time: 0.18717577029019594 Scheduler time: 3.142691624816507 Scheduler overhead time: 0.04013587208464742 Adapter cache time: 0.25500047020614147 Engine time: 0.04136134637519717 
