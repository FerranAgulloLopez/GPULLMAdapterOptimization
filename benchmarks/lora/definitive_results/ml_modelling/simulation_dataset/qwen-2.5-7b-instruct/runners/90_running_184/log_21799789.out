INFO 06-01 00:47:07 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:08 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.434984310064465,
    "estimated_duration": 3600.191796172884,
    "input_throughput": 4707.437258763799,
    "output_throughput": 4113.126699455683,
    "total_throughput": 8820.563958219482,
    "itl": 205.69846285395266,
    "ttft": 1449174.251921311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.756826371899745,
    "arrivals": 106283,
    "finished_requests": 68038,
    "scheduler_time": 60.8816973057153
}
#Debug simulation 
Total elapsed time: 5.4350888561457396. Arrivals time: 0.21058283699676394 Scheduler time: 5.13302840013057 Scheduler overhead time: 0.028852947056293488 Adapter cache time: 0.020638823974877596 Engine time: 0.02884081471711397 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [53 53 54]
Adapter prompts. [540, 4320, 540, 540, 1080, 540, 540, 540, 4320, 540, 1080, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 540, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 540, 1080, 1080, 1080, 4320, 540, 540, 4320, 540, 4320, 540, 540, 1080, 540, 1080, 4320, 540, 540, 1080, 540, 540, 540, 540, 540, 4320, 1080, 1080, 4320, 1080, 540, 4320, 4320, 4320, 1080, 1080, 540, 540, 540, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 540, 540, 4320, 1080, 4320, 4320, 540, 4320, 540, 1080, 540, 540, 1080, 1080, 4320, 4320, 4320, 540, 4320, 1080, 1080, 540, 540, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 540, 1080, 1080, 4320, 1080, 4320, 540, 540, 540, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 540, 1080, 1080, 540, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 540, 4320, 540, 4320, 1080, 540, 1080, 540, 540, 1080, 1080, 1080, 4320, 1080, 540, 540]
Prompts retrieved: 319140 . Total input tokens: 71158771 . Total output tokens: 63858637
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.012705102562904,
    "estimated_duration": 3600.1680857109886,
    "input_throughput": 4517.158258400691,
    "output_throughput": 3954.9000660584743,
    "total_throughput": 8472.058324459165,
    "itl": 173.9486376054502,
    "ttft": 1506926.0116995908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.838069485574937,
    "arrivals": 106283,
    "finished_requests": 65253,
    "scheduler_time": 58.592260354580034
}
#Debug simulation 
Total elapsed time: 5.012841012794524. Arrivals time: 0.20254020020365715 Scheduler time: 4.698253483977169 Scheduler overhead time: 0.03322223713621497 Adapter cache time: 0.030832672957330942 Engine time: 0.0329013136215508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.057539933361113,
    "estimated_duration": 3600.102730763659,
    "input_throughput": 4683.993836037847,
    "output_throughput": 4123.346501518075,
    "total_throughput": 8807.340337555921,
    "itl": 206.5206180057443,
    "ttft": 1415322.9305118516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.033722846503474,
    "arrivals": 101554,
    "finished_requests": 67875,
    "scheduler_time": 60.70460974066684
}
#Debug simulation 
Total elapsed time: 5.057624114211649. Arrivals time: 0.20210010325536132 Scheduler time: 4.758339615538716 Scheduler overhead time: 0.02852663490921259 Adapter cache time: 0.02722873166203499 Engine time: 0.02844134671613574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.052263336721808,
    "estimated_duration": 3600.0991993757702,
    "input_throughput": 4683.3620592797815,
    "output_throughput": 4123.298325383335,
    "total_throughput": 8806.660384663117,
    "itl": 206.53937133443998,
    "ttft": 1415385.9604164446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.303142560829848,
    "arrivals": 101554,
    "finished_requests": 67871,
    "scheduler_time": 60.70077805126946
}
#Debug simulation 
Total elapsed time: 5.052352648694068. Arrivals time: 0.2061426267027855 Scheduler time: 4.749623435083777 Scheduler overhead time: 0.028397769667208195 Adapter cache time: 0.02679768530651927 Engine time: 0.028489266987890005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.834685118868947,
    "estimated_duration": 3600.1771664356984,
    "input_throughput": 4502.563693566362,
    "output_throughput": 3966.950052666271,
    "total_throughput": 8469.513746232633,
    "itl": 174.98807857961106,
    "ttft": 1472727.5449328083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.70126758167515,
    "arrivals": 101554,
    "finished_requests": 65176,
    "scheduler_time": 58.545417493036894
}
#Debug simulation 
Total elapsed time: 4.8347730580717325. Arrivals time: 0.1983446879312396 Scheduler time: 4.514321688562632 Scheduler overhead time: 0.0328089720569551 Adapter cache time: 0.041686886455863714 Engine time: 0.03271539369598031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.076439625117928,
    "estimated_duration": 3600.0058834107135,
    "input_throughput": 4683.57845682898,
    "output_throughput": 4123.301039146248,
    "total_throughput": 8806.879495975229,
    "itl": 206.5269909230565,
    "ttft": 1415323.0706027104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.126388563252932,
    "arrivals": 101554,
    "finished_requests": 67871,
    "scheduler_time": 60.70151520889677
}
#Debug simulation 
Total elapsed time: 5.076560882851481. Arrivals time: 0.21012779138982296 Scheduler time: 4.768627893179655 Scheduler overhead time: 0.028682630974799395 Adapter cache time: 0.027549412567168474 Engine time: 0.028607530519366264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.84289315296337,
    "estimated_duration": 3600.0044300647764,
    "input_throughput": 4502.394737249907,
    "output_throughput": 3966.8317851883985,
    "total_throughput": 8469.226522438305,
    "itl": 174.99828578073522,
    "ttft": 1472856.2421067103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2057,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.792455048803106,
    "arrivals": 101554,
    "finished_requests": 65170,
    "scheduler_time": 58.5418181857117
}
#Debug simulation 
Total elapsed time: 4.842983191367239. Arrivals time: 0.207931375131011 Scheduler time: 4.5123873027041554 Scheduler overhead time: 0.03293133107945323 Adapter cache time: 0.04180942662060261 Engine time: 0.032914559822529554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.051870630122721,
    "estimated_duration": 3600.099119072437,
    "input_throughput": 4684.043533874908,
    "output_throughput": 4123.737571932471,
    "total_throughput": 8807.781105807378,
    "itl": 206.51336089959773,
    "ttft": 1415258.0151964817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.93490618809116,
    "arrivals": 101554,
    "finished_requests": 67880,
    "scheduler_time": 60.70575002098846
}
#Debug simulation 
Total elapsed time: 5.051958306226879. Arrivals time: 0.2055576890707016 Scheduler time: 4.749064365401864 Scheduler overhead time: 0.028588683810085058 Adapter cache time: 0.027156943455338478 Engine time: 0.028611242305487394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 1080, 270, 270, 270, 4320, 270, 1080, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 270, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 270, 1080, 1080, 1080, 4320, 270, 270, 4320, 270, 4320, 270, 270, 1080, 270, 1080, 4320, 270, 270, 1080, 270, 270, 270, 270, 270, 4320, 1080, 1080, 4320, 1080, 270, 4320, 4320, 4320, 1080, 1080, 270, 270, 270, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 270, 270, 4320, 1080, 4320, 4320, 270, 4320, 270, 1080, 270, 270, 1080, 1080, 4320, 4320, 4320, 270, 4320, 1080, 1080, 270, 270, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 270, 1080, 1080, 4320, 1080, 4320, 270, 270, 270, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 270, 1080, 1080, 270, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 270, 4320, 270, 4320, 1080, 270, 1080, 270, 270, 1080, 1080, 1080, 4320, 1080, 270, 270]
Prompts retrieved: 304830 . Total input tokens: 67996776 . Total output tokens: 60988908
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.844104380346835,
    "estimated_duration": 3600.113264719541,
    "input_throughput": 4502.041132659374,
    "output_throughput": 3966.537147578453,
    "total_throughput": 8468.578280237827,
    "itl": 174.9915469334737,
    "ttft": 1472742.804559611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2046,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.845609275921954,
    "arrivals": 101554,
    "finished_requests": 65169,
    "scheduler_time": 58.54246604389501
}
#Debug simulation 
Total elapsed time: 4.844190177042037. Arrivals time: 0.2023666501045227 Scheduler time: 4.518977152649313 Scheduler overhead time: 0.03278646897524595 Adapter cache time: 0.04171118000522256 Engine time: 0.03332224069163203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.958773281890899,
    "estimated_duration": 3600.0160634735203,
    "input_throughput": 4746.809652708011,
    "output_throughput": 4181.693285411289,
    "total_throughput": 8928.5029381193,
    "itl": 203.67600858723944,
    "ttft": 1376879.2531420246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.247956988578774,
    "arrivals": 99226,
    "finished_requests": 68816,
    "scheduler_time": 61.35019940585316
}
#Debug simulation 
Total elapsed time: 4.958860429935157. Arrivals time: 0.2073543076403439 Scheduler time: 4.649929667823017 Scheduler overhead time: 0.028194482438266277 Adapter cache time: 0.03172037797048688 Engine time: 0.028776997700333595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.009040281642228,
    "estimated_duration": 3600.0158078054346,
    "input_throughput": 4746.711379141684,
    "output_throughput": 4181.664138074142,
    "total_throughput": 8928.375517215827,
    "itl": 203.69093034043183,
    "ttft": 1376911.6035107318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.510292167935939,
    "arrivals": 99226,
    "finished_requests": 68814,
    "scheduler_time": 61.346272695576715
}
#Debug simulation 
Total elapsed time: 5.009124932810664. Arrivals time: 0.20776998065412045 Scheduler time: 4.698770289774984 Scheduler overhead time: 0.028236573096364737 Adapter cache time: 0.03251099633052945 Engine time: 0.028942150063812733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.959214025642723,
    "estimated_duration": 3600.1833692781083,
    "input_throughput": 4639.745059249411,
    "output_throughput": 4094.33784006276,
    "total_throughput": 8734.08289931217,
    "itl": 168.50086927922027,
    "ttft": 1413194.7794273153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.410628410428707,
    "arrivals": 99226,
    "finished_requests": 67257,
    "scheduler_time": 60.09582692546537
}
#Debug simulation 
Total elapsed time: 4.959301554597914. Arrivals time: 0.21731364261358976 Scheduler time: 4.6184686427004635 Scheduler overhead time: 0.033286870457232 Adapter cache time: 0.041180912870913744 Engine time: 0.03376124054193497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.044583722949028,
    "estimated_duration": 3600.140000356444,
    "input_throughput": 4745.752386937287,
    "output_throughput": 4180.693805938052,
    "total_throughput": 8926.446192875339,
    "itl": 203.73159268717149,
    "ttft": 1377256.9502922432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.310007417197274,
    "arrivals": 99226,
    "finished_requests": 68801,
    "scheduler_time": 61.337424784905174
}
#Debug simulation 
Total elapsed time: 5.044672620948404. Arrivals time: 0.20912068150937557 Scheduler time: 4.733526642434299 Scheduler overhead time: 0.028195930644869804 Adapter cache time: 0.0322054922580719 Engine time: 0.028737044893205166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.967998679261655,
    "estimated_duration": 3600.0521902787686,
    "input_throughput": 4639.799402104381,
    "output_throughput": 4094.353698483083,
    "total_throughput": 8734.153100587464,
    "itl": 168.49181175110903,
    "ttft": 1413149.6906909193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.479111010357711,
    "arrivals": 99226,
    "finished_requests": 67255,
    "scheduler_time": 60.09224504540997
}
#Debug simulation 
Total elapsed time: 4.968118334189057. Arrivals time: 0.20919936848804355 Scheduler time: 4.634706344455481 Scheduler overhead time: 0.03326480137184262 Adapter cache time: 0.04138910165056586 Engine time: 0.034187077544629574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.041386718861759,
    "estimated_duration": 3600.1061410401694,
    "input_throughput": 4746.983097298996,
    "output_throughput": 4181.7758727664195,
    "total_throughput": 8928.758970065415,
    "itl": 203.67036545230974,
    "ttft": 1376888.6800219084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.156169909913913,
    "arrivals": 99226,
    "finished_requests": 68819,
    "scheduler_time": 61.352870876999624
}
#Debug simulation 
Total elapsed time: 5.041475100908428. Arrivals time: 0.21487477235496044 Scheduler time: 4.724127562250942 Scheduler overhead time: 0.02837573178112507 Adapter cache time: 0.03239324456080794 Engine time: 0.028799538034945726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 1080, 135, 135, 135, 4320, 135, 1080, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 135, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 135, 1080, 1080, 1080, 4320, 135, 135, 4320, 135, 4320, 135, 135, 1080, 135, 1080, 4320, 135, 135, 1080, 135, 135, 135, 135, 135, 4320, 1080, 1080, 4320, 1080, 135, 4320, 4320, 4320, 1080, 1080, 135, 135, 135, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 135, 135, 4320, 1080, 4320, 4320, 135, 4320, 135, 1080, 135, 135, 1080, 1080, 4320, 4320, 4320, 135, 4320, 1080, 1080, 135, 135, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 135, 1080, 1080, 4320, 1080, 4320, 135, 135, 135, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 135, 1080, 1080, 135, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 135, 4320, 135, 4320, 1080, 135, 1080, 135, 135, 1080, 1080, 1080, 4320, 1080, 135, 135]
Prompts retrieved: 297675 . Total input tokens: 66367712 . Total output tokens: 59573913
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.9230906357988715,
    "estimated_duration": 3600.1711615034687,
    "input_throughput": 4638.128925244409,
    "output_throughput": 4093.196778412615,
    "total_throughput": 8731.325703657025,
    "itl": 168.46892632659453,
    "ttft": 1413606.1385990733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1352,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.507925571054228,
    "arrivals": 99226,
    "finished_requests": 67239,
    "scheduler_time": 60.08033301352961
}
#Debug simulation 
Total elapsed time: 4.923184301704168. Arrivals time: 0.21471438463777304 Scheduler time: 4.585261232685298 Scheduler overhead time: 0.03315871022641659 Adapter cache time: 0.040954004507511854 Engine time: 0.033860831055790186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.232267926912755,
    "estimated_duration": 3600.1040378206194,
    "input_throughput": 4928.572845006233,
    "output_throughput": 4342.207012846029,
    "total_throughput": 9270.779857852263,
    "itl": 196.01425062969034,
    "ttft": 1296124.6678464678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0168614232517186,
    "arrivals": 98086,
    "finished_requests": 71440,
    "scheduler_time": 63.334238689517946
}
#Debug simulation 
Total elapsed time: 5.232355748768896. Arrivals time: 0.21628923760727048 Scheduler time: 4.91970897000283 Scheduler overhead time: 0.02921221824362874 Adapter cache time: 0.024166200309991837 Engine time: 0.029649064876139164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.09131582127884,
    "estimated_duration": 3600.1084315199682,
    "input_throughput": 4928.8840426698625,
    "output_throughput": 4342.751696897962,
    "total_throughput": 9271.635739567824,
    "itl": 196.01015248254026,
    "ttft": 1296017.3370118095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1416445827670425,
    "arrivals": 98086,
    "finished_requests": 71444,
    "scheduler_time": 63.33647622965854
}
#Debug simulation 
Total elapsed time: 5.091433571185917. Arrivals time: 0.21303944289684296 Scheduler time: 4.783110362011939 Scheduler overhead time: 0.02889664564281702 Adapter cache time: 0.02378484420478344 Engine time: 0.029465130995959044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.139539313968271,
    "estimated_duration": 3600.105304232386,
    "input_throughput": 4803.33588566713,
    "output_throughput": 4238.131585224074,
    "total_throughput": 9041.467470891204,
    "itl": 163.85098091929825,
    "ttft": 1335744.0623619694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1047136051580395,
    "arrivals": 98086,
    "finished_requests": 69630,
    "scheduler_time": 61.78037028491858
}
#Debug simulation 
Total elapsed time: 5.139623527880758. Arrivals time: 0.21290442813187838 Scheduler time: 4.810626028105617 Scheduler overhead time: 0.034354378934949636 Adapter cache time: 0.031006780918687582 Engine time: 0.034990598913282156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.145491153933108,
    "estimated_duration": 3600.143036259534,
    "input_throughput": 4929.035269231105,
    "output_throughput": 4342.89800225395,
    "total_throughput": 9271.933271485055,
    "itl": 196.00480808155083,
    "ttft": 1295914.4530846507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.057752659420934,
    "arrivals": 98086,
    "finished_requests": 71448,
    "scheduler_time": 63.338811801161775
}
#Debug simulation 
Total elapsed time: 5.1455788551829755. Arrivals time: 0.21209460590034723 Scheduler time: 4.8370451326482 Scheduler overhead time: 0.028998836874961853 Adapter cache time: 0.024354124907404184 Engine time: 0.029859928879886866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.119335790164769,
    "estimated_duration": 3600.1296117991546,
    "input_throughput": 4803.741771773968,
    "output_throughput": 4238.251575718889,
    "total_throughput": 9041.993347492857,
    "itl": 163.84955737667985,
    "ttft": 1335636.843328723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.122725568395112,
    "arrivals": 98086,
    "finished_requests": 69636,
    "scheduler_time": 61.77923899400096
}
#Debug simulation 
Total elapsed time: 5.119421172887087. Arrivals time: 0.21414743037894368 Scheduler time: 4.789209479931742 Scheduler overhead time: 0.03431373881176114 Adapter cache time: 0.03117850748822093 Engine time: 0.03486433019861579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.117150515317917,
    "estimated_duration": 3600.2050081699094,
    "input_throughput": 4928.751823780186,
    "output_throughput": 4342.635201195783,
    "total_throughput": 9271.38702497597,
    "itl": 196.01198683088754,
    "ttft": 1296041.0468748068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9704431443405006,
    "arrivals": 98086,
    "finished_requests": 71444,
    "scheduler_time": 63.33647234944438
}
#Debug simulation 
Total elapsed time: 5.117236246354878. Arrivals time: 0.21232135547325015 Scheduler time: 4.808448480442166 Scheduler overhead time: 0.02898225001990795 Adapter cache time: 0.02455328730866313 Engine time: 0.029745593201369047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 1080, 66, 66, 66, 4320, 66, 1080, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 66, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 66, 1080, 1080, 1080, 4320, 66, 66, 4320, 66, 4320, 66, 66, 1080, 66, 1080, 4320, 66, 66, 1080, 66, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 66, 4320, 4320, 4320, 1080, 1080, 66, 66, 66, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 1080, 66, 66, 1080, 1080, 4320, 4320, 4320, 66, 4320, 1080, 1080, 66, 66, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 4320, 1080, 4320, 66, 66, 66, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 66, 1080, 1080, 66, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 1080, 1080, 4320, 1080, 66, 66]
Prompts retrieved: 294018 . Total input tokens: 65534784 . Total output tokens: 58851924
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.1277826889418066,
    "estimated_duration": 3600.068930071773,
    "input_throughput": 4803.256086448116,
    "output_throughput": 4238.033575567072,
    "total_throughput": 9041.289662015188,
    "itl": 163.85445138218884,
    "ttft": 1335791.967292939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1540236753225335,
    "arrivals": 98086,
    "finished_requests": 69628,
    "scheduler_time": 61.77865868321604
}
#Debug simulation 
Total elapsed time: 5.127894286066294. Arrivals time: 0.21393392095342278 Scheduler time: 4.79765918571502 Scheduler overhead time: 0.034126526676118374 Adapter cache time: 0.03128768177703023 Engine time: 0.035181577783077955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.215968406293541,
    "estimated_duration": 3600.163209649709,
    "input_throughput": 5081.0632559571795,
    "output_throughput": 4441.6722433969535,
    "total_throughput": 9522.735499354132,
    "itl": 190.79998642395128,
    "ttft": 1194928.7581455405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1905297323898465,
    "arrivals": 97521,
    "finished_requests": 73494,
    "scheduler_time": 64.41508139111268
}
#Debug simulation 
Total elapsed time: 5.216058255173266. Arrivals time: 0.2106766952201724 Scheduler time: 4.911074453499168 Scheduler overhead time: 0.02980571985244751 Adapter cache time: 0.02042315388098359 Engine time: 0.03052158746868372 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.341404220089316,
    "estimated_duration": 3600.176881250015,
    "input_throughput": 5080.838693028015,
    "output_throughput": 4441.555936676086,
    "total_throughput": 9522.3946297041,
    "itl": 190.80371225789136,
    "ttft": 1194994.0271699135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2660955849639193,
    "arrivals": 97521,
    "finished_requests": 73493,
    "scheduler_time": 64.41482770976646
}
#Debug simulation 
Total elapsed time: 5.341491349041462. Arrivals time: 0.22655406733974814 Scheduler time: 5.019640436396003 Scheduler overhead time: 0.03009548783302307 Adapter cache time: 0.0208314536139369 Engine time: 0.03062531817704439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.138719879090786,
    "estimated_duration": 3600.156817459186,
    "input_throughput": 4933.770082975383,
    "output_throughput": 4321.568972926102,
    "total_throughput": 9255.339055901486,
    "itl": 160.80348270922636,
    "ttft": 1295011.033606641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2624909156002175,
    "arrivals": 97521,
    "finished_requests": 71397,
    "scheduler_time": 62.733589909790474
}
#Debug simulation 
Total elapsed time: 5.138806687202305. Arrivals time: 0.22575108101591468 Scheduler time: 4.80015673302114 Scheduler overhead time: 0.034525157418102026 Adapter cache time: 0.02702421462163329 Engine time: 0.03549030888825655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.280299538746476,
    "estimated_duration": 3600.0108842551426,
    "input_throughput": 5080.818805297719,
    "output_throughput": 4441.496016006708,
    "total_throughput": 9522.314821304426,
    "itl": 190.79936791425743,
    "ttft": 1195048.5811452428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 388,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2144826917746105,
    "arrivals": 97521,
    "finished_requests": 73488,
    "scheduler_time": 64.4122167716279
}
#Debug simulation 
Total elapsed time: 5.280394595116377. Arrivals time: 0.21415360271930695 Scheduler time: 4.971592539921403 Scheduler overhead time: 0.02979800244793296 Adapter cache time: 0.020724479109048843 Engine time: 0.030516296159476042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.192231354769319,
    "estimated_duration": 3600.0803746494876,
    "input_throughput": 4933.357634197043,
    "output_throughput": 4321.161857813972,
    "total_throughput": 9254.519492011015,
    "itl": 160.8046611728117,
    "ttft": 1295104.057505246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2773298623971685,
    "arrivals": 97521,
    "finished_requests": 71392,
    "scheduler_time": 62.73179564730712
}
#Debug simulation 
Total elapsed time: 5.1923476490192115. Arrivals time: 0.21516009327024221 Scheduler time: 4.863296260125935 Scheduler overhead time: 0.034777453169226646 Adapter cache time: 0.027449763845652342 Engine time: 0.03562840772792697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.317374560981989,
    "estimated_duration": 3600.0982180297196,
    "input_throughput": 5080.949710869526,
    "output_throughput": 4441.652985998616,
    "total_throughput": 9522.602696868142,
    "itl": 190.79892659263874,
    "ttft": 1194888.745370221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.163129564716942,
    "arrivals": 97521,
    "finished_requests": 73493,
    "scheduler_time": 64.4144662510164
}
#Debug simulation 
Total elapsed time: 5.317462529055774. Arrivals time: 0.21525718178600073 Scheduler time: 5.007618884090334 Scheduler overhead time: 0.029807589016854763 Adapter cache time: 0.02061810065060854 Engine time: 0.03058273158967495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 1080, 33, 33, 33, 4320, 33, 1080, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 1080, 4320, 4320, 33, 4320, 1080, 4320, 4320, 4320, 1080, 4320, 33, 1080, 1080, 1080, 4320, 33, 33, 4320, 33, 4320, 33, 33, 1080, 33, 1080, 4320, 33, 33, 1080, 33, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 33, 4320, 4320, 4320, 1080, 1080, 33, 33, 33, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 1080, 33, 33, 1080, 1080, 4320, 4320, 4320, 33, 4320, 1080, 1080, 33, 33, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 4320, 1080, 4320, 33, 33, 33, 1080, 1080, 1080, 4320, 4320, 1080, 4320, 33, 1080, 1080, 33, 4320, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 4320, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 1080, 1080, 4320, 1080, 33, 33]
Prompts retrieved: 292269 . Total input tokens: 65130866 . Total output tokens: 58502807
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.177257060073316,
    "estimated_duration": 3600.0432270822316,
    "input_throughput": 4933.507983012424,
    "output_throughput": 4321.302556305292,
    "total_throughput": 9254.810539317716,
    "itl": 160.8119036028813,
    "ttft": 1295068.376794814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 387,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2940551159903433,
    "arrivals": 97521,
    "finished_requests": 71393,
    "scheduler_time": 62.73110022918668
}
#Debug simulation 
Total elapsed time: 5.177346805110574. Arrivals time: 0.21493820287287235 Scheduler time: 4.848422782029957 Scheduler overhead time: 0.03471474861726165 Adapter cache time: 0.027460183016955853 Engine time: 0.035872864071279764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.064632601104677,
    "estimated_duration": 3600.204094789064,
    "input_throughput": 4701.113202025741,
    "output_throughput": 4123.401509788509,
    "total_throughput": 8824.51471181425,
    "itl": 205.1446109639212,
    "ttft": 1267573.8528965716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.238053514401178,
    "arrivals": 92215,
    "finished_requests": 67951,
    "scheduler_time": 59.83250509909272
}
#Debug simulation 
Total elapsed time: 5.064720030874014. Arrivals time: 0.2016313965432346 Scheduler time: 4.748025875538588 Scheduler overhead time: 0.02889298414811492 Adapter cache time: 0.043896221090108156 Engine time: 0.02911006286740303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.97257592715323,
    "estimated_duration": 3600.215780821125,
    "input_throughput": 4701.057389437875,
    "output_throughput": 4123.2995197344135,
    "total_throughput": 8824.35690917229,
    "itl": 205.1742285082409,
    "ttft": 1267829.8316721523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2365,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.706426072299616,
    "arrivals": 92215,
    "finished_requests": 67948,
    "scheduler_time": 59.82622006480901
}
#Debug simulation 
Total elapsed time: 4.972694983240217. Arrivals time: 0.21006442606449127 Scheduler time: 4.647829207126051 Scheduler overhead time: 0.02875655237585306 Adapter cache time: 0.04395486181601882 Engine time: 0.029016317334026098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.983383710961789,
    "estimated_duration": 3600.0058428737666,
    "input_throughput": 4597.438093819324,
    "output_throughput": 4040.524553256968,
    "total_throughput": 8637.962647076292,
    "itl": 170.84459189132505,
    "ttft": 1342922.733448911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.180596630144613,
    "arrivals": 92215,
    "finished_requests": 66427,
    "scheduler_time": 58.58624416964398
}
#Debug simulation 
Total elapsed time: 4.983476907014847. Arrivals time: 0.21160935517400503 Scheduler time: 4.630050759762526 Scheduler overhead time: 0.033487919718027115 Adapter cache time: 0.059170660097151995 Engine time: 0.033871682826429605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 4.963310217950493,
    "estimated_duration": 3600.0192590601555,
    "input_throughput": 4701.330126888965,
    "output_throughput": 4123.525162439123,
    "total_throughput": 8824.855289328088,
    "itl": 205.15582537066865,
    "ttft": 1267615.0841143106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2364,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.392494984671672,
    "arrivals": 92215,
    "finished_requests": 67949,
    "scheduler_time": 59.826828288214884
}
#Debug simulation 
Total elapsed time: 4.9634153181687. Arrivals time: 0.20022595906630158 Scheduler time: 4.648461738135666 Scheduler overhead time: 0.028711377643048763 Adapter cache time: 0.04359626350924373 Engine time: 0.02929569035768509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 4.956428367178887,
    "estimated_duration": 3600.070146548494,
    "input_throughput": 4597.451529067602,
    "output_throughput": 4040.600434951568,
    "total_throughput": 8638.05196401917,
    "itl": 170.84636395895194,
    "ttft": 1342938.7038799145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.273496152050434,
    "arrivals": 92215,
    "finished_requests": 66428,
    "scheduler_time": 58.58627169365406
}
#Debug simulation 
Total elapsed time: 4.956511388067156. Arrivals time: 0.20871603675186634 Scheduler time: 4.606562826316804 Scheduler overhead time: 0.03314444562420249 Adapter cache time: 0.05898583494126797 Engine time: 0.03377704741433263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 4.99993841862306,
    "estimated_duration": 3600.1564997648948,
    "input_throughput": 4701.395620191878,
    "output_throughput": 4123.701289366033,
    "total_throughput": 8825.096909557911,
    "itl": 205.1331354257367,
    "ttft": 1267373.3077965423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.059508746263822,
    "arrivals": 92215,
    "finished_requests": 67954,
    "scheduler_time": 59.83385670091118
}
#Debug simulation 
Total elapsed time: 5.000064863823354. Arrivals time: 0.20544283604249358 Scheduler time: 4.679592213127762 Scheduler overhead time: 0.02896688273176551 Adapter cache time: 0.04361336678266525 Engine time: 0.029269396793097258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [53 53 54]
Adapter prompts. [270, 4320, 270, 270, 540, 270, 270, 270, 4320, 270, 540, 4320, 540, 270, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 270, 4320, 540, 4320, 4320, 4320, 540, 4320, 270, 540, 540, 540, 4320, 270, 270, 4320, 270, 4320, 270, 270, 540, 270, 540, 4320, 270, 270, 540, 270, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 270, 4320, 4320, 4320, 540, 540, 270, 270, 270, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 270, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 540, 270, 270, 540, 540, 4320, 4320, 4320, 270, 4320, 540, 540, 270, 270, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 4320, 540, 4320, 270, 270, 270, 540, 540, 540, 4320, 4320, 540, 4320, 270, 540, 540, 270, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 540, 540, 4320, 540, 270, 270]
Prompts retrieved: 276210 . Total input tokens: 61553482 . Total output tokens: 55279979
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 4.950271940790117,
    "estimated_duration": 3600.039438710876,
    "input_throughput": 4597.257413915008,
    "output_throughput": 4040.325181884252,
    "total_throughput": 8637.58259579926,
    "itl": 170.85058610979866,
    "ttft": 1343053.5087050356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.399049286841871,
    "arrivals": 92215,
    "finished_requests": 66425,
    "scheduler_time": 58.583982116453726
}
#Debug simulation 
Total elapsed time: 4.950356779620051. Arrivals time: 0.20319761615246534 Scheduler time: 4.60573677206412 Scheduler overhead time: 0.033102111890912056 Adapter cache time: 0.05959399789571762 Engine time: 0.03351906081661582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.056133017875254,
    "estimated_duration": 3600.059675272325,
    "input_throughput": 4825.673618503518,
    "output_throughput": 4270.69004039134,
    "total_throughput": 9096.363658894858,
    "itl": 199.49404376270473,
    "ttft": 1075463.667077109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1680,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.141619409807169,
    "arrivals": 89808,
    "finished_requests": 70095,
    "scheduler_time": 61.55715341463994
}
#Debug simulation 
Total elapsed time: 5.0562218888662755. Arrivals time: 0.19442748231813312 Scheduler time: 4.74861844535917 Scheduler overhead time: 0.028698375448584557 Adapter cache time: 0.0419109552167356 Engine time: 0.029499821830540895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.130055092275143,
    "estimated_duration": 3600.1513497193555,
    "input_throughput": 4825.096311952034,
    "output_throughput": 4270.039647416035,
    "total_throughput": 9095.13595936807,
    "itl": 199.51141643527023,
    "ttft": 1075817.7712604268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.474224897806872,
    "arrivals": 89808,
    "finished_requests": 70088,
    "scheduler_time": 61.554009208988745
}
#Debug simulation 
Total elapsed time: 5.130144624970853. Arrivals time: 0.19964817678555846 Scheduler time: 4.816836713347584 Scheduler overhead time: 0.02903183549642563 Adapter cache time: 0.04184951959177852 Engine time: 0.02955888630822301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.139194040093571,
    "estimated_duration": 3600.1370081432383,
    "input_throughput": 4762.736518420244,
    "output_throughput": 4224.022020718317,
    "total_throughput": 8986.758539138562,
    "itl": 164.3988707662848,
    "ttft": 1126769.453809629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.439130496364029,
    "arrivals": 89808,
    "finished_requests": 69187,
    "scheduler_time": 60.666409945722094
}
#Debug simulation 
Total elapsed time: 5.139311079867184. Arrivals time: 0.20023977616801858 Scheduler time: 4.801048885565251 Scheduler overhead time: 0.03447471419349313 Adapter cache time: 0.052142214961349964 Engine time: 0.03566582966595888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.106110929045826,
    "estimated_duration": 3600.2070200928797,
    "input_throughput": 4825.78110176336,
    "output_throughput": 4270.915787393615,
    "total_throughput": 9096.696889156974,
    "itl": 199.4984998122978,
    "ttft": 1075406.8871690426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.257130900649225,
    "arrivals": 89808,
    "finished_requests": 70099,
    "scheduler_time": 61.55852819363395
}
#Debug simulation 
Total elapsed time: 5.106222116854042. Arrivals time: 0.19587238179519773 Scheduler time: 4.796428970061243 Scheduler overhead time: 0.028952232096344233 Adapter cache time: 0.04222787683829665 Engine time: 0.0295281452126801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.081454569008201,
    "estimated_duration": 3600.1202394136417,
    "input_throughput": 4762.685649297269,
    "output_throughput": 4223.894200399461,
    "total_throughput": 8986.57984969673,
    "itl": 164.39694320314734,
    "ttft": 1126856.6907568239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4998841610922655,
    "arrivals": 89808,
    "finished_requests": 69186,
    "scheduler_time": 60.66503090358446
}
#Debug simulation 
Total elapsed time: 5.081541453953832. Arrivals time: 0.1989911124110222 Scheduler time: 4.745658334810287 Scheduler overhead time: 0.03428022563457489 Adapter cache time: 0.051837580278515816 Engine time: 0.035099192056804895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.152743492741138,
    "estimated_duration": 3600.046456346235,
    "input_throughput": 4825.996611619578,
    "output_throughput": 4271.177937966356,
    "total_throughput": 9097.174549585934,
    "itl": 199.4846325378835,
    "ttft": 1075271.367153282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.035244696615122,
    "arrivals": 89808,
    "finished_requests": 70100,
    "scheduler_time": 61.558778098946384
}
#Debug simulation 
Total elapsed time: 5.152828497812152. Arrivals time: 0.19536661123856902 Scheduler time: 4.843797014094889 Scheduler overhead time: 0.029003714211285114 Adapter cache time: 0.042100821156054735 Engine time: 0.029389959294348955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 540, 135, 135, 135, 4320, 135, 540, 4320, 540, 135, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 135, 4320, 540, 4320, 4320, 4320, 540, 4320, 135, 540, 540, 540, 4320, 135, 135, 4320, 135, 4320, 135, 135, 540, 135, 540, 4320, 135, 135, 540, 135, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 135, 4320, 4320, 4320, 540, 540, 135, 135, 135, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 135, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 540, 135, 135, 540, 540, 4320, 4320, 4320, 135, 4320, 540, 540, 135, 135, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 4320, 540, 4320, 135, 135, 135, 540, 540, 540, 4320, 4320, 540, 4320, 135, 540, 540, 135, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 540, 540, 4320, 540, 135, 135]
Prompts retrieved: 269055 . Total input tokens: 59949771 . Total output tokens: 53839434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.086062375921756,
    "estimated_duration": 3600.118085653746,
    "input_throughput": 4762.6729435144125,
    "output_throughput": 4223.793952924939,
    "total_throughput": 8986.466896439351,
    "itl": 164.3929322693536,
    "ttft": 1126821.7440322074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.56075273752203,
    "arrivals": 89808,
    "finished_requests": 69185,
    "scheduler_time": 60.66522530033449
}
#Debug simulation 
Total elapsed time: 5.08615468069911. Arrivals time: 0.1981472480110824 Scheduler time: 4.751675590872765 Scheduler overhead time: 0.03411618294194341 Adapter cache time: 0.05143116135150194 Engine time: 0.03511748230084777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.316959081683308,
    "estimated_duration": 3600.085606675259,
    "input_throughput": 5024.454686983127,
    "output_throughput": 4435.489525691267,
    "total_throughput": 9459.944212674394,
    "itl": 190.96645083060704,
    "ttft": 875322.9452018501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6718058004533507,
    "arrivals": 88684,
    "finished_requests": 72930,
    "scheduler_time": 63.46482828343983
}
#Debug simulation 
Total elapsed time: 5.317051474004984. Arrivals time: 0.19122810382395983 Scheduler time: 5.0154652846977115 Scheduler overhead time: 0.030166554264724255 Adapter cache time: 0.03554725041612983 Engine time: 0.03099005902186036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.235211662016809,
    "estimated_duration": 3600.1688235946267,
    "input_throughput": 5024.338548084914,
    "output_throughput": 4435.387000561946,
    "total_throughput": 9459.72554864686,
    "itl": 190.97396245753728,
    "ttft": 875379.4670962731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8357286401628548,
    "arrivals": 88684,
    "finished_requests": 72930,
    "scheduler_time": 63.46455166303391
}
#Debug simulation 
Total elapsed time: 5.235300145111978. Arrivals time: 0.19053130969405174 Scheduler time: 4.935029832180589 Scheduler overhead time: 0.029901704285293818 Adapter cache time: 0.03558096196502447 Engine time: 0.030678955372422934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.300220963079482,
    "estimated_duration": 3600.0943946167267,
    "input_throughput": 4943.019834871448,
    "output_throughput": 4370.154855807597,
    "total_throughput": 9313.174690679045,
    "itl": 158.43009628436508,
    "ttft": 942924.815786816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.800880555566383,
    "arrivals": 88684,
    "finished_requests": 71785,
    "scheduler_time": 62.27023834390662
}
#Debug simulation 
Total elapsed time: 5.30030922126025. Arrivals time: 0.19437319179996848 Scheduler time: 4.973043232224882 Scheduler overhead time: 0.03562964079901576 Adapter cache time: 0.04447444109246135 Engine time: 0.03646101616322994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.246832663193345,
    "estimated_duration": 3600.142643470266,
    "input_throughput": 5024.375084917214,
    "output_throughput": 4435.419254557068,
    "total_throughput": 9459.794339474282,
    "itl": 190.96756185140092,
    "ttft": 875327.2567255835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 872,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.730311048005217,
    "arrivals": 88684,
    "finished_requests": 72930,
    "scheduler_time": 63.46577660768439
}
#Debug simulation 
Total elapsed time: 5.2469204110093415. Arrivals time: 0.19243214325979352 Scheduler time: 4.9445400214754045 Scheduler overhead time: 0.029876781161874533 Adapter cache time: 0.03584166523069143 Engine time: 0.030584177002310753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.319847938138992,
    "estimated_duration": 3600.0792124172604,
    "input_throughput": 4943.040958271411,
    "output_throughput": 4370.244395104846,
    "total_throughput": 9313.285353376257,
    "itl": 158.41907734966705,
    "ttft": 942886.562401815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8335365261696306,
    "arrivals": 88684,
    "finished_requests": 71786,
    "scheduler_time": 62.26906161028777
}
#Debug simulation 
Total elapsed time: 5.319936566986144. Arrivals time: 0.2012571799568832 Scheduler time: 4.984790438786149 Scheduler overhead time: 0.03606596076861024 Adapter cache time: 0.04456035466864705 Engine time: 0.0369534557685256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.238342280033976,
    "estimated_duration": 3600.1207504388067,
    "input_throughput": 5024.472859082637,
    "output_throughput": 4435.484003711175,
    "total_throughput": 9459.956862793813,
    "itl": 190.9605998831421,
    "ttft": 875226.7909322348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6162940080393478,
    "arrivals": 88684,
    "finished_requests": 72932,
    "scheduler_time": 63.46644029072223
}
#Debug simulation 
Total elapsed time: 5.2384367869235575. Arrivals time: 0.19250016333535314 Scheduler time: 4.935848351567984 Scheduler overhead time: 0.029970301780849695 Adapter cache time: 0.035792709328234196 Engine time: 0.030723615549504757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 540, 66, 66, 66, 4320, 66, 540, 4320, 540, 66, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 66, 4320, 540, 4320, 4320, 4320, 540, 4320, 66, 540, 540, 540, 4320, 66, 66, 4320, 66, 4320, 66, 66, 540, 66, 540, 4320, 66, 66, 540, 66, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 66, 4320, 4320, 4320, 540, 540, 66, 66, 66, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 66, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 540, 66, 66, 540, 540, 4320, 4320, 4320, 66, 4320, 540, 540, 66, 66, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 4320, 540, 4320, 66, 66, 66, 540, 540, 540, 4320, 4320, 540, 4320, 66, 540, 540, 66, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 540, 540, 4320, 540, 66, 66]
Prompts retrieved: 265398 . Total input tokens: 59148136 . Total output tokens: 53102990
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.292535167187452,
    "estimated_duration": 3600.1413626577814,
    "input_throughput": 4942.4178685206225,
    "output_throughput": 4369.8034091600275,
    "total_throughput": 9312.22127768065,
    "itl": 158.2572899495557,
    "ttft": 943328.9322307316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 860,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8739289195835824,
    "arrivals": 88684,
    "finished_requests": 71780,
    "scheduler_time": 62.26251690573921
}
#Debug simulation 
Total elapsed time: 5.292671926319599. Arrivals time: 0.19758237712085247 Scheduler time: 4.962419267278165 Scheduler overhead time: 0.03556111315265298 Adapter cache time: 0.04421626357361674 Engine time: 0.03648323519155383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.415193467866629,
    "estimated_duration": 3600.114030557942,
    "input_throughput": 5164.258921298291,
    "output_throughput": 4565.144842774026,
    "total_throughput": 9729.403764072316,
    "itl": 185.86842110401713,
    "ttft": 725236.1429925057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1905297323898465,
    "arrivals": 88054,
    "finished_requests": 75141,
    "scheduler_time": 65.00511678153084
}
#Debug simulation 
Total elapsed time: 5.415284594055265. Arrivals time: 0.19388243043795228 Scheduler time: 5.115822135005146 Scheduler overhead time: 0.030797726940363646 Adapter cache time: 0.02931129513308406 Engine time: 0.031473828945308924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.4893911788240075,
    "estimated_duration": 3600.130134090372,
    "input_throughput": 5164.2358213524785,
    "output_throughput": 4565.1244226905055,
    "total_throughput": 9729.360244042984,
    "itl": 185.87109483981956,
    "ttft": 725255.6049299962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2656869896454788,
    "arrivals": 88054,
    "finished_requests": 75141,
    "scheduler_time": 65.0047704883964
}
#Debug simulation 
Total elapsed time: 5.489478275179863. Arrivals time: 0.19375849282369018 Scheduler time: 5.188279370777309 Scheduler overhead time: 0.031155331525951624 Adapter cache time: 0.030615875963121653 Engine time: 0.03153402218595147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.340314861852676,
    "estimated_duration": 3600.1496821903206,
    "input_throughput": 5063.779178455908,
    "output_throughput": 4483.777738424223,
    "total_throughput": 9547.55691688013,
    "itl": 154.82591286920163,
    "ttft": 811172.237300601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2750022384896946,
    "arrivals": 88054,
    "finished_requests": 73670,
    "scheduler_time": 63.50545278654266
}
#Debug simulation 
Total elapsed time: 5.3404005342163146. Arrivals time: 0.1936654052697122 Scheduler time: 5.019130191765726 Scheduler overhead time: 0.036194151267409325 Adapter cache time: 0.03762167040258646 Engine time: 0.037239893805235624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.4737384528853,
    "estimated_duration": 3600.0172433124635,
    "input_throughput": 5164.340263796435,
    "output_throughput": 4565.233411181617,
    "total_throughput": 9729.573674978052,
    "itl": 185.87203594891645,
    "ttft": 725256.4088390103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.219924313980155,
    "arrivals": 88054,
    "finished_requests": 75139,
    "scheduler_time": 65.002447874568
}
#Debug simulation 
Total elapsed time: 5.473826289176941. Arrivals time: 0.19420394441112876 Scheduler time: 5.17304766504094 Scheduler overhead time: 0.030784787144511938 Adapter cache time: 0.029953425284475088 Engine time: 0.031783272977918386 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.368371463846415,
    "estimated_duration": 3600.0658300041396,
    "input_throughput": 5064.013787764275,
    "output_throughput": 4483.758009497687,
    "total_throughput": 9547.771797261961,
    "itl": 154.82750492230593,
    "ttft": 811195.4294096365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2920044276304592,
    "arrivals": 88054,
    "finished_requests": 73670,
    "scheduler_time": 63.50351945143131
}
#Debug simulation 
Total elapsed time: 5.368458183016628. Arrivals time: 0.1947727780789137 Scheduler time: 5.045990404672921 Scheduler overhead time: 0.03622316289693117 Adapter cache time: 0.03780370857566595 Engine time: 0.03708895994350314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.441986149176955,
    "estimated_duration": 3600.0109016610477,
    "input_throughput": 5164.367972169678,
    "output_throughput": 4565.242008688617,
    "total_throughput": 9729.609980858295,
    "itl": 185.86642302675185,
    "ttft": 725211.1178285694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169109665306746,
    "arrivals": 88054,
    "finished_requests": 75140,
    "scheduler_time": 65.00278051931363
}
#Debug simulation 
Total elapsed time: 5.442112043034285. Arrivals time: 0.1927208355627954 Scheduler time: 5.143434428609908 Scheduler overhead time: 0.03095806622877717 Adapter cache time: 0.02938231686130166 Engine time: 0.031555294059216976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 540, 33, 33, 33, 4320, 33, 540, 4320, 540, 33, 540, 540, 540, 540, 4320, 4320, 4320, 540, 540, 540, 4320, 4320, 33, 4320, 540, 4320, 4320, 4320, 540, 4320, 33, 540, 540, 540, 4320, 33, 33, 4320, 33, 4320, 33, 33, 540, 33, 540, 4320, 33, 33, 540, 33, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 33, 4320, 4320, 4320, 540, 540, 33, 33, 33, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 33, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 540, 33, 33, 540, 540, 4320, 4320, 4320, 33, 4320, 540, 540, 33, 33, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 4320, 540, 4320, 33, 33, 33, 540, 540, 540, 4320, 4320, 540, 4320, 33, 540, 540, 33, 4320, 4320, 4320, 4320, 4320, 4320, 540, 540, 540, 540, 540, 4320, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 540, 540, 4320, 540, 33, 33]
Prompts retrieved: 263649 . Total input tokens: 58741361 . Total output tokens: 52765913
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.303029374219477,
    "estimated_duration": 3600.128788536885,
    "input_throughput": 5064.166609275513,
    "output_throughput": 4483.694597648036,
    "total_throughput": 9547.86120692355,
    "itl": 154.83024890780453,
    "ttft": 811159.764693234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3132422316446914,
    "arrivals": 88054,
    "finished_requests": 73671,
    "scheduler_time": 63.50503681675216
}
#Debug simulation 
Total elapsed time: 5.303115027025342. Arrivals time: 0.1979530081152916 Scheduler time: 4.97804514830932 Scheduler overhead time: 0.035809435416013 Adapter cache time: 0.03789758263155818 Engine time: 0.036944872699677944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.270452328957617,
    "estimated_duration": 3600.220373582114,
    "input_throughput": 5019.214416038816,
    "output_throughput": 4453.9754059680945,
    "total_throughput": 9473.18982200691,
    "itl": 190.39533724747105,
    "ttft": 695715.1439682534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4599101351761865,
    "arrivals": 85140,
    "finished_requests": 73104,
    "scheduler_time": 63.3033270773965
}
#Debug simulation 
Total elapsed time: 5.270542544312775. Arrivals time: 0.18587373849004507 Scheduler time: 4.963402001187205 Scheduler overhead time: 0.030255393590778112 Adapter cache time: 0.04655231349170208 Engine time: 0.03072934178635478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.294939894229174,
    "estimated_duration": 3600.1289685338825,
    "input_throughput": 5018.402995534232,
    "output_throughput": 4453.4699006989495,
    "total_throughput": 9471.87289623318,
    "itl": 190.41384924819087,
    "ttft": 696229.8192569937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.815575011228056,
    "arrivals": 85140,
    "finished_requests": 73093,
    "scheduler_time": 63.29678488726729
}
#Debug simulation 
Total elapsed time: 5.295044015161693. Arrivals time: 0.18607686646282673 Scheduler time: 4.987056865822524 Scheduler overhead time: 0.03031578240916133 Adapter cache time: 0.04684984777122736 Engine time: 0.030928777530789375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.374770316295326,
    "estimated_duration": 3600.021820492727,
    "input_throughput": 4985.568947896953,
    "output_throughput": 4430.679255665424,
    "total_throughput": 9416.248203562378,
    "itl": 156.5297299252574,
    "ttft": 730736.0825035805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.774846398234308,
    "arrivals": 85140,
    "finished_requests": 72600,
    "scheduler_time": 62.49786721991084
}
#Debug simulation 
Total elapsed time: 5.374885676428676. Arrivals time: 0.18717086175456643 Scheduler time: 5.044434475712478 Scheduler overhead time: 0.03606584761291742 Adapter cache time: 0.05383393354713917 Engine time: 0.03680018475279212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.294080436695367,
    "estimated_duration": 3600.2022072691516,
    "input_throughput": 5019.239742566233,
    "output_throughput": 4453.997880347724,
    "total_throughput": 9473.237622913957,
    "itl": 190.40218322903846,
    "ttft": 695698.0198672133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.568542618879439,
    "arrivals": 85140,
    "finished_requests": 73104,
    "scheduler_time": 63.30281897765926
}
#Debug simulation 
Total elapsed time: 5.294166425708681. Arrivals time: 0.18526498973369598 Scheduler time: 4.987242047209293 Scheduler overhead time: 0.030259535647928715 Adapter cache time: 0.04656534595414996 Engine time: 0.031050501856952906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.31221500877291,
    "estimated_duration": 3600.1061737997657,
    "input_throughput": 4985.483242305693,
    "output_throughput": 4430.59071870783,
    "total_throughput": 9416.073961013524,
    "itl": 156.54051054296997,
    "ttft": 730748.2048951177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.844931271131983,
    "arrivals": 85140,
    "finished_requests": 72601,
    "scheduler_time": 62.498845245716325
}
#Debug simulation 
Total elapsed time: 5.312302853912115. Arrivals time: 0.18837998574599624 Scheduler time: 4.980664924252778 Scheduler overhead time: 0.03591935150325298 Adapter cache time: 0.053926581516861916 Engine time: 0.03693842701613903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.253111811354756,
    "estimated_duration": 3600.002493658837,
    "input_throughput": 5019.518189731697,
    "output_throughput": 4454.244970175741,
    "total_throughput": 9473.763159907438,
    "itl": 190.3881387560196,
    "ttft": 695535.5306032754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1781,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.325279575220622,
    "arrivals": 85140,
    "finished_requests": 73104,
    "scheduler_time": 63.30232408041396
}
#Debug simulation 
Total elapsed time: 5.2532029380090535. Arrivals time: 0.18255141656845808 Scheduler time: 4.949948644731194 Scheduler overhead time: 0.029978268779814243 Adapter cache time: 0.04615270905196667 Engine time: 0.030853260308504105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [53 53 54]
Adapter prompts. [135, 4320, 135, 135, 270, 135, 135, 135, 4320, 135, 270, 4320, 270, 135, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 135, 4320, 270, 4320, 4320, 4320, 270, 4320, 135, 270, 270, 270, 4320, 135, 135, 4320, 135, 4320, 135, 135, 270, 135, 270, 4320, 135, 135, 270, 135, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 135, 4320, 4320, 4320, 270, 270, 135, 135, 135, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 135, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 270, 135, 135, 270, 270, 4320, 4320, 4320, 135, 4320, 270, 270, 135, 135, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 4320, 270, 4320, 135, 135, 135, 270, 270, 270, 4320, 4320, 270, 4320, 135, 270, 270, 135, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 270, 270, 4320, 270, 135, 135]
Prompts retrieved: 254745 . Total input tokens: 56784317 . Total output tokens: 50996017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.355942420195788,
    "estimated_duration": 3600.018901837023,
    "input_throughput": 4985.426879520453,
    "output_throughput": 4430.502015381382,
    "total_throughput": 9415.928894901836,
    "itl": 156.54231750641438,
    "ttft": 730849.4878578299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.924770339615512,
    "arrivals": 85140,
    "finished_requests": 72597,
    "scheduler_time": 62.496799514803214
}
#Debug simulation 
Total elapsed time: 5.356063007377088. Arrivals time: 0.18815890420228243 Scheduler time: 5.025154877454042 Scheduler overhead time: 0.03599271038547158 Adapter cache time: 0.05347256828099489 Engine time: 0.03678429592400789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.520008657127619,
    "estimated_duration": 3600.1283048651676,
    "input_throughput": 5296.119578358775,
    "output_throughput": 4687.889311387217,
    "total_throughput": 9984.008889745992,
    "itl": 178.87621237265864,
    "ttft": 407122.11336109036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9227657954558453,
    "arrivals": 83948,
    "finished_requests": 76981,
    "scheduler_time": 65.94940294468448
}
#Debug simulation 
Total elapsed time: 5.520094498991966. Arrivals time: 0.1830993383191526 Scheduler time: 5.215272720437497 Scheduler overhead time: 0.03397684497758746 Adapter cache time: 0.04037338215857744 Engine time: 0.03281334135681391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.536176166962832,
    "estimated_duration": 3600.1715876622084,
    "input_throughput": 5295.75814256686,
    "output_throughput": 4687.703235544635,
    "total_throughput": 9983.461378111495,
    "itl": 178.88920958807446,
    "ttft": 407312.73355970014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.110461510338358,
    "arrivals": 83948,
    "finished_requests": 76979,
    "scheduler_time": 65.94767780863593
}
#Debug simulation 
Total elapsed time: 5.536268780939281. Arrivals time: 0.1836241683922708 Scheduler time: 5.233491966500878 Scheduler overhead time: 0.03205810347571969 Adapter cache time: 0.039918926544487476 Engine time: 0.03268337156623602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.522758322767913,
    "estimated_duration": 3600.057454585006,
    "input_throughput": 5235.470332840199,
    "output_throughput": 4640.504550482454,
    "total_throughput": 9875.974883322653,
    "itl": 148.6942939593241,
    "ttft": 463716.3113405432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0537801191210487,
    "arrivals": 83948,
    "finished_requests": 76121,
    "scheduler_time": 64.77899702069018
}
#Debug simulation 
Total elapsed time: 5.522861454170197. Arrivals time: 0.18595873471349478 Scheduler time: 5.197904317174107 Scheduler overhead time: 0.03751326026394963 Adapter cache time: 0.04576936038210988 Engine time: 0.03847283497452736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.609391710720956,
    "estimated_duration": 3600.06459320173,
    "input_throughput": 5295.9155332943365,
    "output_throughput": 4687.842554788939,
    "total_throughput": 9983.758088083276,
    "itl": 178.8807753259159,
    "ttft": 407187.4901756155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.992786058627507,
    "arrivals": 83948,
    "finished_requests": 76979,
    "scheduler_time": 65.94736477368997
}
#Debug simulation 
Total elapsed time: 5.609510340727866. Arrivals time: 0.18285275343805552 Scheduler time: 5.307006848510355 Scheduler overhead time: 0.032166894525289536 Adapter cache time: 0.039983788039535284 Engine time: 0.03281218325719237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.549984878860414,
    "estimated_duration": 3600.001747418795,
    "input_throughput": 5235.551347583104,
    "output_throughput": 4640.5763586026815,
    "total_throughput": 9876.127706185785,
    "itl": 148.7041969037397,
    "ttft": 463752.377979022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0987962308526042,
    "arrivals": 83948,
    "finished_requests": 76121,
    "scheduler_time": 64.77706716154084
}
#Debug simulation 
Total elapsed time: 5.550128759816289. Arrivals time: 0.18602192914113402 Scheduler time: 5.224557611625642 Scheduler overhead time: 0.037793563678860664 Adapter cache time: 0.046082861721515656 Engine time: 0.038416760973632336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.553538274019957,
    "estimated_duration": 3600.156944056482,
    "input_throughput": 5296.178554514944,
    "output_throughput": 4688.00090170047,
    "total_throughput": 9984.179456215415,
    "itl": 178.87222329035563,
    "ttft": 406999.61754656583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8584880819264153,
    "arrivals": 83948,
    "finished_requests": 76983,
    "scheduler_time": 65.95100931173175
}
#Debug simulation 
Total elapsed time: 5.55362582532689. Arrivals time: 0.1808417378924787 Scheduler time: 5.253207087516785 Scheduler overhead time: 0.032018888276070356 Adapter cache time: 0.04022542620077729 Engine time: 0.03270654194056988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 270, 66, 66, 66, 4320, 66, 270, 4320, 270, 66, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 66, 4320, 270, 4320, 4320, 4320, 270, 4320, 66, 270, 270, 270, 4320, 66, 66, 4320, 66, 4320, 66, 66, 270, 66, 270, 4320, 66, 66, 270, 66, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 66, 4320, 4320, 4320, 270, 270, 66, 66, 66, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 66, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 270, 66, 66, 270, 270, 4320, 4320, 4320, 66, 4320, 270, 270, 66, 66, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 4320, 270, 4320, 66, 66, 66, 270, 270, 270, 4320, 4320, 270, 4320, 66, 270, 270, 66, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 270, 270, 4320, 270, 66, 66]
Prompts retrieved: 251088 . Total input tokens: 55949827 . Total output tokens: 50281244
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.484425727743655,
    "estimated_duration": 3600.0736462321156,
    "input_throughput": 5235.3253994473425,
    "output_throughput": 4640.426180582331,
    "total_throughput": 9875.751580029673,
    "itl": 148.70646201632852,
    "ttft": 464017.6110935181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.147308020629022,
    "arrivals": 83948,
    "finished_requests": 76116,
    "scheduler_time": 64.7768812522132
}
#Debug simulation 
Total elapsed time: 5.484529766719788. Arrivals time: 0.18379617109894753 Scheduler time: 5.162536453455687 Scheduler overhead time: 0.037336114794015884 Adapter cache time: 0.04558238247409463 Engine time: 0.038199740927666426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.726556984707713,
    "estimated_duration": 3600.073730857841,
    "input_throughput": 5466.855812230909,
    "output_throughput": 4795.174291023896,
    "total_throughput": 10262.030103254805,
    "itl": 174.53894915471122,
    "ttft": 282672.1865586682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5853326513571855,
    "arrivals": 83337,
    "finished_requests": 78525,
    "scheduler_time": 67.30255341536012
}
#Debug simulation 
Total elapsed time: 5.72667609481141. Arrivals time: 0.1812094678170979 Scheduler time: 5.429033203050494 Scheduler overhead time: 0.0328101422637701 Adapter cache time: 0.03525730315595865 Engine time: 0.03338571125641465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.638479215092957,
    "estimated_duration": 3600.1646427838327,
    "input_throughput": 5466.81136915486,
    "output_throughput": 4795.138476403439,
    "total_throughput": 10261.949845558298,
    "itl": 174.54432173958577,
    "ttft": 282671.59248987475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6828653172077646,
    "arrivals": 83337,
    "finished_requests": 78526,
    "scheduler_time": 67.30310850047681
}
#Debug simulation 
Total elapsed time: 5.638568900059909. Arrivals time: 0.18285310175269842 Scheduler time: 5.340137160383165 Scheduler overhead time: 0.03263831930235028 Adapter cache time: 0.03469592146575451 Engine time: 0.03340823855251074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.607403276953846,
    "estimated_duration": 3600.0954440834516,
    "input_throughput": 5390.132373265542,
    "output_throughput": 4733.771719304717,
    "total_throughput": 10123.90409257026,
    "itl": 144.14057746226015,
    "ttft": 359526.5260859002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6709306051395934,
    "arrivals": 83337,
    "finished_requests": 77367,
    "scheduler_time": 65.8199573093585
}
#Debug simulation 
Total elapsed time: 5.6074913358315825. Arrivals time: 0.18797702761366963 Scheduler time: 5.282804315444082 Scheduler overhead time: 0.038563954178243876 Adapter cache time: 0.04073465010151267 Engine time: 0.03973020473495126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.694929978810251,
    "estimated_duration": 3600.016838657207,
    "input_throughput": 5466.94220667617,
    "output_throughput": 4795.2500706743995,
    "total_throughput": 10262.19227735057,
    "itl": 174.54310343610504,
    "ttft": 282652.7717022528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6191244475310598,
    "arrivals": 83337,
    "finished_requests": 78525,
    "scheduler_time": 67.3010295518925
}
#Debug simulation 
Total elapsed time: 5.695036611054093. Arrivals time: 0.18257519230246544 Scheduler time: 5.39630356291309 Scheduler overhead time: 0.03281333390623331 Adapter cache time: 0.03496096096932888 Engine time: 0.033488437067717314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.644226090051234,
    "estimated_duration": 3600.100961812153,
    "input_throughput": 5390.322162029564,
    "output_throughput": 4733.69641039784,
    "total_throughput": 10124.018572427405,
    "itl": 144.139136500045,
    "ttft": 359505.8680573289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6905481958203064,
    "arrivals": 83337,
    "finished_requests": 77368,
    "scheduler_time": 65.81962860268493
}
#Debug simulation 
Total elapsed time: 5.644344666041434. Arrivals time: 0.1845252006314695 Scheduler time: 5.322931656148285 Scheduler overhead time: 0.03880414133891463 Adapter cache time: 0.040671166963875294 Engine time: 0.03972806502133608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.668767852243036,
    "estimated_duration": 3600.05294050538,
    "input_throughput": 5466.887383394185,
    "output_throughput": 4795.201983217669,
    "total_throughput": 10262.089366611855,
    "itl": 174.54082413510523,
    "ttft": 282642.4413611565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.551836103054211,
    "arrivals": 83337,
    "finished_requests": 78525,
    "scheduler_time": 67.30220612417435
}
#Debug simulation 
Total elapsed time: 5.668885609135032. Arrivals time: 0.18362943176180124 Scheduler time: 5.369766441639513 Scheduler overhead time: 0.032597919926047325 Adapter cache time: 0.03490989375859499 Engine time: 0.03318265359848738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 270, 33, 33, 33, 4320, 33, 270, 4320, 270, 33, 270, 270, 270, 270, 4320, 4320, 4320, 270, 270, 270, 4320, 4320, 33, 4320, 270, 4320, 4320, 4320, 270, 4320, 33, 270, 270, 270, 4320, 33, 33, 4320, 33, 4320, 33, 33, 270, 33, 270, 4320, 33, 33, 270, 33, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 33, 4320, 4320, 4320, 270, 270, 33, 33, 33, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 33, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 270, 33, 33, 270, 270, 4320, 4320, 4320, 33, 4320, 270, 270, 33, 33, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 4320, 270, 4320, 33, 33, 33, 270, 270, 270, 4320, 4320, 270, 4320, 33, 270, 270, 33, 4320, 4320, 4320, 4320, 4320, 4320, 270, 270, 270, 270, 270, 4320, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 270, 270, 4320, 270, 33, 33]
Prompts retrieved: 249339 . Total input tokens: 55560116 . Total output tokens: 49932788
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.673152894247323,
    "estimated_duration": 3600.1683938596407,
    "input_throughput": 5390.2211999577285,
    "output_throughput": 4733.60774708929,
    "total_throughput": 10123.828947047017,
    "itl": 144.147042063623,
    "ttft": 359548.2272204799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 513,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7118005857244118,
    "arrivals": 83337,
    "finished_requests": 77368,
    "scheduler_time": 65.82109202721304
}
#Debug simulation 
Total elapsed time: 5.673244427423924. Arrivals time: 0.18597746035084128 Scheduler time: 5.349877453874797 Scheduler overhead time: 0.03874727338552475 Adapter cache time: 0.04131109965965152 Engine time: 0.039567106403410435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.735755108296871,
    "estimated_duration": 3600.0092904386424,
    "input_throughput": 5594.85167260384,
    "output_throughput": 4876.933525318977,
    "total_throughput": 10471.785197922818,
    "itl": 148.94664243368246,
    "ttft": 55145.01942884977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.19514920466587,
    "arrivals": 81595,
    "finished_requests": 80397,
    "scheduler_time": 67.29542133389833
}
#Debug simulation 
Total elapsed time: 5.735844707116485. Arrivals time: 0.172703396063298 Scheduler time: 5.431953235063702 Scheduler overhead time: 0.03787114517763257 Adapter cache time: 0.03826413722708821 Engine time: 0.03798217559233308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.722327326890081,
    "estimated_duration": 3600.0351458008813,
    "input_throughput": 5594.811490519274,
    "output_throughput": 4876.898499304562,
    "total_throughput": 10471.709989823836,
    "itl": 148.9996862421822,
    "ttft": 55167.11338638001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4015003010095133,
    "arrivals": 81595,
    "finished_requests": 80397,
    "scheduler_time": 67.29565489087877
}
#Debug simulation 
Total elapsed time: 5.722493953071535. Arrivals time: 0.17370892176404595 Scheduler time: 5.417016745079309 Scheduler overhead time: 0.037804882042109966 Adapter cache time: 0.038630923721939325 Engine time: 0.03823738545179367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.752064032945782,
    "estimated_duration": 3600.117330563535,
    "input_throughput": 5558.983544813335,
    "output_throughput": 4854.911769573934,
    "total_throughput": 10413.89531438727,
    "itl": 133.1208802693945,
    "ttft": 86477.71513980793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.405404693018606,
    "arrivals": 81595,
    "finished_requests": 79900,
    "scheduler_time": 66.46787290237486
}
#Debug simulation 
Total elapsed time: 5.752174315974116. Arrivals time: 0.1752848420292139 Scheduler time: 5.433536964934319 Scheduler overhead time: 0.04134194180369377 Adapter cache time: 0.04098851094022393 Engine time: 0.042281802743673325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.713388199917972,
    "estimated_duration": 3600.1560626741725,
    "input_throughput": 5594.773017989284,
    "output_throughput": 4876.9644133032825,
    "total_throughput": 10471.737431292566,
    "itl": 148.9717846923819,
    "ttft": 55152.187085061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.265438059968839,
    "arrivals": 81595,
    "finished_requests": 80399,
    "scheduler_time": 67.29818537155818
}
#Debug simulation 
Total elapsed time: 5.713482012972236. Arrivals time: 0.17351843137294054 Scheduler time: 5.4064091756008565 Scheduler overhead time: 0.03980951802805066 Adapter cache time: 0.03862913977354765 Engine time: 0.03801766550168395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.73279803711921,
    "estimated_duration": 3600.010941855065,
    "input_throughput": 5559.081992591818,
    "output_throughput": 4854.959688259652,
    "total_throughput": 10414.04168085147,
    "itl": 133.126409585185,
    "ttft": 86569.45887483771,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4476579652540367,
    "arrivals": 81595,
    "finished_requests": 79897,
    "scheduler_time": 66.46574480288555
}
#Debug simulation 
Total elapsed time: 5.732887653168291. Arrivals time: 0.1754153724759817 Scheduler time: 5.4146198481321335 Scheduler overhead time: 0.04121232219040394 Adapter cache time: 0.04169591795653105 Engine time: 0.0413047494366765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.755822438746691,
    "estimated_duration": 3600.127228008593,
    "input_throughput": 5594.957823516098,
    "output_throughput": 4877.04291765049,
    "total_throughput": 10472.000741166588,
    "itl": 148.92607791761233,
    "ttft": 55047.00357726807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1216125078777974,
    "arrivals": 81595,
    "finished_requests": 80401,
    "scheduler_time": 67.29761336418493
}
#Debug simulation 
Total elapsed time: 5.755946637131274. Arrivals time: 0.17262303549796343 Scheduler time: 5.452407433651388 Scheduler overhead time: 0.0376724973320961 Adapter cache time: 0.03845166601240635 Engine time: 0.0377347101457417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.763941890094429,
    "estimated_duration": 3600.068791530684,
    "input_throughput": 5559.058217743344,
    "output_throughput": 4854.93972812909,
    "total_throughput": 10413.997945872434,
    "itl": 133.1330447902371,
    "ttft": 86541.8563921306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4915460367128692,
    "arrivals": 81595,
    "finished_requests": 79899,
    "scheduler_time": 66.46618522761297
}
#Debug simulation 
Total elapsed time: 5.764051099307835. Arrivals time: 0.17758499877527356 Scheduler time: 5.443177406210452 Scheduler overhead time: 0.04124594759196043 Adapter cache time: 0.041396564338356256 Engine time: 0.041823809035122395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.8124106507748365,
    "estimated_duration": 3600.106306977838,
    "input_throughput": 5529.695876317507,
    "output_throughput": 4900.620008304829,
    "total_throughput": 10430.315884622336,
    "itl": 121.46392077612886,
    "ttft": 40397.52007413325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9495306928851959,
    "arrivals": 81010,
    "finished_requests": 80104,
    "scheduler_time": 66.6040152441316
}
#Debug simulation 
Total elapsed time: 5.812496080063283. Arrivals time: 0.17435305286198854 Scheduler time: 5.493125570006669 Scheduler overhead time: 0.04440750787034631 Adapter cache time: 0.0355137730948627 Engine time: 0.04504983266815543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.785065114032477,
    "estimated_duration": 3600.0613343808,
    "input_throughput": 5529.597179328037,
    "output_throughput": 4900.555674292262,
    "total_throughput": 10430.152853620299,
    "itl": 121.48977772978147,
    "ttft": 40443.23841710425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0787236435082788,
    "arrivals": 81010,
    "finished_requests": 80102,
    "scheduler_time": 66.60438874030206
}
#Debug simulation 
Total elapsed time: 5.785156041849405. Arrivals time: 0.17331817280501127 Scheduler time: 5.467557535972446 Scheduler overhead time: 0.04415168333798647 Adapter cache time: 0.035320525988936424 Engine time: 0.04484245926141739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.778518982231617,
    "estimated_duration": 3600.058585000108,
    "input_throughput": 5525.778964510769,
    "output_throughput": 4902.430219756957,
    "total_throughput": 10428.209184267726,
    "itl": 120.22604621800158,
    "ttft": 42869.38066650406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.079008172992626,
    "arrivals": 81010,
    "finished_requests": 80054,
    "scheduler_time": 66.51917398917413
}
#Debug simulation 
Total elapsed time: 5.778637827839702. Arrivals time: 0.17541275406256318 Scheduler time: 5.45825888030231 Scheduler overhead time: 0.04425157979130745 Adapter cache time: 0.03563228901475668 Engine time: 0.04494494292885065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.806125415954739,
    "estimated_duration": 3600.0149868854996,
    "input_throughput": 5529.644479958702,
    "output_throughput": 4900.595154261539,
    "total_throughput": 10430.239634220241,
    "itl": 121.46694372788387,
    "ttft": 40399.3322835409,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9959086769306902,
    "arrivals": 81010,
    "finished_requests": 80101,
    "scheduler_time": 66.60246653018588
}
#Debug simulation 
Total elapsed time: 5.806214461103082. Arrivals time: 0.17381585761904716 Scheduler time: 5.488628413528204 Scheduler overhead time: 0.04400044772773981 Adapter cache time: 0.03512853104621172 Engine time: 0.04461388196796179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.773520410060883,
    "estimated_duration": 3600.0483089759614,
    "input_throughput": 5526.100844368652,
    "output_throughput": 4902.791430879617,
    "total_throughput": 10428.89227524827,
    "itl": 120.22612628828124,
    "ttft": 42779.405469679165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1055422219261564,
    "arrivals": 81010,
    "finished_requests": 80057,
    "scheduler_time": 66.51865561150403
}
#Debug simulation 
Total elapsed time: 5.773613092955202. Arrivals time: 0.1757668750360608 Scheduler time: 5.453022067435086 Scheduler overhead time: 0.04433131963014603 Adapter cache time: 0.03560599172487855 Engine time: 0.044770261738449335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.779925198759884,
    "estimated_duration": 3600.02136577684,
    "input_throughput": 5529.634681960939,
    "output_throughput": 4900.586470878633,
    "total_throughput": 10430.221152839571,
    "itl": 121.45010228527788,
    "ttft": 40399.431650883955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9076520881475572,
    "arrivals": 81010,
    "finished_requests": 80101,
    "scheduler_time": 66.60192720313148
}
#Debug simulation 
Total elapsed time: 5.780058423988521. Arrivals time: 0.17273557279258966 Scheduler time: 5.4634590544737875 Scheduler overhead time: 0.044086412992328405 Adapter cache time: 0.0353144770488143 Engine time: 0.04429907817393541 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.7543192049488425,
    "estimated_duration": 3600.1281921544664,
    "input_throughput": 5526.064611631032,
    "output_throughput": 4902.67764310841,
    "total_throughput": 10428.742254739442,
    "itl": 120.23722719475222,
    "ttft": 42823.51292446274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1359600523486733,
    "arrivals": 81010,
    "finished_requests": 80057,
    "scheduler_time": 66.52093706475162
}
#Debug simulation 
Total elapsed time: 5.754434381145984. Arrivals time: 0.17252185381948948 Scheduler time: 5.437465318012983 Scheduler overhead time: 0.044152830727398396 Adapter cache time: 0.03552212659269571 Engine time: 0.044683403335511684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.700401053763926,
    "estimated_duration": 3600.078835722132,
    "input_throughput": 5444.6007697129435,
    "output_throughput": 4882.409469923248,
    "total_throughput": 10327.010239636193,
    "itl": 93.89795242953221,
    "ttft": 21588.986985767453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7138731366023656,
    "arrivals": 79794,
    "finished_requests": 79318,
    "scheduler_time": 64.54765124785241
}
#Debug simulation 
Total elapsed time: 5.700486138928682. Arrivals time: 0.17360393423587084 Scheduler time: 5.367482948582619 Scheduler overhead time: 0.05350938579067588 Adapter cache time: 0.027843674179166555 Engine time: 0.05379287851974368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.794612211175263,
    "estimated_duration": 3600.0806425965234,
    "input_throughput": 5444.598037077018,
    "output_throughput": 4882.4070194501855,
    "total_throughput": 10327.005056527203,
    "itl": 93.90958572900134,
    "ttft": 21634.17910333085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8256084329681526,
    "arrivals": 79794,
    "finished_requests": 79318,
    "scheduler_time": 64.5486430254424
}
#Debug simulation 
Total elapsed time: 5.794699646998197. Arrivals time: 0.17459130520001054 Scheduler time: 5.4586102636530995 Scheduler overhead time: 0.05411389796063304 Adapter cache time: 0.028029223438352346 Engine time: 0.05499672191217542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.759835577104241,
    "estimated_duration": 3600.0913445322262,
    "input_throughput": 5444.661016662862,
    "output_throughput": 4882.5108359254455,
    "total_throughput": 10327.171852588308,
    "itl": 93.90974591285264,
    "ttft": 21589.099945392056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.829152128286671,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.54888946737587
}
#Debug simulation 
Total elapsed time: 5.7599222478456795. Arrivals time: 0.17410488007590175 Scheduler time: 5.424885073676705 Scheduler overhead time: 0.053898470010608435 Adapter cache time: 0.02799248183146119 Engine time: 0.054783799685537815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.7190023409202695,
    "estimated_duration": 3600.0537291181486,
    "input_throughput": 5444.638740100516,
    "output_throughput": 4882.443519615355,
    "total_throughput": 10327.082259715871,
    "itl": 93.90219932361022,
    "ttft": 21499.319173255633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.752878466285757,
    "arrivals": 79794,
    "finished_requests": 79318,
    "scheduler_time": 64.54757296921376
}
#Debug simulation 
Total elapsed time: 5.7191198617219925. Arrivals time: 0.1734804236330092 Scheduler time: 5.386826912406832 Scheduler overhead time: 0.05328292539343238 Adapter cache time: 0.027635629288852215 Engine time: 0.05374652426689863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.727988796308637,
    "estimated_duration": 3600.0802834434685,
    "input_throughput": 5444.598580243798,
    "output_throughput": 4882.407506531377,
    "total_throughput": 10327.006086775176,
    "itl": 93.91219818644261,
    "ttft": 21634.04305197753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8515363022685096,
    "arrivals": 79794,
    "finished_requests": 79318,
    "scheduler_time": 64.5488562749255
}
#Debug simulation 
Total elapsed time: 5.728079687338322. Arrivals time: 0.17643492622300982 Scheduler time: 5.390468908939511 Scheduler overhead time: 0.05396458460018039 Adapter cache time: 0.027885525953024626 Engine time: 0.054869386833161116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.753869426902384,
    "estimated_duration": 3600.0468141379943,
    "input_throughput": 5444.649198178085,
    "output_throughput": 4882.452897826747,
    "total_throughput": 10327.102096004832,
    "itl": 93.89453534587835,
    "ttft": 21454.55234487581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6744281651451958,
    "arrivals": 79794,
    "finished_requests": 79318,
    "scheduler_time": 64.54697337748773
}
#Debug simulation 
Total elapsed time: 5.753960165195167. Arrivals time: 0.17728192312642932 Scheduler time: 5.415506473742425 Scheduler overhead time: 0.05400364240631461 Adapter cache time: 0.02779577998444438 Engine time: 0.05502676963806152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.72683284105733,
    "estimated_duration": 3600.005865957067,
    "input_throughput": 5444.710850433308,
    "output_throughput": 4882.459544361648,
    "total_throughput": 10327.170394794955,
    "itl": 93.91289015469052,
    "ttft": 21409.604051674603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8756810292601545,
    "arrivals": 79794,
    "finished_requests": 79317,
    "scheduler_time": 64.54729806108479
}
#Debug simulation 
Total elapsed time: 5.726926608942449. Arrivals time: 0.1756067336536944 Scheduler time: 5.391706950496882 Scheduler overhead time: 0.053611351642757654 Adapter cache time: 0.027732448652386665 Engine time: 0.05402239924296737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.8697160659357905,
    "estimated_duration": 3599.78613208825,
    "input_throughput": 2322.1762886093225,
    "output_throughput": 2058.042541461288,
    "total_throughput": 4380.21883007061,
    "itl": 39.427104700997354,
    "ttft": 10779.08952613831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.740810477991085,
    "arrivals": 33938,
    "finished_requests": 33837,
    "scheduler_time": 13.475050895687245
}
#Debug simulation 
Total elapsed time: 2.86982444813475. Arrivals time: 0.09163365047425032 Scheduler time: 2.354959142860025 Scheduler overhead time: 0.09330128645524383 Adapter cache time: 0.19484440796077251 Engine time: 0.09105718741193414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.8960004481486976,
    "estimated_duration": 3599.814267224399,
    "input_throughput": 2322.1581391323793,
    "output_throughput": 2058.0264563794453,
    "total_throughput": 4380.184595511825,
    "itl": 39.4469459849261,
    "ttft": 10778.968448333804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.567390316336615,
    "arrivals": 33938,
    "finished_requests": 33837,
    "scheduler_time": 13.483840805434813
}
#Debug simulation 
Total elapsed time: 2.8961041779257357. Arrivals time: 0.09252858581021428 Scheduler time: 2.3774332981556654 Scheduler overhead time: 0.09428971773013473 Adapter cache time: 0.1954528046771884 Engine time: 0.09193893847987056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.8348553981631994,
    "estimated_duration": 3599.78795439619,
    "input_throughput": 2322.175113062223,
    "output_throughput": 2058.041499625682,
    "total_throughput": 4380.216612687905,
    "itl": 39.4489336231797,
    "ttft": 10779.142876226862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.595592675208025,
    "arrivals": 33938,
    "finished_requests": 33837,
    "scheduler_time": 13.484017109016587
}
#Debug simulation 
Total elapsed time: 2.8349455883726478. Arrivals time: 0.09483579313382506 Scheduler time: 2.319438009057194 Scheduler overhead time: 0.09290604665875435 Adapter cache time: 0.19320333003997803 Engine time: 0.09062271285802126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.8208457799628377,
    "estimated_duration": 3599.805518102555,
    "input_throughput": 2322.1637830051936,
    "output_throughput": 2058.0314582952806,
    "total_throughput": 4380.195241300474,
    "itl": 39.43466703956336,
    "ttft": 10779.099870348131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.030366184840311,
    "arrivals": 33938,
    "finished_requests": 33837,
    "scheduler_time": 13.478156932896889
}
#Debug simulation 
Total elapsed time: 2.8209390938282013. Arrivals time: 0.09214519616216421 Scheduler time: 2.3079468524083495 Scheduler overhead time: 0.09301524795591831 Adapter cache time: 0.19277365738525987 Engine time: 0.09149487037211657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.818913472816348,
    "estimated_duration": 3599.812425097653,
    "input_throughput": 2322.1593274469665,
    "output_throughput": 2058.027509530313,
    "total_throughput": 4380.18683697728,
    "itl": 39.452702259984164,
    "ttft": 10779.054973607661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.753065587579218,
    "arrivals": 33938,
    "finished_requests": 33837,
    "scheduler_time": 13.485592791058634
}
#Debug simulation 
Total elapsed time: 2.8189943437464535. Arrivals time: 0.09134497912600636 Scheduler time: 2.3064857465215027 Scheduler overhead time: 0.09298258507624269 Adapter cache time: 0.1948911682702601 Engine time: 0.08960133045911789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.856440659146756,
    "estimated_duration": 3599.8232093759443,
    "input_throughput": 2322.2173739607597,
    "output_throughput": 2058.04717873474,
    "total_throughput": 4380.2645526955,
    "itl": 39.42009727395964,
    "ttft": 10672.978885674709,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.450569427973575,
    "arrivals": 33938,
    "finished_requests": 33838,
    "scheduler_time": 13.472281411531013
}
#Debug simulation 
Total elapsed time: 2.8565217168070376. Arrivals time: 0.09147218335419893 Scheduler time: 2.339838474523276 Scheduler overhead time: 0.09588297130540013 Adapter cache time: 0.19474411383271217 Engine time: 0.09040938038378954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.8488572789356112,
    "estimated_duration": 3599.801410198229,
    "input_throughput": 2322.1664329365544,
    "output_throughput": 2058.0338068127035,
    "total_throughput": 4380.200239749258,
    "itl": 39.45733596507886,
    "ttft": 10779.10394108606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.934890976845288,
    "arrivals": 33938,
    "finished_requests": 33837,
    "scheduler_time": 13.487453152513543
}
#Debug simulation 
Total elapsed time: 2.848935971967876. Arrivals time: 0.09166259551420808 Scheduler time: 2.3358726664446294 Scheduler overhead time: 0.09303971333429217 Adapter cache time: 0.19366748398169875 Engine time: 0.09114385768771172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.7212977460585535,
    "estimated_duration": 3599.7660881567904,
    "input_throughput": 2145.5113501429273,
    "output_throughput": 1940.1132820760683,
    "total_throughput": 4085.624632218996,
    "itl": 35.7957884288523,
    "ttft": 9306.41251319716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.941186203239691,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.106842953160292
}
#Debug simulation 
Total elapsed time: 2.721378056332469. Arrivals time: 0.08679493144154549 Scheduler time: 2.207963445689529 Scheduler overhead time: 0.10112702799960971 Adapter cache time: 0.17956619197502732 Engine time: 0.0989179597236216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.671477052848786,
    "estimated_duration": 3599.762071678958,
    "input_throughput": 2145.5137440230246,
    "output_throughput": 1940.1154467808,
    "total_throughput": 4085.6291908038247,
    "itl": 35.80487054027222,
    "ttft": 9306.45940182457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2270,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.38968366880871,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.111438188593192
}
#Debug simulation 
Total elapsed time: 2.6715649836696684. Arrivals time: 0.08639800734817982 Scheduler time: 2.1633948627859354 Scheduler overhead time: 0.10014072526246309 Adapter cache time: 0.17890758207067847 Engine time: 0.09580139396712184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.685098844114691,
    "estimated_duration": 3599.7575843742684,
    "input_throughput": 2145.5164185291987,
    "output_throughput": 1940.1178652461936,
    "total_throughput": 4085.6342837753923,
    "itl": 35.80647345866856,
    "ttft": 9306.383254930299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.395748294610481,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.111553123858018
}
#Debug simulation 
Total elapsed time: 2.685203846078366. Arrivals time: 0.08569848071783781 Scheduler time: 2.176869281101972 Scheduler overhead time: 0.10017353715375066 Adapter cache time: 0.17941032443195581 Engine time: 0.09628410451114178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.697203226853162,
    "estimated_duration": 3599.7359282627644,
    "input_throughput": 2145.5290482175146,
    "output_throughput": 1940.1142581507181,
    "total_throughput": 4085.6433063682325,
    "itl": 35.79929351693582,
    "ttft": 9420.557971383741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.090332129578792,
    "arrivals": 31534,
    "finished_requests": 31452,
    "scheduler_time": 10.108347246385636
}
#Debug simulation 
Total elapsed time: 2.6973133026622236. Arrivals time: 0.08682664856314659 Scheduler time: 2.1852683066390455 Scheduler overhead time: 0.10052618570625782 Adapter cache time: 0.17931572161614895 Engine time: 0.09820501878857613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.6864958689548075,
    "estimated_duration": 3599.740576276003,
    "input_throughput": 2145.5262778935958,
    "output_throughput": 1940.1117530599859,
    "total_throughput": 4085.6380309535816,
    "itl": 35.80741593506638,
    "ttft": 9420.659803305094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.489294525813142,
    "arrivals": 31534,
    "finished_requests": 31452,
    "scheduler_time": 10.11241678189515
}
#Debug simulation 
Total elapsed time: 2.6865776302292943. Arrivals time: 0.08609959110617638 Scheduler time: 2.1790696708485484 Scheduler overhead time: 0.09947643522173166 Adapter cache time: 0.17778688203543425 Engine time: 0.09709250601008534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.7051926371641457,
    "estimated_duration": 3599.7454550806515,
    "input_throughput": 2145.5233700203285,
    "output_throughput": 1940.1091235889976,
    "total_throughput": 4085.632493609326,
    "itl": 35.79329416947271,
    "ttft": 9420.47260351597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.778444018543028,
    "arrivals": 31534,
    "finished_requests": 31452,
    "scheduler_time": 10.105318060528752
}
#Debug simulation 
Total elapsed time: 2.705273660365492. Arrivals time: 0.08579592825844884 Scheduler time: 2.1946542598307133 Scheduler overhead time: 0.1011864161118865 Adapter cache time: 0.17895757174119353 Engine time: 0.09733937820419669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.7140560131520033,
    "estimated_duration": 3599.7324817830686,
    "input_throughput": 2145.531102404135,
    "output_throughput": 1940.1161156677508,
    "total_throughput": 4085.647218071886,
    "itl": 35.809635853990706,
    "ttft": 9420.718907679815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2267,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.581195115707518,
    "arrivals": 31534,
    "finished_requests": 31452,
    "scheduler_time": 10.113478189573954
}
#Debug simulation 
Total elapsed time: 2.7141354931518435. Arrivals time: 0.08591025276109576 Scheduler time: 2.2029509567655623 Scheduler overhead time: 0.10038559045642614 Adapter cache time: 0.1796911028213799 Engine time: 0.09776902804151177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.6040346468798816,
    "estimated_duration": 3599.979390813972,
    "input_throughput": 2077.3543923842,
    "output_throughput": 1833.1291053607629,
    "total_throughput": 3910.4834977449627,
    "itl": 33.2399360053458,
    "ttft": 7644.6404160031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.778922871491001,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.261911549208011
}
#Debug simulation 
Total elapsed time: 2.6041104369796813. Arrivals time: 0.08349449746310711 Scheduler time: 2.0911459089256823 Scheduler overhead time: 0.10647975699976087 Adapter cache time: 0.17093278374522924 Engine time: 0.10186525341123343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.570929836947471,
    "estimated_duration": 3599.9880208715554,
    "input_throughput": 2077.3494124542876,
    "output_throughput": 1833.1247108989908,
    "total_throughput": 3910.4741233532786,
    "itl": 33.24257473266258,
    "ttft": 7644.775732532683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9531767384219,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.2635529072867255
}
#Debug simulation 
Total elapsed time: 2.571013417094946. Arrivals time: 0.0834853071719408 Scheduler time: 2.057337749283761 Scheduler overhead time: 0.10646803304553032 Adapter cache time: 0.17059842124581337 Engine time: 0.10337514197453856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.586086791008711,
    "estimated_duration": 3599.97617616283,
    "input_throughput": 2077.3562473880506,
    "output_throughput": 1833.1307422800876,
    "total_throughput": 3910.486989668138,
    "itl": 33.242741211229756,
    "ttft": 7644.671054592555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9631739228404843,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.263618708445425
}
#Debug simulation 
Total elapsed time: 2.5861732908524573. Arrivals time: 0.08481887215748429 Scheduler time: 2.0700066378340125 Scheduler overhead time: 0.10673580784350634 Adapter cache time: 0.1708162329159677 Engine time: 0.10387077834457159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.62570599000901,
    "estimated_duration": 3599.997233422984,
    "input_throughput": 2077.344096425675,
    "output_throughput": 1833.1200198521428,
    "total_throughput": 3910.464116277818,
    "itl": 33.24123263914425,
    "ttft": 7644.736857763396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8428560024429776,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.262534574768399
}
#Debug simulation 
Total elapsed time: 2.6257875156588852. Arrivals time: 0.08302753511816263 Scheduler time: 2.1054298798553646 Scheduler overhead time: 0.11194748245179653 Adapter cache time: 0.1716958419419825 Engine time: 0.10278782434761524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.574392589274794,
    "estimated_duration": 3599.971901385461,
    "input_throughput": 2077.35871413938,
    "output_throughput": 1833.1329190264696,
    "total_throughput": 3910.4916331658496,
    "itl": 33.24437816045582,
    "ttft": 7644.64082467294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9940839263238033,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.263964643720944
}
#Debug simulation 
Total elapsed time: 2.5744758774526417. Arrivals time: 0.08330156048759818 Scheduler time: 2.0589721221476793 Scheduler overhead time: 0.10755056142807007 Adapter cache time: 0.17113639460876584 Engine time: 0.10350887896493077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.613489655777812,
    "estimated_duration": 3599.9699393574238,
    "input_throughput": 2077.3598463255116,
    "output_throughput": 1833.1339181065296,
    "total_throughput": 3910.4937644320416,
    "itl": 33.23884550468921,
    "ttft": 7644.600824787014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.714965667771116,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.261284854205642
}
#Debug simulation 
Total elapsed time: 2.613591249566525. Arrivals time: 0.0862935041077435 Scheduler time: 2.096615503076464 Scheduler overhead time: 0.10630025807768106 Adapter cache time: 0.17133518727496266 Engine time: 0.10316831013187766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5969668100588024,
    "estimated_duration": 3599.9823669182792,
    "input_throughput": 2077.352675035967,
    "output_throughput": 1833.1275899134994,
    "total_throughput": 3910.4802649494663,
    "itl": 33.2445810266565,
    "ttft": 7644.786715397944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0334448614716814,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.264195322901327
}
#Debug simulation 
Total elapsed time: 2.597081996034831. Arrivals time: 0.08286127913743258 Scheduler time: 2.086253718007356 Scheduler overhead time: 0.10626460472121835 Adapter cache time: 0.17040745029225945 Engine time: 0.10139477485790849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5294435787945986,
    "estimated_duration": 3600.0296971427706,
    "input_throughput": 2033.2943380465967,
    "output_throughput": 1803.9709520047456,
    "total_throughput": 3837.2652900513426,
    "itl": 32.48294630200205,
    "ttft": 5996.989115115978,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3925219234894153,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.385399645681721
}
#Debug simulation 
Total elapsed time: 2.529521951917559. Arrivals time: 0.08102607075124979 Scheduler time: 2.0205364278517663 Scheduler overhead time: 0.10800817608833313 Adapter cache time: 0.16378994518890977 Engine time: 0.10506665892899036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5176068181172013,
    "estimated_duration": 3600.01457680611,
    "input_throughput": 2033.3028780383843,
    "output_throughput": 1803.9785288207663,
    "total_throughput": 3837.2814068591506,
    "itl": 32.48443499518441,
    "ttft": 5997.0554177254735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.47487957334379,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.386106903346946
}
#Debug simulation 
Total elapsed time: 2.51768501708284. Arrivals time: 0.08069512527436018 Scheduler time: 2.0097793811000884 Scheduler overhead time: 0.10874347109347582 Adapter cache time: 0.1627042070031166 Engine time: 0.10477600246667862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.546520040370524,
    "estimated_duration": 3600.0177478050578,
    "input_throughput": 2033.3010870468565,
    "output_throughput": 1803.9769398247065,
    "total_throughput": 3837.278026871563,
    "itl": 32.484426255439544,
    "ttft": 5997.047776309081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4792303746566262,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.3861611538235135
}
#Debug simulation 
Total elapsed time: 2.546595779247582. Arrivals time: 0.08162324922159314 Scheduler time: 2.0362669080495834 Scheduler overhead time: 0.11017620656639338 Adapter cache time: 0.16355046350508928 Engine time: 0.10374413058161736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.5514484946615994,
    "estimated_duration": 3600.0260416703295,
    "input_throughput": 2033.2964026570555,
    "output_throughput": 1803.9727837598562,
    "total_throughput": 3837.2691864169115,
    "itl": 32.48344300552964,
    "ttft": 5997.122530952707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4205363959912165,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.385623778096034
}
#Debug simulation 
Total elapsed time: 2.5515759009867907. Arrivals time: 0.08128698542714119 Scheduler time: 2.0437974906526506 Scheduler overhead time: 0.10770713118836284 Adapter cache time: 0.163003321737051 Engine time: 0.10513846902176738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.5653780992142856,
    "estimated_duration": 3600.0030994347526,
    "input_throughput": 2033.3093605250847,
    "output_throughput": 1803.9842801856746,
    "total_throughput": 3837.2936407107595,
    "itl": 32.48449179713768,
    "ttft": 5997.097739776171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4959556282497992,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.386373735555704
}
#Debug simulation 
Total elapsed time: 2.565458808094263. Arrivals time: 0.08209805423393846 Scheduler time: 2.0545899840071797 Scheduler overhead time: 0.10865432908758521 Adapter cache time: 0.16330494498834014 Engine time: 0.10575815895572305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5484523600898683,
    "estimated_duration": 3600.0134799582524,
    "input_throughput": 2033.3034975427051,
    "output_throughput": 1803.979078454815,
    "total_throughput": 3837.2825759975203,
    "itl": 32.482239609932826,
    "ttft": 5997.046710681612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3604728841804785,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.385049290232158
}
#Debug simulation 
Total elapsed time: 2.5485318591818213. Arrivals time: 0.08111322019249201 Scheduler time: 2.0390393072739244 Scheduler overhead time: 0.10883011994883418 Adapter cache time: 0.16391277825459838 Engine time: 0.10457228077575564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.539500522892922,
    "estimated_duration": 3600.0084113116113,
    "input_throughput": 2033.3063603407227,
    "output_throughput": 1803.981618374574,
    "total_throughput": 3837.287978715297,
    "itl": 32.485020464415896,
    "ttft": 5996.888109917089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5144414348527804,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.386575850835749
}
#Debug simulation 
Total elapsed time: 2.539584763813764. Arrivals time: 0.08232591999694705 Scheduler time: 2.0288697881624103 Scheduler overhead time: 0.10832226695492864 Adapter cache time: 0.16370061738416553 Engine time: 0.10565097350627184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.340530753135681,
    "estimated_duration": 3599.9488639571146,
    "input_throughput": 1820.03057476709,
    "output_throughput": 1617.065747317612,
    "total_throughput": 3437.096322084702,
    "itl": 29.72111466902989,
    "ttft": 8132.405988237224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.931225247741847,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5700831904276837
}
#Debug simulation 
Total elapsed time: 2.3406132641248405. Arrivals time: 0.0762444268912077 Scheduler time: 1.821044429205358 Scheduler overhead time: 0.11661514919251204 Adapter cache time: 0.15983487898483872 Engine time: 0.11220632214099169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.37655023438856,
    "estimated_duration": 3599.9614358122153,
    "input_throughput": 1820.024218821041,
    "output_throughput": 1617.0601001692673,
    "total_throughput": 3437.084318990308,
    "itl": 29.726438006912463,
    "ttft": 8132.40924621337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.312407739984137,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5726682400000613
}
#Debug simulation 
Total elapsed time: 2.3766242093406618. Arrivals time: 0.07632913766428828 Scheduler time: 1.8569108839146793 Scheduler overhead time: 0.1164625003002584 Adapter cache time: 0.161198609508574 Engine time: 0.11083952896296978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.3385038231499493,
    "estimated_duration": 3599.962460107262,
    "input_throughput": 1820.0237009706987,
    "output_throughput": 1617.0596400681775,
    "total_throughput": 3437.0833410388764,
    "itl": 29.726502674944562,
    "ttft": 8132.566338111435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.325632104482441,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5726561182436396
}
#Debug simulation 
Total elapsed time: 2.338581524323672. Arrivals time: 0.07510530762374401 Scheduler time: 1.8237929218448699 Scheduler overhead time: 0.11617618519812822 Adapter cache time: 0.15921311266720295 Engine time: 0.10948010673746467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.372150157112628,
    "estimated_duration": 3599.9747487518025,
    "input_throughput": 1820.0174882536999,
    "output_throughput": 1617.0541201763715,
    "total_throughput": 3437.0716084300716,
    "itl": 29.723657026864608,
    "ttft": 8132.561479621027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.059895833188023,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.570960622142668
}
#Debug simulation 
Total elapsed time: 2.372239858843386. Arrivals time: 0.07739562494680285 Scheduler time: 1.8516188617795706 Scheduler overhead time: 0.11668021604418755 Adapter cache time: 0.159259004984051 Engine time: 0.11250388063490391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.3537653773091733,
    "estimated_duration": 3599.9651799632793,
    "input_throughput": 1820.0223259011723,
    "output_throughput": 1617.0584183426406,
    "total_throughput": 3437.080744243813,
    "itl": 29.891304967535213,
    "ttft": 8132.781842915373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.406265709549073,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.6465584354197853
}
#Debug simulation 
Total elapsed time: 2.35384119534865. Arrivals time: 0.07525893347337842 Scheduler time: 1.8395625171251595 Scheduler overhead time: 0.11729042464867234 Adapter cache time: 0.15724945813417435 Engine time: 0.10942779527977109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.370067692361772,
    "estimated_duration": 3599.9721375962326,
    "input_throughput": 1820.0188083608064,
    "output_throughput": 1617.055293068747,
    "total_throughput": 3437.0741014295536,
    "itl": 29.719672133030784,
    "ttft": 8132.3590157614,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.794717471520247,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5691167315498276
}
#Debug simulation 
Total elapsed time: 2.3701470042578876. Arrivals time: 0.0760344578884542 Scheduler time: 1.8525175396353006 Scheduler overhead time: 0.11544329859316349 Adapter cache time: 0.15925042843446136 Engine time: 0.11223326157778502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.3845418342389166,
    "estimated_duration": 3599.9792934389766,
    "input_throughput": 1820.0151906265578,
    "output_throughput": 1617.0520787743187,
    "total_throughput": 3437.0672694008763,
    "itl": 29.729366058081276,
    "ttft": 8132.582115770441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.484962151869944,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5737083812766954
}
#Debug simulation 
Total elapsed time: 2.384651490021497. Arrivals time: 0.07651817006990314 Scheduler time: 1.8640853208489716 Scheduler overhead time: 0.11610248871147633 Adapter cache time: 0.16014159843325615 Engine time: 0.11305126221850514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.3090563090518117,
    "estimated_duration": 3600.02577682028,
    "input_throughput": 1741.8675278316066,
    "output_throughput": 1554.3863702394135,
    "total_throughput": 3296.25389807102,
    "itl": 28.62023853068041,
    "ttft": 5126.320515410932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.305326763447453,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5792222635855053
}
#Debug simulation 
Total elapsed time: 2.3091342579573393. Arrivals time: 0.07311470434069633 Scheduler time: 1.7928688498213887 Scheduler overhead time: 0.12027059495449066 Adapter cache time: 0.15159280505031347 Engine time: 0.11512677650898695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2652242528274655,
    "estimated_duration": 3600.016633811691,
    "input_throughput": 1741.8719516749904,
    "output_throughput": 1554.3903179344882,
    "total_throughput": 3296.2622696094786,
    "itl": 28.62251476992017,
    "ttft": 4985.471756792992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.514453850765715,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5803110676806225
}
#Debug simulation 
Total elapsed time: 2.265302374958992. Arrivals time: 0.07294534519314766 Scheduler time: 1.7508446392603219 Scheduler overhead time: 0.1198681565001607 Adapter cache time: 0.15033404296264052 Engine time: 0.11486714612692595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.3154982239939272,
    "estimated_duration": 3600.0021589241887,
    "input_throughput": 1741.8789553931638,
    "output_throughput": 1554.3965678265697,
    "total_throughput": 3296.2755232197333,
    "itl": 28.622704306388883,
    "ttft": 4985.48602725051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5223991078510446,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5803181563206783
}
#Debug simulation 
Total elapsed time: 2.3155831061303616. Arrivals time: 0.07363169640302658 Scheduler time: 1.7970440573990345 Scheduler overhead time: 0.12067849934101105 Adapter cache time: 0.1509565352462232 Engine time: 0.11599773447960615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.279005893971771,
    "estimated_duration": 3600.0183402497214,
    "input_throughput": 1741.8711260134908,
    "output_throughput": 1554.3895811408104,
    "total_throughput": 3296.260707154301,
    "itl": 28.620498131088173,
    "ttft": 4985.444870917024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3804345863172425,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5796226995815905
}
#Debug simulation 
Total elapsed time: 2.2790855737403035. Arrivals time: 0.07190323248505592 Scheduler time: 1.7686591180972755 Scheduler overhead time: 0.11919144447892904 Adapter cache time: 0.15040436014533043 Engine time: 0.11226291442289948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.267987441737205,
    "estimated_duration": 3600.0095200392166,
    "input_throughput": 1741.8753936883172,
    "output_throughput": 1554.393389476104,
    "total_throughput": 3296.268783164421,
    "itl": 28.623083995589667,
    "ttft": 4985.639388659516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5636463497951603,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5804520522200647
}
#Debug simulation 
Total elapsed time: 2.2680796277709305. Arrivals time: 0.07516056578606367 Scheduler time: 1.7536641405895352 Scheduler overhead time: 0.1189035871066153 Adapter cache time: 0.15114748058840632 Engine time: 0.1129747899249196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.3026428688317537,
    "estimated_duration": 3600.0053551021997,
    "input_throughput": 1741.8774089079045,
    "output_throughput": 1554.3951877930308,
    "total_throughput": 3296.272596700935,
    "itl": 28.61899639379872,
    "ttft": 4985.486155247641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.229254318494272,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.579050255055751
}
#Debug simulation 
Total elapsed time: 2.3027230915613472. Arrivals time: 0.0728682023473084 Scheduler time: 1.7843294078484178 Scheduler overhead time: 0.12078903336077929 Adapter cache time: 0.15151110151782632 Engine time: 0.1162845934741199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2782940408214927,
    "estimated_duration": 3600.0208959411075,
    "input_throughput": 1741.8698894414927,
    "output_throughput": 1554.3884776638647,
    "total_throughput": 3296.258367105357,
    "itl": 28.783529346806837,
    "ttft": 4985.733046278497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1081,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.613681770898449,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.6358524587895724
}
#Debug simulation 
Total elapsed time: 2.2783812629058957. Arrivals time: 0.07196036819368601 Scheduler time: 1.7674370929598808 Scheduler overhead time: 0.11907765408977866 Adapter cache time: 0.14996413979679346 Engine time: 0.11323970416560769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2380098681896925,
    "estimated_duration": 3599.9422158460557,
    "input_throughput": 1709.4843836413304,
    "output_throughput": 1527.5306297402954,
    "total_throughput": 3237.015013381626,
    "itl": 28.269392195181236,
    "ttft": 7694.930204877687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.83629264635968,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3114380166940782
}
#Debug simulation 
Total elapsed time: 2.2380865872837603. Arrivals time: 0.07193203363567591 Scheduler time: 1.7254404751583934 Scheduler overhead time: 0.12073667487129569 Adapter cache time: 0.14517314499244094 Engine time: 0.11769321700558066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2423382340930402,
    "estimated_duration": 3599.9453604356586,
    "input_throughput": 1709.4828903889945,
    "output_throughput": 1527.5292954264503,
    "total_throughput": 3237.012185815445,
    "itl": 28.27021317485294,
    "ttft": 7694.909628998405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.950930779222403,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3118801101225979
}
#Debug simulation 
Total elapsed time: 2.2424138570204377. Arrivals time: 0.07171403104439378 Scheduler time: 1.7308221836574376 Scheduler overhead time: 0.12031541671603918 Adapter cache time: 0.14531293464824557 Engine time: 0.11695590522140265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2517553246580064,
    "estimated_duration": 3599.949275836592,
    "input_throughput": 1709.481031109768,
    "output_throughput": 1527.527634044811,
    "total_throughput": 3237.0086651545794,
    "itl": 28.270295591413465,
    "ttft": 7694.8879128579265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9556143471598746,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3119843160236597
}
#Debug simulation 
Total elapsed time: 2.2518594968132675. Arrivals time: 0.07198421470820904 Scheduler time: 1.7385051297023892 Scheduler overhead time: 0.1213878015987575 Adapter cache time: 0.14489956246688962 Engine time: 0.11754460679367185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2325724279507995,
    "estimated_duration": 3599.9313158575037,
    "input_throughput": 1709.3748352624345,
    "output_throughput": 1527.429419494417,
    "total_throughput": 3236.8042547568516,
    "itl": 28.26938060678172,
    "ttft": 7839.262718094968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.874114859355603,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3117917080876864
}
#Debug simulation 
Total elapsed time: 2.232646041084081. Arrivals time: 0.07105435524135828 Scheduler time: 1.721866279374808 Scheduler overhead time: 0.12068401603028178 Adapter cache time: 0.14490271266549826 Engine time: 0.11673100618645549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.2813521116040647,
    "estimated_duration": 3599.929660874088,
    "input_throughput": 1709.3756211075122,
    "output_throughput": 1527.4301216943477,
    "total_throughput": 3236.80574280186,
    "itl": 28.27104080502332,
    "ttft": 7839.1989773940395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9792560590058614,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3121785919316398
}
#Debug simulation 
Total elapsed time: 2.281489093787968. Arrivals time: 0.07235801126807928 Scheduler time: 1.7678720112890005 Scheduler overhead time: 0.1201192089356482 Adapter cache time: 0.14567493787035346 Engine time: 0.11836822517216206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2235930780880153,
    "estimated_duration": 3599.938682011932,
    "input_throughput": 1709.486061734982,
    "output_throughput": 1527.5321292213537,
    "total_throughput": 3237.0181909563357,
    "itl": 28.268588050889182,
    "ttft": 7694.837254003568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7940301769412785,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3113257211769374
}
#Debug simulation 
Total elapsed time: 2.2236858918331563. Arrivals time: 0.07453651912510395 Scheduler time: 1.7114272452890873 Scheduler overhead time: 0.12072972860187292 Adapter cache time: 0.145723897498101 Engine time: 0.11399280745536089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2360980701632798,
    "estimated_duration": 3599.9314113867827,
    "input_throughput": 1709.3747899017521,
    "output_throughput": 1527.429378961914,
    "total_throughput": 3236.8041688636663,
    "itl": 28.271466358720197,
    "ttft": 7839.181571440677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.003903801143165,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.312424240992138
}
#Debug simulation 
Total elapsed time: 2.2361732781864703. Arrivals time: 0.07144006295129657 Scheduler time: 1.7274444168433547 Scheduler overhead time: 0.12001601420342922 Adapter cache time: 0.14488615095615387 Engine time: 0.11508191097527742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.138289739843458,
    "estimated_duration": 3599.256421898431,
    "input_throughput": 1574.1826465955216,
    "output_throughput": 1407.398475190648,
    "total_throughput": 2981.5811217861697,
    "itl": 26.75936701624189,
    "ttft": 7041.140454276597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0972135968600183,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.3980343244827586
}
#Debug simulation 
Total elapsed time: 2.13836671365425. Arrivals time: 0.0678097615018487 Scheduler time: 1.619043427053839 Scheduler overhead time: 0.12707941280677915 Adapter cache time: 0.13688637083396316 Engine time: 0.1276275352574885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1076241778209805,
    "estimated_duration": 3599.238998058794,
    "input_throughput": 1574.19026718032,
    "output_throughput": 1407.4052883768106,
    "total_throughput": 2981.5955555571304,
    "itl": 26.76093487270928,
    "ttft": 7041.21714751507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2951952132931934,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39844380920293593
}
#Debug simulation 
Total elapsed time: 2.107709923759103. Arrivals time: 0.06747708423063159 Scheduler time: 1.5974188651889563 Scheduler overhead time: 0.12554721673950553 Adapter cache time: 0.13578223902732134 Engine time: 0.12177991587668657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.156035707797855,
    "estimated_duration": 3599.2460090182662,
    "input_throughput": 1574.187200820272,
    "output_throughput": 1407.4025468966747,
    "total_throughput": 2981.589747716947,
    "itl": 26.7612027222467,
    "ttft": 7041.237400642026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3022871738485633,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39851244581763334
}
#Debug simulation 
Total elapsed time: 2.1561144907027483. Arrivals time: 0.06771005690097809 Scheduler time: 1.6423154403455555 Scheduler overhead time: 0.12587427347898483 Adapter cache time: 0.13677824148908257 Engine time: 0.12295142933726311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.132673589978367,
    "estimated_duration": 3599.2382074812995,
    "input_throughput": 1574.1906129533213,
    "output_throughput": 1407.4055975152678,
    "total_throughput": 2981.596210468589,
    "itl": 26.76009157845498,
    "ttft": 7041.142987712314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1664876879844477,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.3981577120620243
}
#Debug simulation 
Total elapsed time: 2.1327541288919747. Arrivals time: 0.06774557428434491 Scheduler time: 1.6224036295898259 Scheduler overhead time: 0.12525955913588405 Adapter cache time: 0.13598866946995258 Engine time: 0.12161606550216675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.1104313880205154,
    "estimated_duration": 3599.256704004912,
    "input_throughput": 1574.1825232125116,
    "output_throughput": 1407.3983648800302,
    "total_throughput": 2981.5808880925415,
    "itl": 26.761974536835357,
    "ttft": 7041.096278171768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3418996165692803,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39829882172347103
}
#Debug simulation 
Total elapsed time: 2.110510861966759. Arrivals time: 0.06738734571263194 Scheduler time: 1.6012314180843532 Scheduler overhead time: 0.12638881197199225 Adapter cache time: 0.13536307169124484 Engine time: 0.12034287536516786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1294374582357705,
    "estimated_duration": 3599.244444352606,
    "input_throughput": 1574.187885151857,
    "output_throughput": 1407.4031587235372,
    "total_throughput": 2981.5910438753945,
    "itl": 26.758015954454542,
    "ttft": 7041.152365260752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.025930898440931,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.3979282003656724
}
#Debug simulation 
Total elapsed time: 2.129514555912465. Arrivals time: 0.06708787335082889 Scheduler time: 1.6212966907769442 Scheduler overhead time: 0.12580463476479053 Adapter cache time: 0.13642594311386347 Engine time: 0.11902388231828809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1279224078170955,
    "estimated_duration": 3599.2610962945796,
    "input_throughput": 1574.1806021888774,
    "output_throughput": 1407.3966473882642,
    "total_throughput": 2981.5772495771416,
    "itl": 26.761813104810024,
    "ttft": 7041.233959413145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1012,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.385158919096034,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39832759399975654
}
#Debug simulation 
Total elapsed time: 2.128019825089723. Arrivals time: 0.0674696839414537 Scheduler time: 1.6141265560872853 Scheduler overhead time: 0.12799592083320022 Adapter cache time: 0.1364850769750774 Engine time: 0.12194634415209293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0630959160625935,
    "estimated_duration": 3600.02806622771,
    "input_throughput": 1544.0324068985767,
    "output_throughput": 1353.463059277106,
    "total_throughput": 2897.495466175683,
    "itl": 26.061624873322117,
    "ttft": 7224.871575654036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.726115087578097,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.20074876213758386
}
#Debug simulation 
Total elapsed time: 2.0631736582145095. Arrivals time: 0.06619970686733723 Scheduler time: 1.554057752713561 Scheduler overhead time: 0.1270441827364266 Adapter cache time: 0.13209519954398274 Engine time: 0.12267480185255408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.077532864175737,
    "estimated_duration": 3600.0161462262026,
    "input_throughput": 1543.9116865701867,
    "output_throughput": 1353.3858744237589,
    "total_throughput": 2897.2975609939454,
    "itl": 26.062410112052078,
    "ttft": 7384.532087178292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8359342528739995,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20072094896931053
}
#Debug simulation 
Total elapsed time: 2.0776699697598815. Arrivals time: 0.06785834534093738 Scheduler time: 1.5679457588121295 Scheduler overhead time: 0.12697861436754465 Adapter cache time: 0.13052373193204403 Engine time: 0.12320627132430673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.092833955772221,
    "estimated_duration": 3600.0265137133033,
    "input_throughput": 1544.0330727638272,
    "output_throughput": 1353.4636429591678,
    "total_throughput": 2897.496715722995,
    "itl": 26.06324880477842,
    "ttft": 7224.93553523327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8399772137031072,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.20079863430810327
}
#Debug simulation 
Total elapsed time: 2.0929112159647048. Arrivals time: 0.06664059404283762 Scheduler time: 1.5829611187800765 Scheduler overhead time: 0.12706638546660542 Adapter cache time: 0.1316647781059146 Engine time: 0.12375110201537609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.0613633752800524,
    "estimated_duration": 3600.014013458136,
    "input_throughput": 1543.9126012348324,
    "output_throughput": 1353.3866762145753,
    "total_throughput": 2897.299277449408,
    "itl": 26.061798640563207,
    "ttft": 7384.457265570032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7619785002362822,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.2006227893463039
}
#Debug simulation 
Total elapsed time: 2.061438557226211. Arrivals time: 0.06619336875155568 Scheduler time: 1.5510775386355817 Scheduler overhead time: 0.1294152424670756 Adapter cache time: 0.13019777787849307 Engine time: 0.12360440054908395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.0682146423496306,
    "estimated_duration": 3600.016969235013,
    "input_throughput": 1543.9113336127057,
    "output_throughput": 1353.3855650228566,
    "total_throughput": 2897.2968986355622,
    "itl": 26.062459014020213,
    "ttft": 7384.43195422666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8627386490441902,
    "arrivals": 22557,
    "finished_requests": 22511,
    "scheduler_time": 0.20076936154380184
}
#Debug simulation 
Total elapsed time: 2.0683228480629623. Arrivals time: 0.06638144142925739 Scheduler time: 1.5570414569228888 Scheduler overhead time: 0.12803894327953458 Adapter cache time: 0.13146548299118876 Engine time: 0.12460816325619817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0977427349425852,
    "estimated_duration": 3600.0287408910976,
    "input_throughput": 1544.032117539183,
    "output_throughput": 1353.4628056313607,
    "total_throughput": 2897.4949231705436,
    "itl": 26.06135135783475,
    "ttft": 7224.906377029022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.686388366324804,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.2006410119164985
}
#Debug simulation 
Total elapsed time: 2.097818424925208. Arrivals time: 0.06666206894442439 Scheduler time: 1.5879037361592054 Scheduler overhead time: 0.12766718165948987 Adapter cache time: 0.13082994846627116 Engine time: 0.12399361561983824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0939807910472155,
    "estimated_duration": 3600.02870224714,
    "input_throughput": 1544.0321341133597,
    "output_throughput": 1353.4628201599003,
    "total_throughput": 2897.49495427326,
    "itl": 26.063153535179012,
    "ttft": 7224.897748854553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8860030995309318,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.20081885834830965
}
#Debug simulation 
Total elapsed time: 2.0940559981390834. Arrivals time: 0.06600696314126253 Scheduler time: 1.582038002088666 Scheduler overhead time: 0.12918300880119205 Adapter cache time: 0.13143463898450136 Engine time: 0.12415548972785473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0214317301288247,
    "estimated_duration": 3599.866500741036,
    "input_throughput": 1451.4316014008955,
    "output_throughput": 1307.8396098941014,
    "total_throughput": 2759.271211294997,
    "itl": 25.486673878008258,
    "ttft": 3599.4430295728625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.661844844955507,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09638318515492153
}
#Debug simulation 
Total elapsed time: 2.0215079081244767. Arrivals time: 0.06282557221129537 Scheduler time: 1.5164498495869339 Scheduler overhead time: 0.13192413887009025 Adapter cache time: 0.12270678440108895 Engine time: 0.12540566455572844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9926538281142712,
    "estimated_duration": 3599.880075299144,
    "input_throughput": 1451.4261282900693,
    "output_throughput": 1307.834678245155,
    "total_throughput": 2759.260806535224,
    "itl": 25.48763857466411,
    "ttft": 3599.444305927867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7702830294519722,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09638985704299362
}
#Debug simulation 
Total elapsed time: 1.992730456404388. Arrivals time: 0.06295262789353728 Scheduler time: 1.4924309002235532 Scheduler overhead time: 0.1294893166050315 Adapter cache time: 0.12093908479437232 Engine time: 0.1249896022491157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.029546151868999,
    "estimated_duration": 3599.8625695497153,
    "input_throughput": 1451.4331864212133,
    "output_throughput": 1307.8410381063243,
    "total_throughput": 2759.2742245275376,
    "itl": 25.487542447378768,
    "ttft": 3599.505920843484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7737025854177881,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09642138152131464
}
#Debug simulation 
Total elapsed time: 2.0296331481076777. Arrivals time: 0.06333701964467764 Scheduler time: 1.5244520734995604 Scheduler overhead time: 0.12978232419118285 Adapter cache time: 0.12208529701456428 Engine time: 0.12802277458831668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.0112442723475397,
    "estimated_duration": 3599.8629499208287,
    "input_throughput": 1451.4330330589146,
    "output_throughput": 1307.8408999163548,
    "total_throughput": 2759.2739329752694,
    "itl": 25.48627758313788,
    "ttft": 3599.503867513781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6979616580880166,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09639069102900281
}
#Debug simulation 
Total elapsed time: 2.011344211176038. Arrivals time: 0.06248186156153679 Scheduler time: 1.5109600936993957 Scheduler overhead time: 0.12959053926169872 Adapter cache time: 0.1214693165384233 Engine time: 0.12489710235968232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.048429018817842,
    "estimated_duration": 3599.8644328818696,
    "input_throughput": 1451.4324351423315,
    "output_throughput": 1307.8403611524268,
    "total_throughput": 2759.2727962947583,
    "itl": 25.487431591367223,
    "ttft": 3599.4831055863656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7959610056132118,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.0962951584860271
}
#Debug simulation 
Total elapsed time: 2.0485204020515084. Arrivals time: 0.0652686133980751 Scheduler time: 1.5373838650994003 Scheduler overhead time: 0.13135091168805957 Adapter cache time: 0.12398162437602878 Engine time: 0.12797441240400076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0234953118488193,
    "estimated_duration": 3599.8608581589488,
    "input_throughput": 1451.43387643937,
    "output_throughput": 1307.841659860099,
    "total_throughput": 2759.275536299469,
    "itl": 25.485241922736183,
    "ttft": 3599.4881515233847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6235973101318606,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.096295158486027
}
#Debug simulation 
Total elapsed time: 2.0235714809969068. Arrivals time: 0.06280695181339979 Scheduler time: 1.519967429805547 Scheduler overhead time: 0.1304393745958805 Adapter cache time: 0.1221396173350513 Engine time: 0.1261407402344048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_128_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.033393980935216,
    "estimated_duration": 3599.8617690619976,
    "input_throughput": 1451.4335091709502,
    "output_throughput": 1307.8413289260154,
    "total_throughput": 2759.2748380969656,
    "itl": 25.487742176211782,
    "ttft": 3599.3848726946067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8188481947407091,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09648776642199255
}
#Debug simulation 
Total elapsed time: 2.033470335882157. Arrivals time: 0.06253984477370977 Scheduler time: 1.5310073639266193 Scheduler overhead time: 0.1293247058056295 Adapter cache time: 0.12287718709558249 Engine time: 0.12564529990777373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.758458806667477,
    "estimated_duration": 3599.581594432156,
    "input_throughput": 1189.4318513636615,
    "output_throughput": 1036.9485736268814,
    "total_throughput": 2226.380424990543,
    "itl": 23.998868697975325,
    "ttft": 6751.33028675435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.589230112687412,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0031606644983855152
}
#Debug simulation 
Total elapsed time: 1.7585436198860407. Arrivals time: 0.054851398803293705 Scheduler time: 1.2310359561815858 Scheduler overhead time: 0.13578883511945605 Adapter cache time: 0.13958830945193768 Engine time: 0.1321953092701733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.755398774985224,
    "estimated_duration": 3599.570220755287,
    "input_throughput": 1189.4356096494305,
    "output_throughput": 1036.9518501063728,
    "total_throughput": 2226.3874597558033,
    "itl": 24.003149302394814,
    "ttft": 6751.332582677861,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0347958112971,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003158996526367462
}
#Debug simulation 
Total elapsed time: 1.7554740402847528. Arrivals time: 0.05471844971179962 Scheduler time: 1.231170978397131 Scheduler overhead time: 0.13376055052503943 Adapter cache time: 0.1396200954914093 Engine time: 0.13139007752761245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.770215641707182,
    "estimated_duration": 3599.5631017010883,
    "input_throughput": 1189.437962061746,
    "output_throughput": 1036.953900943159,
    "total_throughput": 2226.3918630049047,
    "itl": 24.002575858851724,
    "ttft": 6751.4169952833445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2155,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.04678024368357,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003165543292435791
}
#Debug simulation 
Total elapsed time: 1.770292644854635. Arrivals time: 0.055014226119965315 Scheduler time: 1.2402867185883224 Scheduler overhead time: 0.13822725135833025 Adapter cache time: 0.14037919230759144 Engine time: 0.13048302568495274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7518088230863214,
    "estimated_duration": 3599.5698214324375,
    "input_throughput": 1189.4357416009805,
    "output_throughput": 1036.9519651419432,
    "total_throughput": 2226.387706742924,
    "itl": 23.999811241089517,
    "ttft": 6751.333095911153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.735982750451437,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003168754114468014
}
#Debug simulation 
Total elapsed time: 1.7518883650191128. Arrivals time: 0.055190338753163815 Scheduler time: 1.2262402321211994 Scheduler overhead time: 0.1355103086680174 Adapter cache time: 0.13920687651261687 Engine time: 0.13100964110344648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.7338501098565757,
    "estimated_duration": 3599.559045252273,
    "input_throughput": 1189.439302474322,
    "output_throughput": 1036.9550695169676,
    "total_throughput": 2226.3943719912895,
    "itl": 24.003247814371218,
    "ttft": 6751.3425016173405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.134319464918079,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0031500729242759373
}
#Debug simulation 
Total elapsed time: 1.733927648048848. Arrivals time: 0.05393699649721384 Scheduler time: 1.2110384372062981 Scheduler overhead time: 0.13529921369627118 Adapter cache time: 0.13852600241079926 Engine time: 0.13000240130349994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.7411937611177564,
    "estimated_duration": 3599.5549462645354,
    "input_throughput": 1189.4406569465243,
    "output_throughput": 1036.9562503479808,
    "total_throughput": 2226.396907294505,
    "itl": 23.997519335721968,
    "ttft": 6751.268175937389,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.437578284924192,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0031507817882810802
}
#Debug simulation 
Total elapsed time: 1.74127457709983. Arrivals time: 0.05438405787572265 Scheduler time: 1.2158957133069634 Scheduler overhead time: 0.137823099270463 Adapter cache time: 0.13919208059087396 Engine time: 0.12855941615998745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_128_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.760784219019115,
    "estimated_duration": 3599.5611198467072,
    "input_throughput": 1189.4386169451493,
    "output_throughput": 1036.9544718715479,
    "total_throughput": 2226.393088816697,
    "itl": 24.004246379192203,
    "ttft": 6751.439848779733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.218689413517459,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.00317113095049121
}
#Debug simulation 
Total elapsed time: 1.7608624678105116. Arrivals time: 0.05509845120832324 Scheduler time: 1.2345121689140797 Scheduler overhead time: 0.13482306292280555 Adapter cache time: 0.13969861436635256 Engine time: 0.13190873665735126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.678352695889771,
    "estimated_duration": 3599.612639263087,
    "input_throughput": 1093.452655729584,
    "output_throughput": 982.7468548738618,
    "total_throughput": 2076.199510603446,
    "itl": 23.521055463960693,
    "ttft": 5923.54008872639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3328711531428485,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6785117192193866. Arrivals time: 0.05111904349178076 Scheduler time: 1.165149923413992 Scheduler overhead time: 0.13732600258663297 Adapter cache time: 0.12756303464993834 Engine time: 0.13156538689509034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6877365689724684,
    "estimated_duration": 3599.604543170103,
    "input_throughput": 1093.4551150815123,
    "output_throughput": 982.7490652305333,
    "total_throughput": 2076.2041803120455,
    "itl": 23.52388580511324,
    "ttft": 5923.461770836795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.547901828514881,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6878217090852559. Arrivals time: 0.05137523077428341 Scheduler time: 1.1709297499619424 Scheduler overhead time: 0.13751768181100488 Adapter cache time: 0.1287292749620974 Engine time: 0.13350980635732412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6839416990987957,
    "estimated_duration": 3599.6128072977176,
    "input_throughput": 1093.452604685785,
    "output_throughput": 982.7468089979543,
    "total_throughput": 2076.1994136837393,
    "itl": 23.5233578218526,
    "ttft": 5923.46422779999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.558567503746554,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6840214440599084. Arrivals time: 0.05151415802538395 Scheduler time: 1.1684706737287343 Scheduler overhead time: 0.13726444076746702 Adapter cache time: 0.12870269967243075 Engine time: 0.1319981417618692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6808254341594875,
    "estimated_duration": 3599.6231637077176,
    "input_throughput": 1093.5855840935565,
    "output_throughput": 982.8595492078772,
    "total_throughput": 2076.4451333014335,
    "itl": 23.521623905001146,
    "ttft": 5697.078327383671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.416464019042871,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6809141780249774. Arrivals time: 0.051497211679816246 Scheduler time: 1.160897333174944 Scheduler overhead time: 0.13807847257703543 Adapter cache time: 0.12831760616973042 Engine time: 0.13482793932780623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.7005806816741824,
    "estimated_duration": 3599.613391811839,
    "input_throughput": 1093.4524271282478,
    "output_throughput": 982.746649417098,
    "total_throughput": 2076.1990765453456,
    "itl": 23.523401605366033,
    "ttft": 5923.563780497607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.596559733133759,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.70066833589226. Arrivals time: 0.051649879198521376 Scheduler time: 1.184897339437157 Scheduler overhead time: 0.13586539682000875 Adapter cache time: 0.1290252679027617 Engine time: 0.13336527161300182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6885839449241757,
    "estimated_duration": 3599.6111659943726,
    "input_throughput": 1093.4531032639188,
    "output_throughput": 982.7472570979157,
    "total_throughput": 2076.2003603618346,
    "itl": 23.5205821518523,
    "ttft": 5923.4541228957705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2591548214432926,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6886711460538208. Arrivals time: 0.05177966505289078 Scheduler time: 1.170091814827174 Scheduler overhead time: 0.13820858485996723 Adapter cache time: 0.12872441532090306 Engine time: 0.13395000202581286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_128_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.701722505968064,
    "estimated_duration": 3599.6103904251036,
    "input_throughput": 1093.4533388584782,
    "output_throughput": 982.7474688398793,
    "total_throughput": 2076.2008076983575,
    "itl": 23.524296683509426,
    "ttft": 5923.479097799034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6449749409035337,
    "arrivals": 15906,
    "finished_requests": 15880,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.7018103110603988. Arrivals time: 0.05204192455857992 Scheduler time: 1.1821355447173119 Scheduler overhead time: 0.1378852711059153 Adapter cache time: 0.12977100908756256 Engine time: 0.13397780433297157 
