INFO 06-01 00:47:18 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:18 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 88.26599142793566,
    "estimated_duration": 3600.0431921335503,
    "input_throughput": 6808.335814847286,
    "output_throughput": 6014.124788088601,
    "total_throughput": 12822.460602935887,
    "itl": 76.36789148380366,
    "ttft": 2064698.409024682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 659,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9704431443405006,
    "arrivals": 1150725,
    "finished_requests": 99025,
    "scheduler_time": 345.87052423572146
}
#Debug simulation 
Total elapsed time: 88.26623501023278. Arrivals time: 0.5284977196715772 Scheduler time: 87.50718724168837 Scheduler overhead time: 0.09111869102343917 Adapter cache time: 0.020223611500114202 Engine time: 0.0838992060162127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 92.75608803099021,
    "estimated_duration": 3600.0193360735407,
    "input_throughput": 6938.89078586041,
    "output_throughput": 6136.44398479662,
    "total_throughput": 13075.33477065703,
    "itl": 82.3138781468086,
    "ttft": 2039384.4660711323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 725,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4324957904592246,
    "arrivals": 1150725,
    "finished_requests": 100911,
    "scheduler_time": 339.14825763330765
}
#Debug simulation 
Total elapsed time: 92.75630151666701. Arrivals time: 0.5457770647481084 Scheduler time: 91.97772084688768 Scheduler overhead time: 0.09242738643661141 Adapter cache time: 0.020950691774487495 Engine time: 0.08458735421299934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 94.38590819993988,
    "estimated_duration": 3600.0338404592935,
    "input_throughput": 7002.503342241859,
    "output_throughput": 6197.948960711247,
    "total_throughput": 13200.452302953106,
    "itl": 82.12965972627754,
    "ttft": 2043468.5416763786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0627687394107115,
    "arrivals": 1127715,
    "finished_requests": 101729,
    "scheduler_time": 335.6322124043097
}
#Debug simulation 
Total elapsed time: 94.38609057292342. Arrivals time: 0.5537242935970426 Scheduler time: 93.60340356687084 Scheduler overhead time: 0.09117816435173154 Adapter cache time: 0.020215208176523447 Engine time: 0.08313378086313605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.7063887421973,
    "estimated_duration": 3600.0075938867503,
    "input_throughput": 7037.46793285153,
    "output_throughput": 6209.62773466395,
    "total_throughput": 13247.095667515481,
    "itl": 84.77087758495132,
    "ttft": 2036697.5767758703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.357114925428764,
    "arrivals": 1127715,
    "finished_requests": 102304,
    "scheduler_time": 333.11426869514383
}
#Debug simulation 
Total elapsed time: 96.70657515106723. Arrivals time: 0.5582210207358003 Scheduler time: 95.91785667929798 Scheduler overhead time: 0.09123251819983125 Adapter cache time: 0.020925568882375956 Engine time: 0.08368061063811183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.2707923031412,
    "estimated_duration": 3600.012118222941,
    "input_throughput": 7037.45908847273,
    "output_throughput": 6209.619930678139,
    "total_throughput": 13247.07901915087,
    "itl": 84.77096259812028,
    "ttft": 2036699.113959049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.361668430045247,
    "arrivals": 1127715,
    "finished_requests": 102304,
    "scheduler_time": 333.1142395266898
}
#Debug simulation 
Total elapsed time: 96.27098692813888. Arrivals time: 0.5494053391739726 Scheduler time: 95.49111380474642 Scheduler overhead time: 0.09134060703217983 Adapter cache time: 0.020866646897047758 Engine time: 0.08390057506039739 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 96.69887769408524,
    "estimated_duration": 3600.0324744121604,
    "input_throughput": 7037.630404747112,
    "output_throughput": 6209.711484241629,
    "total_throughput": 13247.341888988742,
    "itl": 84.7691407287076,
    "ttft": 2036711.2466142178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.261912216232141,
    "arrivals": 1127715,
    "finished_requests": 102307,
    "scheduler_time": 333.1226175182988
}
#Debug simulation 
Total elapsed time: 96.69906334532425. Arrivals time: 0.6088832537643611 Scheduler time: 95.85770925367251 Scheduler overhead time: 0.09198551066219807 Adapter cache time: 0.021197514608502388 Engine time: 0.08459512423723936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 96.50682860333472,
    "estimated_duration": 3600.04202084688,
    "input_throughput": 7037.400634018201,
    "output_throughput": 6209.568352410854,
    "total_throughput": 13246.968986429056,
    "itl": 84.77121207386176,
    "ttft": 2036711.040759282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.390969062279912,
    "arrivals": 1127715,
    "finished_requests": 102304,
    "scheduler_time": 333.11444136409693
}
#Debug simulation 
Total elapsed time: 96.50701976614073. Arrivals time: 0.5523395831696689 Scheduler time: 95.72278390359133 Scheduler overhead time: 0.09150155121460557 Adapter cache time: 0.02111817244440317 Engine time: 0.08465917268767953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 94.80993720935658,
    "estimated_duration": 3600.0213020596916,
    "input_throughput": 7002.527731037856,
    "output_throughput": 6197.970547350398,
    "total_throughput": 13200.498278388253,
    "itl": 82.128837823632,
    "ttft": 2043448.7530237366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.015293898764032,
    "arrivals": 1127715,
    "finished_requests": 101729,
    "scheduler_time": 335.637546108292
}
#Debug simulation 
Total elapsed time: 94.81012800335884. Arrivals time: 0.5355801237747073 Scheduler time: 94.0458553773351 Scheduler overhead time: 0.09024802036583424 Adapter cache time: 0.020262502133846283 Engine time: 0.08402350218966603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 97.18201803369448,
    "estimated_duration": 3600.073640812358,
    "input_throughput": 7037.338823514499,
    "output_throughput": 6209.513812877353,
    "total_throughput": 13246.852636391852,
    "itl": 84.77183658133106,
    "ttft": 2036723.7927309454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4217787399515593,
    "arrivals": 1127715,
    "finished_requests": 102304,
    "scheduler_time": 333.1148728666187
}
#Debug simulation 
Total elapsed time: 97.18220482766628. Arrivals time: 0.5727821723558009 Scheduler time: 96.37727586412802 Scheduler overhead time: 0.09114191867411137 Adapter cache time: 0.02125657256692648 Engine time: 0.08492924692109227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 93.29111717594787,
    "estimated_duration": 3600.008306168062,
    "input_throughput": 6925.487076594564,
    "output_throughput": 6145.559153875787,
    "total_throughput": 13071.04623047035,
    "itl": 82.29017641251276,
    "ttft": 2045213.9480177276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9587121561169945,
    "arrivals": 1116080,
    "finished_requests": 101122,
    "scheduler_time": 337.7892884508442
}
#Debug simulation 
Total elapsed time: 93.29130922211334. Arrivals time: 0.536171997897327 Scheduler time: 92.52493193652481 Scheduler overhead time: 0.09071241458877921 Adapter cache time: 0.020432678051292896 Engine time: 0.08406241703778505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.7467929511331,
    "estimated_duration": 3600.0127143062145,
    "input_throughput": 6925.197764143064,
    "output_throughput": 6145.14357465635,
    "total_throughput": 13070.341338799413,
    "itl": 82.29390971425391,
    "ttft": 2045160.9031391891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0889195803483074,
    "arrivals": 1116080,
    "finished_requests": 101117,
    "scheduler_time": 337.7767154720215
}
#Debug simulation 
Total elapsed time: 93.7469788948074. Arrivals time: 0.5378867974504828 Scheduler time: 92.98024649731815 Scheduler overhead time: 0.09100816212594509 Adapter cache time: 0.020261533092707396 Engine time: 0.08296952908858657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.51215677382424,
    "estimated_duration": 3600.0163382798232,
    "input_throughput": 6925.190792859721,
    "output_throughput": 6145.1373886182755,
    "total_throughput": 13070.328181477997,
    "itl": 82.2939656429756,
    "ttft": 2045162.4219431027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.092531238365927,
    "arrivals": 1116080,
    "finished_requests": 101117,
    "scheduler_time": 337.77672778759097
}
#Debug simulation 
Total elapsed time: 93.5123444008641. Arrivals time: 0.5474234619177878 Scheduler time: 92.73643237585202 Scheduler overhead time: 0.08962055295705795 Adapter cache time: 0.020252376329153776 Engine time: 0.08393273362889886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 93.30883073993027,
    "estimated_duration": 3600.0525864869505,
    "input_throughput": 6925.401893734358,
    "output_throughput": 6145.483564057987,
    "total_throughput": 13070.885457792345,
    "itl": 82.29094589383001,
    "ttft": 2045232.7909226285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0022973728389344,
    "arrivals": 1116080,
    "finished_requests": 101122,
    "scheduler_time": 337.78978347577697
}
#Debug simulation 
Total elapsed time: 93.30903071304783. Arrivals time: 0.557402828708291 Scheduler time: 92.52489988552406 Scheduler overhead time: 0.08999638026580215 Adapter cache time: 0.02014956623315811 Engine time: 0.08218276128172874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 93.47029031300917,
    "estimated_duration": 3600.0431013604584,
    "input_throughput": 6925.139310298434,
    "output_throughput": 6145.0917050520475,
    "total_throughput": 13070.23101535048,
    "itl": 82.29442343719508,
    "ttft": 2045173.5059623236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1191910410858714,
    "arrivals": 1116080,
    "finished_requests": 101117,
    "scheduler_time": 337.77683106552456
}
#Debug simulation 
Total elapsed time: 93.47047922993079. Arrivals time: 0.561264353338629 Scheduler time: 92.67919138073921 Scheduler overhead time: 0.09127861121669412 Adapter cache time: 0.020551743917167187 Engine time: 0.08374260272830725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 93.20066385390237,
    "estimated_duration": 3600.026069642206,
    "input_throughput": 6925.520126157839,
    "output_throughput": 6145.745495170514,
    "total_throughput": 13071.265621328354,
    "itl": 82.28908523739689,
    "ttft": 2045189.8269529631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9136321887373613,
    "arrivals": 1116080,
    "finished_requests": 101124,
    "scheduler_time": 337.79571881577715
}
#Debug simulation 
Total elapsed time: 93.20085462601855. Arrivals time: 0.5300641320645809 Scheduler time: 92.44310264568776 Scheduler overhead time: 0.0899252207018435 Adapter cache time: 0.019712504465132952 Engine time: 0.08339277282357216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 93.78541206289083,
    "estimated_duration": 3600.006906433829,
    "input_throughput": 6925.152269970581,
    "output_throughput": 6145.152933029972,
    "total_throughput": 13070.305203000553,
    "itl": 82.29540509351482,
    "ttft": 2045102.4992940682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.146479612737894,
    "arrivals": 1116080,
    "finished_requests": 101116,
    "scheduler_time": 337.7703608752346
}
#Debug simulation 
Total elapsed time: 93.78560336492956. Arrivals time: 0.5554555924609303 Scheduler time: 93.00062119401991 Scheduler overhead time: 0.09080911427736282 Adapter cache time: 0.020505917724221945 Engine time: 0.0833809687756002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 99.43755078408867,
    "estimated_duration": 3600.090511111212,
    "input_throughput": 7152.044905685597,
    "output_throughput": 6326.320666024065,
    "total_throughput": 13478.365571709663,
    "itl": 87.88632675215199,
    "ttft": 2050423.996468283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.075010690386443,
    "arrivals": 1110230,
    "finished_requests": 103984,
    "scheduler_time": 325.51278597208915
}
#Debug simulation 
Total elapsed time: 99.4377509066835. Arrivals time: 0.5573333231732249 Scheduler time: 98.65274512767792 Scheduler overhead time: 0.08915084460750222 Adapter cache time: 0.02082673879340291 Engine time: 0.08308340143412352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 99.26517998985946,
    "estimated_duration": 3600.102783374958,
    "input_throughput": 7151.705812094424,
    "output_throughput": 6326.096050693778,
    "total_throughput": 13477.801862788201,
    "itl": 87.88790372840033,
    "ttft": 2050417.953874512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.211939183878718,
    "arrivals": 1110230,
    "finished_requests": 103976,
    "scheduler_time": 325.50474555980827
}
#Debug simulation 
Total elapsed time: 99.26536854589358. Arrivals time: 0.5740391411818564 Scheduler time: 98.46134618204087 Scheduler overhead time: 0.0914520169608295 Adapter cache time: 0.02045837650075555 Engine time: 0.08392598293721676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 97.99925600597635,
    "estimated_duration": 3600.107021883645,
    "input_throughput": 7151.697392187175,
    "output_throughput": 6326.088602800452,
    "total_throughput": 13477.785994987626,
    "itl": 87.88795008037897,
    "ttft": 2050419.720829265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.215941646993164,
    "arrivals": 1110230,
    "finished_requests": 103976,
    "scheduler_time": 325.5048020125345
}
#Debug simulation 
Total elapsed time: 97.99944866495207. Arrivals time: 0.5603995225392282 Scheduler time: 97.2123620887287 Scheduler overhead time: 0.08899565692991018 Adapter cache time: 0.020269278902560472 Engine time: 0.08374952245503664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 99.24153051804751,
    "estimated_duration": 3600.010716980555,
    "input_throughput": 7151.888709263269,
    "output_throughput": 6326.257833782724,
    "total_throughput": 13478.146543045994,
    "itl": 87.88635908491258,
    "ttft": 2050380.297688042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.120413832548059,
    "arrivals": 1110230,
    "finished_requests": 103976,
    "scheduler_time": 325.5040044395484
}
#Debug simulation 
Total elapsed time: 99.24172471323982. Arrivals time: 0.5598263796418905 Scheduler time: 98.45478941872716 Scheduler overhead time: 0.0891626006923616 Adapter cache time: 0.020554775837808847 Engine time: 0.08356713969260454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 98.56124252732843,
    "estimated_duration": 3600.0098536126716,
    "input_throughput": 7151.394036925861,
    "output_throughput": 6326.097129191435,
    "total_throughput": 13477.491166117296,
    "itl": 87.8869476651669,
    "ttft": 2050382.5842579564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2441104951500916,
    "arrivals": 1110230,
    "finished_requests": 103972,
    "scheduler_time": 325.49590111812705
}
#Debug simulation 
Total elapsed time: 98.56143435603008. Arrivals time: 0.9234029646031559 Scheduler time: 97.40967888897285 Scheduler overhead time: 0.08946188632398844 Adapter cache time: 0.020690646953880787 Engine time: 0.08429754292592406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 98.40231283381581,
    "estimated_duration": 3600.0422092293375,
    "input_throughput": 7152.140864901661,
    "output_throughput": 6326.405546471502,
    "total_throughput": 13478.546411373163,
    "itl": 87.88545695001416,
    "ttft": 2050404.4324620946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.02725409994364,
    "arrivals": 1110230,
    "finished_requests": 103984,
    "scheduler_time": 325.5124202733682
}
#Debug simulation 
Total elapsed time: 98.40250273095444. Arrivals time: 0.5767365689389408 Scheduler time: 97.59883134905249 Scheduler overhead time: 0.0889123841188848 Adapter cache time: 0.020134564954787493 Engine time: 0.08340582018718123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 98.40868586394936,
    "estimated_duration": 3600.038855776902,
    "input_throughput": 7151.33642479648,
    "output_throughput": 6326.046165711531,
    "total_throughput": 13477.382590508012,
    "itl": 87.88754459811057,
    "ttft": 2050394.1980328313,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2727823584526825,
    "arrivals": 1110230,
    "finished_requests": 103972,
    "scheduler_time": 325.4961313805009
}
#Debug simulation 
Total elapsed time: 98.40887688612565. Arrivals time: 0.5443416936323047 Scheduler time: 97.63821368524805 Scheduler overhead time: 0.08882362954318523 Adapter cache time: 0.020316581707447767 Engine time: 0.0830406523309648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 92.99081764509901,
    "estimated_duration": 3600.0277296645513,
    "input_throughput": 6962.1772058782035,
    "output_throughput": 6173.652446302391,
    "total_throughput": 13135.829652180595,
    "itl": 79.5977508892381,
    "ttft": 2044828.2604506952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8240506953839486,
    "arrivals": 1107373,
    "finished_requests": 101320,
    "scheduler_time": 335.7213498058846
}
#Debug simulation 
Total elapsed time: 92.9910060740076. Arrivals time: 0.5464751115068793 Scheduler time: 92.21667274879292 Scheduler overhead time: 0.08933528419584036 Adapter cache time: 0.01952029811218381 Engine time: 0.08460001833736897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.89115663710982,
    "estimated_duration": 3600.1031585974292,
    "input_throughput": 7175.507440199063,
    "output_throughput": 6352.959899324239,
    "total_throughput": 13528.467339523302,
    "itl": 85.80947849584565,
    "ttft": 2037463.4767610524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0535774551937416,
    "arrivals": 1107373,
    "finished_requests": 104580,
    "scheduler_time": 323.8308273927035
}
#Debug simulation 
Total elapsed time: 96.89136835932732. Arrivals time: 0.5311736511066556 Scheduler time: 96.13482944201678 Scheduler overhead time: 0.0891035939566791 Adapter cache time: 0.019917400553822517 Engine time: 0.08269868139177561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 97.37340974621475,
    "estimated_duration": 3600.1066721982966,
    "input_throughput": 7175.500437109582,
    "output_throughput": 6352.953699017569,
    "total_throughput": 13528.454136127151,
    "itl": 85.80954248977352,
    "ttft": 2037464.8257594665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.057029046062391,
    "arrivals": 1107373,
    "finished_requests": 104580,
    "scheduler_time": 323.8308894026762
}
#Debug simulation 
Total elapsed time: 97.37359721539542. Arrivals time: 0.5622866721823812 Scheduler time: 96.58598270872608 Scheduler overhead time: 0.08905516564846039 Adapter cache time: 0.019690669141709805 Engine time: 0.08265241095796227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 92.37811758415774,
    "estimated_duration": 3600.0705604432337,
    "input_throughput": 6962.094375426399,
    "output_throughput": 6173.578997091563,
    "total_throughput": 13135.673372517962,
    "itl": 79.59847298532169,
    "ttft": 2044846.2275581895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.866649206678838,
    "arrivals": 1107373,
    "finished_requests": 101320,
    "scheduler_time": 335.7215820732038
}
#Debug simulation 
Total elapsed time: 92.3783024721779. Arrivals time: 0.5189514071680605 Scheduler time: 91.63058229861781 Scheduler overhead time: 0.09141303226351738 Adapter cache time: 0.019433211535215378 Engine time: 0.08351656887680292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 97.45519149536267,
    "estimated_duration": 3600.0036880402918,
    "input_throughput": 7175.455149064527,
    "output_throughput": 6352.992936085022,
    "total_throughput": 13528.44808514955,
    "itl": 85.80928074080475,
    "ttft": 2037444.5990739814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0831858336366755,
    "arrivals": 1107373,
    "finished_requests": 104578,
    "scheduler_time": 323.8217860707095
}
#Debug simulation 
Total elapsed time: 97.45537848118693. Arrivals time: 0.5631784573197365 Scheduler time: 96.66554777650163 Scheduler overhead time: 0.0898485197685659 Adapter cache time: 0.01981869712471962 Engine time: 0.08340353239327669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 92.92498121364042,
    "estimated_duration": 3600.069454534158,
    "input_throughput": 6962.247622315194,
    "output_throughput": 6173.856999343931,
    "total_throughput": 13136.104621659126,
    "itl": 79.59708774379659,
    "ttft": 2044803.0267027982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7820699757616703,
    "arrivals": 1107373,
    "finished_requests": 101323,
    "scheduler_time": 335.72853456388134
}
#Debug simulation 
Total elapsed time: 92.9251707228832. Arrivals time: 0.5248890779912472 Scheduler time: 92.1747819148004 Scheduler overhead time: 0.08893319871276617 Adapter cache time: 0.019373721443116665 Engine time: 0.0829876190982759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 97.24747475795448,
    "estimated_duration": 3600.030871594805,
    "input_throughput": 7175.400967757989,
    "output_throughput": 6352.944965127005,
    "total_throughput": 13528.345932884995,
    "itl": 85.80984138297234,
    "ttft": 2037455.851690369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1102228977158646,
    "arrivals": 1107373,
    "finished_requests": 104578,
    "scheduler_time": 323.8219325611676
}
#Debug simulation 
Total elapsed time: 97.24765438213944. Arrivals time: 0.5650660018436611 Scheduler time: 96.45600173156708 Scheduler overhead time: 0.08901369897648692 Adapter cache time: 0.02002423908561468 Engine time: 0.08405286120250821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 98.68084791628644,
    "estimated_duration": 3600.0784854201734,
    "input_throughput": 7223.326131725973,
    "output_throughput": 6436.244680175539,
    "total_throughput": 13659.57081190151,
    "itl": 88.46051165564538,
    "ttft": 2034222.34872126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8730184992868744,
    "arrivals": 1105887,
    "finished_requests": 105614,
    "scheduler_time": 320.17600766952046
}
#Debug simulation 
Total elapsed time: 98.6810296070762. Arrivals time: 0.567591876257211 Scheduler time: 97.88965824712068 Scheduler overhead time: 0.08815130218863487 Adapter cache time: 0.019915136508643627 Engine time: 0.08215021574869752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.86489029088989,
    "estimated_duration": 3600.0327187609932,
    "input_throughput": 7112.778688526137,
    "output_throughput": 6340.775149359271,
    "total_throughput": 13453.553837885407,
    "itl": 85.72231930613655,
    "ttft": 2034743.5080641103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.956929825933191,
    "arrivals": 1105887,
    "finished_requests": 104094,
    "scheduler_time": 325.20246029860846
}
#Debug simulation 
Total elapsed time: 96.86507253488526. Arrivals time: 0.5743405395187438 Scheduler time: 96.06651364220306 Scheduler overhead time: 0.08866188582032919 Adapter cache time: 0.01979999616742134 Engine time: 0.08208093792200089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.39907053019851,
    "estimated_duration": 3600.0357820170957,
    "input_throughput": 7112.772636291092,
    "output_throughput": 6340.769754018962,
    "total_throughput": 13453.542390310053,
    "itl": 85.72236710661291,
    "ttft": 2034744.909699039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9599902731925372,
    "arrivals": 1105887,
    "finished_requests": 104094,
    "scheduler_time": 325.20246310742255
}
#Debug simulation 
Total elapsed time: 96.399257409852. Arrivals time: 0.5421621631830931 Scheduler time: 95.63233953528106 Scheduler overhead time: 0.08846061863005161 Adapter cache time: 0.01957144308835268 Engine time: 0.08314154203981161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 97.41418140288442,
    "estimated_duration": 3600.042489223708,
    "input_throughput": 7113.425210023589,
    "output_throughput": 6335.9574416907935,
    "total_throughput": 13449.382651714383,
    "itl": 86.64798277474091,
    "ttft": 2041823.140330448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8917953949933757,
    "arrivals": 1105887,
    "finished_requests": 104078,
    "scheduler_time": 325.8696472594283
}
#Debug simulation 
Total elapsed time: 97.4143657903187. Arrivals time: 0.5713216648437083 Scheduler time: 96.61674847640097 Scheduler overhead time: 0.08961061760783195 Adapter cache time: 0.01997585454955697 Engine time: 0.08322659553959966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 96.56136422790587,
    "estimated_duration": 3600.0610161691848,
    "input_throughput": 7112.722780250965,
    "output_throughput": 6340.725309231049,
    "total_throughput": 13453.448089482015,
    "itl": 85.72288830458793,
    "ttft": 2034754.6824974457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9850152766890858,
    "arrivals": 1105887,
    "finished_requests": 104094,
    "scheduler_time": 325.2026722560412
}
#Debug simulation 
Total elapsed time: 96.5615578116849. Arrivals time: 0.5612003519199789 Scheduler time: 95.77525219507515 Scheduler overhead time: 0.08895021816715598 Adapter cache time: 0.019649572670459747 Engine time: 0.08253550995141268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 99.14861065289006,
    "estimated_duration": 3600.0352067371273,
    "input_throughput": 7223.412968666236,
    "output_throughput": 6436.32205502815,
    "total_throughput": 13659.735023694388,
    "itl": 88.45959442351936,
    "ttft": 2034204.5332259333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8299107804801034,
    "arrivals": 1105887,
    "finished_requests": 105614,
    "scheduler_time": 320.17573666661
}
#Debug simulation 
Total elapsed time: 99.1487920852378. Arrivals time: 0.5721516022458673 Scheduler time: 98.35339416423813 Scheduler overhead time: 0.08774328185245395 Adapter cache time: 0.0196952554397285 Engine time: 0.08254589047282934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.6127839977853,
    "estimated_duration": 3600.0381464870916,
    "input_throughput": 7115.875431763805,
    "output_throughput": 6326.263798683241,
    "total_throughput": 13442.139230447045,
    "itl": 86.05691143295086,
    "ttft": 2051827.7324388423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0276529085636095,
    "arrivals": 1105887,
    "finished_requests": 104120,
    "scheduler_time": 325.22154053196454
}
#Debug simulation 
Total elapsed time: 96.61297583812848. Arrivals time: 0.5736635229550302 Scheduler time: 95.81409150315449 Scheduler overhead time: 0.08871193882077932 Adapter cache time: 0.019734305795282125 Engine time: 0.08267028722912073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 94.55554469581693,
    "estimated_duration": 3600.0112588813586,
    "input_throughput": 6811.668696730636,
    "output_throughput": 6101.832305609445,
    "total_throughput": 12913.501002340081,
    "itl": 81.0289716402097,
    "ttft": 2030786.2590994881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9984984967881216,
    "arrivals": 966726,
    "finished_requests": 99625,
    "scheduler_time": 340.2033569518226
}
#Debug simulation 
Total elapsed time: 94.55573925282806. Arrivals time: 0.5320862275548279 Scheduler time: 93.79113901313394 Scheduler overhead time: 0.09208445623517036 Adapter cache time: 0.020450494717806578 Engine time: 0.08484487049281597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 98.01348259206861,
    "estimated_duration": 3600.0387054399503,
    "input_throughput": 6932.105469391118,
    "output_throughput": 6204.965231691897,
    "total_throughput": 13137.070701083016,
    "itl": 84.64997328901515,
    "ttft": 2004689.9355656295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3242243721848412,
    "arrivals": 966726,
    "finished_requests": 101299,
    "scheduler_time": 334.3182627357315
}
#Debug simulation 
Total elapsed time: 98.0136769451201. Arrivals time: 0.5538046923466027 Scheduler time: 97.22694123489782 Scheduler overhead time: 0.09216908318921924 Adapter cache time: 0.020507415756583214 Engine time: 0.08547624060884118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 98.11081083863974,
    "estimated_duration": 3600.0427191885324,
    "input_throughput": 6932.097740669359,
    "output_throughput": 6204.958313671101,
    "total_throughput": 13137.056054340459,
    "itl": 84.65005964752478,
    "ttft": 2004691.4472531495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3281897227093573,
    "arrivals": 966726,
    "finished_requests": 101299,
    "scheduler_time": 334.3183111337589
}
#Debug simulation 
Total elapsed time: 98.11099830688909. Arrivals time: 0.5601609353907406 Scheduler time: 97.31780742947012 Scheduler overhead time: 0.09203593153506517 Adapter cache time: 0.020930721890181303 Engine time: 0.08506694668903947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 94.66008334187791,
    "estimated_duration": 3600.0535390455752,
    "input_throughput": 6811.588698345066,
    "output_throughput": 6101.760643766334,
    "total_throughput": 12913.349342111402,
    "itl": 81.02965711392858,
    "ttft": 2030803.24088898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.040759431354221,
    "arrivals": 966726,
    "finished_requests": 99625,
    "scheduler_time": 340.20337618139604
}
#Debug simulation 
Total elapsed time: 94.660272390116. Arrivals time: 0.5578974788077176 Scheduler time: 93.87038980051875 Scheduler overhead time: 0.09177880035713315 Adapter cache time: 0.020469220355153084 Engine time: 0.08489507297053933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 97.04231169912964,
    "estimated_duration": 3600.023729851782,
    "input_throughput": 6932.032917746199,
    "output_throughput": 6204.990487915393,
    "total_throughput": 13137.023405661592,
    "itl": 84.65115945675191,
    "ttft": 2004631.5909121814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3581191238760972,
    "arrivals": 966726,
    "finished_requests": 101298,
    "scheduler_time": 334.3124003025908
}
#Debug simulation 
Total elapsed time: 97.04249939695. Arrivals time: 0.5539559577591717 Scheduler time: 96.25732554960996 Scheduler overhead time: 0.09077755268663168 Adapter cache time: 0.021091503091156483 Engine time: 0.0847854190506041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 94.45251680538058,
    "estimated_duration": 3600.0313495568776,
    "input_throughput": 6811.866236392217,
    "output_throughput": 6101.969362767888,
    "total_throughput": 12913.835599160104,
    "itl": 81.02759870004942,
    "ttft": 2030762.465385727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9525028425710882,
    "arrivals": 966726,
    "finished_requests": 99627,
    "scheduler_time": 340.20972893181215
}
#Debug simulation 
Total elapsed time: 94.45270519237965. Arrivals time: 0.5288372542709112 Scheduler time: 93.69284740835428 Scheduler overhead time: 0.09138400061056018 Adapter cache time: 0.020216892939060926 Engine time: 0.08442599512636662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 4320, 1080, 17280, 17280, 1080, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 1080, 17280, 4320, 17280, 4320, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 4320, 4320, 4320, 17280, 4320, 1080, 4320, 1080, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 1080, 17280, 4320, 4320, 1080, 1080, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 4320, 4320, 17280, 1080, 1080, 17280, 1080, 17280, 4320, 1080, 17280, 4320, 4320, 1080, 17280, 17280, 17280, 1080, 4320, 17280, 1080, 17280, 4320, 4320, 17280, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 1080, 17280, 1080, 17280, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 17280, 1080, 17280, 1080, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 17280, 17280, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 4320, 17280, 1080, 1080, 4320, 4320, 1080, 1080, 17280, 17280, 17280, 17280, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 17280, 4320, 4320, 4320, 17280, 1080, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 4320, 1080, 17280, 17280, 17280, 4320, 1080, 17280, 17280, 4320, 4320, 17280, 17280, 1080, 17280, 17280, 4320, 1080, 17280, 4320, 4320, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 4320, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 17280, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 4320, 17280, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 17280, 1080, 4320, 1080, 1080, 4320, 17280, 4320, 17280, 1080, 17280, 17280, 4320, 17280, 4320, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2903040 . Total input tokens: 646692637 . Total output tokens: 580579922
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 97.13261679001153,
    "estimated_duration": 3600.004761819022,
    "input_throughput": 6931.948330921272,
    "output_throughput": 6205.02262577923,
    "total_throughput": 13136.970956700503,
    "itl": 84.65229247611059,
    "ttft": 2004571.1643417825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.38830003261567,
    "arrivals": 966726,
    "finished_requests": 101297,
    "scheduler_time": 334.3063593064248
}
#Debug simulation 
Total elapsed time: 97.13280051480979. Arrivals time: 0.5471805217675865 Scheduler time: 96.35241333022714 Scheduler overhead time: 0.09207567945122719 Adapter cache time: 0.020768079441040754 Engine time: 0.0855617574416101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 95.9085567491129,
    "estimated_duration": 3600.0298807668823,
    "input_throughput": 6870.629083426117,
    "output_throughput": 6121.48502370362,
    "total_throughput": 12992.114107129737,
    "itl": 83.11395105972743,
    "ttft": 2028118.7564366576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9219863031898001,
    "arrivals": 943309,
    "finished_requests": 99923,
    "scheduler_time": 338.77414680403393
}
#Debug simulation 
Total elapsed time: 95.90874719526619. Arrivals time: 0.5415039309300482 Scheduler time: 95.13590446580201 Scheduler overhead time: 0.0916343773715198 Adapter cache time: 0.020410966593772173 Engine time: 0.08471229998394847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 95.98437527194619,
    "estimated_duration": 3600.033901907972,
    "input_throughput": 6928.823638794068,
    "output_throughput": 6179.158198540947,
    "total_throughput": 13107.981837335015,
    "itl": 83.27498036795825,
    "ttft": 2018031.7747432664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1093114540283624,
    "arrivals": 943309,
    "finished_requests": 100809,
    "scheduler_time": 335.3621159057171
}
#Debug simulation 
Total elapsed time: 95.98456023307517. Arrivals time: 0.5537090823054314 Scheduler time: 95.20102766249329 Scheduler overhead time: 0.09121148660779 Adapter cache time: 0.02003747085109353 Engine time: 0.0838586837053299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.39771155733615,
    "estimated_duration": 3600.037392030258,
    "input_throughput": 6928.816921518894,
    "output_throughput": 6179.152208042686,
    "total_throughput": 13107.96912956158,
    "itl": 83.27504620226422,
    "ttft": 2018032.9654024802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.112815836425879,
    "arrivals": 943309,
    "finished_requests": 100809,
    "scheduler_time": 335.362101645584
}
#Debug simulation 
Total elapsed time: 96.39789987402037. Arrivals time: 0.5332111166790128 Scheduler time: 95.63445388618857 Scheduler overhead time: 0.0913987997919321 Adapter cache time: 0.020282048266381025 Engine time: 0.0839800457470119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 96.78929991880432,
    "estimated_duration": 3600.0476135831905,
    "input_throughput": 6928.973357430728,
    "output_throughput": 6179.3171612689675,
    "total_throughput": 13108.290518699696,
    "itl": 83.27263885538912,
    "ttft": 2017986.604701934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0214634605636683,
    "arrivals": 943309,
    "finished_requests": 100812,
    "scheduler_time": 335.3738582948701
}
#Debug simulation 
Total elapsed time: 96.78949192585424. Arrivals time: 0.5461608138866723 Scheduler time: 96.0137736229226 Scheduler overhead time: 0.09063043957576156 Adapter cache time: 0.019946550950407982 Engine time: 0.08473450504243374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 96.06578305689618,
    "estimated_duration": 3600.013174500543,
    "input_throughput": 6928.863532134343,
    "output_throughput": 6179.193775613402,
    "total_throughput": 13108.057307747746,
    "itl": 83.27559224533584,
    "ttft": 2018043.7352493454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.13985290050507,
    "arrivals": 943309,
    "finished_requests": 100809,
    "scheduler_time": 335.35605580730027
}
#Debug simulation 
Total elapsed time: 96.06596015905961. Arrivals time: 0.5395318916998804 Scheduler time: 95.2981910048984 Scheduler overhead time: 0.09036895539611578 Adapter cache time: 0.019778401125222445 Engine time: 0.08363189501687884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 96.95669136196375,
    "estimated_duration": 3600.0330862325404,
    "input_throughput": 6936.286529003038,
    "output_throughput": 6187.837574379748,
    "total_throughput": 13124.124103382785,
    "itl": 83.28246827318156,
    "ttft": 2011391.8791482851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9375525910965778,
    "arrivals": 943309,
    "finished_requests": 100965,
    "scheduler_time": 335.0431998560945
}
#Debug simulation 
Total elapsed time: 96.95688573596999. Arrivals time: 0.5474446653388441 Scheduler time: 96.17848958121613 Scheduler overhead time: 0.09152827924117446 Adapter cache time: 0.020427938550710678 Engine time: 0.08393178367987275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 4320, 540, 17280, 17280, 540, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 540, 540, 4320, 540, 17280, 540, 17280, 4320, 17280, 4320, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 17280, 17280, 540, 4320, 4320, 4320, 17280, 4320, 540, 4320, 540, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 540, 17280, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 17280, 540, 4320, 17280, 540, 17280, 4320, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 17280, 17280, 4320, 540, 540, 17280, 4320, 4320, 540, 540, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 540, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 540, 540, 4320, 4320, 17280, 540, 540, 17280, 540, 17280, 4320, 540, 17280, 4320, 4320, 540, 17280, 17280, 17280, 540, 4320, 17280, 540, 17280, 4320, 4320, 17280, 17280, 540, 4320, 17280, 540, 4320, 4320, 540, 4320, 540, 4320, 17280, 17280, 4320, 540, 17280, 540, 17280, 4320, 4320, 4320, 4320, 4320, 540, 540, 17280, 540, 17280, 540, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 17280, 17280, 540, 540, 17280, 540, 540, 540, 4320, 540, 4320, 17280, 17280, 4320, 4320, 540, 17280, 4320, 17280, 540, 4320, 4320, 540, 540, 4320, 540, 17280, 17280, 540, 17280, 17280, 540, 4320, 17280, 540, 540, 4320, 4320, 540, 540, 17280, 17280, 17280, 17280, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 17280, 4320, 4320, 4320, 17280, 540, 4320, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 4320, 540, 17280, 17280, 17280, 4320, 540, 17280, 17280, 4320, 4320, 17280, 17280, 540, 17280, 17280, 4320, 540, 17280, 4320, 4320, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 4320, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 17280, 540, 540, 540, 4320, 540, 4320, 4320, 540, 17280, 4320, 17280, 540, 17280, 540, 4320, 4320, 4320, 4320, 540, 4320, 17280, 17280, 540, 17280, 17280, 540, 17280, 4320, 17280, 4320, 4320, 4320, 540, 4320, 540, 540, 17280, 540, 4320, 540, 540, 4320, 17280, 4320, 17280, 540, 17280, 17280, 4320, 17280, 4320, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2833920 . Total input tokens: 631333502 . Total output tokens: 566694952
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.09461011458188,
    "estimated_duration": 3600.0412129827623,
    "input_throughput": 6928.8095675252025,
    "output_throughput": 6179.145649715792,
    "total_throughput": 13107.955217240995,
    "itl": 83.27607588405334,
    "ttft": 2018055.4525039126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.167518733516336,
    "arrivals": 943309,
    "finished_requests": 100809,
    "scheduler_time": 335.3563284179482
}
#Debug simulation 
Total elapsed time: 96.09478931780905. Arrivals time: 0.527728489600122 Scheduler time: 95.33898499375209 Scheduler overhead time: 0.09014134388417006 Adapter cache time: 0.01996753364801407 Engine time: 0.08358339918777347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 100.43437415733933,
    "estimated_duration": 3600.004968145276,
    "input_throughput": 7137.235150327473,
    "output_throughput": 6294.702979722535,
    "total_throughput": 13431.938130050008,
    "itl": 88.06294700903631,
    "ttft": 1988431.354898634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1974302001437573,
    "arrivals": 931969,
    "finished_requests": 103961,
    "scheduler_time": 326.7274058239319
}
#Debug simulation 
Total elapsed time: 100.43455188022926. Arrivals time: 0.5617195176891983 Scheduler time: 99.64288345398381 Scheduler overhead time: 0.0906904679723084 Adapter cache time: 0.020602062344551086 Engine time: 0.08443143963813782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 99.11889912607148,
    "estimated_duration": 3600.0321492944727,
    "input_throughput": 7051.855357729312,
    "output_throughput": 6246.806713769846,
    "total_throughput": 13298.662071499159,
    "itl": 86.78449328084179,
    "ttft": 1986260.2994935354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.181221490292816,
    "arrivals": 931969,
    "finished_requests": 102675,
    "scheduler_time": 331.73480754452277
}
#Debug simulation 
Total elapsed time: 99.1190883028321. Arrivals time: 0.5516528841108084 Scheduler time: 98.33645855775103 Scheduler overhead time: 0.09117473708465695 Adapter cache time: 0.020656741689890623 Engine time: 0.08473430620506406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 100.12720912508667,
    "estimated_duration": 3600.035764363835,
    "input_throughput": 7051.848276425703,
    "output_throughput": 6246.80044087673,
    "total_throughput": 13298.648717302434,
    "itl": 86.78455348308789,
    "ttft": 1986261.7097849778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1848319635167774,
    "arrivals": 931969,
    "finished_requests": 102675,
    "scheduler_time": 331.73491217921384
}
#Debug simulation 
Total elapsed time: 100.1273941011168. Arrivals time: 0.5396910887211561 Scheduler time: 99.35657581454143 Scheduler overhead time: 0.09135570609942079 Adapter cache time: 0.020781022030860186 Engine time: 0.08455071086063981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 100.25793101359159,
    "estimated_duration": 3600.052069805839,
    "input_throughput": 7137.141769559393,
    "output_throughput": 6294.620622312879,
    "total_throughput": 13431.762391872273,
    "itl": 88.06381736032249,
    "ttft": 1988450.6721385766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2441017975285464,
    "arrivals": 931969,
    "finished_requests": 103961,
    "scheduler_time": 326.7276358098614
}
#Debug simulation 
Total elapsed time: 100.25812481157482. Arrivals time: 0.5543496930040419 Scheduler time: 99.47249764902517 Scheduler overhead time: 0.09087511617690325 Adapter cache time: 0.02073420211672783 Engine time: 0.08495789533481002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 99.54497735621408,
    "estimated_duration": 3600.0231311873226,
    "input_throughput": 7051.786634389556,
    "output_throughput": 6246.619585631175,
    "total_throughput": 13298.406220020732,
    "itl": 86.78584857909371,
    "ttft": 1986278.9452214914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2128750578872904,
    "arrivals": 931969,
    "finished_requests": 102673,
    "scheduler_time": 331.729240728648
}
#Debug simulation 
Total elapsed time: 99.54515937296674. Arrivals time: 0.5543749341741204 Scheduler time: 98.75898288888857 Scheduler overhead time: 0.0913145774975419 Adapter cache time: 0.020987590309232473 Engine time: 0.08464448153972626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 100.18781140400097,
    "estimated_duration": 3600.0826492205388,
    "input_throughput": 7137.226698271272,
    "output_throughput": 6294.604932169099,
    "total_throughput": 13431.83163044037,
    "itl": 88.0626195455814,
    "ttft": 1988443.620614901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.146856111739723,
    "arrivals": 931969,
    "finished_requests": 103963,
    "scheduler_time": 326.7363236439522
}
#Debug simulation 
Total elapsed time: 100.18800030788407. Arrivals time: 0.5558550436981022 Scheduler time: 99.40147966193035 Scheduler overhead time: 0.09112301515415311 Adapter cache time: 0.0209150449372828 Engine time: 0.08424582844600081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 4320, 270, 17280, 17280, 270, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 270, 270, 4320, 270, 17280, 270, 17280, 4320, 17280, 4320, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 17280, 17280, 270, 4320, 4320, 4320, 17280, 4320, 270, 4320, 270, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 270, 17280, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 17280, 270, 4320, 17280, 270, 17280, 4320, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 17280, 17280, 4320, 270, 270, 17280, 4320, 4320, 270, 270, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 270, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 270, 270, 4320, 4320, 17280, 270, 270, 17280, 270, 17280, 4320, 270, 17280, 4320, 4320, 270, 17280, 17280, 17280, 270, 4320, 17280, 270, 17280, 4320, 4320, 17280, 17280, 270, 4320, 17280, 270, 4320, 4320, 270, 4320, 270, 4320, 17280, 17280, 4320, 270, 17280, 270, 17280, 4320, 4320, 4320, 4320, 4320, 270, 270, 17280, 270, 17280, 270, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 17280, 17280, 270, 270, 17280, 270, 270, 270, 4320, 270, 4320, 17280, 17280, 4320, 4320, 270, 17280, 4320, 17280, 270, 4320, 4320, 270, 270, 4320, 270, 17280, 17280, 270, 17280, 17280, 270, 4320, 17280, 270, 270, 4320, 4320, 270, 270, 17280, 17280, 17280, 17280, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 17280, 4320, 4320, 4320, 17280, 270, 4320, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 4320, 270, 17280, 17280, 17280, 4320, 270, 17280, 17280, 4320, 4320, 17280, 17280, 270, 17280, 17280, 4320, 270, 17280, 4320, 4320, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 4320, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 17280, 270, 270, 270, 4320, 270, 4320, 4320, 270, 17280, 4320, 17280, 270, 17280, 270, 4320, 4320, 4320, 4320, 270, 4320, 17280, 17280, 270, 17280, 17280, 270, 17280, 4320, 17280, 4320, 4320, 4320, 270, 4320, 270, 270, 17280, 270, 4320, 270, 270, 4320, 17280, 4320, 17280, 270, 17280, 17280, 4320, 17280, 4320, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2799360 . Total input tokens: 623655065 . Total output tokens: 559758541
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 100.23725672997534,
    "estimated_duration": 3600.0109081778182,
    "input_throughput": 7051.68724415045,
    "output_throughput": 6246.516350524696,
    "total_throughput": 13298.203594675146,
    "itl": 86.78720718572318,
    "ttft": 1986233.759689132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.241421167403462,
    "arrivals": 931969,
    "finished_requests": 102671,
    "scheduler_time": 331.72357646853044
}
#Debug simulation 
Total elapsed time: 100.23745165811852. Arrivals time: 0.6039248649030924 Scheduler time: 99.40201023826376 Scheduler overhead time: 0.09158359281718731 Adapter cache time: 0.0206182561814785 Engine time: 0.08475551940500736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 98.06355053698644,
    "estimated_duration": 3600.001960648876,
    "input_throughput": 7003.430630203225,
    "output_throughput": 6254.686593543267,
    "total_throughput": 13258.11722374649,
    "itl": 85.51329852913153,
    "ttft": 2002156.4899889147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9372887419094644,
    "arrivals": 926257,
    "finished_requests": 102113,
    "scheduler_time": 330.7333270368245
}
#Debug simulation 
Total elapsed time: 98.06373642105609. Arrivals time: 0.5486996578983963 Scheduler time: 97.28717793338001 Scheduler overhead time: 0.09012628439813852 Adapter cache time: 0.01976682571694255 Engine time: 0.08373834285885096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.19303742190823,
    "estimated_duration": 3600.0457787229525,
    "input_throughput": 6932.354346019718,
    "output_throughput": 6190.145450846214,
    "total_throughput": 13122.499796865932,
    "itl": 83.85784936488518,
    "ttft": 2021212.7206409837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0625476060784487,
    "arrivals": 926257,
    "finished_requests": 101120,
    "scheduler_time": 334.51703141174113
}
#Debug simulation 
Total elapsed time: 96.19320794288069. Arrivals time: 0.5545386555604637 Scheduler time: 95.40804413706064 Scheduler overhead time: 0.0912581100128591 Adapter cache time: 0.020062314346432686 Engine time: 0.08467676537111402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.16702930396423,
    "estimated_duration": 3600.0494183755213,
    "input_throughput": 6932.347337404454,
    "output_throughput": 6190.139192604681,
    "total_throughput": 13122.486530009135,
    "itl": 83.85793030177383,
    "ttft": 2021214.1822644381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0661596026085416,
    "arrivals": 926257,
    "finished_requests": 101120,
    "scheduler_time": 334.5170590677568
}
#Debug simulation 
Total elapsed time: 96.16720753815025. Arrivals time: 0.5479272594675422 Scheduler time: 95.3897476522252 Scheduler overhead time: 0.09096796112135053 Adapter cache time: 0.019832712598145008 Engine time: 0.08427120884880424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 97.91154411714524,
    "estimated_duration": 3600.018784679453,
    "input_throughput": 7003.397900948708,
    "output_throughput": 6254.657363407317,
    "total_throughput": 13258.055264356026,
    "itl": 85.51433021708378,
    "ttft": 2002152.2410764263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9809584254561805,
    "arrivals": 926257,
    "finished_requests": 102113,
    "scheduler_time": 330.728281111472
}
#Debug simulation 
Total elapsed time: 97.91173408692703. Arrivals time: 0.6094394996762276 Scheduler time: 97.07145846495405 Scheduler overhead time: 0.09097509644925594 Adapter cache time: 0.020392280537635088 Engine time: 0.08492739824578166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 95.86888065515086,
    "estimated_duration": 3600.0088014604817,
    "input_throughput": 6932.425551258463,
    "output_throughput": 6190.209032533286,
    "total_throughput": 13122.634583791749,
    "itl": 83.85836803273678,
    "ttft": 2021225.1772866372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.092316390182825,
    "arrivals": 926257,
    "finished_requests": 101120,
    "scheduler_time": 334.51049990770167
}
#Debug simulation 
Total elapsed time: 95.86906492430717. Arrivals time: 0.5497952797450125 Scheduler time: 95.08934929966927 Scheduler overhead time: 0.09063116693869233 Adapter cache time: 0.02028242638334632 Engine time: 0.0843845047056675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 98.34030559239909,
    "estimated_duration": 3600.0136299354945,
    "input_throughput": 7003.424595492923,
    "output_throughput": 6254.707985759338,
    "total_throughput": 13258.132581252261,
    "itl": 85.51234921513503,
    "ttft": 2002134.7046896964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8927018366730468,
    "arrivals": 926257,
    "finished_requests": 102114,
    "scheduler_time": 330.73937254406934
}
#Debug simulation 
Total elapsed time: 98.34047221718356. Arrivals time: 0.5563990795053542 Scheduler time: 97.5549586629495 Scheduler overhead time: 0.0901064039207995 Adapter cache time: 0.019964130129665136 Engine time: 0.08484376734122634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 4320, 135, 17280, 17280, 135, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 135, 135, 4320, 135, 17280, 135, 17280, 4320, 17280, 4320, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 17280, 17280, 135, 4320, 4320, 4320, 17280, 4320, 135, 4320, 135, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 135, 17280, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 17280, 135, 4320, 17280, 135, 17280, 4320, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 17280, 17280, 4320, 135, 135, 17280, 4320, 4320, 135, 135, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 135, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 135, 135, 4320, 4320, 17280, 135, 135, 17280, 135, 17280, 4320, 135, 17280, 4320, 4320, 135, 17280, 17280, 17280, 135, 4320, 17280, 135, 17280, 4320, 4320, 17280, 17280, 135, 4320, 17280, 135, 4320, 4320, 135, 4320, 135, 4320, 17280, 17280, 4320, 135, 17280, 135, 17280, 4320, 4320, 4320, 4320, 4320, 135, 135, 17280, 135, 17280, 135, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 17280, 17280, 135, 135, 17280, 135, 135, 135, 4320, 135, 4320, 17280, 17280, 4320, 4320, 135, 17280, 4320, 17280, 135, 4320, 4320, 135, 135, 4320, 135, 17280, 17280, 135, 17280, 17280, 135, 4320, 17280, 135, 135, 4320, 4320, 135, 135, 17280, 17280, 17280, 17280, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 17280, 4320, 4320, 4320, 17280, 135, 4320, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 4320, 135, 17280, 17280, 17280, 4320, 135, 17280, 17280, 4320, 4320, 17280, 17280, 135, 17280, 17280, 4320, 135, 17280, 4320, 4320, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 4320, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 17280, 135, 135, 135, 4320, 135, 4320, 4320, 135, 17280, 4320, 17280, 135, 17280, 135, 4320, 4320, 4320, 4320, 135, 4320, 17280, 17280, 135, 17280, 17280, 135, 17280, 4320, 17280, 4320, 4320, 4320, 135, 4320, 135, 135, 17280, 135, 4320, 135, 135, 4320, 17280, 4320, 17280, 135, 17280, 17280, 4320, 17280, 4320, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2782080 . Total input tokens: 619810953 . Total output tokens: 556306045
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 96.07248433725908,
    "estimated_duration": 3600.0361448425406,
    "input_throughput": 6932.3728973536645,
    "output_throughput": 6190.162015991286,
    "total_throughput": 13122.53491334495,
    "itl": 83.8587076832104,
    "ttft": 2021235.848035239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 632,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.119353454262017,
    "arrivals": 926257,
    "finished_requests": 101120,
    "scheduler_time": 334.51070618712436
}
#Debug simulation 
Total elapsed time: 96.07264805492014. Arrivals time: 0.5478061581961811 Scheduler time: 95.2939742160961 Scheduler overhead time: 0.09122424433007836 Adapter cache time: 0.020230598282068968 Engine time: 0.08468583505600691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 99.58212748309597,
    "estimated_duration": 3600.000259446634,
    "input_throughput": 7084.411433881472,
    "output_throughput": 6265.4748262343455,
    "total_throughput": 13349.886260115818,
    "itl": 85.3319228033861,
    "ttft": 1993007.3894593797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9128048399580015,
    "arrivals": 923309,
    "finished_requests": 103152,
    "scheduler_time": 330.2072446453358
}
#Debug simulation 
Total elapsed time: 99.58230267604813. Arrivals time: 0.5622529275715351 Scheduler time: 98.79076767666265 Scheduler overhead time: 0.09030619403347373 Adapter cache time: 0.020143082831054926 Engine time: 0.08452370762825012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 101.23319038422778,
    "estimated_duration": 3600.029938344949,
    "input_throughput": 7246.624735569152,
    "output_throughput": 6379.610001398649,
    "total_throughput": 13626.234736967801,
    "itl": 89.27520570957182,
    "ttft": 1989920.017341042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.124261705502873,
    "arrivals": 923309,
    "finished_requests": 105468,
    "scheduler_time": 321.3936059631515
}
#Debug simulation 
Total elapsed time: 101.23338640434667. Arrivals time: 0.5815565120428801 Scheduler time: 100.42183667514473 Scheduler overhead time: 0.0909856609068811 Adapter cache time: 0.020358821377158165 Engine time: 0.08432316733524203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 102.25004980806261,
    "estimated_duration": 3600.0337429116603,
    "input_throughput": 7246.617077233369,
    "output_throughput": 6379.603259336332,
    "total_throughput": 13626.2203365697,
    "itl": 89.2752737350829,
    "ttft": 1989921.2741809746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1280334306694653,
    "arrivals": 923309,
    "finished_requests": 105468,
    "scheduler_time": 321.39363880467016
}
#Debug simulation 
Total elapsed time: 102.25022855121642. Arrivals time: 0.5626399461179972 Scheduler time: 101.45802997983992 Scheduler overhead time: 0.09066518303006887 Adapter cache time: 0.020339221693575382 Engine time: 0.08474856428802013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 101.74197130696848,
    "estimated_duration": 3600.0701925258772,
    "input_throughput": 7246.712593038552,
    "output_throughput": 6379.807551442598,
    "total_throughput": 13626.52014448115,
    "itl": 89.27511535074905,
    "ttft": 1989912.7649552426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0372309026750592,
    "arrivals": 923309,
    "finished_requests": 105471,
    "scheduler_time": 321.4024539505746
}
#Debug simulation 
Total elapsed time: 101.74215323897079. Arrivals time: 0.5694162980653346 Scheduler time: 100.94490437069908 Scheduler overhead time: 0.0898670544847846 Adapter cache time: 0.020333140157163143 Engine time: 0.08348670601844788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 101.6118905027397,
    "estimated_duration": 3600.060652920211,
    "input_throughput": 7246.562909666121,
    "output_throughput": 6379.555572590243,
    "total_throughput": 13626.118482256365,
    "itl": 89.27579972881517,
    "ttft": 1989931.6858321354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1548189871758257,
    "arrivals": 923309,
    "finished_requests": 105468,
    "scheduler_time": 321.3937632567407
}
#Debug simulation 
Total elapsed time: 101.61208287766203. Arrivals time: 0.5841753920540214 Scheduler time: 100.79871656838804 Scheduler overhead time: 0.08987160120159388 Adapter cache time: 0.02063142554834485 Engine time: 0.08436604123562574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 98.85949687100947,
    "estimated_duration": 3600.008368713213,
    "input_throughput": 7084.402975739781,
    "output_throughput": 6265.5126571448445,
    "total_throughput": 13349.915632884626,
    "itl": 85.3308560495759,
    "ttft": 1992986.537311275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8687814343138303,
    "arrivals": 923309,
    "finished_requests": 103153,
    "scheduler_time": 330.2131681761633
}
#Debug simulation 
Total elapsed time: 98.85968928830698. Arrivals time: 0.5574125172570348 Scheduler time: 98.0731303258799 Scheduler overhead time: 0.0901855849660933 Adapter cache time: 0.01983368769288063 Engine time: 0.08467836258932948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 4320, 66, 17280, 17280, 66, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 66, 66, 4320, 66, 17280, 66, 17280, 4320, 17280, 4320, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 17280, 17280, 66, 4320, 4320, 4320, 17280, 4320, 66, 4320, 66, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 66, 17280, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 17280, 66, 4320, 17280, 66, 17280, 4320, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 17280, 17280, 4320, 66, 66, 17280, 4320, 4320, 66, 66, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 66, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 66, 66, 4320, 4320, 17280, 66, 66, 17280, 66, 17280, 4320, 66, 17280, 4320, 4320, 66, 17280, 17280, 17280, 66, 4320, 17280, 66, 17280, 4320, 4320, 17280, 17280, 66, 4320, 17280, 66, 4320, 4320, 66, 4320, 66, 4320, 17280, 17280, 4320, 66, 17280, 66, 17280, 4320, 4320, 4320, 4320, 4320, 66, 66, 17280, 66, 17280, 66, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 17280, 17280, 66, 66, 17280, 66, 66, 66, 4320, 66, 4320, 17280, 17280, 4320, 4320, 66, 17280, 4320, 17280, 66, 4320, 4320, 66, 66, 4320, 66, 17280, 17280, 66, 17280, 17280, 66, 4320, 17280, 66, 66, 4320, 4320, 66, 66, 17280, 17280, 17280, 17280, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 17280, 4320, 4320, 4320, 17280, 66, 4320, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 4320, 66, 17280, 17280, 17280, 4320, 66, 17280, 17280, 4320, 4320, 17280, 17280, 66, 17280, 17280, 4320, 66, 17280, 4320, 4320, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 4320, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 17280, 66, 66, 66, 4320, 66, 4320, 4320, 66, 17280, 4320, 17280, 66, 17280, 66, 4320, 4320, 4320, 4320, 66, 4320, 17280, 17280, 66, 17280, 17280, 66, 17280, 4320, 17280, 4320, 4320, 4320, 66, 4320, 66, 66, 17280, 66, 4320, 66, 66, 4320, 17280, 4320, 17280, 66, 17280, 17280, 4320, 17280, 4320, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2773248 . Total input tokens: 617853364 . Total output tokens: 554535687
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 102.22087062615901,
    "estimated_duration": 3600.0889364869186,
    "input_throughput": 7246.50597811552,
    "output_throughput": 6379.505452554659,
    "total_throughput": 13626.011430670178,
    "itl": 89.27636176281504,
    "ttft": 1989943.130946203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1827363277599217,
    "arrivals": 923309,
    "finished_requests": 105468,
    "scheduler_time": 321.39412948288594
}
#Debug simulation 
Total elapsed time: 102.22105769533664. Arrivals time: 0.5696069272235036 Scheduler time: 101.42340552899987 Scheduler overhead time: 0.08874186733737588 Adapter cache time: 0.020878208335489035 Engine time: 0.08448386704549193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 102.2834829268977,
    "estimated_duration": 3600.011200805056,
    "input_throughput": 7342.399655336893,
    "output_throughput": 6479.885672239944,
    "total_throughput": 13822.285327576838,
    "itl": 90.65319631920522,
    "ttft": 1992154.1462482053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9189258154458673,
    "arrivals": 921853,
    "finished_requests": 106682,
    "scheduler_time": 315.44845761004467
}
#Debug simulation 
Total elapsed time: 102.28368155797943. Arrivals time: 0.5744181042537093 Scheduler time: 101.48322825925425 Scheduler overhead time: 0.08787555806338787 Adapter cache time: 0.019736202899366617 Engine time: 0.0843024393543601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 102.8929828768596,
    "estimated_duration": 3600.0150112144356,
    "input_throughput": 7342.194106874954,
    "output_throughput": 6479.540203953487,
    "total_throughput": 13821.73431082844,
    "itl": 90.65459275612945,
    "ttft": 1992122.176701662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0475973546039374,
    "arrivals": 921853,
    "finished_requests": 106678,
    "scheduler_time": 315.44083301356045
}
#Debug simulation 
Total elapsed time: 102.89317698171362. Arrivals time: 0.5809567430987954 Scheduler time: 102.08500602981076 Scheduler overhead time: 0.08946716645732522 Adapter cache time: 0.020141401328146458 Engine time: 0.08419972099363804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 101.91465350193903,
    "estimated_duration": 3600.0183351262144,
    "input_throughput": 7342.187327796849,
    "output_throughput": 6479.534221367289,
    "total_throughput": 13821.721549164138,
    "itl": 90.65466011655025,
    "ttft": 1992123.3553337583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.050942008364956,
    "arrivals": 921853,
    "finished_requests": 106678,
    "scheduler_time": 315.4408122715487
}
#Debug simulation 
Total elapsed time: 101.9148413259536. Arrivals time: 0.5672952644526958 Scheduler time: 101.1202989993617 Scheduler overhead time: 0.08935040328651667 Adapter cache time: 0.01996254501864314 Engine time: 0.08420457504689693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 102.25895626284182,
    "estimated_duration": 3600.0567834598396,
    "input_throughput": 7342.306688450841,
    "output_throughput": 6479.803626203062,
    "total_throughput": 13822.110314653903,
    "itl": 90.6540701307567,
    "ttft": 1992172.1937088426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9638353143236476,
    "arrivals": 921853,
    "finished_requests": 106682,
    "scheduler_time": 315.4491307658775
}
#Debug simulation 
Total elapsed time: 102.25915074395016. Arrivals time: 0.5727095110341907 Scheduler time: 101.45882263872772 Scheduler overhead time: 0.08935500169172883 Adapter cache time: 0.02039308426901698 Engine time: 0.08422566903755069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 102.45562375662848,
    "estimated_duration": 3600.0442144368326,
    "input_throughput": 7342.134547682173,
    "output_throughput": 6479.487642528589,
    "total_throughput": 13821.622190210763,
    "itl": 90.6552108146147,
    "ttft": 1992133.5716578653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0767215345799954,
    "arrivals": 921853,
    "finished_requests": 106678,
    "scheduler_time": 315.4410120945572
}
#Debug simulation 
Total elapsed time: 102.45580136589706. Arrivals time: 0.5842210571281612 Scheduler time: 101.64166090264916 Scheduler overhead time: 0.08882386703044176 Adapter cache time: 0.0206214701756835 Engine time: 0.08739797445014119 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 102.60822772374377,
    "estimated_duration": 3600.0931134038983,
    "input_throughput": 7342.307036888702,
    "output_throughput": 6479.939341886339,
    "total_throughput": 13822.246378775042,
    "itl": 90.65296363914672,
    "ttft": 1992172.175850639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8747615349036344,
    "arrivals": 921853,
    "finished_requests": 106686,
    "scheduler_time": 315.4572979559888
}
#Debug simulation 
Total elapsed time: 102.60841138893738. Arrivals time: 0.5726557392627001 Scheduler time: 101.80857950588688 Scheduler overhead time: 0.08955761464312673 Adapter cache time: 0.020174240227788687 Engine time: 0.08357924735173583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 4320, 33, 17280, 17280, 33, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 33, 33, 4320, 33, 17280, 33, 17280, 4320, 17280, 4320, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 17280, 17280, 33, 4320, 4320, 4320, 17280, 4320, 33, 4320, 33, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 33, 17280, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 17280, 33, 4320, 17280, 33, 17280, 4320, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 17280, 17280, 4320, 33, 33, 17280, 4320, 4320, 33, 33, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 17280, 17280, 33, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 33, 33, 4320, 4320, 17280, 33, 33, 17280, 33, 17280, 4320, 33, 17280, 4320, 4320, 33, 17280, 17280, 17280, 33, 4320, 17280, 33, 17280, 4320, 4320, 17280, 17280, 33, 4320, 17280, 33, 4320, 4320, 33, 4320, 33, 4320, 17280, 17280, 4320, 33, 17280, 33, 17280, 4320, 4320, 4320, 4320, 4320, 33, 33, 17280, 33, 17280, 33, 4320, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 17280, 17280, 33, 33, 17280, 33, 33, 33, 4320, 33, 4320, 17280, 17280, 4320, 4320, 33, 17280, 4320, 17280, 33, 4320, 4320, 33, 33, 4320, 33, 17280, 17280, 33, 17280, 17280, 33, 4320, 17280, 33, 33, 4320, 4320, 33, 33, 17280, 17280, 17280, 17280, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 17280, 4320, 4320, 4320, 17280, 33, 4320, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 4320, 33, 17280, 17280, 17280, 4320, 33, 17280, 17280, 4320, 4320, 17280, 17280, 33, 17280, 17280, 4320, 33, 17280, 4320, 4320, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 4320, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 17280, 33, 33, 33, 4320, 33, 4320, 4320, 33, 17280, 4320, 17280, 33, 17280, 33, 4320, 4320, 4320, 4320, 33, 4320, 17280, 17280, 33, 17280, 17280, 33, 17280, 4320, 17280, 4320, 4320, 4320, 33, 4320, 33, 33, 17280, 33, 4320, 33, 33, 4320, 17280, 4320, 17280, 33, 17280, 17280, 4320, 17280, 4320, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2769024 . Total input tokens: 616944113 . Total output tokens: 553679964
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 101.74007885111496,
    "estimated_duration": 3600.0720108229284,
    "input_throughput": 7342.077858592055,
    "output_throughput": 6479.4376139903625,
    "total_throughput": 13821.515472582418,
    "itl": 90.65576985993495,
    "ttft": 1992144.5339404994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1041358600184306,
    "arrivals": 921853,
    "finished_requests": 106678,
    "scheduler_time": 315.4412941166614
}
#Debug simulation 
Total elapsed time: 101.74025875190273. Arrivals time: 0.5680600889027119 Scheduler time: 100.94576654629782 Scheduler overhead time: 0.08844822738319635 Adapter cache time: 0.020319629926234484 Engine time: 0.08386974595487118 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 104.55894154775888,
    "estimated_duration": 3600.0077017712783,
    "input_throughput": 6988.738103982666,
    "output_throughput": 6196.83702038295,
    "total_throughput": 13185.575124365616,
    "itl": 91.29017382863637,
    "ttft": 1992220.7545928508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6740867959312384,
    "arrivals": 805539,
    "finished_requests": 101586,
    "scheduler_time": 334.7850309602622
}
#Debug simulation 
Total elapsed time: 104.55913461418822. Arrivals time: 0.5417541041970253 Scheduler time: 103.78351670783013 Scheduler overhead time: 0.09217526717111468 Adapter cache time: 0.019684232771396637 Engine time: 0.0866792625747621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 103.92819315008819,
    "estimated_duration": 3600.0121063655765,
    "input_throughput": 7030.743300903146,
    "output_throughput": 6232.056264569047,
    "total_throughput": 13262.799565472193,
    "itl": 92.59435828232473,
    "ttft": 1958193.7999266598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0156538750627133,
    "arrivals": 805539,
    "finished_requests": 102251,
    "scheduler_time": 332.40676665465594
}
#Debug simulation 
Total elapsed time: 103.92836268199608. Arrivals time: 0.5527028734795749 Scheduler time: 103.13939933571965 Scheduler overhead time: 0.09369281074032187 Adapter cache time: 0.020779495127499104 Engine time: 0.08650532271713018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 104.19569843681529,
    "estimated_duration": 3600.0152955434523,
    "input_throughput": 7030.737072515446,
    "output_throughput": 6232.050743721404,
    "total_throughput": 13262.787816236849,
    "itl": 92.59439028628101,
    "ttft": 1958194.975932781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0188205824047443,
    "arrivals": 805539,
    "finished_requests": 102251,
    "scheduler_time": 332.4067891251687
}
#Debug simulation 
Total elapsed time: 104.19587434083223. Arrivals time: 0.5517036854289472 Scheduler time: 103.40536966407672 Scheduler overhead time: 0.09395984513685107 Adapter cache time: 0.021038764622062445 Engine time: 0.08813564386218786 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 103.88196155894548,
    "estimated_duration": 3600.0088584331065,
    "input_throughput": 7000.161663760046,
    "output_throughput": 6209.287498733904,
    "total_throughput": 13209.44916249395,
    "itl": 92.67294308060202,
    "ttft": 1977551.9082231116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8560446745203698,
    "arrivals": 805539,
    "finished_requests": 101834,
    "scheduler_time": 333.8488760474981
}
#Debug simulation 
Total elapsed time: 103.88213314395398. Arrivals time: 0.5324133425019681 Scheduler time: 103.11186656868085 Scheduler overhead time: 0.09458840172737837 Adapter cache time: 0.020636107306927443 Engine time: 0.08719581086188555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 104.44179945578799,
    "estimated_duration": 3600.0067344002205,
    "input_throughput": 7030.690459032395,
    "output_throughput": 6231.98084204079,
    "total_throughput": 13262.671301073186,
    "itl": 92.59533020289298,
    "ttft": 1958208.2514923476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.044851616192613,
    "arrivals": 805539,
    "finished_requests": 102250,
    "scheduler_time": 332.4013995308017
}
#Debug simulation 
Total elapsed time: 104.44198807980865. Arrivals time: 0.5513426498509943 Scheduler time: 103.6544888955541 Scheduler overhead time: 0.09300646930932999 Adapter cache time: 0.020583189092576504 Engine time: 0.08708067471161485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 105.111322064884,
    "estimated_duration": 3600.010053565859,
    "input_throughput": 6988.733538418639,
    "output_throughput": 6196.832972147666,
    "total_throughput": 13185.566510566305,
    "itl": 91.28951490390233,
    "ttft": 1992204.6830836732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6355575113114689,
    "arrivals": 805539,
    "finished_requests": 101586,
    "scheduler_time": 334.7905070647528
}
#Debug simulation 
Total elapsed time: 105.1115089780651. Arrivals time: 0.525611060205847 Scheduler time: 104.35092548467219 Scheduler overhead time: 0.0936384224332869 Adapter cache time: 0.020072944927960634 Engine time: 0.08647305751219392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 1080, 540, 17280, 17280, 540, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 540, 540, 1080, 540, 17280, 540, 17280, 1080, 17280, 1080, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 17280, 17280, 540, 1080, 1080, 1080, 17280, 1080, 540, 1080, 540, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 540, 17280, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 17280, 540, 1080, 17280, 540, 17280, 1080, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 17280, 17280, 1080, 540, 540, 17280, 1080, 1080, 540, 540, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 540, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 540, 540, 1080, 1080, 17280, 540, 540, 17280, 540, 17280, 1080, 540, 17280, 1080, 1080, 540, 17280, 17280, 17280, 540, 1080, 17280, 540, 17280, 1080, 1080, 17280, 17280, 540, 1080, 17280, 540, 1080, 1080, 540, 1080, 540, 1080, 17280, 17280, 1080, 540, 17280, 540, 17280, 1080, 1080, 1080, 1080, 1080, 540, 540, 17280, 540, 17280, 540, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 17280, 17280, 540, 540, 17280, 540, 540, 540, 1080, 540, 1080, 17280, 17280, 1080, 1080, 540, 17280, 1080, 17280, 540, 1080, 1080, 540, 540, 1080, 540, 17280, 17280, 540, 17280, 17280, 540, 1080, 17280, 540, 540, 1080, 1080, 540, 540, 17280, 17280, 17280, 17280, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 17280, 1080, 1080, 1080, 17280, 540, 1080, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 1080, 540, 17280, 17280, 17280, 1080, 540, 17280, 17280, 1080, 1080, 17280, 17280, 540, 17280, 17280, 1080, 540, 17280, 1080, 1080, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 1080, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 17280, 540, 540, 540, 1080, 540, 1080, 1080, 540, 17280, 1080, 17280, 540, 17280, 540, 1080, 1080, 1080, 1080, 540, 1080, 17280, 17280, 540, 17280, 17280, 540, 17280, 1080, 17280, 1080, 1080, 1080, 540, 1080, 540, 540, 17280, 540, 1080, 540, 540, 1080, 17280, 1080, 17280, 540, 17280, 17280, 1080, 17280, 1080, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2419200 . Total input tokens: 538837550 . Total output tokens: 483773560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 104.08165226737037,
    "estimated_duration": 3600.0333138810797,
    "input_throughput": 7030.638550595392,
    "output_throughput": 6231.934830573377,
    "total_throughput": 13262.57338116877,
    "itl": 92.59578308933402,
    "ttft": 1958218.379156495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 617,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0713856651261415,
    "arrivals": 805539,
    "finished_requests": 102250,
    "scheduler_time": 332.4015450013285
}
#Debug simulation 
Total elapsed time: 104.0818211492151. Arrivals time: 0.555291457567364 Scheduler time: 103.29017656156793 Scheduler overhead time: 0.09396440535783768 Adapter cache time: 0.02063151029869914 Engine time: 0.08682406041771173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 105.82668837625533,
    "estimated_duration": 3600.061846749819,
    "input_throughput": 7130.726107712886,
    "output_throughput": 6357.760220331735,
    "total_throughput": 13488.48632804462,
    "itl": 97.3708329197824,
    "ttft": 1927902.1613199667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1760067859362273,
    "arrivals": 794133,
    "finished_requests": 104021,
    "scheduler_time": 324.93550672950096
}
#Debug simulation 
Total elapsed time: 105.82685310719535. Arrivals time: 0.5591377788223326 Scheduler time: 105.02992067905143 Scheduler overhead time: 0.09419639315456152 Adapter cache time: 0.02120027830824256 Engine time: 0.0872031431645155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 106.83991399779916,
    "estimated_duration": 3600.0123951854293,
    "input_throughput": 7129.961561890093,
    "output_throughput": 6357.672276520343,
    "total_throughput": 13487.633838410437,
    "itl": 97.37787949053177,
    "ttft": 1927725.0441380453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.32164291720838,
    "arrivals": 794133,
    "finished_requests": 104012,
    "scheduler_time": 324.9158705230838
}
#Debug simulation 
Total elapsed time: 106.84008071664721. Arrivals time: 0.5481902603060007 Scheduler time: 106.05487420782447 Scheduler overhead time: 0.09255240252241492 Adapter cache time: 0.021233243867754936 Engine time: 0.08818049263209105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 105.87863988103345,
    "estimated_duration": 3600.016114410005,
    "input_throughput": 7129.954195831881,
    "output_throughput": 6357.665708324473,
    "total_throughput": 13487.619904156354,
    "itl": 97.37792835656879,
    "ttft": 1927726.2951047383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.325483451355248,
    "arrivals": 794133,
    "finished_requests": 104012,
    "scheduler_time": 324.91594929064195
}
#Debug simulation 
Total elapsed time: 105.87881098221987. Arrivals time: 0.5552369728684425 Scheduler time: 105.08299749158323 Scheduler overhead time: 0.09580630529671907 Adapter cache time: 0.02179984049871564 Engine time: 0.08810827415436506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 106.63135877624154,
    "estimated_duration": 3600.0422905983055,
    "input_throughput": 7130.519290575826,
    "output_throughput": 6357.706424664292,
    "total_throughput": 13488.225715240118,
    "itl": 97.3726508196437,
    "ttft": 1927848.6029544547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.221945659508911,
    "arrivals": 794133,
    "finished_requests": 104019,
    "scheduler_time": 324.9286256295792
}
#Debug simulation 
Total elapsed time: 106.63152700383216. Arrivals time: 0.547928970772773 Scheduler time: 105.84758343733847 Scheduler overhead time: 0.0924822953529656 Adapter cache time: 0.021304937545210123 Engine time: 0.08736745314672589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 105.47709095478058,
    "estimated_duration": 3600.0081551015237,
    "input_throughput": 7148.810750200711,
    "output_throughput": 6381.216100148572,
    "total_throughput": 13530.026850349283,
    "itl": 96.74334214840069,
    "ttft": 1932127.6730226588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.274531680047516,
    "arrivals": 794133,
    "finished_requests": 104254,
    "scheduler_time": 323.6008285218439
}
#Debug simulation 
Total elapsed time: 105.47725843591616. Arrivals time: 0.5476167923770845 Scheduler time: 104.69242805475369 Scheduler overhead time: 0.09307259786874056 Adapter cache time: 0.021333581302314997 Engine time: 0.0874129575677216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 106.14830633997917,
    "estimated_duration": 3600.0114818539,
    "input_throughput": 7130.825868027555,
    "output_throughput": 6357.849166695763,
    "total_throughput": 13488.67503472332,
    "itl": 97.37011883876534,
    "ttft": 1927884.7559166485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1259257596754084,
    "arrivals": 794133,
    "finished_requests": 104021,
    "scheduler_time": 324.93512282113795
}
#Debug simulation 
Total elapsed time: 106.14847355661914. Arrivals time: 0.5483477506786585 Scheduler time: 105.36314030364156 Scheduler overhead time: 0.09293214278295636 Adapter cache time: 0.02121021505445242 Engine time: 0.08748200302943587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 1080, 270, 17280, 17280, 270, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 270, 270, 1080, 270, 17280, 270, 17280, 1080, 17280, 1080, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 17280, 17280, 270, 1080, 1080, 1080, 17280, 1080, 270, 1080, 270, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 270, 17280, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 17280, 270, 1080, 17280, 270, 17280, 1080, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 17280, 17280, 1080, 270, 270, 17280, 1080, 1080, 270, 270, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 270, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 270, 270, 1080, 1080, 17280, 270, 270, 17280, 270, 17280, 1080, 270, 17280, 1080, 1080, 270, 17280, 17280, 17280, 270, 1080, 17280, 270, 17280, 1080, 1080, 17280, 17280, 270, 1080, 17280, 270, 1080, 1080, 270, 1080, 270, 1080, 17280, 17280, 1080, 270, 17280, 270, 17280, 1080, 1080, 1080, 1080, 1080, 270, 270, 17280, 270, 17280, 270, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 17280, 17280, 270, 270, 17280, 270, 270, 270, 1080, 270, 1080, 17280, 17280, 1080, 1080, 270, 17280, 1080, 17280, 270, 1080, 1080, 270, 270, 1080, 270, 17280, 17280, 270, 17280, 17280, 270, 1080, 17280, 270, 270, 1080, 1080, 270, 270, 17280, 17280, 17280, 17280, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 17280, 1080, 1080, 1080, 17280, 270, 1080, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 1080, 270, 17280, 17280, 17280, 1080, 270, 17280, 17280, 1080, 1080, 17280, 17280, 270, 17280, 17280, 1080, 270, 17280, 1080, 1080, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 1080, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 17280, 270, 270, 270, 1080, 270, 1080, 1080, 270, 17280, 1080, 17280, 270, 17280, 270, 1080, 1080, 1080, 1080, 270, 1080, 17280, 17280, 270, 17280, 17280, 270, 17280, 1080, 17280, 1080, 1080, 1080, 270, 1080, 270, 270, 17280, 270, 1080, 270, 270, 1080, 17280, 1080, 17280, 270, 17280, 17280, 1080, 17280, 1080, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2384640 . Total input tokens: 531075915 . Total output tokens: 476856170
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 105.4586110021919,
    "estimated_duration": 3600.0037200135775,
    "input_throughput": 7148.81955730394,
    "output_throughput": 6381.223961600062,
    "total_throughput": 13530.043518904002,
    "itl": 96.74384996799573,
    "ttft": 1932138.3144747033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.302952035777275,
    "arrivals": 794133,
    "finished_requests": 104254,
    "scheduler_time": 323.5953749663816
}
#Debug simulation 
Total elapsed time: 105.45878459932283. Arrivals time: 0.5583726791664958 Scheduler time: 104.66327818762511 Scheduler overhead time: 0.09236487373709679 Adapter cache time: 0.021666918881237507 Engine time: 0.08789655892178416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 105.55344724608585,
    "estimated_duration": 3600.008972557684,
    "input_throughput": 7097.4978659141625,
    "output_throughput": 6312.233156423303,
    "total_throughput": 13409.731022337464,
    "itl": 93.25158094842354,
    "ttft": 1957436.1653654715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9128048399580015,
    "arrivals": 788332,
    "finished_requests": 103624,
    "scheduler_time": 327.49187408685106
}
#Debug simulation 
Total elapsed time: 105.55361761385575. Arrivals time: 0.5590111180208623 Scheduler time: 104.75813340162858 Scheduler overhead time: 0.09338509477674961 Adapter cache time: 0.020970535464584827 Engine time: 0.08703230693936348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 105.19753581564873,
    "estimated_duration": 3600.0233704322864,
    "input_throughput": 7097.351981060032,
    "output_throughput": 6312.143745131118,
    "total_throughput": 13409.49572619115,
    "itl": 93.25417162959813,
    "ttft": 1957488.964270081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.041617254014133,
    "arrivals": 788332,
    "finished_requests": 103623,
    "scheduler_time": 327.4757714233498
}
#Debug simulation 
Total elapsed time: 105.1977052949369. Arrivals time: 0.5476200762204826 Scheduler time: 104.41229018988088 Scheduler overhead time: 0.09464204404503107 Adapter cache time: 0.020814565010368824 Engine time: 0.08741040900349617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 105.4656566339545,
    "estimated_duration": 3600.026593612384,
    "input_throughput": 7097.345626650403,
    "output_throughput": 6312.138093735061,
    "total_throughput": 13409.483720385464,
    "itl": 93.25422348903722,
    "ttft": 1957490.0054273335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0448549706675223,
    "arrivals": 788332,
    "finished_requests": 103623,
    "scheduler_time": 327.4757568867723
}
#Debug simulation 
Total elapsed time: 105.46582672186196. Arrivals time: 0.5485954247415066 Scheduler time: 104.68239776650444 Scheduler overhead time: 0.09230665815994143 Adapter cache time: 0.020788810215890408 Engine time: 0.08676695404574275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 105.52388022793457,
    "estimated_duration": 3600.0164072286884,
    "input_throughput": 7097.483208324969,
    "output_throughput": 6312.220120544708,
    "total_throughput": 13409.703328869678,
    "itl": 93.25235378498199,
    "ttft": 1957454.686497787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9578552137338439,
    "arrivals": 788332,
    "finished_requests": 103624,
    "scheduler_time": 327.4868622783655
}
#Debug simulation 
Total elapsed time: 105.52405751030892. Arrivals time: 0.5460949973203242 Scheduler time: 104.74262164905667 Scheduler overhead time: 0.09322690963745117 Adapter cache time: 0.02096847491338849 Engine time: 0.08697404386475682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 105.948489906732,
    "estimated_duration": 3600.0137692447943,
    "input_throughput": 7097.370909600709,
    "output_throughput": 6312.160579532167,
    "total_throughput": 13409.531489132874,
    "itl": 93.25461803528187,
    "ttft": 1957499.6008539456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.070634496882561,
    "arrivals": 788332,
    "finished_requests": 103623,
    "scheduler_time": 327.47015704167444
}
#Debug simulation 
Total elapsed time: 105.94865810172632. Arrivals time: 0.5593972196802497 Scheduler time: 105.15252129081637 Scheduler overhead time: 0.09354649903252721 Adapter cache time: 0.02090615313500166 Engine time: 0.0871493062004447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 105.42973408987746,
    "estimated_duration": 3600.0027539670086,
    "input_throughput": 7097.752903617407,
    "output_throughput": 6312.588782038543,
    "total_throughput": 13410.34168565595,
    "itl": 93.24983863079737,
    "ttft": 1957411.8934080228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8687814343138303,
    "arrivals": 788332,
    "finished_requests": 103626,
    "scheduler_time": 327.49727508450167
}
#Debug simulation 
Total elapsed time: 105.42990748072043. Arrivals time: 0.5556536731310189 Scheduler time: 104.63826079992577 Scheduler overhead time: 0.09284717822447419 Adapter cache time: 0.020596924237906933 Engine time: 0.08711765334010124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 1080, 135, 17280, 17280, 135, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 135, 135, 1080, 135, 17280, 135, 17280, 1080, 17280, 1080, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 17280, 17280, 135, 1080, 1080, 1080, 17280, 1080, 135, 1080, 135, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 135, 17280, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 17280, 135, 1080, 17280, 135, 17280, 1080, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 17280, 17280, 1080, 135, 135, 17280, 1080, 1080, 135, 135, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 135, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 135, 135, 1080, 1080, 17280, 135, 135, 17280, 135, 17280, 1080, 135, 17280, 1080, 1080, 135, 17280, 17280, 17280, 135, 1080, 17280, 135, 17280, 1080, 1080, 17280, 17280, 135, 1080, 17280, 135, 1080, 1080, 135, 1080, 135, 1080, 17280, 17280, 1080, 135, 17280, 135, 17280, 1080, 1080, 1080, 1080, 1080, 135, 135, 17280, 135, 17280, 135, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 17280, 17280, 135, 135, 17280, 135, 135, 135, 1080, 135, 1080, 17280, 17280, 1080, 1080, 135, 17280, 1080, 17280, 135, 1080, 1080, 135, 135, 1080, 135, 17280, 17280, 135, 17280, 17280, 135, 1080, 17280, 135, 135, 1080, 1080, 135, 135, 17280, 17280, 17280, 17280, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 17280, 1080, 1080, 1080, 17280, 135, 1080, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 1080, 135, 17280, 17280, 17280, 1080, 135, 17280, 17280, 1080, 1080, 17280, 17280, 135, 17280, 17280, 1080, 135, 17280, 1080, 1080, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 1080, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 17280, 135, 135, 135, 1080, 135, 1080, 1080, 135, 17280, 1080, 17280, 135, 17280, 135, 1080, 1080, 1080, 1080, 135, 1080, 17280, 17280, 135, 17280, 17280, 135, 17280, 1080, 17280, 1080, 1080, 1080, 135, 1080, 135, 135, 17280, 135, 1080, 135, 135, 1080, 17280, 1080, 17280, 135, 17280, 17280, 1080, 17280, 1080, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2367360 . Total input tokens: 527217306 . Total output tokens: 473385958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 105.95648220088333,
    "estimated_duration": 3600.0033687211744,
    "input_throughput": 7097.391414129795,
    "output_throughput": 6312.178815563769,
    "total_throughput": 13409.570229693563,
    "itl": 93.25506014021688,
    "ttft": 1957510.7870073777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.098048822320995,
    "arrivals": 788332,
    "finished_requests": 103623,
    "scheduler_time": 327.4647460098442
}
#Debug simulation 
Total elapsed time: 105.95664915582165. Arrivals time: 0.5494021503254771 Scheduler time: 105.17014658357948 Scheduler overhead time: 0.09342635655775666 Adapter cache time: 0.02113601239398122 Engine time: 0.08735680766403675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.19624468591064,
    "estimated_duration": 3600.0810714953473,
    "input_throughput": 7295.31043285394,
    "output_throughput": 6462.386690179866,
    "total_throughput": 13757.697123033806,
    "itl": 98.23868198041876,
    "ttft": 1925326.1398958713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0444058129471143,
    "arrivals": 785377,
    "finished_requests": 106435,
    "scheduler_time": 315.8487167132584
}
#Debug simulation 
Total elapsed time: 108.19642086559907. Arrivals time: 0.5712891821749508 Scheduler time: 107.39135056780651 Scheduler overhead time: 0.09233525348827243 Adapter cache time: 0.020601841155439615 Engine time: 0.08610856160521507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 107.64070258522406,
    "estimated_duration": 3600.0044186453433,
    "input_throughput": 7248.720269576649,
    "output_throughput": 6419.12739893128,
    "total_throughput": 13667.84766850793,
    "itl": 95.5217084910468,
    "ttft": 1939497.9725935892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1710255534527882,
    "arrivals": 785377,
    "finished_requests": 105714,
    "scheduler_time": 318.42136575285707
}
#Debug simulation 
Total elapsed time: 107.64088435936719. Arrivals time: 0.5811964874155819 Scheduler time: 106.82613385515288 Scheduler overhead time: 0.091433250810951 Adapter cache time: 0.021208895836025476 Engine time: 0.08627735683694482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 107.33420077199116,
    "estimated_duration": 3600.0080780030307,
    "input_throughput": 7248.712901354226,
    "output_throughput": 6419.120873978368,
    "total_throughput": 13667.833775332594,
    "itl": 95.52177614877833,
    "ttft": 1939499.185549731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1746896644868023,
    "arrivals": 785377,
    "finished_requests": 105714,
    "scheduler_time": 318.42136099947936
}
#Debug simulation 
Total elapsed time: 107.33437449904159. Arrivals time: 0.559784016571939 Scheduler time: 106.54394920030609 Scheduler overhead time: 0.09129353752359748 Adapter cache time: 0.02050895383581519 Engine time: 0.0848897541873157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 108.4344858629629,
    "estimated_duration": 3600.1027538600515,
    "input_throughput": 7295.266495335417,
    "output_throughput": 6462.3477691171465,
    "total_throughput": 13757.614264452563,
    "itl": 98.24044581321643,
    "ttft": 1925324.1782162022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.09173911555436,
    "arrivals": 785377,
    "finished_requests": 106435,
    "scheduler_time": 315.8442652714797
}
#Debug simulation 
Total elapsed time: 108.434658089187. Arrivals time: 0.9130166517570615 Scheduler time: 107.28794869082049 Scheduler overhead time: 0.09175240248441696 Adapter cache time: 0.021184890531003475 Engine time: 0.08612196147441864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 107.49107069801539,
    "estimated_duration": 3600.035930730183,
    "input_throughput": 7248.656819574341,
    "output_throughput": 6419.071210578974,
    "total_throughput": 13667.728030153316,
    "itl": 95.5222666039319,
    "ttft": 1939508.5545743376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.202355497498066,
    "arrivals": 785377,
    "finished_requests": 105714,
    "scheduler_time": 318.42154789364787
}
#Debug simulation 
Total elapsed time: 107.49125793995336. Arrivals time: 0.5792142571881413 Scheduler time: 106.68161803018302 Scheduler overhead time: 0.09067425550892949 Adapter cache time: 0.02125327056273818 Engine time: 0.08439855743199587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.56231326889247,
    "estimated_duration": 3600.0330761641167,
    "input_throughput": 7295.4076933049555,
    "output_throughput": 6462.472846163206,
    "total_throughput": 13757.88053946816,
    "itl": 98.2378905666155,
    "ttft": 1925308.7712984444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9973535969946192,
    "arrivals": 785377,
    "finished_requests": 106435,
    "scheduler_time": 315.84825575638547
}
#Debug simulation 
Total elapsed time: 108.56248780665919. Arrivals time: 0.5883151502348483 Scheduler time: 107.74015145888552 Scheduler overhead time: 0.09207755140960217 Adapter cache time: 0.02132430812343955 Engine time: 0.08608748763799667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 1080, 66, 17280, 17280, 66, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 66, 66, 1080, 66, 17280, 66, 17280, 1080, 17280, 1080, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 17280, 17280, 66, 1080, 1080, 1080, 17280, 1080, 66, 1080, 66, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 66, 17280, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 17280, 66, 1080, 17280, 66, 17280, 1080, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 17280, 17280, 1080, 66, 66, 17280, 1080, 1080, 66, 66, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 66, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 66, 66, 1080, 1080, 17280, 66, 66, 17280, 66, 17280, 1080, 66, 17280, 1080, 1080, 66, 17280, 17280, 17280, 66, 1080, 17280, 66, 17280, 1080, 1080, 17280, 17280, 66, 1080, 17280, 66, 1080, 1080, 66, 1080, 66, 1080, 17280, 17280, 1080, 66, 17280, 66, 17280, 1080, 1080, 1080, 1080, 1080, 66, 66, 17280, 66, 17280, 66, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 17280, 17280, 66, 66, 17280, 66, 66, 66, 1080, 66, 1080, 17280, 17280, 1080, 1080, 66, 17280, 1080, 17280, 66, 1080, 1080, 66, 66, 1080, 66, 17280, 17280, 66, 17280, 17280, 66, 1080, 17280, 66, 66, 1080, 1080, 66, 66, 17280, 17280, 17280, 17280, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 17280, 1080, 1080, 1080, 17280, 66, 1080, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 1080, 66, 17280, 17280, 17280, 1080, 66, 17280, 17280, 1080, 1080, 17280, 17280, 66, 17280, 17280, 1080, 66, 17280, 1080, 1080, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 1080, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 17280, 66, 66, 66, 1080, 66, 1080, 1080, 66, 17280, 1080, 17280, 66, 17280, 66, 1080, 1080, 1080, 1080, 66, 1080, 17280, 17280, 66, 17280, 17280, 66, 17280, 1080, 17280, 1080, 1080, 1080, 66, 1080, 66, 66, 17280, 66, 1080, 66, 66, 1080, 17280, 1080, 17280, 66, 17280, 17280, 1080, 17280, 1080, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2358528 . Total input tokens: 525253595 . Total output tokens: 471618938
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 107.35646160505712,
    "estimated_duration": 3600.064756664647,
    "input_throughput": 7248.59877914436,
    "output_throughput": 6419.01981269073,
    "total_throughput": 13667.61859183509,
    "itl": 95.5227771708242,
    "ttft": 1939519.2505881023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2309016070142413,
    "arrivals": 785377,
    "finished_requests": 105714,
    "scheduler_time": 318.42192775720287
}
#Debug simulation 
Total elapsed time: 107.35664821881801. Arrivals time: 0.5713081327266991 Scheduler time: 106.54991240752861 Scheduler overhead time: 0.09198496537283063 Adapter cache time: 0.020879508927464485 Engine time: 0.08850796101614833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 107.46254327194765,
    "estimated_duration": 3600.0573184557106,
    "input_throughput": 7294.052198942246,
    "output_throughput": 6457.220522803181,
    "total_throughput": 13751.272721745427,
    "itl": 96.37658721156347,
    "ttft": 1927031.762145078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.925046790933733,
    "arrivals": 784050,
    "finished_requests": 106907,
    "scheduler_time": 316.1428295137363
}
#Debug simulation 
Total elapsed time: 107.46272446308285. Arrivals time: 0.5822656899690628 Scheduler time: 106.64771147444844 Scheduler overhead time: 0.09150906093418598 Adapter cache time: 0.02075164206326008 Engine time: 0.08596013812348247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 107.77264395728707,
    "estimated_duration": 3600.0201532312626,
    "input_throughput": 7318.9923607373175,
    "output_throughput": 6484.9598075292415,
    "total_throughput": 13803.95216826656,
    "itl": 96.3420567235511,
    "ttft": 1931965.6933804343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.041208658695693,
    "arrivals": 784050,
    "finished_requests": 107303,
    "scheduler_time": 314.4821663067917
}
#Debug simulation 
Total elapsed time: 107.77283465722576. Arrivals time: 0.5754171432927251 Scheduler time: 106.96551143703982 Scheduler overhead time: 0.09189215209335089 Adapter cache time: 0.020630990155041218 Engine time: 0.08549614390358329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 108.3121355320327,
    "estimated_duration": 3600.023438528879,
    "input_throughput": 7318.985681595204,
    "output_throughput": 6484.953889505829,
    "total_throughput": 13803.939571101033,
    "itl": 96.3421049694144,
    "ttft": 1931966.61567477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.044517723172914,
    "arrivals": 784050,
    "finished_requests": 107303,
    "scheduler_time": 314.48214253990335
}
#Debug simulation 
Total elapsed time: 108.31231292011216. Arrivals time: 0.5798443425446749 Scheduler time: 107.5014455835335 Scheduler overhead time: 0.09090888779610395 Adapter cache time: 0.02032920764759183 Engine time: 0.08550104778259993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 107.41219050204381,
    "estimated_duration": 3600.1030741163354,
    "input_throughput": 7293.959494880689,
    "output_throughput": 6457.138454488819,
    "total_throughput": 13751.097949369507,
    "itl": 96.37750918952005,
    "ttft": 1927048.7623829397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9706326055503325,
    "arrivals": 784050,
    "finished_requests": 106907,
    "scheduler_time": 316.1432994754049
}
#Debug simulation 
Total elapsed time: 107.41237126290798. Arrivals time: 0.5652214800938964 Scheduler time: 106.61336604412645 Scheduler overhead time: 0.09306145505979657 Adapter cache time: 0.02024653274565935 Engine time: 0.08596062706783414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 107.92925219517201,
    "estimated_duration": 3600.0496709239114,
    "input_throughput": 7318.932350518918,
    "output_throughput": 6484.906635748867,
    "total_throughput": 13803.838986267785,
    "itl": 96.34254908622965,
    "ttft": 1931976.0512875763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.070297249387953,
    "arrivals": 784050,
    "finished_requests": 107303,
    "scheduler_time": 314.48249537016596
}
#Debug simulation 
Total elapsed time: 107.92943951906636. Arrivals time: 0.5723175606690347 Scheduler time: 107.12538508977741 Scheduler overhead time: 0.09079756448045373 Adapter cache time: 0.020628619007766247 Engine time: 0.08582654781639576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 107.53179177595302,
    "estimated_duration": 3600.0122713000724,
    "input_throughput": 7294.143469826864,
    "output_throughput": 6457.30132236606,
    "total_throughput": 13751.444792192924,
    "itl": 96.37594757029987,
    "ttft": 1927015.7340864232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 629,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8807416354934385,
    "arrivals": 784050,
    "finished_requests": 106907,
    "scheduler_time": 316.1424876677502
}
#Debug simulation 
Total elapsed time: 107.53199045313522. Arrivals time: 0.5621137162670493 Scheduler time: 106.73496856167912 Scheduler overhead time: 0.09189293766394258 Adapter cache time: 0.020493177697062492 Engine time: 0.08856731792911887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 1080, 33, 17280, 17280, 33, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 33, 33, 1080, 33, 17280, 33, 17280, 1080, 17280, 1080, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 17280, 17280, 33, 1080, 1080, 1080, 17280, 1080, 33, 1080, 33, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 33, 17280, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 17280, 33, 1080, 17280, 33, 17280, 1080, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 17280, 17280, 1080, 33, 33, 17280, 1080, 1080, 33, 33, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 17280, 17280, 33, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 33, 33, 1080, 1080, 17280, 33, 33, 17280, 33, 17280, 1080, 33, 17280, 1080, 1080, 33, 17280, 17280, 17280, 33, 1080, 17280, 33, 17280, 1080, 1080, 17280, 17280, 33, 1080, 17280, 33, 1080, 1080, 33, 1080, 33, 1080, 17280, 17280, 1080, 33, 17280, 33, 17280, 1080, 1080, 1080, 1080, 1080, 33, 33, 17280, 33, 17280, 33, 1080, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 17280, 17280, 33, 33, 17280, 33, 33, 33, 1080, 33, 1080, 17280, 17280, 1080, 1080, 33, 17280, 1080, 17280, 33, 1080, 1080, 33, 33, 1080, 33, 17280, 17280, 33, 17280, 17280, 33, 1080, 17280, 33, 33, 1080, 1080, 33, 33, 17280, 17280, 17280, 17280, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 17280, 1080, 1080, 1080, 17280, 33, 1080, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 1080, 33, 17280, 17280, 17280, 1080, 33, 17280, 17280, 1080, 1080, 17280, 17280, 33, 17280, 17280, 1080, 33, 17280, 1080, 1080, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 1080, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 17280, 33, 33, 33, 1080, 33, 1080, 1080, 33, 17280, 1080, 17280, 33, 17280, 33, 1080, 1080, 1080, 1080, 33, 1080, 17280, 17280, 33, 17280, 17280, 33, 17280, 1080, 17280, 1080, 1080, 1080, 33, 1080, 33, 33, 17280, 33, 1080, 33, 33, 1080, 17280, 1080, 17280, 33, 17280, 17280, 1080, 17280, 1080, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2354304 . Total input tokens: 524297978 . Total output tokens: 470757468
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 108.21190462587401,
    "estimated_duration": 3600.076945318079,
    "input_throughput": 7318.8769018580015,
    "output_throughput": 6484.857505715701,
    "total_throughput": 13803.734407573702,
    "itl": 96.34306506795852,
    "ttft": 1931985.8925974243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.097585821039973,
    "arrivals": 784050,
    "finished_requests": 107303,
    "scheduler_time": 314.48268126986767
}
#Debug simulation 
Total elapsed time: 108.21210208721459. Arrivals time: 0.5721333627589047 Scheduler time: 107.40706782601774 Scheduler overhead time: 0.09166590124368668 Adapter cache time: 0.02055318560451269 Engine time: 0.08651849487796426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.14387433463708,
    "estimated_duration": 3600.0111507064275,
    "input_throughput": 7213.814044688157,
    "output_throughput": 6366.5458356990075,
    "total_throughput": 13580.359880387165,
    "itl": 98.91220200178523,
    "ttft": 1946769.548849603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8301716708718143,
    "arrivals": 771112,
    "finished_requests": 104920,
    "scheduler_time": 324.3614801213755
}
#Debug simulation 
Total elapsed time: 109.14406626205891. Arrivals time: 0.5671135140582919 Scheduler time: 108.33745938027278 Scheduler overhead time: 0.09487641742452979 Adapter cache time: 0.020493128336966038 Engine time: 0.08838234841823578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.89336221199483,
    "estimated_duration": 3600.000462534054,
    "input_throughput": 7290.570174406395,
    "output_throughput": 6443.435283247711,
    "total_throughput": 13734.005457654106,
    "itl": 98.8258736061056,
    "ttft": 1947528.8385715985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9710628867708195,
    "arrivals": 771112,
    "finished_requests": 106149,
    "scheduler_time": 319.700971950278
}
#Debug simulation 
Total elapsed time: 109.89354151580483. Arrivals time: 0.55855554016307 Scheduler time: 109.09745174320415 Scheduler overhead time: 0.09352947073057294 Adapter cache time: 0.02132780896499753 Engine time: 0.08794418489560485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.40757665969431,
    "estimated_duration": 3600.003939501625,
    "input_throughput": 7290.563133004081,
    "output_throughput": 6443.4290600279855,
    "total_throughput": 13733.992193032065,
    "itl": 98.82591438333135,
    "ttft": 1947530.1832507863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.974533372446907,
    "arrivals": 771112,
    "finished_requests": 106149,
    "scheduler_time": 319.70097843215666
}
#Debug simulation 
Total elapsed time: 109.40776779688895. Arrivals time: 0.5611386084929109 Scheduler time: 108.61110180569813 Scheduler overhead time: 0.092722128611058 Adapter cache time: 0.02071196213364601 Engine time: 0.08743578474968672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 110.34457369800657,
    "estimated_duration": 3600.0062683816946,
    "input_throughput": 7137.66396066608,
    "output_throughput": 6298.548199526601,
    "total_throughput": 13436.212160192681,
    "itl": 97.8312777351216,
    "ttft": 1962113.4700273809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7131906218151483,
    "arrivals": 771112,
    "finished_requests": 103801,
    "scheduler_time": 328.36492090842603
}
#Debug simulation 
Total elapsed time: 110.34476229082793. Arrivals time: 0.5508277108892798 Scheduler time: 109.55506946053356 Scheduler overhead time: 0.09461959032341838 Adapter cache time: 0.020775909535586834 Engine time: 0.08830332476645708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 109.52256046095863,
    "estimated_duration": 3600.0284535491032,
    "input_throughput": 7290.513488615685,
    "output_throughput": 6443.385184117576,
    "total_throughput": 13733.89867273326,
    "itl": 98.82630158609405,
    "ttft": 1947539.8545565016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9989296070113822,
    "arrivals": 771112,
    "finished_requests": 106149,
    "scheduler_time": 319.701196283662
}
#Debug simulation 
Total elapsed time: 109.52274002786726. Arrivals time: 0.5686279735527933 Scheduler time: 108.71743749594316 Scheduler overhead time: 0.09314414486289024 Adapter cache time: 0.02111094119027257 Engine time: 0.087798445019871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.35400916822255,
    "estimated_duration": 3600.002572281254,
    "input_throughput": 7213.831234443652,
    "output_throughput": 6366.56100650402,
    "total_throughput": 13580.392240947673,
    "itl": 98.91154632576398,
    "ttft": 1946752.5962630336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7880500763514744,
    "arrivals": 771112,
    "finished_requests": 104920,
    "scheduler_time": 324.3667210552054
}
#Debug simulation 
Total elapsed time: 109.35418680030853. Arrivals time: 0.5568299242295325 Scheduler time: 108.559361432679 Scheduler overhead time: 0.09380893548950553 Adapter cache time: 0.020770173519849777 Engine time: 0.0886380672454834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 540, 270, 17280, 17280, 270, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 270, 17280, 270, 17280, 540, 540, 540, 270, 270, 540, 270, 17280, 270, 17280, 540, 17280, 540, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 17280, 17280, 270, 540, 540, 540, 17280, 540, 270, 540, 270, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 270, 17280, 540, 540, 270, 270, 270, 540, 270, 540, 270, 17280, 270, 540, 17280, 270, 17280, 540, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 17280, 17280, 540, 270, 270, 17280, 540, 540, 270, 270, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 270, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 270, 270, 540, 540, 17280, 270, 270, 17280, 270, 17280, 540, 270, 17280, 540, 540, 270, 17280, 17280, 17280, 270, 540, 17280, 270, 17280, 540, 540, 17280, 17280, 270, 540, 17280, 270, 540, 540, 270, 540, 270, 540, 17280, 17280, 540, 270, 17280, 270, 17280, 540, 540, 540, 540, 540, 270, 270, 17280, 270, 17280, 270, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 270, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 270, 270, 270, 270, 270, 540, 270, 270, 540, 17280, 17280, 270, 270, 17280, 270, 270, 270, 540, 270, 540, 17280, 17280, 540, 540, 270, 17280, 540, 17280, 270, 540, 540, 270, 270, 540, 270, 17280, 17280, 270, 17280, 17280, 270, 540, 17280, 270, 270, 540, 540, 270, 270, 17280, 17280, 17280, 17280, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 17280, 540, 540, 540, 17280, 270, 540, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 540, 270, 17280, 17280, 17280, 540, 270, 17280, 17280, 540, 540, 17280, 17280, 270, 17280, 17280, 540, 270, 17280, 540, 540, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 540, 17280, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 17280, 270, 270, 270, 540, 270, 540, 540, 270, 17280, 540, 17280, 270, 17280, 270, 540, 540, 540, 540, 270, 540, 17280, 17280, 270, 17280, 17280, 270, 17280, 540, 17280, 540, 540, 540, 270, 540, 270, 270, 17280, 270, 540, 270, 270, 540, 17280, 540, 17280, 270, 17280, 17280, 540, 17280, 540, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2315520 . Total input tokens: 515609097 . Total output tokens: 462994603
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.20982268406078,
    "estimated_duration": 3600.01933248461,
    "input_throughput": 7290.393349606325,
    "output_throughput": 6443.341509499842,
    "total_throughput": 13733.734859106165,
    "itl": 98.82792185373992,
    "ttft": 1947558.7482687808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0253379021584945,
    "arrivals": 771112,
    "finished_requests": 106147,
    "scheduler_time": 319.69576985389745
}
#Debug simulation 
Total elapsed time: 109.21000401629135. Arrivals time: 0.5588918230496347 Scheduler time: 108.41550049278885 Scheduler overhead time: 0.09295530570670962 Adapter cache time: 0.020667494274675846 Engine time: 0.08755630487576127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.20512428600341,
    "estimated_duration": 3600.121737779991,
    "input_throughput": 7262.535243078445,
    "output_throughput": 6452.1140372113505,
    "total_throughput": 13714.649280289796,
    "itl": 102.32189285348728,
    "ttft": 1926036.1783149175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1117365433136372,
    "arrivals": 765327,
    "finished_requests": 105709,
    "scheduler_time": 316.4780095510455
}
#Debug simulation 
Total elapsed time: 108.20530427386984. Arrivals time: 0.563440321944654 Scheduler time: 107.40597278485075 Scheduler overhead time: 0.09305538237094879 Adapter cache time: 0.020807947032153606 Engine time: 0.08743596589192748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.18513015005738,
    "estimated_duration": 3600.016940591941,
    "input_throughput": 7158.176871179607,
    "output_throughput": 6394.375743191616,
    "total_throughput": 13552.552614371223,
    "itl": 99.12402630387123,
    "ttft": 1961052.940902251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.875362331212969,
    "arrivals": 765327,
    "finished_requests": 104176,
    "scheduler_time": 322.78877123266557
}
#Debug simulation 
Total elapsed time: 110.18530615791678. Arrivals time: 0.5502316756173968 Scheduler time: 109.39927752548829 Scheduler overhead time: 0.09357413835823536 Adapter cache time: 0.020171193405985832 Engine time: 0.08694231882691383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.71961464686319,
    "estimated_duration": 3600.0204359753857,
    "input_throughput": 7158.169921059913,
    "output_throughput": 6394.369534672662,
    "total_throughput": 13552.539455732574,
    "itl": 99.12406717690806,
    "ttft": 1961054.208304467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8788518809527275,
    "arrivals": 765327,
    "finished_requests": 104176,
    "scheduler_time": 322.7887770663563
}
#Debug simulation 
Total elapsed time: 110.7197901760228. Arrivals time: 0.6181379812769592 Scheduler time: 109.86627622134984 Scheduler overhead time: 0.09253938589245081 Adapter cache time: 0.02080542128533125 Engine time: 0.08744225697591901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 107.55087477574125,
    "estimated_duration": 3600.036835526969,
    "input_throughput": 7262.414579203308,
    "output_throughput": 6452.0662040948155,
    "total_throughput": 13714.480783298122,
    "itl": 102.32213725987728,
    "ttft": 1925997.3095131617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1567030314053244,
    "arrivals": 765327,
    "finished_requests": 105707,
    "scheduler_time": 316.46927884781536
}
#Debug simulation 
Total elapsed time: 107.55105196079239. Arrivals time: 0.5524894557893276 Scheduler time: 106.7629514890723 Scheduler overhead time: 0.092650200240314 Adapter cache time: 0.021057344507426023 Engine time: 0.08725049998611212 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 109.77717720717192,
    "estimated_duration": 3600.0091543710605,
    "input_throughput": 7158.192353125299,
    "output_throughput": 6394.38957316254,
    "total_throughput": 13552.58192628784,
    "itl": 99.12442722769457,
    "ttft": 1961063.6861418625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9026193465851289,
    "arrivals": 765327,
    "finished_requests": 104176,
    "scheduler_time": 322.78333073336603
}
#Debug simulation 
Total elapsed time: 109.7773542967625. Arrivals time: 0.5554546155035496 Scheduler time: 108.9870012709871 Scheduler overhead time: 0.09281136002391577 Adapter cache time: 0.02040960267186165 Engine time: 0.08707359014078975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 107.38459626724944,
    "estimated_duration": 3600.0728671583793,
    "input_throughput": 7262.63383125288,
    "output_throughput": 6452.201624000658,
    "total_throughput": 13714.835455253538,
    "itl": 102.32112991191092,
    "ttft": 1926018.9101537867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.063134703482465,
    "arrivals": 765327,
    "finished_requests": 105709,
    "scheduler_time": 316.477740769143
}
#Debug simulation 
Total elapsed time: 107.38477771729231. Arrivals time: 0.5550399478524923 Scheduler time: 106.59347184747458 Scheduler overhead time: 0.09352912055328488 Adapter cache time: 0.021132581867277622 Engine time: 0.08705548569560051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 540, 135, 17280, 17280, 135, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 135, 17280, 135, 17280, 540, 540, 540, 135, 135, 540, 135, 17280, 135, 17280, 540, 17280, 540, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 17280, 17280, 135, 540, 540, 540, 17280, 540, 135, 540, 135, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 135, 17280, 540, 540, 135, 135, 135, 540, 135, 540, 135, 17280, 135, 540, 17280, 135, 17280, 540, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 17280, 17280, 540, 135, 135, 17280, 540, 540, 135, 135, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 135, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 135, 135, 540, 540, 17280, 135, 135, 17280, 135, 17280, 540, 135, 17280, 540, 540, 135, 17280, 17280, 17280, 135, 540, 17280, 135, 17280, 540, 540, 17280, 17280, 135, 540, 17280, 135, 540, 540, 135, 540, 135, 540, 17280, 17280, 540, 135, 17280, 135, 17280, 540, 540, 540, 540, 540, 135, 135, 17280, 135, 17280, 135, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 135, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 135, 135, 135, 135, 135, 540, 135, 135, 540, 17280, 17280, 135, 135, 17280, 135, 135, 135, 540, 135, 540, 17280, 17280, 540, 540, 135, 17280, 540, 17280, 135, 540, 540, 135, 135, 540, 135, 17280, 17280, 135, 17280, 17280, 135, 540, 17280, 135, 135, 540, 540, 135, 135, 17280, 17280, 17280, 17280, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 17280, 540, 540, 540, 17280, 135, 540, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 540, 135, 17280, 17280, 17280, 540, 135, 17280, 17280, 540, 540, 17280, 17280, 135, 17280, 17280, 540, 135, 17280, 540, 540, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 540, 17280, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 17280, 135, 135, 135, 540, 135, 540, 540, 135, 17280, 540, 17280, 135, 17280, 135, 540, 540, 540, 540, 135, 540, 17280, 17280, 135, 17280, 17280, 135, 17280, 540, 17280, 540, 540, 540, 135, 540, 135, 135, 17280, 135, 540, 135, 135, 540, 17280, 540, 17280, 135, 17280, 17280, 540, 17280, 540, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2298240 . Total input tokens: 511762382 . Total output tokens: 459532329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.4743414488621,
    "estimated_duration": 3600.0337782714787,
    "input_throughput": 7158.1433917470085,
    "output_throughput": 6394.345836125116,
    "total_throughput": 13552.489227872125,
    "itl": 99.12485914919743,
    "ttft": 1961073.706483324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9268898273631891,
    "arrivals": 765327,
    "finished_requests": 104176,
    "scheduler_time": 322.7835841144405
}
#Debug simulation 
Total elapsed time: 110.4745182171464. Arrivals time: 0.5409254282712936 Scheduler time: 109.69764548260719 Scheduler overhead time: 0.09310404350981116 Adapter cache time: 0.020465352572500706 Engine time: 0.08701433148235083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.54399064276367,
    "estimated_duration": 3600.0281775631624,
    "input_throughput": 7153.939005397727,
    "output_throughput": 6375.191211846377,
    "total_throughput": 13529.130217244103,
    "itl": 98.36221278961985,
    "ttft": 1914520.0904804063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 610,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8668975237990086,
    "arrivals": 762451,
    "finished_requests": 104330,
    "scheduler_time": 323.79398517425125
}
#Debug simulation 
Total elapsed time: 108.54418515600264. Arrivals time: 0.5582670029252768 Scheduler time: 107.75037620123476 Scheduler overhead time: 0.09294554078951478 Adapter cache time: 0.02066429704427719 Engine time: 0.08691890211775899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 111.1811035820283,
    "estimated_duration": 3600.1030954033963,
    "input_throughput": 7369.196741580339,
    "output_throughput": 6528.586092439776,
    "total_throughput": 13897.782834020114,
    "itl": 101.50496605314558,
    "ttft": 1917874.67482738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.101696972164796,
    "arrivals": 762451,
    "finished_requests": 107470,
    "scheduler_time": 311.84794696727397
}
#Debug simulation 
Total elapsed time: 111.18128676805645. Arrivals time: 0.5765636968426406 Scheduler time: 110.37085191486403 Scheduler overhead time: 0.09196198219433427 Adapter cache time: 0.021016499493271112 Engine time: 0.08673569513484836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.67864118190482,
    "estimated_duration": 3600.10679487683,
    "input_throughput": 7369.189168986211,
    "output_throughput": 6528.579383658013,
    "total_throughput": 13897.768552644224,
    "itl": 101.5050170562323,
    "ttft": 1917875.8877666947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.105379808750012,
    "arrivals": 762451,
    "finished_requests": 107470,
    "scheduler_time": 311.8479636040959
}
#Debug simulation 
Total elapsed time: 110.67883293004707. Arrivals time: 0.5597396558150649 Scheduler time: 109.88403018610552 Scheduler overhead time: 0.09209474455565214 Adapter cache time: 0.021039816550910473 Engine time: 0.08746526390314102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 111.73325270134956,
    "estimated_duration": 3600.0170335014,
    "input_throughput": 7183.956008909796,
    "output_throughput": 6399.64305324197,
    "total_throughput": 13583.599062151767,
    "itl": 99.41038065279203,
    "ttft": 1918613.481187776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8492473832936849,
    "arrivals": 762451,
    "finished_requests": 104741,
    "scheduler_time": 322.3961027756956
}
#Debug simulation 
Total elapsed time: 111.73343905014917. Arrivals time: 0.5637243492528796 Scheduler time: 110.93208412919194 Scheduler overhead time: 0.09343477478250861 Adapter cache time: 0.02077327109873295 Engine time: 0.08824882982298732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 110.9823362189345,
    "estimated_duration": 3600.0014032828835,
    "input_throughput": 7368.919905366896,
    "output_throughput": 6528.305510816838,
    "total_throughput": 13897.225416183735,
    "itl": 101.50393415652822,
    "ttft": 1917845.5262948815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.131913857683543,
    "arrivals": 762451,
    "finished_requests": 107464,
    "scheduler_time": 311.83887665507757
}
#Debug simulation 
Total elapsed time: 110.98253298923373. Arrivals time: 0.8886316982097924 Scheduler time: 109.85986220557243 Scheduler overhead time: 0.09173397580161691 Adapter cache time: 0.0207086936570704 Engine time: 0.08727265195921063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.42344710882753,
    "estimated_duration": 3600.1060661191646,
    "input_throughput": 7376.159622048486,
    "output_throughput": 6532.385037575049,
    "total_throughput": 13908.544659623536,
    "itl": 101.32165873769428,
    "ttft": 1919904.977551184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.946522741981284,
    "arrivals": 762451,
    "finished_requests": 107493,
    "scheduler_time": 311.69866957259654
}
#Debug simulation 
Total elapsed time: 109.42361890198663. Arrivals time: 0.5639541274867952 Scheduler time: 108.6257574846968 Scheduler overhead time: 0.09150219848379493 Adapter cache time: 0.02101153414696455 Engine time: 0.0870100581087172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 540, 66, 17280, 17280, 66, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 66, 17280, 66, 17280, 540, 540, 540, 66, 66, 540, 66, 17280, 66, 17280, 540, 17280, 540, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 17280, 17280, 66, 540, 540, 540, 17280, 540, 66, 540, 66, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 66, 17280, 540, 540, 66, 66, 66, 540, 66, 540, 66, 17280, 66, 540, 17280, 66, 17280, 540, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 17280, 17280, 540, 66, 66, 17280, 540, 540, 66, 66, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 66, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 66, 66, 540, 540, 17280, 66, 66, 17280, 66, 17280, 540, 66, 17280, 540, 540, 66, 17280, 17280, 17280, 66, 540, 17280, 66, 17280, 540, 540, 17280, 17280, 66, 540, 17280, 66, 540, 540, 66, 540, 66, 540, 17280, 17280, 540, 66, 17280, 66, 17280, 540, 540, 540, 540, 540, 66, 66, 17280, 66, 17280, 66, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 66, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 66, 66, 66, 66, 66, 540, 66, 66, 540, 17280, 17280, 66, 66, 17280, 66, 66, 66, 540, 66, 540, 17280, 17280, 540, 540, 66, 17280, 540, 17280, 66, 540, 540, 66, 66, 540, 66, 17280, 17280, 66, 17280, 17280, 66, 540, 17280, 66, 66, 540, 540, 66, 66, 17280, 17280, 17280, 17280, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 17280, 540, 540, 540, 17280, 66, 540, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 540, 66, 17280, 17280, 17280, 540, 66, 17280, 17280, 540, 540, 17280, 17280, 66, 17280, 17280, 540, 66, 17280, 540, 540, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 540, 17280, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 17280, 66, 66, 66, 540, 66, 540, 540, 66, 17280, 540, 17280, 66, 17280, 66, 540, 540, 540, 540, 66, 540, 17280, 17280, 66, 17280, 17280, 66, 17280, 540, 17280, 540, 540, 540, 66, 540, 66, 66, 17280, 66, 540, 66, 66, 540, 17280, 540, 17280, 66, 17280, 17280, 540, 17280, 540, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2289408 . Total input tokens: 509793012 . Total output tokens: 457761006
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.82524254499003,
    "estimated_duration": 3600.029447107866,
    "input_throughput": 7368.862502308623,
    "output_throughput": 6528.254656050269,
    "total_throughput": 13897.117158358893,
    "itl": 101.50442104175451,
    "ttft": 1917855.6578772438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 644,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1595796906948097,
    "arrivals": 762451,
    "finished_requests": 107464,
    "scheduler_time": 311.839054569915
}
#Debug simulation 
Total elapsed time: 110.82541604805738. Arrivals time: 0.5613126279786229 Scheduler time: 110.0303821163252 Scheduler overhead time: 0.09185760235413909 Adapter cache time: 0.020984912756830454 Engine time: 0.08643943164497614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.13875292707235,
    "estimated_duration": 3600.021057655615,
    "input_throughput": 7221.487758999373,
    "output_throughput": 6432.1957091771965,
    "total_throughput": 13653.683468176569,
    "itl": 97.98150296775576,
    "ttft": 1936654.7602676996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7781433792249557,
    "arrivals": 761080,
    "finished_requests": 105427,
    "scheduler_time": 319.90200368470545
}
#Debug simulation 
Total elapsed time: 109.13891962217167. Arrivals time: 0.5634331642650068 Scheduler time: 108.33980009006336 Scheduler overhead time: 0.09345577470958233 Adapter cache time: 0.020231300964951515 Engine time: 0.08694601664319634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.24699071608484,
    "estimated_duration": 3600.0082995409853,
    "input_throughput": 7221.37807385464,
    "output_throughput": 6432.174615528654,
    "total_throughput": 13653.552689383294,
    "itl": 97.98380874348248,
    "ttft": 1936701.660534001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8953456095745842,
    "arrivals": 761080,
    "finished_requests": 105426,
    "scheduler_time": 319.88957130593354
}
#Debug simulation 
Total elapsed time: 109.24716049525887. Arrivals time: 0.5548437424004078 Scheduler time: 108.45731342537329 Scheduler overhead time: 0.09297437220811844 Adapter cache time: 0.020244083367288113 Engine time: 0.08679212396964431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.80377519223839,
    "estimated_duration": 3600.011770447963,
    "input_throughput": 7221.371111451976,
    "output_throughput": 6432.168414026776,
    "total_throughput": 13653.53952547875,
    "itl": 97.98384073655079,
    "ttft": 1936702.7150765164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8987992315180717,
    "arrivals": 761080,
    "finished_requests": 105426,
    "scheduler_time": 319.88958859094333
}
#Debug simulation 
Total elapsed time: 109.80395039124414. Arrivals time: 0.5515305711887777 Scheduler time: 109.01761915022507 Scheduler overhead time: 0.0924383383244276 Adapter cache time: 0.020430983509868383 Engine time: 0.08723155874758959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 109.31886990694329,
    "estimated_duration": 3600.062383354348,
    "input_throughput": 7221.404862372661,
    "output_throughput": 6432.121872961663,
    "total_throughput": 13653.526735334324,
    "itl": 97.98200649813765,
    "ttft": 1936670.7895908523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8189382850262228,
    "arrivals": 761080,
    "finished_requests": 105427,
    "scheduler_time": 319.90273455472294
}
#Debug simulation 
Total elapsed time: 109.31904065562412. Arrivals time: 0.54586431523785 Scheduler time: 108.53735221084207 Scheduler overhead time: 0.09265974210575223 Adapter cache time: 0.020584159065037966 Engine time: 0.08772012870758772 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 109.34757428383455,
    "estimated_duration": 3600.0353870911817,
    "input_throughput": 7221.323738432893,
    "output_throughput": 6432.126218267506,
    "total_throughput": 13653.449956700399,
    "itl": 97.9842333726624,
    "ttft": 1936710.9232040015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9223151895776425,
    "arrivals": 761080,
    "finished_requests": 105426,
    "scheduler_time": 319.88968927612547
}
#Debug simulation 
Total elapsed time: 109.347763849888. Arrivals time: 0.5647518034093082 Scheduler time: 108.5467270752415 Scheduler overhead time: 0.09311325056478381 Adapter cache time: 0.020700165070593357 Engine time: 0.08721648342907429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.03078086208552,
    "estimated_duration": 3600.045037542436,
    "input_throughput": 7221.497433750798,
    "output_throughput": 6432.169530803278,
    "total_throughput": 13653.666964554077,
    "itl": 97.98043663659561,
    "ttft": 1936637.1324724525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7372192213381392,
    "arrivals": 761080,
    "finished_requests": 105428,
    "scheduler_time": 319.908493881214
}
#Debug simulation 
Total elapsed time: 109.0309677310288. Arrivals time: 0.5603935192339122 Scheduler time: 108.23522004205734 Scheduler overhead time: 0.09304302837699652 Adapter cache time: 0.020755695179104805 Engine time: 0.08699998538941145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 540, 33, 17280, 17280, 33, 540, 17280, 17280, 17280, 17280, 540, 540, 540, 540, 17280, 17280, 540, 540, 33, 17280, 33, 17280, 540, 540, 540, 33, 33, 540, 33, 17280, 33, 17280, 540, 17280, 540, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 17280, 17280, 33, 540, 540, 540, 17280, 540, 33, 540, 33, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 33, 17280, 540, 540, 33, 33, 33, 540, 33, 540, 33, 17280, 33, 540, 17280, 33, 17280, 540, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 17280, 17280, 540, 33, 33, 17280, 540, 540, 33, 33, 17280, 540, 17280, 540, 17280, 17280, 540, 17280, 17280, 33, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 33, 33, 540, 540, 17280, 33, 33, 17280, 33, 17280, 540, 33, 17280, 540, 540, 33, 17280, 17280, 17280, 33, 540, 17280, 33, 17280, 540, 540, 17280, 17280, 33, 540, 17280, 33, 540, 540, 33, 540, 33, 540, 17280, 17280, 540, 33, 17280, 33, 17280, 540, 540, 540, 540, 540, 33, 33, 17280, 33, 17280, 33, 540, 17280, 540, 17280, 540, 17280, 540, 17280, 33, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 33, 33, 33, 33, 33, 540, 33, 33, 540, 17280, 17280, 33, 33, 17280, 33, 33, 33, 540, 33, 540, 17280, 17280, 540, 540, 33, 17280, 540, 17280, 33, 540, 540, 33, 33, 540, 33, 17280, 17280, 33, 17280, 17280, 33, 540, 17280, 33, 33, 540, 540, 33, 33, 17280, 17280, 17280, 17280, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 17280, 540, 540, 540, 17280, 33, 540, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 540, 33, 17280, 17280, 17280, 540, 33, 17280, 17280, 540, 540, 17280, 17280, 33, 17280, 17280, 540, 33, 17280, 540, 540, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 540, 17280, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 17280, 33, 33, 33, 540, 33, 540, 540, 33, 17280, 540, 17280, 33, 17280, 33, 540, 540, 540, 540, 33, 540, 17280, 17280, 33, 17280, 17280, 33, 17280, 540, 17280, 540, 540, 540, 33, 540, 33, 33, 17280, 33, 540, 33, 33, 540, 17280, 540, 17280, 33, 17280, 17280, 540, 17280, 540, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2285184 . Total input tokens: 508844357 . Total output tokens: 456900888
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.26803885959089,
    "estimated_duration": 3600.060920652615,
    "input_throughput": 7221.272520934809,
    "output_throughput": 6432.080598181191,
    "total_throughput": 13653.353119116,
    "itl": 97.9846254472975,
    "ttft": 1936720.4750043706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 581,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9474659468606064,
    "arrivals": 761080,
    "finished_requests": 105426,
    "scheduler_time": 319.8899720417166
}
#Debug simulation 
Total elapsed time: 109.26821352774277. Arrivals time: 0.559143427759409 Scheduler time: 108.47267561033368 Scheduler overhead time: 0.09369332063943148 Adapter cache time: 0.020715909078717232 Engine time: 0.08700142661109567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 110.43965293606743,
    "estimated_duration": 3600.0377761738705,
    "input_throughput": 7194.277563255527,
    "output_throughput": 6371.911192659694,
    "total_throughput": 13566.188755915222,
    "itl": 99.81281967203802,
    "ttft": 1960840.456289924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6098165533086484,
    "arrivals": 753814,
    "finished_requests": 105036,
    "scheduler_time": 322.2924788919137
}
#Debug simulation 
Total elapsed time: 110.43983558705077. Arrivals time: 0.5488265454769135 Scheduler time: 109.65898565901443 Scheduler overhead time: 0.09172687260434031 Adapter cache time: 0.019530647434294224 Engine time: 0.08716569421812892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 112.9767444068566,
    "estimated_duration": 3600.0045021284504,
    "input_throughput": 7215.2531988898045,
    "output_throughput": 6415.382810311814,
    "total_throughput": 13630.636009201618,
    "itl": 101.62003778823421,
    "ttft": 1947395.6913615759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7849735147948442,
    "arrivals": 753814,
    "finished_requests": 105342,
    "scheduler_time": 321.5308138389195
}
#Debug simulation 
Total elapsed time: 112.97692386014387. Arrivals time: 0.5575689477846026 Scheduler time: 112.1858564116992 Scheduler overhead time: 0.09210618771612644 Adapter cache time: 0.019704924430698156 Engine time: 0.08704460179433227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.90280081005767,
    "estimated_duration": 3600.007127513397,
    "input_throughput": 7215.247937006574,
    "output_throughput": 6415.378131751783,
    "total_throughput": 13630.626068758358,
    "itl": 101.62006743756655,
    "ttft": 1947396.884889644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7875546068884542,
    "arrivals": 753814,
    "finished_requests": 105342,
    "scheduler_time": 321.53085813175716
}
#Debug simulation 
Total elapsed time: 109.90298285381868. Arrivals time: 0.46179321967065334 Scheduler time: 109.22144203353673 Scheduler overhead time: 0.08706498052924871 Adapter cache time: 0.018268411979079247 Engine time: 0.08135347720235586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 107.3501742510125,
    "estimated_duration": 3600.021255926036,
    "input_throughput": 7338.891945848782,
    "output_throughput": 6495.636647007744,
    "total_throughput": 13834.528592856524,
    "itl": 104.23342116215608,
    "ttft": 1930467.1996571221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0491911038546684,
    "arrivals": 753814,
    "finished_requests": 107267,
    "scheduler_time": 314.0729062612835
}
#Debug simulation 
Total elapsed time: 107.35035671433434. Arrivals time: 0.46668112464249134 Scheduler time: 106.66552730370313 Scheduler overhead time: 0.08668208587914705 Adapter cache time: 0.01900031790137291 Engine time: 0.0799833657220006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 110.01235920982435,
    "estimated_duration": 3600.030465912333,
    "input_throughput": 7215.201161753873,
    "output_throughput": 6415.336541922035,
    "total_throughput": 13630.537703675907,
    "itl": 101.6203911204839,
    "ttft": 1947406.6260935825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8106933035887818,
    "arrivals": 753814,
    "finished_requests": 105342,
    "scheduler_time": 321.5310578340022
}
#Debug simulation 
Total elapsed time: 110.01253561768681. Arrivals time: 0.461463388055563 Scheduler time: 109.33057211572304 Scheduler overhead time: 0.08798609441146255 Adapter cache time: 0.018509841989725828 Engine time: 0.08122186688706279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.59789961902425,
    "estimated_duration": 3600.0643399931823,
    "input_throughput": 7194.224756563392,
    "output_throughput": 6371.962229998212,
    "total_throughput": 13566.186986561604,
    "itl": 99.81227986250298,
    "ttft": 1960819.36563032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5727664551185254,
    "arrivals": 753814,
    "finished_requests": 105037,
    "scheduler_time": 322.29887942419293
}
#Debug simulation 
Total elapsed time: 108.59806709596887. Arrivals time: 0.4580433084629476 Scheduler time: 107.91855142172426 Scheduler overhead time: 0.08906822232529521 Adapter cache time: 0.018082996364682913 Engine time: 0.08120756456628442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 270, 135, 17280, 17280, 135, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 135, 17280, 135, 17280, 270, 270, 270, 135, 135, 270, 135, 17280, 135, 17280, 270, 17280, 270, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 17280, 17280, 135, 270, 270, 270, 17280, 270, 135, 270, 135, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 135, 17280, 270, 270, 135, 135, 135, 270, 135, 270, 135, 17280, 135, 270, 17280, 135, 17280, 270, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 17280, 17280, 270, 135, 135, 17280, 270, 270, 135, 135, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 135, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 135, 135, 270, 270, 17280, 135, 135, 17280, 135, 17280, 270, 135, 17280, 270, 270, 135, 17280, 17280, 17280, 135, 270, 17280, 135, 17280, 270, 270, 17280, 17280, 135, 270, 17280, 135, 270, 270, 135, 270, 135, 270, 17280, 17280, 270, 135, 17280, 135, 17280, 270, 270, 270, 270, 270, 135, 135, 17280, 135, 17280, 135, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 135, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 135, 135, 135, 135, 135, 270, 135, 135, 270, 17280, 17280, 135, 135, 17280, 135, 135, 135, 270, 135, 270, 17280, 17280, 270, 270, 135, 17280, 270, 17280, 135, 270, 270, 135, 135, 270, 135, 17280, 17280, 135, 17280, 17280, 135, 270, 17280, 135, 135, 270, 270, 135, 135, 17280, 17280, 17280, 17280, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 17280, 270, 270, 270, 17280, 135, 270, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 270, 135, 17280, 17280, 17280, 270, 135, 17280, 17280, 270, 270, 17280, 17280, 135, 17280, 17280, 270, 135, 17280, 270, 270, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 270, 17280, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 17280, 135, 135, 135, 270, 135, 270, 270, 135, 17280, 270, 17280, 135, 17280, 135, 270, 270, 270, 270, 135, 270, 17280, 17280, 135, 17280, 17280, 135, 17280, 270, 17280, 270, 270, 270, 135, 270, 135, 135, 17280, 135, 270, 135, 135, 270, 17280, 270, 17280, 135, 17280, 17280, 270, 17280, 270, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2263680 . Total input tokens: 504023803 . Total output tokens: 452587319
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.20696885697544,
    "estimated_duration": 3600.0229746193963,
    "input_throughput": 7215.2161758762495,
    "output_throughput": 6415.349891604985,
    "total_throughput": 13630.566067481233,
    "itl": 101.6208069014515,
    "ttft": 1947416.1977036982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 546,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8344607692211827,
    "arrivals": 753814,
    "finished_requests": 105342,
    "scheduler_time": 321.52570038493064
}
#Debug simulation 
Total elapsed time: 110.20713426126167. Arrivals time: 0.45754718547686934 Scheduler time: 109.52989473938942 Scheduler overhead time: 0.08804367482662201 Adapter cache time: 0.017994406633079052 Engine time: 0.08032167702913284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.78920682799071,
    "estimated_duration": 3600.1267988902578,
    "input_throughput": 7428.421412335708,
    "output_throughput": 6600.707232679994,
    "total_throughput": 14029.128645015702,
    "itl": 102.51785182074885,
    "ttft": 1925285.4703267324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8913814257504715,
    "arrivals": 750842,
    "finished_requests": 108399,
    "scheduler_time": 307.3845921628106
}
#Debug simulation 
Total elapsed time: 109.78937167907134. Arrivals time: 0.46389747643843293 Scheduler time: 109.11088874004781 Scheduler overhead time: 0.08567391987890005 Adapter cache time: 0.018185504246503115 Engine time: 0.07892740797251463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.13811895018443,
    "estimated_duration": 3600.118938080569,
    "input_throughput": 7483.776914982868,
    "output_throughput": 6642.231662698707,
    "total_throughput": 14126.008577681574,
    "itl": 104.29659904047519,
    "ttft": 1924321.0704621293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0681191113498114,
    "arrivals": 750842,
    "finished_requests": 109084,
    "scheduler_time": 304.9741232138116
}
#Debug simulation 
Total elapsed time: 109.1382790892385. Arrivals time: 0.4640620881691575 Scheduler time: 108.45840511936694 Scheduler overhead time: 0.08667348651215434 Adapter cache time: 0.018196312710642815 Engine time: 0.07925265515223145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 108.93344826810062,
    "estimated_duration": 3600.1227283620556,
    "input_throughput": 7483.7690359122835,
    "output_throughput": 6642.224669623859,
    "total_throughput": 14125.993705536142,
    "itl": 104.29664787453507,
    "ttft": 1924322.4701585046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.071909392811367,
    "arrivals": 750842,
    "finished_requests": 109084,
    "scheduler_time": 304.9741232138116
}
#Debug simulation 
Total elapsed time: 108.9336113431491. Arrivals time: 0.48207474080845714 Scheduler time: 108.23527337796986 Scheduler overhead time: 0.08662816230207682 Adapter cache time: 0.018140237778425217 Engine time: 0.07957408763468266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 109.32362068910152,
    "estimated_duration": 3600.062155375057,
    "input_throughput": 7483.894954361729,
    "output_throughput": 6642.336428635562,
    "total_throughput": 14126.23138299729,
    "itl": 104.29574775659748,
    "ttft": 1924310.6016445893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9835398804326407,
    "arrivals": 750842,
    "finished_requests": 109084,
    "scheduler_time": 304.97871947137014
}
#Debug simulation 
Total elapsed time: 109.32376194000244. Arrivals time: 0.48136522015556693 Scheduler time: 108.62711452040821 Scheduler overhead time: 0.08623910322785378 Adapter cache time: 0.01853580866008997 Engine time: 0.07847931561991572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 109.20612090686336,
    "estimated_duration": 3600.0185589984894,
    "input_throughput": 7483.668086282026,
    "output_throughput": 6642.277423884257,
    "total_throughput": 14125.945510166282,
    "itl": 104.29735874999335,
    "ttft": 1924324.0473649055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0979404265992376,
    "arrivals": 750842,
    "finished_requests": 109080,
    "scheduler_time": 304.96506085445594
}
#Debug simulation 
Total elapsed time: 109.20625663874671. Arrivals time: 0.4794646571390331 Scheduler time: 108.51238700468093 Scheduler overhead time: 0.08575459429994226 Adapter cache time: 0.01839890144765377 Engine time: 0.07854817900806665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.90827287407592,
    "estimated_duration": 3600.082993475267,
    "input_throughput": 7428.51180055267,
    "output_throughput": 6600.787549361606,
    "total_throughput": 14029.299349914276,
    "itl": 102.51711605036652,
    "ttft": 1925269.3260924066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 618,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8478510822495158,
    "arrivals": 750842,
    "finished_requests": 108399,
    "scheduler_time": 307.3842170526333
}
#Debug simulation 
Total elapsed time: 109.90841251797974. Arrivals time: 0.47847726196050644 Scheduler time: 109.21637566201389 Scheduler overhead time: 0.08524604793637991 Adapter cache time: 0.018262535333633423 Engine time: 0.0779905547387898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 270, 66, 17280, 17280, 66, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 66, 17280, 66, 17280, 270, 270, 270, 66, 66, 270, 66, 17280, 66, 17280, 270, 17280, 270, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 17280, 17280, 66, 270, 270, 270, 17280, 270, 66, 270, 66, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 66, 17280, 270, 270, 66, 66, 66, 270, 66, 270, 66, 17280, 66, 270, 17280, 66, 17280, 270, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 17280, 17280, 270, 66, 66, 17280, 270, 270, 66, 66, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 66, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 66, 66, 270, 270, 17280, 66, 66, 17280, 66, 17280, 270, 66, 17280, 270, 270, 66, 17280, 17280, 17280, 66, 270, 17280, 66, 17280, 270, 270, 17280, 17280, 66, 270, 17280, 66, 270, 270, 66, 270, 66, 270, 17280, 17280, 270, 66, 17280, 66, 17280, 270, 270, 270, 270, 270, 66, 66, 17280, 66, 17280, 66, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 66, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 66, 66, 66, 66, 66, 270, 66, 66, 270, 17280, 17280, 66, 66, 17280, 66, 66, 66, 270, 66, 270, 17280, 17280, 270, 270, 66, 17280, 270, 17280, 66, 270, 270, 66, 66, 270, 66, 17280, 17280, 66, 17280, 17280, 66, 270, 17280, 66, 66, 270, 270, 66, 66, 17280, 17280, 17280, 17280, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 17280, 270, 270, 270, 17280, 66, 270, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 270, 66, 17280, 17280, 17280, 270, 66, 17280, 17280, 270, 270, 17280, 17280, 66, 17280, 17280, 270, 66, 17280, 270, 270, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 270, 17280, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 17280, 66, 66, 66, 270, 66, 270, 270, 66, 17280, 270, 17280, 66, 17280, 66, 270, 270, 270, 270, 66, 270, 17280, 17280, 66, 17280, 17280, 66, 17280, 270, 17280, 270, 270, 270, 66, 270, 66, 66, 17280, 66, 270, 66, 66, 270, 17280, 270, 17280, 66, 17280, 17280, 270, 17280, 270, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2254848 . Total input tokens: 502040347 . Total output tokens: 450803971
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.23864335985854,
    "estimated_duration": 3600.0457578934506,
    "input_throughput": 7483.611546027848,
    "output_throughput": 6642.227240464905,
    "total_throughput": 14125.838786492752,
    "itl": 104.29784540035668,
    "ttft": 1924334.4071694536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1249774906784293,
    "arrivals": 750842,
    "finished_requests": 109080,
    "scheduler_time": 304.96522268536023
}
#Debug simulation 
Total elapsed time: 109.23878643196076. Arrivals time: 0.4884832501411438 Scheduler time: 108.5353520619683 Scheduler overhead time: 0.08507228037342429 Adapter cache time: 0.018709369003772736 Engine time: 0.07965580327436328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 107.62811557203531,
    "estimated_duration": 3600.0192980080565,
    "input_throughput": 7440.754280073322,
    "output_throughput": 6593.827708961042,
    "total_throughput": 14034.581989034363,
    "itl": 101.48825988586745,
    "ttft": 1940328.5575561079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7965063056885529,
    "arrivals": 749452,
    "finished_requests": 108633,
    "scheduler_time": 308.25462038796013
}
#Debug simulation 
Total elapsed time: 107.62826628424227. Arrivals time: 0.4847314921207726 Scheduler time: 106.93030782416463 Scheduler overhead time: 0.08509234758093953 Adapter cache time: 0.017939784564077854 Engine time: 0.07829293748363853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 107.39722983306274,
    "estimated_duration": 3600.112813293616,
    "input_throughput": 7418.3530864319755,
    "output_throughput": 6570.75936972054,
    "total_throughput": 13989.112456152516,
    "itl": 101.43679954918753,
    "ttft": 1943161.6482531293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8585179323330594,
    "arrivals": 749452,
    "finished_requests": 108231,
    "scheduler_time": 309.6208755992656
}
#Debug simulation 
Total elapsed time: 107.3973727109842. Arrivals time: 0.48516265535727143 Scheduler time: 106.69673566659912 Scheduler overhead time: 0.08654830418527126 Adapter cache time: 0.01837522303685546 Engine time: 0.07878028880804777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 108.14088259683922,
    "estimated_duration": 3600.1152351790906,
    "input_throughput": 7418.3480959246135,
    "output_throughput": 6570.754949410179,
    "total_throughput": 13989.103045334792,
    "itl": 101.4368304352903,
    "ttft": 1943162.631217456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8609197239577886,
    "arrivals": 749452,
    "finished_requests": 108231,
    "scheduler_time": 309.6208956930895
}
#Debug simulation 
Total elapsed time: 108.14104197360575. Arrivals time: 0.49005715688690543 Scheduler time: 107.43429694417864 Scheduler overhead time: 0.08626777166500688 Adapter cache time: 0.018242964055389166 Engine time: 0.07968082372099161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 108.27001698408276,
    "estimated_duration": 3600.0627546183314,
    "input_throughput": 7440.664462205984,
    "output_throughput": 6593.748114403807,
    "total_throughput": 14034.412576609791,
    "itl": 101.48904077576755,
    "ttft": 1940344.039863834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.83973875402472,
    "arrivals": 749452,
    "finished_requests": 108633,
    "scheduler_time": 308.2549445884048
}
#Debug simulation 
Total elapsed time: 108.27017119107768. Arrivals time: 0.49555245600640774 Scheduler time: 107.55427235225216 Scheduler overhead time: 0.08978636702522635 Adapter cache time: 0.018476342782378197 Engine time: 0.07950608991086483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 107.37345628300682,
    "estimated_duration": 3600.01662030091,
    "input_throughput": 7418.239362952658,
    "output_throughput": 6570.694109190756,
    "total_throughput": 13988.933472143413,
    "itl": 101.43647061958993,
    "ttft": 1943151.243285727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8850644509494345,
    "arrivals": 749452,
    "finished_requests": 108227,
    "scheduler_time": 309.6120713481259
}
#Debug simulation 
Total elapsed time: 107.37361737014726. Arrivals time: 0.4749134420417249 Scheduler time: 106.6839229138568 Scheduler overhead time: 0.08589699910953641 Adapter cache time: 0.01825216645374894 Engine time: 0.07869752496480942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.09803122095764,
    "estimated_duration": 3600.103273004237,
    "input_throughput": 7440.718492957652,
    "output_throughput": 6593.840565076495,
    "total_throughput": 14034.559058034149,
    "itl": 101.48744028529492,
    "ttft": 1940392.8710600808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7551595231075516,
    "arrivals": 749452,
    "finished_requests": 108638,
    "scheduler_time": 308.2635059419214
}
#Debug simulation 
Total elapsed time: 108.09817451192066. Arrivals time: 0.7527210968546569 Scheduler time: 107.13134555798024 Scheduler overhead time: 0.0855566281825304 Adapter cache time: 0.018209456466138363 Engine time: 0.07865472370758653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 270, 33, 17280, 17280, 33, 270, 17280, 17280, 17280, 17280, 270, 270, 270, 270, 17280, 17280, 270, 270, 33, 17280, 33, 17280, 270, 270, 270, 33, 33, 270, 33, 17280, 33, 17280, 270, 17280, 270, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 17280, 17280, 33, 270, 270, 270, 17280, 270, 33, 270, 33, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 33, 17280, 270, 270, 33, 33, 33, 270, 33, 270, 33, 17280, 33, 270, 17280, 33, 17280, 270, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 17280, 17280, 270, 33, 33, 17280, 270, 270, 33, 33, 17280, 270, 17280, 270, 17280, 17280, 270, 17280, 17280, 33, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 33, 33, 270, 270, 17280, 33, 33, 17280, 33, 17280, 270, 33, 17280, 270, 270, 33, 17280, 17280, 17280, 33, 270, 17280, 33, 17280, 270, 270, 17280, 17280, 33, 270, 17280, 33, 270, 270, 33, 270, 33, 270, 17280, 17280, 270, 33, 17280, 33, 17280, 270, 270, 270, 270, 270, 33, 33, 17280, 33, 17280, 33, 270, 17280, 270, 17280, 270, 17280, 270, 17280, 33, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 33, 33, 33, 33, 33, 270, 33, 33, 270, 17280, 17280, 33, 33, 17280, 33, 33, 33, 270, 33, 270, 17280, 17280, 270, 270, 33, 17280, 270, 17280, 33, 270, 270, 33, 33, 270, 33, 17280, 17280, 33, 17280, 17280, 33, 270, 17280, 33, 33, 270, 270, 33, 33, 17280, 17280, 17280, 17280, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 17280, 270, 270, 270, 17280, 33, 270, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 270, 33, 17280, 17280, 17280, 270, 33, 17280, 17280, 270, 270, 17280, 17280, 33, 17280, 17280, 270, 33, 17280, 270, 270, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 270, 17280, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 17280, 33, 33, 33, 270, 33, 270, 270, 33, 17280, 270, 17280, 33, 17280, 33, 270, 270, 270, 270, 33, 270, 17280, 17280, 33, 17280, 17280, 33, 17280, 270, 17280, 270, 270, 270, 33, 270, 33, 33, 17280, 33, 270, 33, 33, 270, 17280, 270, 17280, 33, 17280, 17280, 270, 17280, 270, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2250624 . Total input tokens: 501116837 . Total output tokens: 449955359
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 107.71225312771276,
    "estimated_duration": 3600.041896002747,
    "input_throughput": 7418.187279890373,
    "output_throughput": 6570.647976698422,
    "total_throughput": 13988.835256588796,
    "itl": 101.43692408065489,
    "ttft": 1943160.5364555398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9102152082323978,
    "arrivals": 749452,
    "finished_requests": 108227,
    "scheduler_time": 309.6121962927035
}
#Debug simulation 
Total elapsed time: 107.71240611700341. Arrivals time: 0.4820848545059562 Scheduler time: 107.01540873851627 Scheduler overhead time: 0.08580460399389267 Adapter cache time: 0.01817791396752 Engine time: 0.07893087714910507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.53131689270958,
    "estimated_duration": 3600.1031234285865,
    "input_throughput": 7611.843066845857,
    "output_throughput": 6745.757876199831,
    "total_throughput": 14357.600943045687,
    "itl": 105.32437911075348,
    "ttft": 1930084.2317763243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.839353134103613,
    "arrivals": 745115,
    "finished_requests": 110826,
    "scheduler_time": 298.9430222384426
}
#Debug simulation 
Total elapsed time: 109.53146767476574. Arrivals time: 0.4859845140017569 Scheduler time: 108.8330005640164 Scheduler overhead time: 0.08481415500864387 Adapter cache time: 0.018284205812960863 Engine time: 0.07806984148919582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.49644854478538,
    "estimated_duration": 3600.0404124763663,
    "input_throughput": 7429.709374179308,
    "output_throughput": 6578.891425196045,
    "total_throughput": 14008.600799375352,
    "itl": 101.64027021077472,
    "ttft": 1942090.640533235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8769967124867315,
    "arrivals": 745115,
    "finished_requests": 108211,
    "scheduler_time": 308.99261783471775
}
#Debug simulation 
Total elapsed time: 109.49659465719014. Arrivals time: 0.4749950123950839 Scheduler time: 108.80552826216444 Scheduler overhead time: 0.08687987038865685 Adapter cache time: 0.0180314676836133 Engine time: 0.07903791405260563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.26551127294078,
    "estimated_duration": 3600.0435967570684,
    "input_throughput": 7429.702802514397,
    "output_throughput": 6578.88560608957,
    "total_throughput": 14008.588408603966,
    "itl": 101.64030987507022,
    "ttft": 1942091.7439255484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8802008709311602,
    "arrivals": 745115,
    "finished_requests": 108211,
    "scheduler_time": 308.99259795695644
}
#Debug simulation 
Total elapsed time: 109.26565392827615. Arrivals time: 0.4785578278824687 Scheduler time: 108.57212649751455 Scheduler overhead time: 0.08610786218196154 Adapter cache time: 0.0179154509678483 Engine time: 0.07933074701577425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 109.50790680991486,
    "estimated_duration": 3600.019619589973,
    "input_throughput": 7611.438518526989,
    "output_throughput": 6745.609348308463,
    "total_throughput": 14357.047866835454,
    "itl": 105.32424144699516,
    "ttft": 1930108.4838026029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8832338394271102,
    "arrivals": 745115,
    "finished_requests": 110819,
    "scheduler_time": 298.93447484505646
}
#Debug simulation 
Total elapsed time: 109.50805764785036. Arrivals time: 0.48867293912917376 Scheduler time: 108.80787975620478 Scheduler overhead time: 0.08379292162135243 Adapter cache time: 0.018134287558496 Engine time: 0.07860588142648339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 110.34965384798124,
    "estimated_duration": 3600.0675326873948,
    "input_throughput": 7429.653404316443,
    "output_throughput": 6578.841864758036,
    "total_throughput": 14008.495269074478,
    "itl": 101.64068338014364,
    "ttft": 1942100.754134345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.903842582777146,
    "arrivals": 745115,
    "finished_requests": 108211,
    "scheduler_time": 308.99279213687237
}
#Debug simulation 
Total elapsed time: 110.34980875812471. Arrivals time: 0.4774332973174751 Scheduler time: 109.65553022315726 Scheduler overhead time: 0.08695913106203079 Adapter cache time: 0.01857847534120083 Engine time: 0.07955059641972184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 109.4189169621095,
    "estimated_duration": 3600.060585144739,
    "input_throughput": 7611.933008315819,
    "output_throughput": 6745.837584014886,
    "total_throughput": 14357.770592330704,
    "itl": 105.3235729174659,
    "ttft": 1930067.668462804,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7970202272361806,
    "arrivals": 745115,
    "finished_requests": 110826,
    "scheduler_time": 298.9426167841991
}
#Debug simulation 
Total elapsed time: 109.41907833330333. Arrivals time: 0.4849487319588661 Scheduler time: 108.7230433486402 Scheduler overhead time: 0.08391394652426243 Adapter cache time: 0.018036983907222748 Engine time: 0.07805715641006827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 135, 66, 17280, 17280, 66, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 66, 17280, 66, 17280, 135, 135, 135, 66, 66, 135, 66, 17280, 66, 17280, 135, 17280, 135, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 17280, 17280, 66, 135, 135, 135, 17280, 135, 66, 135, 66, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 66, 17280, 135, 135, 66, 66, 66, 135, 66, 135, 66, 17280, 66, 135, 17280, 66, 17280, 135, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 17280, 17280, 135, 66, 66, 17280, 135, 135, 66, 66, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 66, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 66, 66, 135, 135, 17280, 66, 66, 17280, 66, 17280, 135, 66, 17280, 135, 135, 66, 17280, 17280, 17280, 66, 135, 17280, 66, 17280, 135, 135, 17280, 17280, 66, 135, 17280, 66, 135, 135, 66, 135, 66, 135, 17280, 17280, 135, 66, 17280, 66, 17280, 135, 135, 135, 135, 135, 66, 66, 17280, 66, 17280, 66, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 66, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 66, 66, 66, 66, 66, 135, 66, 66, 135, 17280, 17280, 66, 66, 17280, 66, 66, 66, 135, 66, 135, 17280, 17280, 135, 135, 66, 17280, 135, 17280, 66, 135, 135, 66, 66, 135, 66, 17280, 17280, 66, 17280, 17280, 66, 135, 17280, 66, 66, 135, 135, 66, 66, 17280, 17280, 17280, 17280, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 17280, 135, 135, 135, 17280, 66, 135, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 135, 66, 17280, 17280, 17280, 135, 66, 17280, 17280, 135, 135, 17280, 17280, 66, 17280, 17280, 135, 66, 17280, 135, 135, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 135, 17280, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 17280, 66, 66, 66, 135, 66, 135, 135, 66, 17280, 135, 17280, 66, 17280, 66, 135, 135, 135, 135, 66, 135, 17280, 17280, 66, 17280, 17280, 66, 17280, 135, 17280, 135, 135, 135, 66, 135, 66, 66, 17280, 66, 135, 66, 66, 135, 17280, 135, 17280, 66, 17280, 17280, 135, 17280, 135, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2237568 . Total input tokens: 498215820 . Total output tokens: 447347921
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 109.60924844816327,
    "estimated_duration": 3600.092884157742,
    "input_throughput": 7429.601085489116,
    "output_throughput": 6578.7955372548795,
    "total_throughput": 14008.396622743994,
    "itl": 101.64110013601066,
    "ttft": 1942110.9338487266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.92874183248728,
    "arrivals": 745115,
    "finished_requests": 108211,
    "scheduler_time": 308.99314431894715
}
#Debug simulation 
Total elapsed time: 109.60940468497574. Arrivals time: 0.4807976959273219 Scheduler time: 108.91253364831209 Scheduler overhead time: 0.0861547808162868 Adapter cache time: 0.018238801043480635 Engine time: 0.07939187716692686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 107.8069675359875,
    "estimated_duration": 3600.009915914053,
    "input_throughput": 7685.896052032035,
    "output_throughput": 6760.262768282059,
    "total_throughput": 14446.158820314095,
    "itl": 103.45292727072939,
    "ttft": 1931470.2210423918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.72917557532203,
    "arrivals": 743719,
    "finished_requests": 111540,
    "scheduler_time": 297.87000786308965
}
#Debug simulation 
Total elapsed time: 107.80712122190744. Arrivals time: 0.4780479776673019 Scheduler time: 107.1192663484253 Scheduler overhead time: 0.08413441246375442 Adapter cache time: 0.017981866840273142 Engine time: 0.0769295571371913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 111.74708209419623,
    "estimated_duration": 3600.0405198321446,
    "input_throughput": 7642.96814117051,
    "output_throughput": 6741.138291724432,
    "total_throughput": 14384.106432894941,
    "itl": 104.27033011578744,
    "ttft": 1928498.9431785867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8152826130623045,
    "arrivals": 743719,
    "finished_requests": 110993,
    "scheduler_time": 299.1469265946234
}
#Debug simulation 
Total elapsed time: 111.74723815638572. Arrivals time: 0.4859840818680823 Scheduler time: 111.0467638829723 Scheduler overhead time: 0.08583621913567185 Adapter cache time: 0.01845781644806266 Engine time: 0.07818242721259594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 111.8964661131613,
    "estimated_duration": 3600.0435621013444,
    "input_throughput": 7642.961682369061,
    "output_throughput": 6741.132595027422,
    "total_throughput": 14384.094277396483,
    "itl": 104.27036521247005,
    "ttft": 1928499.9426363353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8183270428702347,
    "arrivals": 743719,
    "finished_requests": 110993,
    "scheduler_time": 299.1469244339971
}
#Debug simulation 
Total elapsed time: 111.89663047203794. Arrivals time: 0.4916767883114517 Scheduler time: 111.18970178300515 Scheduler overhead time: 0.08631341671571136 Adapter cache time: 0.01831088587641716 Engine time: 0.07901557488366961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 108.27076524402946,
    "estimated_duration": 3600.051137744038,
    "input_throughput": 7685.808045865396,
    "output_throughput": 6760.18536093649,
    "total_throughput": 14445.993406801887,
    "itl": 103.45379076217559,
    "ttft": 1931486.8946905287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.770280289670909,
    "arrivals": 743719,
    "finished_requests": 111540,
    "scheduler_time": 297.87022501723715
}
#Debug simulation 
Total elapsed time: 108.27091170707718. Arrivals time: 0.48963495856150985 Scheduler time: 107.56998047465459 Scheduler overhead time: 0.08465813333168626 Adapter cache time: 0.018026417586952448 Engine time: 0.0776085969991982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 111.96524985227734,
    "estimated_duration": 3600.067219147613,
    "input_throughput": 7642.911458335137,
    "output_throughput": 6741.0882971640785,
    "total_throughput": 14383.999755499215,
    "itl": 104.27081156617501,
    "ttft": 1928509.7069157716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8413399857841475,
    "arrivals": 743719,
    "finished_requests": 110993,
    "scheduler_time": 299.1472921725807
}
#Debug simulation 
Total elapsed time: 111.96540173096582. Arrivals time: 0.4821718647144735 Scheduler time: 111.27254744200036 Scheduler overhead time: 0.08356484910473228 Adapter cache time: 0.017735186964273453 Engine time: 0.07792107714340091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 108.12916670739651,
    "estimated_duration": 3600.097271782121,
    "input_throughput": 7686.050101169219,
    "output_throughput": 6760.655105286001,
    "total_throughput": 14446.70520645522,
    "itl": 103.45293112128192,
    "ttft": 1931497.6117376054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6893784166197061,
    "arrivals": 743719,
    "finished_requests": 111544,
    "scheduler_time": 297.87892397062063
}
#Debug simulation 
Total elapsed time: 108.12931630108505. Arrivals time: 0.49209401244297624 Scheduler time: 107.42619220959023 Scheduler overhead time: 0.08430513460189104 Adapter cache time: 0.017950846813619137 Engine time: 0.0775137678720057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 135, 33, 17280, 17280, 33, 135, 17280, 17280, 17280, 17280, 135, 135, 135, 135, 17280, 17280, 135, 135, 33, 17280, 33, 17280, 135, 135, 135, 33, 33, 135, 33, 17280, 33, 17280, 135, 17280, 135, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 17280, 17280, 33, 135, 135, 135, 17280, 135, 33, 135, 33, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 33, 17280, 135, 135, 33, 33, 33, 135, 33, 135, 33, 17280, 33, 135, 17280, 33, 17280, 135, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 17280, 17280, 135, 33, 33, 17280, 135, 135, 33, 33, 17280, 135, 17280, 135, 17280, 17280, 135, 17280, 17280, 33, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 33, 33, 135, 135, 17280, 33, 33, 17280, 33, 17280, 135, 33, 17280, 135, 135, 33, 17280, 17280, 17280, 33, 135, 17280, 33, 17280, 135, 135, 17280, 17280, 33, 135, 17280, 33, 135, 135, 33, 135, 33, 135, 17280, 17280, 135, 33, 17280, 33, 17280, 135, 135, 135, 135, 135, 33, 33, 17280, 33, 17280, 33, 135, 17280, 135, 17280, 135, 17280, 135, 17280, 33, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 33, 33, 33, 33, 33, 135, 33, 33, 135, 17280, 17280, 33, 33, 17280, 33, 33, 33, 135, 33, 135, 17280, 17280, 135, 135, 33, 17280, 135, 17280, 33, 135, 135, 33, 33, 135, 33, 17280, 17280, 33, 17280, 17280, 33, 135, 17280, 33, 33, 135, 135, 33, 33, 17280, 17280, 17280, 17280, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 17280, 135, 135, 135, 17280, 33, 135, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 135, 33, 17280, 17280, 17280, 135, 33, 17280, 17280, 135, 135, 17280, 17280, 33, 17280, 17280, 135, 33, 17280, 135, 135, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 135, 17280, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 17280, 33, 33, 33, 135, 33, 135, 135, 33, 17280, 135, 17280, 33, 17280, 33, 135, 135, 135, 135, 33, 135, 17280, 17280, 33, 17280, 17280, 33, 17280, 135, 17280, 135, 135, 135, 33, 135, 33, 33, 17280, 33, 135, 33, 33, 135, 17280, 135, 17280, 33, 17280, 17280, 135, 17280, 135, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2233344 . Total input tokens: 497296390 . Total output tokens: 446494462
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 111.96617860533297,
    "estimated_duration": 3600.091438687297,
    "input_throughput": 7642.86004080852,
    "output_throughput": 6741.042946633875,
    "total_throughput": 14383.902987442396,
    "itl": 104.27130682236174,
    "ttft": 1928519.528677178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8653589589893784,
    "arrivals": 743719,
    "finished_requests": 110993,
    "scheduler_time": 299.1474927390762
}
#Debug simulation 
Total elapsed time: 111.96632272936404. Arrivals time: 0.491492229513824 Scheduler time: 111.26076662307605 Scheduler overhead time: 0.08616481674835086 Adapter cache time: 0.018257085233926773 Engine time: 0.07851200737059116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 113.69429958472028,
    "estimated_duration": 3600.0352858363412,
    "input_throughput": 7734.661687775981,
    "output_throughput": 6831.375263669573,
    "total_throughput": 14566.036951445552,
    "itl": 102.61485242138666,
    "ttft": 1927417.615894571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.661844844955507,
    "arrivals": 740875,
    "finished_requests": 112528,
    "scheduler_time": 294.9148301834432
}
#Debug simulation 
Total elapsed time: 113.6944596809335. Arrivals time: 0.49764862982556224 Scheduler time: 112.98694261536002 Scheduler overhead time: 0.08342230599373579 Adapter cache time: 0.017742369789630175 Engine time: 0.07743864273652434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 110.8688372313045,
    "estimated_duration": 3600.03459066819,
    "input_throughput": 7734.422905873228,
    "output_throughput": 6831.375471710493,
    "total_throughput": 14565.798377583722,
    "itl": 102.6181285224633,
    "ttft": 1927434.4688731527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7739603873179357,
    "arrivals": 740875,
    "finished_requests": 112526,
    "scheduler_time": 294.90725137658603
}
#Debug simulation 
Total elapsed time: 110.86899119615555. Arrivals time: 0.49363255221396685 Scheduler time: 110.16682435711846 Scheduler overhead time: 0.0832382352091372 Adapter cache time: 0.017921668477356434 Engine time: 0.07636790862306952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 111.13056975696236,
    "estimated_duration": 3600.0374268628,
    "input_throughput": 7734.416812511978,
    "output_throughput": 6831.370089791364,
    "total_throughput": 14565.786902303342,
    "itl": 102.61818234295457,
    "ttft": 1927435.6636062395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7767378128692617,
    "arrivals": 740875,
    "finished_requests": 112526,
    "scheduler_time": 294.90731014561936
}
#Debug simulation 
Total elapsed time: 111.13072139397264. Arrivals time: 0.5059273163788021 Scheduler time: 110.41370170889422 Scheduler overhead time: 0.08417907217517495 Adapter cache time: 0.017808907199651003 Engine time: 0.07774684252217412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 110.66652630781755,
    "estimated_duration": 3600.075546980744,
    "input_throughput": 7734.575187832562,
    "output_throughput": 6831.298865554485,
    "total_throughput": 14565.874053387046,
    "itl": 102.6157489937131,
    "ttft": 1927433.2009712555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7016390159539807,
    "arrivals": 740875,
    "finished_requests": 112528,
    "scheduler_time": 294.9154972339408
}
#Debug simulation 
Total elapsed time: 110.66668553184718. Arrivals time: 0.4920731736347079 Scheduler time: 109.9647998274304 Scheduler overhead time: 0.08404566766694188 Adapter cache time: 0.01810753159224987 Engine time: 0.0769445737823844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 110.94526949711144,
    "estimated_duration": 3600.0597790541556,
    "input_throughput": 7734.368790763666,
    "output_throughput": 6831.327674914713,
    "total_throughput": 14565.696465678378,
    "itl": 102.61865489705664,
    "ttft": 1927444.2818140485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7989962330646858,
    "arrivals": 740875,
    "finished_requests": 112526,
    "scheduler_time": 294.9074039167976
}
#Debug simulation 
Total elapsed time: 110.94542825501412. Arrivals time: 0.5065177376382053 Scheduler time: 110.22903498308733 Scheduler overhead time: 0.08452275581657887 Adapter cache time: 0.017580895218998194 Engine time: 0.07661926792934537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 110.57704937504604,
    "estimated_duration": 3600.111277211456,
    "input_throughput": 7734.663974489269,
    "output_throughput": 6831.345507478176,
    "total_throughput": 14566.009481967445,
    "itl": 102.61349506817281,
    "ttft": 1927460.1419222807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6235973101318606,
    "arrivals": 740875,
    "finished_requests": 112532,
    "scheduler_time": 294.92313691952853
}
#Debug simulation 
Total elapsed time: 110.57721108896658. Arrivals time: 0.5059194718487561 Scheduler time: 109.86021679453552 Scheduler overhead time: 0.08473923848941922 Adapter cache time: 0.01758377766236663 Engine time: 0.07753241993486881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_384_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 66, 33, 17280, 17280, 33, 66, 17280, 17280, 17280, 17280, 66, 66, 66, 66, 17280, 17280, 66, 66, 33, 17280, 33, 17280, 66, 66, 66, 33, 33, 66, 33, 17280, 33, 17280, 66, 17280, 66, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 17280, 17280, 33, 66, 66, 66, 17280, 66, 33, 66, 33, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 33, 17280, 66, 66, 33, 33, 33, 66, 33, 66, 33, 17280, 33, 66, 17280, 33, 17280, 66, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 17280, 17280, 66, 33, 33, 17280, 66, 66, 33, 33, 17280, 66, 17280, 66, 17280, 17280, 66, 17280, 17280, 33, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 33, 33, 66, 66, 17280, 33, 33, 17280, 33, 17280, 66, 33, 17280, 66, 66, 33, 17280, 17280, 17280, 33, 66, 17280, 33, 17280, 66, 66, 17280, 17280, 33, 66, 17280, 33, 66, 66, 33, 66, 33, 66, 17280, 17280, 66, 33, 17280, 33, 17280, 66, 66, 66, 66, 66, 33, 33, 17280, 33, 17280, 33, 66, 17280, 66, 17280, 66, 17280, 66, 17280, 33, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 33, 33, 33, 33, 33, 66, 33, 33, 66, 17280, 17280, 33, 33, 17280, 33, 33, 33, 66, 33, 66, 17280, 17280, 66, 66, 33, 17280, 66, 17280, 33, 66, 66, 33, 33, 66, 33, 17280, 17280, 33, 17280, 17280, 33, 66, 17280, 33, 33, 66, 66, 33, 33, 17280, 17280, 17280, 17280, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 17280, 66, 66, 66, 17280, 33, 66, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 66, 33, 17280, 17280, 17280, 66, 33, 17280, 17280, 66, 66, 17280, 17280, 33, 17280, 17280, 66, 33, 17280, 66, 66, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 66, 17280, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 17280, 33, 33, 33, 66, 33, 66, 66, 33, 17280, 66, 17280, 33, 17280, 33, 66, 66, 66, 66, 33, 66, 17280, 17280, 33, 17280, 17280, 33, 17280, 66, 17280, 66, 66, 66, 33, 66, 33, 33, 17280, 33, 66, 33, 33, 66, 17280, 66, 17280, 33, 17280, 17280, 66, 17280, 66, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2224512 . Total input tokens: 495337016 . Total output tokens: 444733421
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 112.0823550443165,
    "estimated_duration": 3600.0837830793384,
    "input_throughput": 7734.317220857404,
    "output_throughput": 6831.282126152122,
    "total_throughput": 14565.599347009527,
    "itl": 102.61916074286373,
    "ttft": 1927453.5140479924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8230152062699163,
    "arrivals": 740875,
    "finished_requests": 112526,
    "scheduler_time": 294.9076890845421
}
#Debug simulation 
Total elapsed time: 112.08250839309767. Arrivals time: 0.5115045849233866 Scheduler time: 111.36062327679247 Scheduler overhead time: 0.08465277357026935 Adapter cache time: 0.017839140258729458 Engine time: 0.07725144177675247 
