INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:01 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7282128292135894,
    "estimated_duration": 3599.9689803919828,
    "input_throughput": 2413.348294755031,
    "output_throughput": 2122.5291222281603,
    "total_throughput": 4535.877416983191,
    "itl": 24.92172953304587,
    "ttft": 4597.6244137923295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.307292109615903
}
#Debug simulation 
Total elapsed time: 2.728372586891055. Arrivals time: 0.10046049300581217 Scheduler time: 2.2726813619956374 Scheduler overhead time: 0.13490619231015444 Adapter cache time: 0.030153453815728426 Engine time: 0.12826926354318857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7189211598597467,
    "estimated_duration": 3599.964109718458,
    "input_throughput": 2413.351559963041,
    "output_throughput": 2122.5319939641236,
    "total_throughput": 4535.883553927164,
    "itl": 24.922573009131387,
    "ttft": 4597.621352539173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.308135681402509
}
#Debug simulation 
Total elapsed time: 2.7190591348335147. Arrivals time: 0.09998048283159733 Scheduler time: 2.266626606695354 Scheduler overhead time: 0.1369327693246305 Adapter cache time: 0.030192211735993624 Engine time: 0.1237725829705596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.7187554128468037,
    "estimated_duration": 3599.9628845518832,
    "input_throughput": 2413.352381293082,
    "output_throughput": 2122.5327163202523,
    "total_throughput": 4535.885097613334,
    "itl": 24.921630118195985,
    "ttft": 4597.662182961211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.307445436955507
}
#Debug simulation 
Total elapsed time: 2.7188601586967707. Arrivals time: 0.09919720562174916 Scheduler time: 2.2700215820223093 Scheduler overhead time: 0.13515007868409157 Adapter cache time: 0.030138959176838398 Engine time: 0.12291273474693298 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 270, 270, 540, 270, 8640, 540, 270, 270, 270, 8640, 8640, 270, 270, 540, 540, 540, 8640, 8640, 270, 8640, 8640, 8640, 8640, 540, 270, 540, 540, 540, 540, 8640]
Prompts retrieved: 103680 . Total input tokens: 23139561 . Total output tokens: 20766431
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7279825252480805,
    "estimated_duration": 3599.965092769158,
    "input_throughput": 2413.3509009436116,
    "output_throughput": 2122.5314143594583,
    "total_throughput": 4535.88231530307,
    "itl": 24.922530511923593,
    "ttft": 4597.663823284918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 34764,
    "finished_requests": 34720,
    "scheduler_time": 5.308143896140587
}
#Debug simulation 
Total elapsed time: 2.7280895370058715. Arrivals time: 0.10146007034927607 Scheduler time: 2.268409099895507 Scheduler overhead time: 0.13609640020877123 Adapter cache time: 0.03028029901906848 Engine time: 0.13000935688614845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6683867280371487,
    "estimated_duration": 3599.6511145317963,
    "input_throughput": 2367.6433434323367,
    "output_throughput": 2083.9172356779077,
    "total_throughput": 4451.560579110244,
    "itl": 24.82742102406364,
    "ttft": 6339.670638458954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.7508946787769055
}
#Debug simulation 
Total elapsed time: 2.668486370705068. Arrivals time: 0.09777118684723973 Scheduler time: 2.2201774357818067 Scheduler overhead time: 0.13688016356900334 Adapter cache time: 0.02876060176640749 Engine time: 0.1232448616065085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.695676506962627,
    "estimated_duration": 3599.6537481096575,
    "input_throughput": 2367.6416112176494,
    "output_throughput": 2083.915711042851,
    "total_throughput": 4451.5573222605,
    "itl": 24.642470450831937,
    "ttft": 6339.366225409839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.592611369409243
}
#Debug simulation 
Total elapsed time: 2.6957791429013014. Arrivals time: 0.09778330288827419 Scheduler time: 2.2396519971080124 Scheduler overhead time: 0.13691637944430113 Adapter cache time: 0.02949228184297681 Engine time: 0.12911956198513508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.697358983103186,
    "estimated_duration": 3599.6562740024006,
    "input_throughput": 2367.639949834365,
    "output_throughput": 2083.914248751129,
    "total_throughput": 4451.554198585493,
    "itl": 24.64248127370955,
    "ttft": 6339.353509625573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.592682507981974
}
#Debug simulation 
Total elapsed time: 2.6975118811242282. Arrivals time: 0.09987400565296412 Scheduler time: 2.240637402050197 Scheduler overhead time: 0.13720606546849012 Adapter cache time: 0.029629265423864126 Engine time: 0.1279383315704763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6993094170466065,
    "estimated_duration": 3599.6479388837242,
    "input_throughput": 2367.645432192723,
    "output_throughput": 2083.9190741320745,
    "total_throughput": 4451.564506324798,
    "itl": 24.642478214850296,
    "ttft": 6339.373018970681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.592724791435449
}
#Debug simulation 
Total elapsed time: 2.6994121251627803. Arrivals time: 0.09600465930998325 Scheduler time: 2.2436106679961085 Scheduler overhead time: 0.13911623181775212 Adapter cache time: 0.029651138465851545 Engine time: 0.1280218930914998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.673792399931699,
    "estimated_duration": 3599.6602431379592,
    "input_throughput": 2367.63733917578,
    "output_throughput": 2083.911950940339,
    "total_throughput": 4451.54929011612,
    "itl": 24.64260823907117,
    "ttft": 6339.373395819943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.592789090719054
}
#Debug simulation 
Total elapsed time: 2.6738967089913785. Arrivals time: 0.09361153468489647 Scheduler time: 2.224912108387798 Scheduler overhead time: 0.13628022884950042 Adapter cache time: 0.029411837458610535 Engine time: 0.1277444581501186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.688036791048944,
    "estimated_duration": 3599.6510977544062,
    "input_throughput": 2367.6433544675388,
    "output_throughput": 2083.917245390708,
    "total_throughput": 4451.560599858247,
    "itl": 24.827432496909132,
    "ttft": 6339.65685644213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.750873745872693
}
#Debug simulation 
Total elapsed time: 2.688175166025758. Arrivals time: 0.09486852819100022 Scheduler time: 2.2383112059906125 Scheduler overhead time: 0.135895942337811 Adapter cache time: 0.029032195918262005 Engine time: 0.12820844817906618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 135, 135, 540, 135, 8640, 540, 135, 135, 135, 8640, 8640, 135, 135, 540, 540, 540, 8640, 8640, 135, 8640, 8640, 8640, 8640, 540, 135, 540, 540, 540, 540, 8640]
Prompts retrieved: 102330 . Total input tokens: 22826505 . Total output tokens: 20488488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.67050278512761,
    "estimated_duration": 3599.6620361118216,
    "input_throughput": 2367.636159867328,
    "output_throughput": 2083.9109129541,
    "total_throughput": 4451.547072821428,
    "itl": 24.642632106440676,
    "ttft": 6339.370122800734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 34293,
    "finished_requests": 34233,
    "scheduler_time": 4.592775413444919
}
#Debug simulation 
Total elapsed time: 2.6706006242893636. Arrivals time: 0.09357934771105647 Scheduler time: 2.2229851465672255 Scheduler overhead time: 0.1381482812575996 Adapter cache time: 0.029395705088973045 Engine time: 0.12432144535705447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6660511307418346,
    "estimated_duration": 3599.805797858407,
    "input_throughput": 2350.2048374479486,
    "output_throughput": 2066.984836911658,
    "total_throughput": 4417.189674359606,
    "itl": 24.48567760981632,
    "ttft": 7433.278993227731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.204492047665281
}
#Debug simulation 
Total elapsed time: 2.6661600708030164. Arrivals time: 0.09731364995241165 Scheduler time: 2.212206847500056 Scheduler overhead time: 0.13751283381134272 Adapter cache time: 0.028946079313755035 Engine time: 0.12781472457572818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6878402098082006,
    "estimated_duration": 3599.7815805434625,
    "input_throughput": 2350.2206483102077,
    "output_throughput": 2066.998742428329,
    "total_throughput": 4417.219390738536,
    "itl": 24.48558325298749,
    "ttft": 7433.281075057235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.204464109374997
}
#Debug simulation 
Total elapsed time: 2.6879908218979836. Arrivals time: 0.09624832542613149 Scheduler time: 2.233388355001807 Scheduler overhead time: 0.138243003282696 Adapter cache time: 0.028808792121708393 Engine time: 0.12871969025582075 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.716403631027788,
    "estimated_duration": 3599.7811780365137,
    "input_throughput": 2350.2209110984427,
    "output_throughput": 2066.99897354831,
    "total_throughput": 4417.219884646753,
    "itl": 24.485597098315317,
    "ttft": 7433.280454121291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.2044876693592395
}
#Debug simulation 
Total elapsed time: 2.7165170973166823. Arrivals time: 0.10128804063424468 Scheduler time: 2.2548776497133076 Scheduler overhead time: 0.13948486326262355 Adapter cache time: 0.028825043700635433 Engine time: 0.12890197103843093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.706890081986785,
    "estimated_duration": 3599.80597691531,
    "input_throughput": 2350.2047205470926,
    "output_throughput": 2066.9847340983656,
    "total_throughput": 4417.189454645459,
    "itl": 24.485622793997276,
    "ttft": 7433.244390063543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.2044925062852805
}
#Debug simulation 
Total elapsed time: 2.7070030332542956. Arrivals time: 0.10009493259713054 Scheduler time: 2.2480201283469796 Scheduler overhead time: 0.13833395391702652 Adapter cache time: 0.0288832220248878 Engine time: 0.1288401409983635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7145620649680495,
    "estimated_duration": 3599.782368814751,
    "input_throughput": 2350.220133664802,
    "output_throughput": 2066.9982898021435,
    "total_throughput": 4417.218423466945,
    "itl": 24.485623009953677,
    "ttft": 7433.2680006989185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.204522863279583
}
#Debug simulation 
Total elapsed time: 2.714680150616914. Arrivals time: 0.09997417917475104 Scheduler time: 2.2540038265287876 Scheduler overhead time: 0.13983281841501594 Adapter cache time: 0.028940921183675528 Engine time: 0.12828764272853732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.693658788688481,
    "estimated_duration": 3599.805964911225,
    "input_throughput": 2350.2047283841976,
    "output_throughput": 2066.9847409910317,
    "total_throughput": 4417.189469375229,
    "itl": 24.485739808464825,
    "ttft": 7433.274345321792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.204537958281741
}
#Debug simulation 
Total elapsed time: 2.6937780627049506. Arrivals time: 0.09963708138093352 Scheduler time: 2.2355177770368755 Scheduler overhead time: 0.13806451903656125 Adapter cache time: 0.028943857178092003 Engine time: 0.12855847598984838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 66, 66, 540, 66, 8640, 540, 66, 66, 66, 8640, 8640, 66, 66, 540, 540, 540, 8640, 8640, 66, 8640, 8640, 8640, 8640, 540, 66, 540, 540, 540, 540, 8640]
Prompts retrieved: 101640 . Total input tokens: 22666365 . Total output tokens: 20357485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.713902583811432,
    "estimated_duration": 3599.783740630328,
    "input_throughput": 2350.2192380363913,
    "output_throughput": 2066.9975021047,
    "total_throughput": 4417.216740141091,
    "itl": 24.485597574502595,
    "ttft": 7433.292722576751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 34087,
    "finished_requests": 34017,
    "scheduler_time": 4.2045215288055555
}
#Debug simulation 
Total elapsed time: 2.7140224911272526. Arrivals time: 0.09488879144191742 Scheduler time: 2.2598852454684675 Scheduler overhead time: 0.13883607974275947 Adapter cache time: 0.028949245810508728 Engine time: 0.1281861737370491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.719744810834527,
    "estimated_duration": 3599.8777694516907,
    "input_throughput": 2326.722887948433,
    "output_throughput": 2068.3616158262234,
    "total_throughput": 4395.084503774656,
    "itl": 24.45686567874607,
    "ttft": 6292.310699865993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.171325968252201
}
#Debug simulation 
Total elapsed time: 2.719846749678254. Arrivals time: 0.09592804638668895 Scheduler time: 2.2647243356332183 Scheduler overhead time: 0.13832886843010783 Adapter cache time: 0.028228844050318003 Engine time: 0.129894295707345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6973503762856126,
    "estimated_duration": 3599.8855182139764,
    "input_throughput": 2326.717879671788,
    "output_throughput": 2068.357163672842,
    "total_throughput": 4395.07504334463,
    "itl": 24.456925259866324,
    "ttft": 6292.442571328705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.171456236095497
}
#Debug simulation 
Total elapsed time: 2.697484548203647. Arrivals time: 0.09676520526409149 Scheduler time: 2.2447166880592704 Scheduler overhead time: 0.1385139306075871 Adapter cache time: 0.02834962960332632 Engine time: 0.1263564433902502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7004009280353785,
    "estimated_duration": 3599.8854528149545,
    "input_throughput": 2326.717921941209,
    "output_throughput": 2068.357201248631,
    "total_throughput": 4395.07512318984,
    "itl": 24.45695494513877,
    "ttft": 6292.465287102996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.171458487809515
}
#Debug simulation 
Total elapsed time: 2.700581066776067. Arrivals time: 0.09539381833747029 Scheduler time: 2.248777888249606 Scheduler overhead time: 0.1388521483168006 Adapter cache time: 0.02823616750538349 Engine time: 0.1264981236308813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.7226824327372015,
    "estimated_duration": 3599.880433516124,
    "input_throughput": 2326.7211660746634,
    "output_throughput": 2068.36008515077,
    "total_throughput": 4395.081251225433,
    "itl": 24.456933841655562,
    "ttft": 6292.400056109238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.171423168767178
}
#Debug simulation 
Total elapsed time: 2.722786446567625. Arrivals time: 0.09902952564880252 Scheduler time: 2.2657449231483042 Scheduler overhead time: 0.13765418995171785 Adapter cache time: 0.028264519292861223 Engine time: 0.12923949118703604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.719370345119387,
    "estimated_duration": 3599.8858943581195,
    "input_throughput": 2326.717636558165,
    "output_throughput": 2068.3569475547606,
    "total_throughput": 4395.074584112926,
    "itl": 24.456957768403715,
    "ttft": 6292.462324359122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.17146336660357
}
#Debug simulation 
Total elapsed time: 2.7194907404482365. Arrivals time: 0.10158826503902674 Scheduler time: 2.255571336019784 Scheduler overhead time: 0.1407793345861137 Adapter cache time: 0.028185382019728422 Engine time: 0.1301633669063449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.73809352517128,
    "estimated_duration": 3599.8762862231147,
    "input_throughput": 2326.723846609676,
    "output_throughput": 2068.3624680369135,
    "total_throughput": 4395.086314646589,
    "itl": 24.45687869491405,
    "ttft": 6292.350326739326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.171130649982226
}
#Debug simulation 
Total elapsed time: 2.738192838151008. Arrivals time: 0.10197912668809295 Scheduler time: 2.275616389233619 Scheduler overhead time: 0.13970715925097466 Adapter cache time: 0.028444077353924513 Engine time: 0.1285742255859077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 540, 33, 33, 540, 33, 8640, 540, 33, 33, 33, 8640, 8640, 33, 33, 540, 540, 540, 8640, 8640, 33, 8640, 8640, 8640, 8640, 540, 33, 540, 540, 540, 540, 8640]
Prompts retrieved: 101310 . Total input tokens: 22594605 . Total output tokens: 20295375
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7198060788214207,
    "estimated_duration": 3599.8879529473656,
    "input_throughput": 2326.7163060290018,
    "output_throughput": 2068.355764768678,
    "total_throughput": 4395.07207079768,
    "itl": 24.456932251902973,
    "ttft": 6292.424464832246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 33973,
    "finished_requests": 33914,
    "scheduler_time": 4.171394021124875
}
#Debug simulation 
Total elapsed time: 2.719906998798251. Arrivals time: 0.09874172881245613 Scheduler time: 2.2603243151679635 Scheduler overhead time: 0.1389889493584633 Adapter cache time: 0.028355947230011225 Engine time: 0.1305129313841462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.65246023517102,
    "estimated_duration": 3599.9595090056428,
    "input_throughput": 2300.100592600032,
    "output_throughput": 2001.85196027123,
    "total_throughput": 4301.952552871262,
    "itl": 24.012339593558266,
    "ttft": 7717.8756663199365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2032389132360515
}
#Debug simulation 
Total elapsed time: 2.652559731155634. Arrivals time: 0.09506107773631811 Scheduler time: 2.193768602795899 Scheduler overhead time: 0.14160369662567973 Adapter cache time: 0.027824861463159323 Engine time: 0.13031782303005457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.639384940266609,
    "estimated_duration": 3599.944428682347,
    "input_throughput": 2300.110227821141,
    "output_throughput": 2001.8603461158864,
    "total_throughput": 4301.970573937027,
    "itl": 24.01234528145403,
    "ttft": 7717.806451427384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2031626456252824
}
#Debug simulation 
Total elapsed time: 2.6396045042201877. Arrivals time: 0.09260798059403896 Scheduler time: 2.1878499132581055 Scheduler overhead time: 0.13994296826422215 Adapter cache time: 0.027907648123800755 Engine time: 0.12734742602333426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.649551280774176,
    "estimated_duration": 3599.944392644383,
    "input_throughput": 2300.110250846855,
    "output_throughput": 2001.8603661559102,
    "total_throughput": 4301.970617002765,
    "itl": 24.0123572071052,
    "ttft": 7717.793471423064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2031689421473435
}
#Debug simulation 
Total elapsed time: 2.649705989751965. Arrivals time: 0.09370028739795089 Scheduler time: 2.193591606337577 Scheduler overhead time: 0.13951702835038304 Adapter cache time: 0.02796670701354742 Engine time: 0.13109213765710592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.650044356007129,
    "estimated_duration": 3599.9398430020606,
    "input_throughput": 2300.113157750692,
    "output_throughput": 2001.862896128366,
    "total_throughput": 4301.976053879058,
    "itl": 24.01246886390064,
    "ttft": 7717.862774399865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2034632958943705
}
#Debug simulation 
Total elapsed time: 2.6501440731808543. Arrivals time: 0.09481537016108632 Scheduler time: 2.1910729533992708 Scheduler overhead time: 0.14190304838120937 Adapter cache time: 0.027962465304881334 Engine time: 0.13037662347778678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6548115429468453,
    "estimated_duration": 3599.946617664914,
    "input_throughput": 2300.108829216738,
    "output_throughput": 2001.8591288652256,
    "total_throughput": 4301.967958081963,
    "itl": 24.012339368169055,
    "ttft": 7717.8822133110925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.203221524651884
}
#Debug simulation 
Total elapsed time: 2.6550156571902335. Arrivals time: 0.09460021089762449 Scheduler time: 2.199727281462401 Scheduler overhead time: 0.14012476336210966 Adapter cache time: 0.027833469677716494 Engine time: 0.1285470244474709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6709546940401196,
    "estimated_duration": 3599.9593114901904,
    "input_throughput": 2300.1007187974055,
    "output_throughput": 2001.8520701048867,
    "total_throughput": 4301.952788902292,
    "itl": 24.01234686216694,
    "ttft": 7717.844107896438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2033711825493936
}
#Debug simulation 
Total elapsed time: 2.6710552340373397. Arrivals time: 0.09721581591293216 Scheduler time: 2.19689729064703 Scheduler overhead time: 0.14960787165910006 Adapter cache time: 0.02814622363075614 Engine time: 0.1340177534148097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 135, 135, 270, 135, 8640, 270, 135, 135, 135, 8640, 8640, 135, 135, 270, 270, 270, 8640, 8640, 135, 8640, 8640, 8640, 8640, 270, 135, 270, 270, 270, 270, 8640]
Prompts retrieved: 99360 . Total input tokens: 22164726 . Total output tokens: 19896871
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.659482492133975,
    "estimated_duration": 3599.947443066164,
    "input_throughput": 2300.1083018443987,
    "output_throughput": 2001.858669876017,
    "total_throughput": 4301.966971720416,
    "itl": 24.01231249763822,
    "ttft": 7717.857154304183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 33289,
    "finished_requests": 33218,
    "scheduler_time": 3.2033007528406943
}
#Debug simulation 
Total elapsed time: 2.6595823052339256. Arrivals time: 0.09672610694542527 Scheduler time: 2.197426514700055 Scheduler overhead time: 0.14131199242547154 Adapter cache time: 0.02781718922778964 Engine time: 0.13217148929834366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.656780252698809,
    "estimated_duration": 3599.939018902891,
    "input_throughput": 2273.72018165311,
    "output_throughput": 2008.535411859166,
    "total_throughput": 4282.255593512276,
    "itl": 23.924745747475832,
    "ttft": 5920.134504081751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.134786837516291
}
#Debug simulation 
Total elapsed time: 2.656895753927529. Arrivals time: 0.0937661319039762 Scheduler time: 2.2040044432505965 Scheduler overhead time: 0.1395934447646141 Adapter cache time: 0.026768578682094812 Engine time: 0.12883260194212198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6790818637236953,
    "estimated_duration": 3599.940883308329,
    "input_throughput": 2273.71900409592,
    "output_throughput": 2008.5343716408775,
    "total_throughput": 4282.253375736797,
    "itl": 23.92465980112108,
    "ttft": 5920.030017996993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.134519629941549
}
#Debug simulation 
Total elapsed time: 2.679210411850363. Arrivals time: 0.09614090342074633 Scheduler time: 2.219391011632979 Scheduler overhead time: 0.14054066454991698 Adapter cache time: 0.02681736834347248 Engine time: 0.131977376062423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6687276298180223,
    "estimated_duration": 3599.94133646934,
    "input_throughput": 2273.7187178799218,
    "output_throughput": 2008.53411880635,
    "total_throughput": 4282.252836686272,
    "itl": 23.924665432991933,
    "ttft": 5920.009280871528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.1344946522292876
}
#Debug simulation 
Total elapsed time: 2.668906596954912. Arrivals time: 0.09315294772386551 Scheduler time: 2.210396721493453 Scheduler overhead time: 0.14242772897705436 Adapter cache time: 0.026936939917504787 Engine time: 0.13163306144997478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6469018468633294,
    "estimated_duration": 3599.939896280643,
    "input_throughput": 2273.7196275017745,
    "output_throughput": 2008.5349223386918,
    "total_throughput": 4282.254549840466,
    "itl": 23.924718703939647,
    "ttft": 5920.117596858606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.13471069502751
}
#Debug simulation 
Total elapsed time: 2.647018204908818. Arrivals time: 0.0921783889643848 Scheduler time: 2.1939137261360884 Scheduler overhead time: 0.14240155462175608 Adapter cache time: 0.026708651799708605 Engine time: 0.12775225611403584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.659219511784613,
    "estimated_duration": 3599.943754365679,
    "input_throughput": 2273.717190740461,
    "output_throughput": 2008.5327697776918,
    "total_throughput": 4282.249960518153,
    "itl": 23.92472212280359,
    "ttft": 5920.101491084883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.1347571893859594
}
#Debug simulation 
Total elapsed time: 2.659340708050877. Arrivals time: 0.09409839287400246 Scheduler time: 2.2008109223097563 Scheduler overhead time: 0.1435026004910469 Adapter cache time: 0.027414559852331877 Engine time: 0.1287356005050242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.658738791011274,
    "estimated_duration": 3599.9606253778993,
    "input_throughput": 2273.7065350932185,
    "output_throughput": 2008.5233569022662,
    "total_throughput": 4282.229891995485,
    "itl": 23.92463940909147,
    "ttft": 5920.1323143353775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.1348455914208833
}
#Debug simulation 
Total elapsed time: 2.6588526940904558. Arrivals time: 0.09442039951682091 Scheduler time: 2.201748935505748 Scheduler overhead time: 0.14047145657241344 Adapter cache time: 0.026966840960085392 Engine time: 0.13107032841071486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 66, 66, 270, 66, 8640, 270, 66, 66, 66, 8640, 8640, 66, 66, 270, 270, 270, 8640, 8640, 66, 8640, 8640, 8640, 8640, 270, 66, 270, 270, 270, 270, 8640]
Prompts retrieved: 98670 . Total input tokens: 21998685 . Total output tokens: 19770507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6399029353633523,
    "estimated_duration": 3599.947770846928,
    "input_throughput": 2273.714653941862,
    "output_throughput": 2008.5305288467891,
    "total_throughput": 4282.245182788651,
    "itl": 23.924691781019202,
    "ttft": 5920.060837855117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 33058,
    "finished_requests": 33004,
    "scheduler_time": 3.134813941820555
}
#Debug simulation 
Total elapsed time: 2.640018123202026. Arrivals time: 0.09473339142277837 Scheduler time: 2.185298413503915 Scheduler overhead time: 0.1403770176693797 Adapter cache time: 0.026773085352033377 Engine time: 0.1289224117062986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.658948529046029,
    "estimated_duration": 3600.024044984219,
    "input_throughput": 2249.0410894006936,
    "output_throughput": 2015.8740356501737,
    "total_throughput": 4264.915125050868,
    "itl": 23.90923318090389,
    "ttft": 5499.971578519735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1145111850005525
}
#Debug simulation 
Total elapsed time: 2.659092528745532. Arrivals time: 0.09260495938360691 Scheduler time: 2.203948151320219 Scheduler overhead time: 0.14091105153784156 Adapter cache time: 0.026021153666079044 Engine time: 0.1313115879893303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6456816787831485,
    "estimated_duration": 3600.005398883497,
    "input_throughput": 2249.0527382295245,
    "output_throughput": 2015.8844767984906,
    "total_throughput": 4264.937215028015,
    "itl": 23.90742204000638,
    "ttft": 5499.997125981367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1130192345753365
}
#Debug simulation 
Total elapsed time: 2.6457914197817445. Arrivals time: 0.09336927393451333 Scheduler time: 2.191084142308682 Scheduler overhead time: 0.14059730852022767 Adapter cache time: 0.026070586871355772 Engine time: 0.1306904200464487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6676274817436934,
    "estimated_duration": 3600.0052756965515,
    "input_throughput": 2249.0528151888384,
    "output_throughput": 2015.884545779126,
    "total_throughput": 4264.937360967964,
    "itl": 23.907430320325496,
    "ttft": 5500.021959795005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1130249473553953
}
#Debug simulation 
Total elapsed time: 2.6677940976805985. Arrivals time: 0.09260033024474978 Scheduler time: 2.2073181606829166 Scheduler overhead time: 0.14019594620913267 Adapter cache time: 0.026195150800049305 Engine time: 0.13737798295915127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6559845958836377,
    "estimated_duration": 3600.0058300314563,
    "input_throughput": 2249.0524688759333,
    "output_throughput": 2015.8842353698599,
    "total_throughput": 4264.936704245793,
    "itl": 23.911604023249108,
    "ttft": 5500.036329742535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.115768828671414
}
#Debug simulation 
Total elapsed time: 2.6561074182391167. Arrivals time: 0.09236759506165981 Scheduler time: 2.202459924388677 Scheduler overhead time: 0.14077423512935638 Adapter cache time: 0.02604730287566781 Engine time: 0.13047355925664306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6568841002881527,
    "estimated_duration": 3600.014021875569,
    "input_throughput": 2249.0473511494147,
    "output_throughput": 2015.8796482184473,
    "total_throughput": 4264.926999367862,
    "itl": 23.909004308495746,
    "ttft": 5500.024312633152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1139906973692373
}
#Debug simulation 
Total elapsed time: 2.6570437750779092. Arrivals time: 0.0929637337103486 Scheduler time: 2.201342719141394 Scheduler overhead time: 0.14087318209931254 Adapter cache time: 0.026086936704814434 Engine time: 0.13129498763009906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6361176730133593,
    "estimated_duration": 3600.022933189225,
    "input_throughput": 2249.041783971998,
    "output_throughput": 2015.8746582125025,
    "total_throughput": 4264.916442184501,
    "itl": 23.909258355765648,
    "ttft": 5499.950114653786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1144623138060563
}
#Debug simulation 
Total elapsed time: 2.6362382057122886. Arrivals time: 0.09197362093254924 Scheduler time: 2.1867794482968748 Scheduler overhead time: 0.14039846695959568 Adapter cache time: 0.02591026294976473 Engine time: 0.12736796401441097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 270, 33, 33, 270, 33, 8640, 270, 33, 33, 33, 8640, 8640, 33, 33, 270, 270, 270, 8640, 8640, 33, 8640, 8640, 8640, 8640, 270, 33, 270, 270, 270, 270, 8640]
Prompts retrieved: 98340 . Total input tokens: 21925467 . Total output tokens: 19704656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6589589649811387,
    "estimated_duration": 3600.0148439951645,
    "input_throughput": 2249.0468375443384,
    "output_throughput": 2015.8791878608565,
    "total_throughput": 4264.926025405195,
    "itl": 23.90903518531867,
    "ttft": 5500.0248231208925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 32964,
    "finished_requests": 32914,
    "scheduler_time": 3.1140507857478568
}
#Debug simulation 
Total elapsed time: 2.6590784918516874. Arrivals time: 0.09278160566464067 Scheduler time: 2.2057895050384104 Scheduler overhead time: 0.14053682563826442 Adapter cache time: 0.026060025673359632 Engine time: 0.12958834460005164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.6219956749118865,
    "estimated_duration": 3599.9856085536153,
    "input_throughput": 2237.755056814423,
    "output_throughput": 1990.603235461038,
    "total_throughput": 4228.35829227546,
    "itl": 23.702800472688057,
    "ttft": 5676.292045220168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8086106223921155
}
#Debug simulation 
Total elapsed time: 2.622112368699163. Arrivals time: 0.09190668072551489 Scheduler time: 2.1671651820652187 Scheduler overhead time: 0.14135667961090803 Adapter cache time: 0.025139414705336094 Engine time: 0.13208925491198897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6280739698559046,
    "estimated_duration": 3599.992367343603,
    "input_throughput": 2237.75085555094,
    "output_throughput": 1990.5994982116651,
    "total_throughput": 4228.350353762605,
    "itl": 23.7028497051807,
    "ttft": 5676.262352758696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.808647859650479
}
#Debug simulation 
Total elapsed time: 2.6282505108974874. Arrivals time: 0.09193733334541321 Scheduler time: 2.1769812679849565 Scheduler overhead time: 0.14070261269807816 Adapter cache time: 0.025042406283318996 Engine time: 0.12922381237149239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6238294588401914,
    "estimated_duration": 3599.9923234624744,
    "input_throughput": 2237.750882827396,
    "output_throughput": 1990.5995224755368,
    "total_throughput": 4228.350405302933,
    "itl": 23.702865095666777,
    "ttft": 5676.271193867737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.808652029580525
}
#Debug simulation 
Total elapsed time: 2.62402445403859. Arrivals time: 0.09191206842660904 Scheduler time: 2.1674910821020603 Scheduler overhead time: 0.14264211617410183 Adapter cache time: 0.025124548003077507 Engine time: 0.13230043184012175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6321658957749605,
    "estimated_duration": 3599.988134006296,
    "input_throughput": 2237.7534869913297,
    "output_throughput": 1990.6018390191357,
    "total_throughput": 4228.355326010465,
    "itl": 23.7027828814232,
    "ttft": 5676.271373652158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8087757506577913
}
#Debug simulation 
Total elapsed time: 2.632303185760975. Arrivals time: 0.09465477103367448 Scheduler time: 2.1724629811942577 Scheduler overhead time: 0.14268285036087036 Adapter cache time: 0.02511114813387394 Engine time: 0.13279611710458994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.606862412299961,
    "estimated_duration": 3599.9924119517696,
    "input_throughput": 2237.750827822558,
    "output_throughput": 1990.5994735457814,
    "total_throughput": 4228.350301368339,
    "itl": 23.702802010138104,
    "ttft": 5676.251504130244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8086217977082137
}
#Debug simulation 
Total elapsed time: 2.6069922521710396. Arrivals time: 0.09264225605875254 Scheduler time: 2.151110014412552 Scheduler overhead time: 0.14144655037671328 Adapter cache time: 0.0252090347930789 Engine time: 0.13209237903356552 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.663317488040775,
    "estimated_duration": 3599.982539325447,
    "input_throughput": 2237.7569646516913,
    "output_throughput": 1990.604932584692,
    "total_throughput": 4228.361897236384,
    "itl": 23.702757374171483,
    "ttft": 5676.260435636119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.80868709837889
}
#Debug simulation 
Total elapsed time: 2.663434026762843. Arrivals time: 0.09815425937995315 Scheduler time: 2.180375966709107 Scheduler overhead time: 0.15331941843032837 Adapter cache time: 0.025699352845549583 Engine time: 0.13519733445718884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 66, 66, 135, 66, 8640, 135, 66, 66, 66, 8640, 8640, 66, 66, 135, 135, 135, 8640, 8640, 66, 8640, 8640, 8640, 8640, 135, 66, 135, 135, 135, 135, 8640]
Prompts retrieved: 97185 . Total input tokens: 21658168 . Total output tokens: 19471223
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.6105578429996967,
    "estimated_duration": 3599.9957620702744,
    "input_throughput": 2237.74874539498,
    "output_throughput": 1990.5976211146751,
    "total_throughput": 4228.346366509654,
    "itl": 23.702782355316575,
    "ttft": 5676.215933805356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 32570,
    "finished_requests": 32519,
    "scheduler_time": 2.8085976539819644
}
#Debug simulation 
Total elapsed time: 2.6106564276851714. Arrivals time: 0.09217294724658132 Scheduler time: 2.1561058810912073 Scheduler overhead time: 0.1411931193433702 Adapter cache time: 0.025125622749328613 Engine time: 0.13172043999657035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.5896791918203235,
    "estimated_duration": 3599.957366424959,
    "input_throughput": 2220.6254647784417,
    "output_throughput": 1964.436875268593,
    "total_throughput": 4185.062340047035,
    "itl": 23.560714667676873,
    "ttft": 5809.204598958665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.501972055296643
}
#Debug simulation 
Total elapsed time: 2.58978577516973. Arrivals time: 0.09151026792824268 Scheduler time: 2.1375936712138355 Scheduler overhead time: 0.14224874041974545 Adapter cache time: 0.024947481229901314 Engine time: 0.1286801784299314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.588946529664099,
    "estimated_duration": 3599.967171509454,
    "input_throughput": 2220.6194165509783,
    "output_throughput": 1964.4315248115945,
    "total_throughput": 4185.050941362573,
    "itl": 23.56074623582864,
    "ttft": 5809.234605749212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.501898790131876
}
#Debug simulation 
Total elapsed time: 2.5890568448230624. Arrivals time: 0.09176528686657548 Scheduler time: 2.131598560605198 Scheduler overhead time: 0.14317870512604713 Adapter cache time: 0.024778942111879587 Engine time: 0.1321476916782558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5984167978167534,
    "estimated_duration": 3599.9689074970784,
    "input_throughput": 2220.618345717334,
    "output_throughput": 1964.4305775176308,
    "total_throughput": 4185.048923234965,
    "itl": 23.56075568890533,
    "ttft": 5809.222236313051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.502006331976979
}
#Debug simulation 
Total elapsed time: 2.59860380878672. Arrivals time: 0.09124615835025907 Scheduler time: 2.1421221322380006 Scheduler overhead time: 0.1412636493332684 Adapter cache time: 0.025191497523337603 Engine time: 0.13384242122992873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.5793320280499756,
    "estimated_duration": 3599.9581538204984,
    "input_throughput": 2220.624979075411,
    "output_throughput": 1964.436445600034,
    "total_throughput": 4185.061424675445,
    "itl": 23.5607227808796,
    "ttft": 5809.179129071769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.501881401547718
}
#Debug simulation 
Total elapsed time: 2.579435476101935. Arrivals time: 0.09006297495216131 Scheduler time: 2.1294822175987065 Scheduler overhead time: 0.14156267186626792 Adapter cache time: 0.02480481658130884 Engine time: 0.12896113144233823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5827361661940813,
    "estimated_duration": 3599.9453724220925,
    "input_throughput": 2220.6328632763175,
    "output_throughput": 1964.4434202183286,
    "total_throughput": 4185.076283494646,
    "itl": 23.560818657428214,
    "ttft": 5809.227736833361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.502143980572391
}
#Debug simulation 
Total elapsed time: 2.5828374791890383. Arrivals time: 0.090923928655684 Scheduler time: 2.125564267858863 Scheduler overhead time: 0.14336655009537935 Adapter cache time: 0.024864807724952698 Engine time: 0.1327262967824936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.5917252362705767,
    "estimated_duration": 3599.9534112194583,
    "input_throughput": 2220.627904540586,
    "output_throughput": 1964.4390335608396,
    "total_throughput": 4185.066938101426,
    "itl": 23.560738526179694,
    "ttft": 5809.233751742529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.501977768076696
}
#Debug simulation 
Total elapsed time: 2.591829647310078. Arrivals time: 0.091205685865134 Scheduler time: 2.1337694581598043 Scheduler overhead time: 0.1433010082691908 Adapter cache time: 0.025162850972265005 Engine time: 0.1331095863133669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 135, 33, 33, 135, 33, 8640, 135, 33, 33, 33, 8640, 8640, 33, 33, 135, 135, 135, 8640, 8640, 33, 8640, 8640, 8640, 8640, 135, 33, 135, 135, 135, 135, 8640]
Prompts retrieved: 96855 . Total input tokens: 21591748 . Total output tokens: 19401075
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5989689957350492,
    "estimated_duration": 3599.948316068793,
    "input_throughput": 2220.6310474839706,
    "output_throughput": 1964.4418139098807,
    "total_throughput": 4185.072861393852,
    "itl": 23.560826538943765,
    "ttft": 5809.230089193399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 32442,
    "finished_requests": 32390,
    "scheduler_time": 2.5019926547028395
}
#Debug simulation 
Total elapsed time: 2.5990993017330766. Arrivals time: 0.09258987382054329 Scheduler time: 2.141371099278331 Scheduler overhead time: 0.1436673104763031 Adapter cache time: 0.024689005687832832 Engine time: 0.13203885033726692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.592351977247745,
    "estimated_duration": 3599.931735450243,
    "input_throughput": 2201.6648043490513,
    "output_throughput": 1966.0639479083882,
    "total_throughput": 4167.728752257439,
    "itl": 23.470884134579403,
    "ttft": 7532.257245732976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4385912034859656
}
#Debug simulation 
Total elapsed time: 2.5924467891454697. Arrivals time: 0.09159620758146048 Scheduler time: 2.135908116120845 Scheduler overhead time: 0.1436311351135373 Adapter cache time: 0.02401934238150716 Engine time: 0.13214913848787546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5791080920025706,
    "estimated_duration": 3599.9432750994774,
    "input_throughput": 2201.6577468935216,
    "output_throughput": 1966.0576456734368,
    "total_throughput": 4167.715392566958,
    "itl": 23.471109576856882,
    "ttft": 7532.237841024578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4385958739040112
}
#Debug simulation 
Total elapsed time: 2.5792164150625467. Arrivals time: 0.08981501497328281 Scheduler time: 2.124823445919901 Scheduler overhead time: 0.1427822015248239 Adapter cache time: 0.02388785220682621 Engine time: 0.13277003122493625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.575452923309058,
    "estimated_duration": 3599.943246016145,
    "input_throughput": 2201.6577646803416,
    "output_throughput": 1966.0576615568839,
    "total_throughput": 4167.715426237226,
    "itl": 23.47110774910665,
    "ttft": 7532.225990491503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4385870754239227
}
#Debug simulation 
Total elapsed time: 2.5756211960688233. Arrivals time: 0.0904719908721745 Scheduler time: 2.1206723409704864 Scheduler overhead time: 0.1462743440642953 Adapter cache time: 0.023850792087614536 Engine time: 0.12914353422820568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 2.6013886318542063,
    "estimated_duration": 3599.9331158227046,
    "input_throughput": 2201.6639601340707,
    "output_throughput": 1966.0631940331232,
    "total_throughput": 4167.7271541671935,
    "itl": 23.470882627644805,
    "ttft": 7532.1884170531675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.438552298255574
}
#Debug simulation 
Total elapsed time: 2.6014911578968167. Arrivals time: 0.08983171079307795 Scheduler time: 2.1469471231102943 Scheduler overhead time: 0.1437591086141765 Adapter cache time: 0.023841686081141233 Engine time: 0.13184447772800922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5757177430205047,
    "estimated_duration": 3599.9453567316737,
    "input_throughput": 2201.6564738070724,
    "output_throughput": 1966.0565088203766,
    "total_throughput": 4167.7129826274495,
    "itl": 23.471073954380937,
    "ttft": 7532.242971064037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.43862573041031
}
#Debug simulation 
Total elapsed time: 2.5758439977653325. Arrivals time: 0.08987847017124295 Scheduler time: 2.1229066979140043 Scheduler overhead time: 0.14205264439806342 Adapter cache time: 0.023931422270834446 Engine time: 0.1322763585485518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 2.587515880353749,
    "estimated_duration": 3599.9280710994403,
    "input_throughput": 2201.667045413882,
    "output_throughput": 1966.065949156153,
    "total_throughput": 4167.732994570035,
    "itl": 23.470941346292282,
    "ttft": 7532.207868504912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4387823518258918
}
#Debug simulation 
Total elapsed time: 2.5876226210966706. Arrivals time: 0.09413708653301 Scheduler time: 2.1321860374882817 Scheduler overhead time: 0.14240668527781963 Adapter cache time: 0.023663345258682966 Engine time: 0.13022292777895927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [10 11 11]
Adapter prompts. [8640, 66, 33, 33, 66, 33, 8640, 66, 33, 33, 33, 8640, 8640, 33, 33, 66, 66, 66, 8640, 8640, 33, 8640, 8640, 8640, 8640, 66, 33, 66, 66, 66, 66, 8640]
Prompts retrieved: 96096 . Total input tokens: 21430832 . Total output tokens: 19239566
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 2.5801507150754333,
    "estimated_duration": 3599.9192681359364,
    "input_throughput": 2201.672429199796,
    "output_throughput": 1966.070756821411,
    "total_throughput": 4167.743186021207,
    "itl": 23.471116682127498,
    "ttft": 7532.184264214111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 32188,
    "finished_requests": 32121,
    "scheduler_time": 2.4385130595271587
}
#Debug simulation 
Total elapsed time: 2.5802658312022686. Arrivals time: 0.08969256933778524 Scheduler time: 2.127850308082998 Scheduler overhead time: 0.14160325657576323 Adapter cache time: 0.02379394695162773 Engine time: 0.13212950248271227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.9327371059916914,
    "estimated_duration": 3599.9162525450815,
    "input_throughput": 1480.489163110957,
    "output_throughput": 1301.7027817486198,
    "total_throughput": 2782.191944859577,
    "itl": 22.908471847494653,
    "ttft": 5028.914830657633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.02207536547043298
}
#Debug simulation 
Total elapsed time: 1.9328631442040205. Arrivals time: 0.0711374687962234 Scheduler time: 1.470340603031218 Scheduler overhead time: 0.14353319257497787 Adapter cache time: 0.044490514788776636 Engine time: 0.13721960317343473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9293262809515,
    "estimated_duration": 3599.916242016738,
    "input_throughput": 1480.4891674408073,
    "output_throughput": 1301.70278555559,
    "total_throughput": 2782.1919529963975,
    "itl": 22.908222912761346,
    "ttft": 5028.8587419273745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.022031581445984383
}
#Debug simulation 
Total elapsed time: 1.9294259999878705. Arrivals time: 0.06912958296015859 Scheduler time: 1.4707549512386322 Scheduler overhead time: 0.14511053217574954 Adapter cache time: 0.044723284896463156 Engine time: 0.13342883018776774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9346177577972412,
    "estimated_duration": 3599.9161498177673,
    "input_throughput": 1480.4892053582396,
    "output_throughput": 1301.7028188940492,
    "total_throughput": 2782.192024252289,
    "itl": 22.90822654665633,
    "ttft": 5028.870308745759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.022027536637943133
}
#Debug simulation 
Total elapsed time: 1.9347736979834735. Arrivals time: 0.07136111101135612 Scheduler time: 1.476891418453306 Scheduler overhead time: 0.1416671252809465 Adapter cache time: 0.044790033251047134 Engine time: 0.13452125480398536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.9103121990337968,
    "estimated_duration": 3599.9162423378666,
    "input_throughput": 1480.489167308741,
    "output_throughput": 1301.7027854394726,
    "total_throughput": 2782.1919527482137,
    "itl": 22.908433367441926,
    "ttft": 5028.884609622069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.022046217828135206
}
#Debug simulation 
Total elapsed time: 1.9104111287742853. Arrivals time: 0.06509769102558494 Scheduler time: 1.46082709915936 Scheduler overhead time: 0.1416116189211607 Adapter cache time: 0.04470241302624345 Engine time: 0.13249799609184265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9308304809965193,
    "estimated_duration": 3599.9161773603123,
    "input_throughput": 1480.4891940311868,
    "output_throughput": 1301.7028089348705,
    "total_throughput": 2782.1920029660573,
    "itl": 22.908194651297936,
    "ttft": 5028.866927106589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.02200005696766341
}
#Debug simulation 
Total elapsed time: 1.9309343192726374. Arrivals time: 0.07102152891457081 Scheduler time: 1.473155823070556 Scheduler overhead time: 0.1446706340648234 Adapter cache time: 0.04499207343906164 Engine time: 0.13121822196990252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.9339833478443325,
    "estimated_duration": 3599.9039526620813,
    "input_throughput": 1480.494221535773,
    "output_throughput": 1301.707229309479,
    "total_throughput": 2782.201450845252,
    "itl": 22.908282825338496,
    "ttft": 5028.859669139463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.02208737477255285
}
#Debug simulation 
Total elapsed time: 1.9340855358168483. Arrivals time: 0.07019103271886706 Scheduler time: 1.4824636285193264 Scheduler overhead time: 0.14031714061275125 Adapter cache time: 0.04390047071501613 Engine time: 0.1321593252941966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 540, 540, 1080, 540, 4320, 1080, 540, 540, 540, 4320, 4320, 540, 540, 1080, 1080, 1080, 4320, 4320, 540, 4320, 4320, 4320, 4320, 1080, 540, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 64800 . Total input tokens: 14412183 . Total output tokens: 12972743
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.9105111616663635,
    "estimated_duration": 3599.916197884276,
    "input_throughput": 1480.489185590572,
    "output_throughput": 1301.7028015135586,
    "total_throughput": 2782.1919871041305,
    "itl": 22.90818797388426,
    "ttft": 5028.860399634508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 21639,
    "finished_requests": 21609,
    "scheduler_time": 0.02201944702186063
}
#Debug simulation 
Total elapsed time: 1.9106241390109062. Arrivals time: 0.07087629660964012 Scheduler time: 1.4608552637510002 Scheduler overhead time: 0.1400441974401474 Adapter cache time: 0.043918343260884285 Engine time: 0.13007476134225726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.861704490147531,
    "estimated_duration": 3600.0110052409386,
    "input_throughput": 1422.2234300245789,
    "output_throughput": 1263.467248677364,
    "total_throughput": 2685.690678701943,
    "itl": 22.616696898477414,
    "ttft": 7292.642767176645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.003685739293775192
}
#Debug simulation 
Total elapsed time: 1.8617994021624327. Arrivals time: 0.06558402813971043 Scheduler time: 1.4167033177800477 Scheduler overhead time: 0.14237034041434526 Adapter cache time: 0.04085917165502906 Engine time: 0.13047583540901542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8702617390081286,
    "estimated_duration": 3600.0206259080933,
    "input_throughput": 1422.2196292857327,
    "output_throughput": 1263.4638721973035,
    "total_throughput": 2685.6835014830363,
    "itl": 22.61672824476083,
    "ttft": 7292.537316946479,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.0036897841018164418
}
#Debug simulation 
Total elapsed time: 1.8703673351556063. Arrivals time: 0.06590546108782291 Scheduler time: 1.421547151170671 Scheduler overhead time: 0.14329632930457592 Adapter cache time: 0.04088614881038666 Engine time: 0.1329638222232461 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8799713118933141,
    "estimated_duration": 3600.000939390192,
    "input_throughput": 1422.227406659312,
    "output_throughput": 1263.4707814188723,
    "total_throughput": 2685.6981880781846,
    "itl": 22.616849502999692,
    "ttft": 7120.072533075405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.0036906180878254684
}
#Debug simulation 
Total elapsed time: 1.8801623918116093. Arrivals time: 0.06549856346100569 Scheduler time: 1.430334712844342 Scheduler overhead time: 0.1430521528236568 Adapter cache time: 0.04086508974432945 Engine time: 0.13381238281726837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.874484762083739,
    "estimated_duration": 3600.0205617385413,
    "input_throughput": 1422.2196546364758,
    "output_throughput": 1263.4638947182611,
    "total_throughput": 2685.683549354737,
    "itl": 22.616738213462206,
    "ttft": 7292.566170937166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.0036938289098576915
}
#Debug simulation 
Total elapsed time: 1.8746095644310117. Arrivals time: 0.06435721460729837 Scheduler time: 1.4276025625877082 Scheduler overhead time: 0.14094368740916252 Adapter cache time: 0.041428329423069954 Engine time: 0.13488811487331986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8488268959335983,
    "estimated_duration": 3600.0010753515335,
    "input_throughput": 1422.2273529460097,
    "output_throughput": 1263.4707337013358,
    "total_throughput": 2685.6980866473455,
    "itl": 22.61681904634044,
    "ttft": 7120.010441177627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1061953396908939,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.003689075237811298
}
#Debug simulation 
Total elapsed time: 1.8489367882721126. Arrivals time: 0.06299895327538252 Scheduler time: 1.4090338665992022 Scheduler overhead time: 0.14067578362300992 Adapter cache time: 0.04125060420483351 Engine time: 0.12959770718589425 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8481396469287574,
    "estimated_duration": 3600.0114693317687,
    "input_throughput": 1422.223246680482,
    "output_throughput": 1263.467085799115,
    "total_throughput": 2685.6903324795967,
    "itl": 22.616716284769215,
    "ttft": 7292.6718634421395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.0036840713217571397
}
#Debug simulation 
Total elapsed time: 1.848244500812143. Arrivals time: 0.0627896087244153 Scheduler time: 1.4063093783333898 Scheduler overhead time: 0.1419747518375516 Adapter cache time: 0.04104579100385308 Engine time: 0.13056929362937808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 270, 270, 1080, 270, 4320, 1080, 270, 270, 270, 4320, 4320, 270, 270, 1080, 1080, 1080, 4320, 4320, 270, 4320, 4320, 4320, 4320, 1080, 270, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 62100 . Total input tokens: 13799752 . Total output tokens: 12428507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8436845690011978,
    "estimated_duration": 3600.0009655425106,
    "input_throughput": 1422.227396327497,
    "output_throughput": 1263.4707722403496,
    "total_throughput": 2685.6981685678466,
    "itl": 22.61674391425461,
    "ttft": 7119.981384481358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 20840,
    "finished_requests": 20798,
    "scheduler_time": 0.0036777747996965763
}
#Debug simulation 
Total elapsed time: 1.843774841632694. Arrivals time: 0.06214266363531351 Scheduler time: 1.404793567955494 Scheduler overhead time: 0.14097936265170574 Adapter cache time: 0.040984227787703276 Engine time: 0.12942278943955898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8348606410436332,
    "estimated_duration": 3600.0194090985706,
    "input_throughput": 1394.7063694462772,
    "output_throughput": 1250.2065929491678,
    "total_throughput": 2644.912962395445,
    "itl": 22.420146887075145,
    "ttft": 4629.5281561336615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.004460383317752286
}
#Debug simulation 
Total elapsed time: 1.8349546194076538. Arrivals time: 0.06215279595926404 Scheduler time: 1.3957637585699558 Scheduler overhead time: 0.14219079306349158 Adapter cache time: 0.038614004384726286 Engine time: 0.13022610219195485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8331339159049094,
    "estimated_duration": 3600.005917086105,
    "input_throughput": 1394.7115964920533,
    "output_throughput": 1250.2112784422823,
    "total_throughput": 2644.9228749343356,
    "itl": 22.42027905386659,
    "ttft": 4629.617782128643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.004479064507944363
}
#Debug simulation 
Total elapsed time: 1.833231583237648. Arrivals time: 0.06241946667432785 Scheduler time: 1.3898520595394075 Scheduler overhead time: 0.14309040596708655 Adapter cache time: 0.0389267080463469 Engine time: 0.133262662217021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8377337362617254,
    "estimated_duration": 3600.0055731263715,
    "input_throughput": 1394.7117297486884,
    "output_throughput": 1250.2113978927468,
    "total_throughput": 2644.9231276414353,
    "itl": 22.420283774628462,
    "ttft": 4629.608648739953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.004475853685912141
}
#Debug simulation 
Total elapsed time: 1.837876404169947. Arrivals time: 0.06405632011592388 Scheduler time: 1.3933241735212505 Scheduler overhead time: 0.14263307163491845 Adapter cache time: 0.03872675308957696 Engine time: 0.13307591201737523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.8367626462131739,
    "estimated_duration": 3600.020427646862,
    "input_throughput": 1394.7059748441304,
    "output_throughput": 1250.2062392301223,
    "total_throughput": 2644.9122140742525,
    "itl": 22.420184440751218,
    "ttft": 4805.945129062399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0044620512897703395
}
#Debug simulation 
Total elapsed time: 1.8368886201642454. Arrivals time: 0.06444848654791713 Scheduler time: 1.3946106992661953 Scheduler overhead time: 0.14147323090583086 Adapter cache time: 0.039053171407431364 Engine time: 0.1316727278754115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8467867663130164,
    "estimated_duration": 3600.0091059215683,
    "input_throughput": 1394.7103610769004,
    "output_throughput": 1250.2101710233997,
    "total_throughput": 2644.9205321003,
    "itl": 22.420342635114334,
    "ttft": 4629.534223278433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1061953396908939,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.0044662212198154725
}
#Debug simulation 
Total elapsed time: 1.8468948742374778. Arrivals time: 0.062013568822294474 Scheduler time: 1.403272407129407 Scheduler overhead time: 0.1436844626441598 Adapter cache time: 0.03908973094075918 Engine time: 0.13288716040551662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8415031391195953,
    "estimated_duration": 3600.0194041615578,
    "input_throughput": 1394.7063713589569,
    "output_throughput": 1250.2065946636824,
    "total_throughput": 2644.912966022639,
    "itl": 22.420161255928697,
    "ttft": 4629.533223267327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.004464428125793536
}
#Debug simulation 
Total elapsed time: 1.8416092894040048. Arrivals time: 0.06404600664973259 Scheduler time: 1.39589107548818 Scheduler overhead time: 0.1425691000185907 Adapter cache time: 0.03890208061784506 Engine time: 0.13440343597903848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 135, 135, 1080, 135, 4320, 1080, 135, 135, 135, 4320, 4320, 135, 135, 1080, 1080, 1080, 4320, 4320, 135, 4320, 4320, 4320, 4320, 1080, 135, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60750 . Total input tokens: 13485916 . Total output tokens: 12171682
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8354313909076154,
    "estimated_duration": 3600.0180988904326,
    "input_throughput": 1394.706877042513,
    "output_throughput": 1250.2070479554502,
    "total_throughput": 2644.9139249979635,
    "itl": 22.420359425770464,
    "ttft": 4629.517553373412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 20382,
    "finished_requests": 20355,
    "scheduler_time": 0.004483109315985612
}
#Debug simulation 
Total elapsed time: 1.8355565750971437. Arrivals time: 0.060121006332337856 Scheduler time: 1.3986464790068567 Scheduler overhead time: 0.14170785201713443 Adapter cache time: 0.038918593898415565 Engine time: 0.13025529962033033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8085512071847916,
    "estimated_duration": 3599.9148701978233,
    "input_throughput": 1397.8527774806719,
    "output_throughput": 1224.208115720754,
    "total_throughput": 2622.060893201426,
    "itl": 22.260719940758232,
    "ttft": 4854.139781233104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.00387134232572589
}
#Debug simulation 
Total elapsed time: 1.8086412651464343. Arrivals time: 0.06308286730200052 Scheduler time: 1.366452311631292 Scheduler overhead time: 0.14224063698202372 Adapter cache time: 0.038387763779610395 Engine time: 0.13218822563067079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8052527201361954,
    "estimated_duration": 3599.9280401336096,
    "input_throughput": 1397.847663591974,
    "output_throughput": 1224.203637091711,
    "total_throughput": 2622.051300683685,
    "itl": 22.26069861716395,
    "ttft": 4854.1189774044815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0038706334617207468
}
#Debug simulation 
Total elapsed time: 1.8053475092165172. Arrivals time: 0.06003636075183749 Scheduler time: 1.367927588056773 Scheduler overhead time: 0.14205951523035765 Adapter cache time: 0.038342987187206745 Engine time: 0.13086292427033186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7986697992309928,
    "estimated_duration": 3599.9281455424652,
    "input_throughput": 1397.8476226618452,
    "output_throughput": 1224.2036012460221,
    "total_throughput": 2622.051223907867,
    "itl": 22.260673909704227,
    "ttft": 4854.135898388304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0038706334617207468
}
#Debug simulation 
Total elapsed time: 1.7987950681708753. Arrivals time: 0.059455924201756716 Scheduler time: 1.3629203280434012 Scheduler overhead time: 0.14218040369451046 Adapter cache time: 0.03802987793460488 Engine time: 0.1299252863973379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7998388740234077,
    "estimated_duration": 3599.925031547186,
    "input_throughput": 1397.848831823386,
    "output_throughput": 1224.2046602025841,
    "total_throughput": 2622.05349202597,
    "itl": 22.260695934000424,
    "ttft": 4854.1075090633685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.003890857501926993
}
#Debug simulation 
Total elapsed time: 1.7999357846565545. Arrivals time: 0.0629119286313653 Scheduler time: 1.3600915716961026 Scheduler overhead time: 0.1412661182694137 Adapter cache time: 0.03794550430029631 Engine time: 0.13172744400799274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8223770139738917,
    "estimated_duration": 3599.9255386215873,
    "input_throughput": 1397.8486349267137,
    "output_throughput": 1224.2044877648939,
    "total_throughput": 2622.0531226916073,
    "itl": 22.260809466654443,
    "ttft": 4854.11979566386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0038859787078767173
}
#Debug simulation 
Total elapsed time: 1.8224675357341766. Arrivals time: 0.06421803124248981 Scheduler time: 1.3761742189526558 Scheduler overhead time: 0.14366845320910215 Adapter cache time: 0.03829380590468645 Engine time: 0.1335338237695396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8148844284005463,
    "estimated_duration": 3599.9150498304666,
    "input_throughput": 1397.852707729029,
    "output_throughput": 1224.2080546338293,
    "total_throughput": 2622.060762362858,
    "itl": 22.26064682714936,
    "ttft": 4854.135242578566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0038672975176846404
}
#Debug simulation 
Total elapsed time: 1.8149721040390432. Arrivals time: 0.06270320992916822 Scheduler time: 1.3725112839601934 Scheduler overhead time: 0.14201704319566488 Adapter cache time: 0.03861321695148945 Engine time: 0.1329901646822691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 66, 66, 1080, 66, 4320, 1080, 66, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 4320, 4320, 66, 4320, 4320, 4320, 4320, 1080, 66, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 60060 . Total input tokens: 13325187 . Total output tokens: 12041045
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8005875800736248,
    "estimated_duration": 3599.9283095010887,
    "input_throughput": 1397.8475589969185,
    "output_throughput": 1224.203545489707,
    "total_throughput": 2622.0511044866253,
    "itl": 22.260823129542402,
    "ttft": 4854.129720512955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 20177,
    "finished_requests": 20150,
    "scheduler_time": 0.0038738442837529695
}
#Debug simulation 
Total elapsed time: 1.8006722503341734. Arrivals time: 0.06142319133505225 Scheduler time: 1.3625260726548731 Scheduler overhead time: 0.14162929961457849 Adapter cache time: 0.03823204291984439 Engine time: 0.13091979222372174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.8009127280674875,
    "estimated_duration": 3599.149597013343,
    "input_throughput": 1393.154928642276,
    "output_throughput": 1220.2457501751123,
    "total_throughput": 2613.4006788173883,
    "itl": 22.187139162893875,
    "ttft": 5599.197810047302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 20063,
    "finished_requests": 20032,
    "scheduler_time": 0.004361973932788291
}
#Debug simulation 
Total elapsed time: 1.801066866144538. Arrivals time: 0.06341662630438805 Scheduler time: 1.3565104552544653 Scheduler overhead time: 0.14341499330475926 Adapter cache time: 0.03730157157406211 Engine time: 0.13392866170033813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7921177190728486,
    "estimated_duration": 3599.162970384456,
    "input_throughput": 1393.3814726551007,
    "output_throughput": 1220.2417718058682,
    "total_throughput": 2613.623244460969,
    "itl": 22.186851343285387,
    "ttft": 5419.763728140888,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.004345085836618151
}
#Debug simulation 
Total elapsed time: 1.7922021262347698. Arrivals time: 0.06090792687609792 Scheduler time: 1.3562027672305703 Scheduler overhead time: 0.14203330921009183 Adapter cache time: 0.03725401312112808 Engine time: 0.1298043425194919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7978453966788948,
    "estimated_duration": 3599.16616387738,
    "input_throughput": 1393.380236325998,
    "output_throughput": 1220.240689101351,
    "total_throughput": 2613.6209254273494,
    "itl": 22.18683811149368,
    "ttft": 5419.692331193415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0043344942625085725
}
#Debug simulation 
Total elapsed time: 1.7979691200889647. Arrivals time: 0.06130453711375594 Scheduler time: 1.3595483154058456 Scheduler overhead time: 0.14279650896787643 Adapter cache time: 0.03725170437246561 Engine time: 0.13057473907247186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.815506428014487,
    "estimated_duration": 3599.1552885951846,
    "input_throughput": 1393.3844465925915,
    "output_throughput": 1220.2443762059008,
    "total_throughput": 2613.6288227984924,
    "itl": 22.186835957115438,
    "ttft": 5419.703646050432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.004329615468458297
}
#Debug simulation 
Total elapsed time: 1.8156069619581103. Arrivals time: 0.06397490063682199 Scheduler time: 1.3613044270314276 Scheduler overhead time: 0.15482604876160622 Adapter cache time: 0.03802143596112728 Engine time: 0.13092606281861663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8086027600802481,
    "estimated_duration": 3599.1670238332376,
    "input_throughput": 1393.3799034029946,
    "output_throughput": 1220.2403975469103,
    "total_throughput": 2613.620300949905,
    "itl": 22.186739313534357,
    "ttft": 5419.692775980527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0043344942625085725
}
#Debug simulation 
Total elapsed time: 1.808706727810204. Arrivals time: 0.061451964545995 Scheduler time: 1.3684040769003332 Scheduler overhead time: 0.14398616133257747 Adapter cache time: 0.037481308449059725 Engine time: 0.1306981504894793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.801963532809168,
    "estimated_duration": 3599.1679998134546,
    "input_throughput": 1393.3795255625546,
    "output_throughput": 1220.2400666564133,
    "total_throughput": 2613.619592218968,
    "itl": 22.18649968540348,
    "ttft": 5419.71079044894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.004352341466691624
}
#Debug simulation 
Total elapsed time: 1.8020494296215475. Arrivals time: 0.06195986736565828 Scheduler time: 1.3616986465640366 Scheduler overhead time: 0.14206992648541927 Adapter cache time: 0.037467407528311014 Engine time: 0.13285284535959363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 1080, 33, 33, 1080, 33, 4320, 1080, 33, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 4320, 4320, 33, 4320, 4320, 4320, 4320, 1080, 33, 1080, 1080, 1080, 1080, 4320]
Prompts retrieved: 59730 . Total input tokens: 13255099 . Total output tokens: 11977724
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7995790070854127,
    "estimated_duration": 3599.1670282938376,
    "input_throughput": 1393.37990167612,
    "output_throughput": 1220.2403960346148,
    "total_throughput": 2613.6202977107346,
    "itl": 22.186745803934286,
    "ttft": 5419.689346489653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 20063,
    "finished_requests": 20033,
    "scheduler_time": 0.0043344942625085725
}
#Debug simulation 
Total elapsed time: 1.7996940077282488. Arrivals time: 0.06327892746776342 Scheduler time: 1.3556477082893252 Scheduler overhead time: 0.14385029906407 Adapter cache time: 0.03746266011148691 Engine time: 0.1329501075670123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.748169723432511,
    "estimated_duration": 3599.9634299126933,
    "input_throughput": 1284.423325409208,
    "output_throughput": 1164.5323852919448,
    "total_throughput": 2448.955710701153,
    "itl": 21.948295517629507,
    "ttft": 6314.544459551369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0015187226776460306
}
#Debug simulation 
Total elapsed time: 1.748249146156013. Arrivals time: 0.05848309537395835 Scheduler time: 1.3055803021416068 Scheduler overhead time: 0.145406492985785 Adapter cache time: 0.037788134068250656 Engine time: 0.13343102391809225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7438791212625802,
    "estimated_duration": 3599.9593206153663,
    "input_throughput": 1284.4247915583692,
    "output_throughput": 1164.5337145874707,
    "total_throughput": 2448.9585061458397,
    "itl": 21.948400758135264,
    "ttft": 6314.519922161538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0014855302273070095
}
#Debug simulation 
Total elapsed time: 1.7439988274127245. Arrivals time: 0.05950736301019788 Scheduler time: 1.3030525855720043 Scheduler overhead time: 0.14437253959476948 Adapter cache time: 0.038038793951272964 Engine time: 0.13199597829952836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.746457904111594,
    "estimated_duration": 3599.959313439215,
    "input_throughput": 1284.4247941187389,
    "output_throughput": 1164.5337169088498,
    "total_throughput": 2448.958511027589,
    "itl": 21.948416262986978,
    "ttft": 6314.512225214456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.001475772639206458
}
#Debug simulation 
Total elapsed time: 1.7465657801367342. Arrivals time: 0.06010756175965071 Scheduler time: 1.3031146512366831 Scheduler overhead time: 0.14212227426469326 Adapter cache time: 0.037678370252251625 Engine time: 0.136869627982378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7549923080950975,
    "estimated_duration": 3599.972322011251,
    "input_throughput": 1284.4201528240385,
    "output_throughput": 1164.5295088429566,
    "total_throughput": 2448.9496616669953,
    "itl": 21.94848142019521,
    "ttft": 6314.624039174661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0015244354577053326
}
#Debug simulation 
Total elapsed time: 1.755085722077638. Arrivals time: 0.060930002480745316 Scheduler time: 1.3110458166338503 Scheduler overhead time: 0.14496696321293712 Adapter cache time: 0.0378617444075644 Engine time: 0.13261465448886156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7303308811970055,
    "estimated_duration": 3599.963447188867,
    "input_throughput": 1284.4233192452787,
    "output_throughput": 1164.5323797033705,
    "total_throughput": 2448.955698948649,
    "itl": 21.948412759493106,
    "ttft": 6314.607261401909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0014880321853340886
}
#Debug simulation 
Total elapsed time: 1.7304293038323522. Arrivals time: 0.059159331023693085 Scheduler time: 1.2903830176219344 Scheduler overhead time: 0.1436688327230513 Adapter cache time: 0.03789099305868149 Engine time: 0.13193838950246572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7372161969542503,
    "estimated_duration": 3599.963482867591,
    "input_throughput": 1284.4233065155424,
    "output_throughput": 1164.5323681618563,
    "total_throughput": 2448.9556746773987,
    "itl": 21.948333248763642,
    "ttft": 6314.622144966017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.0015243103357014498
}
#Debug simulation 
Total elapsed time: 1.737298402003944. Arrivals time: 0.05773786874487996 Scheduler time: 1.2996465335600078 Scheduler overhead time: 0.14340632408857346 Adapter cache time: 0.03781612776219845 Engine time: 0.13154299464076757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 270, 270, 540, 270, 4320, 540, 270, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 4320, 4320, 270, 4320, 4320, 4320, 4320, 540, 270, 540, 540, 540, 540, 4320]
Prompts retrieved: 56160 . Total input tokens: 12472005 . Total output tokens: 11265613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.738094873726368,
    "estimated_duration": 3599.963457404493,
    "input_throughput": 1284.423315600467,
    "output_throughput": 1164.5323763987737,
    "total_throughput": 2448.955691999241,
    "itl": 21.948362545200524,
    "ttft": 6314.576914041882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 18922,
    "finished_requests": 18889,
    "scheduler_time": 0.001483987377292839
}
#Debug simulation 
Total elapsed time: 1.7382202427834272. Arrivals time: 0.05810421286150813 Scheduler time: 1.2985008703544736 Scheduler overhead time: 0.1444122949615121 Adapter cache time: 0.03759082639589906 Engine time: 0.13219832489266992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7146805990487337,
    "estimated_duration": 3599.913764860874,
    "input_throughput": 1267.1131304658595,
    "output_throughput": 1126.863382005701,
    "total_throughput": 2393.9765124715605,
    "itl": 21.63999413534804,
    "ttft": 5873.931558292718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.00460653731711918
}
#Debug simulation 
Total elapsed time: 1.714792013168335. Arrivals time: 0.0584004670381546 Scheduler time: 1.27073621051386 Scheduler overhead time: 0.14525035163387656 Adapter cache time: 0.0361343608237803 Engine time: 0.13655889686197042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7198866279795766,
    "estimated_duration": 3599.8956674253504,
    "input_throughput": 1267.119500511077,
    "output_throughput": 1126.8690469858236,
    "total_throughput": 2393.9885474969005,
    "itl": 21.639895340137176,
    "ttft": 5873.906922257957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.004631640151375702
}
#Debug simulation 
Total elapsed time: 1.719995365012437. Arrivals time: 0.059446245431900024 Scheduler time: 1.2720124535262585 Scheduler overhead time: 0.14855342265218496 Adapter cache time: 0.03651684010401368 Engine time: 0.13484683958813548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7129430761560798,
    "estimated_duration": 3599.895260527533,
    "input_throughput": 1267.119643734177,
    "output_throughput": 1126.8691743563504,
    "total_throughput": 2393.9888180905273,
    "itl": 21.63990784233231,
    "ttft": 5873.907536368535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.004631640151375702
}
#Debug simulation 
Total elapsed time: 1.7131000021472573. Arrivals time: 0.059006744995713234 Scheduler time: 1.2693455554544926 Scheduler overhead time: 0.14530452620238066 Adapter cache time: 0.036597429774701595 Engine time: 0.13516921270638704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.7097830763086677,
    "estimated_duration": 3599.913576367277,
    "input_throughput": 1267.11319681265,
    "output_throughput": 1126.8634410089319,
    "total_throughput": 2393.976637821582,
    "itl": 21.639905734326568,
    "ttft": 5873.936487753655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.004603326495086957
}
#Debug simulation 
Total elapsed time: 1.7099049123935401. Arrivals time: 0.059047230053693056 Scheduler time: 1.2668195380829275 Scheduler overhead time: 0.14560822723433375 Adapter cache time: 0.036301044281572104 Engine time: 0.13434117240831256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7111010989174247,
    "estimated_duration": 3599.8956490357637,
    "input_throughput": 1267.119506983988,
    "output_throughput": 1126.8690527422839,
    "total_throughput": 2393.988559726272,
    "itl": 21.63991529960729,
    "ttft": 5873.898655198616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.004643774575499451
}
#Debug simulation 
Total elapsed time: 1.7111976859159768. Arrivals time: 0.05918243294581771 Scheduler time: 1.2673825807869434 Scheduler overhead time: 0.14417273737490177 Adapter cache time: 0.03642468200996518 Engine time: 0.136660760268569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.7023465619422495,
    "estimated_duration": 3599.91357744177,
    "input_throughput": 1267.1131964344452,
    "output_throughput": 1126.8634406725885,
    "total_throughput": 2393.9766371070336,
    "itl": 21.63999373535848,
    "ttft": 5873.909964770681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.004606537317119179
}
#Debug simulation 
Total elapsed time: 1.702431655023247. Arrivals time: 0.057285159826278687 Scheduler time: 1.2569063720293343 Scheduler overhead time: 0.14549204194918275 Adapter cache time: 0.03632588079199195 Engine time: 0.13894252432510257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 135, 135, 540, 135, 4320, 540, 135, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 4320, 4320, 135, 4320, 4320, 4320, 4320, 540, 135, 540, 540, 540, 540, 4320]
Prompts retrieved: 54810 . Total input tokens: 12158037 . Total output tokens: 11000916
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7039669789373875,
    "estimated_duration": 3599.9007907141777,
    "input_throughput": 1267.117697178275,
    "output_throughput": 1126.8674432539615,
    "total_throughput": 2393.9851404322367,
    "itl": 21.63991882645517,
    "ttft": 5873.877974321785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 18499,
    "finished_requests": 18469,
    "scheduler_time": 0.004643774575499451
}
#Debug simulation 
Total elapsed time: 1.7040619859471917. Arrivals time: 0.05802770238369703 Scheduler time: 1.2615478355437517 Scheduler overhead time: 0.1460010795854032 Adapter cache time: 0.03635291010141373 Engine time: 0.13444504793733358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.683200070168823,
    "estimated_duration": 3599.9769461518704,
    "input_throughput": 1244.5724144953972,
    "output_throughput": 1110.7157239643377,
    "total_throughput": 2355.288138459735,
    "itl": 21.529720678154728,
    "ttft": 6142.316848720502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0004919242130688206
}
#Debug simulation 
Total elapsed time: 1.683283744379878. Arrivals time: 0.05758702615275979 Scheduler time: 1.244027582462877 Scheduler overhead time: 0.14522879989817739 Adapter cache time: 0.035720767453312874 Engine time: 0.1331651951186359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6806843080557883,
    "estimated_duration": 3599.9625584402656,
    "input_throughput": 1244.5773885885108,
    "output_throughput": 1110.7201630820373,
    "total_throughput": 2355.2975516705483,
    "itl": 21.529674153639416,
    "ttft": 6142.158088138071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.00048062377495409906
}
#Debug simulation 
Total elapsed time: 1.6807985133491457. Arrivals time: 0.05674456572160125 Scheduler time: 1.241854791995138 Scheduler overhead time: 0.14561457093805075 Adapter cache time: 0.035338768269866705 Engine time: 0.1335040181875229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7015239177271724,
    "estimated_duration": 3599.9625479552537,
    "input_throughput": 1244.5773922133842,
    "output_throughput": 1110.7201663170472,
    "total_throughput": 2355.297558530431,
    "itl": 21.529685068335812,
    "ttft": 6142.1621647894735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.00048062377495409906
}
#Debug simulation 
Total elapsed time: 1.7016485300846398. Arrivals time: 0.05831582611426711 Scheduler time: 1.2537718950770795 Scheduler overhead time: 0.14796513877809048 Adapter cache time: 0.03545624343678355 Engine time: 0.13780459109693766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6821847530081868,
    "estimated_duration": 3599.95871356946,
    "input_throughput": 1244.5787178368848,
    "output_throughput": 1110.7213493666222,
    "total_throughput": 2355.300067203507,
    "itl": 21.529644887074483,
    "ttft": 6142.27037383189,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.00047657896691284977
}
#Debug simulation 
Total elapsed time: 1.6822665869258344. Arrivals time: 0.0569086903706193 Scheduler time: 1.241981737781316 Scheduler overhead time: 0.14601084357127547 Adapter cache time: 0.03562595695257187 Engine time: 0.13412529788911343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.675973602104932,
    "estimated_duration": 3599.9627009758524,
    "input_throughput": 1244.5773393111758,
    "output_throughput": 1110.7201191045954,
    "total_throughput": 2355.297458415771,
    "itl": 21.52965250492247,
    "ttft": 6142.132079156857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.00048062377495409906
}
#Debug simulation 
Total elapsed time: 1.6760613238438964. Arrivals time: 0.055636045057326555 Scheduler time: 1.2369443215429783 Scheduler overhead time: 0.14475219883024693 Adapter cache time: 0.035523996222764254 Engine time: 0.13540538493543863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6982488129287958,
    "estimated_duration": 3599.9770375475173,
    "input_throughput": 1244.5723828983898,
    "output_throughput": 1110.7156957656628,
    "total_throughput": 2355.2880786640526,
    "itl": 21.529771156788623,
    "ttft": 6142.287850940363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.0004919242130688206
}
#Debug simulation 
Total elapsed time: 1.6983308526687324. Arrivals time: 0.055427238810807467 Scheduler time: 1.259737268090248 Scheduler overhead time: 0.14626561431214213 Adapter cache time: 0.03548418637365103 Engine time: 0.13359903683885932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 66, 66, 540, 66, 4320, 540, 66, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 4320, 4320, 66, 4320, 4320, 4320, 4320, 540, 66, 540, 540, 540, 540, 4320]
Prompts retrieved: 54120 . Total input tokens: 12010651 . Total output tokens: 10862732
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.681978637818247,
    "estimated_duration": 3599.9627560131535,
    "input_throughput": 1244.5773202837072,
    "output_throughput": 1110.720102123576,
    "total_throughput": 2355.297422407283,
    "itl": 21.529745886653277,
    "ttft": 6142.190629778086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 18275,
    "finished_requests": 18244,
    "scheduler_time": 0.00048383459698632197
}
#Debug simulation 
Total elapsed time: 1.6820585140958428. Arrivals time: 0.055240397341549397 Scheduler time: 1.242000161204487 Scheduler overhead time: 0.14512486569583416 Adapter cache time: 0.035329665057361126 Engine time: 0.1366172358393669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6837124340236187,
    "estimated_duration": 3599.860172203326,
    "input_throughput": 1244.147212878754,
    "output_throughput": 1110.001446960176,
    "total_throughput": 2354.14865983893,
    "itl": 21.522489840030683,
    "ttft": 4195.276881173669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6837940462864935. Arrivals time: 0.055025114212185144 Scheduler time: 1.2460584077052772 Scheduler overhead time: 0.14611536590382457 Adapter cache time: 0.03489102842286229 Engine time: 0.13382157310843468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.682319943793118,
    "estimated_duration": 3599.866584730893,
    "input_throughput": 1244.1449966498712,
    "output_throughput": 1109.9994696883214,
    "total_throughput": 2354.1444663381926,
    "itl": 21.5226580362089,
    "ttft": 4195.375374843499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.682405306957662. Arrivals time: 0.05571354320272803 Scheduler time: 1.24301493819803 Scheduler overhead time: 0.14594171894714236 Adapter cache time: 0.03492948180064559 Engine time: 0.13477743975818157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6911889067851007,
    "estimated_duration": 3599.8665031970563,
    "input_throughput": 1244.1450248286703,
    "output_throughput": 1109.9994948288413,
    "total_throughput": 2354.1445196575114,
    "itl": 21.522657337348853,
    "ttft": 4195.366463073787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6912797559052706. Arrivals time: 0.0563465035520494 Scheduler time: 1.2537827580235898 Scheduler overhead time: 0.1456153760664165 Adapter cache time: 0.03480867110192776 Engine time: 0.13295433577150106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6830950086005032,
    "estimated_duration": 3599.8606526871476,
    "input_throughput": 1244.1470468188243,
    "output_throughput": 1110.0012988050698,
    "total_throughput": 2354.148345623894,
    "itl": 21.522537919773793,
    "ttft": 4195.325645611061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6831886619329453. Arrivals time: 0.057065187487751245 Scheduler time: 1.24287068285048 Scheduler overhead time: 0.14629778265953064 Adapter cache time: 0.03495935816317797 Engine time: 0.1340529383160174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7033202047459781,
    "estimated_duration": 3599.8488519746406,
    "input_throughput": 1244.1511252738428,
    "output_throughput": 1110.0049375151234,
    "total_throughput": 2354.156062788966,
    "itl": 21.522666719782194,
    "ttft": 4195.334720189881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7034076428972185. Arrivals time: 0.057366793509572744 Scheduler time: 1.2578656687401235 Scheduler overhead time: 0.14677779516205192 Adapter cache time: 0.03496272396296263 Engine time: 0.13818001514300704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6803700299933553,
    "estimated_duration": 3599.8563564493243,
    "input_throughput": 1244.1485316424037,
    "output_throughput": 1110.0026235328066,
    "total_throughput": 2354.15115517521,
    "itl": 21.52254215371781,
    "ttft": 4195.284667327624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6804560241289437. Arrivals time: 0.05841440940275788 Scheduler time: 1.2390346815809608 Scheduler overhead time: 0.1458906144835055 Adapter cache time: 0.03476216737180948 Engine time: 0.13443890027701855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 540, 33, 33, 540, 33, 4320, 540, 33, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 4320, 4320, 33, 4320, 4320, 4320, 4320, 540, 33, 540, 540, 540, 540, 4320]
Prompts retrieved: 53790 . Total input tokens: 11938721 . Total output tokens: 10793407
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6802692650817335,
    "estimated_duration": 3599.848849085362,
    "input_throughput": 1244.1511262724123,
    "output_throughput": 1110.0049384060258,
    "total_throughput": 2354.156064678438,
    "itl": 21.52264624136944,
    "ttft": 4195.346063703651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 18174,
    "finished_requests": 18153,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6804146450012922. Arrivals time: 0.05693327868357301 Scheduler time: 1.2385585568845272 Scheduler overhead time: 0.14641027618199587 Adapter cache time: 0.03469412727281451 Engine time: 0.1358561823144555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6392508340068161,
    "estimated_duration": 3599.8012425564007,
    "input_throughput": 1196.2624350176272,
    "output_throughput": 1062.4997721495938,
    "total_throughput": 2258.762207167221,
    "itl": 21.249537674113306,
    "ttft": 3936.763786565884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6393340709619224. Arrivals time: 0.051574029959738255 Scheduler time: 1.2022710656747222 Scheduler overhead time: 0.14680343540385365 Adapter cache time: 0.03433137387037277 Engine time: 0.13602889887988567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6300534452311695,
    "estimated_duration": 3599.8038779821636,
    "input_throughput": 1196.2615592307934,
    "output_throughput": 1062.4989942907525,
    "total_throughput": 2258.760553521546,
    "itl": 21.24963886070021,
    "ttft": 3936.690223415408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6301487619057298. Arrivals time: 0.05322594475001097 Scheduler time: 1.1905868500471115 Scheduler overhead time: 0.14645720645785332 Adapter cache time: 0.03397547407075763 Engine time: 0.13754203915596008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6319704856723547,
    "estimated_duration": 3599.803402963254,
    "input_throughput": 1196.2617170857643,
    "output_throughput": 1062.4991344948296,
    "total_throughput": 2258.760851580594,
    "itl": 21.249634537871984,
    "ttft": 3936.665829185938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6320572416298091. Arrivals time: 0.054221843369305134 Scheduler time: 1.1942220241762698 Scheduler overhead time: 0.14661179576069117 Adapter cache time: 0.034119775518774986 Engine time: 0.13457412691786885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6272130953148007,
    "estimated_duration": 3599.8043407866294,
    "input_throughput": 1196.2614054348815,
    "output_throughput": 1062.498857691862,
    "total_throughput": 2258.760263126743,
    "itl": 21.249671551540406,
    "ttft": 3936.6713448650407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6273256880231202. Arrivals time: 0.05544685898348689 Scheduler time: 1.1871540290303528 Scheduler overhead time: 0.14745049457997084 Adapter cache time: 0.034032038412988186 Engine time: 0.13473717775195837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6330807721242309,
    "estimated_duration": 3599.7885708559916,
    "input_throughput": 1196.2666460091589,
    "output_throughput": 1062.5035122800298,
    "total_throughput": 2258.7701582891887,
    "itl": 21.24970111323381,
    "ttft": 3936.7816057116875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6331707299686968. Arrivals time: 0.055942898616194725 Scheduler time: 1.1931863562203944 Scheduler overhead time: 0.1467909482307732 Adapter cache time: 0.03433989733457565 Engine time: 0.1343747559003532 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6232561352662742,
    "estimated_duration": 3599.8011976418393,
    "input_throughput": 1196.2624499433412,
    "output_throughput": 1062.4997854063568,
    "total_throughput": 2258.7622353496977,
    "itl": 21.249542685791173,
    "ttft": 3936.730319307347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6233361279591918. Arrivals time: 0.05405913479626179 Scheduler time: 1.1863359846174717 Scheduler overhead time: 0.14666186179965734 Adapter cache time: 0.03412411222234368 Engine time: 0.13387740962207317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 135, 135, 270, 135, 4320, 270, 135, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 4320, 4320, 135, 4320, 4320, 4320, 4320, 270, 135, 270, 270, 270, 270, 4320]
Prompts retrieved: 51840 . Total input tokens: 11504293 . Total output tokens: 10401025
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.653255030978471,
    "estimated_duration": 3599.7921433609163,
    "input_throughput": 1196.2654588104779,
    "output_throughput": 1062.5024578305286,
    "total_throughput": 2258.7679166410067,
    "itl": 21.249759057794424,
    "ttft": 3936.8059570647183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 17531,
    "finished_requests": 17512,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6533352453261614. Arrivals time: 0.055540215224027634 Scheduler time: 1.2007312951609492 Scheduler overhead time: 0.1471673254854977 Adapter cache time: 0.03433961374685168 Engine time: 0.146709019318223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6405013990588486,
    "estimated_duration": 3599.822809541191,
    "input_throughput": 1174.007506369083,
    "output_throughput": 1063.4101183685489,
    "total_throughput": 2237.4176247376317,
    "itl": 21.23266009076278,
    "ttft": 4402.489802934322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6406056811101735. Arrivals time: 0.054999660700559616 Scheduler time: 1.201195306610316 Scheduler overhead time: 0.14730272721499205 Adapter cache time: 0.033457518089562654 Engine time: 0.13504014955833554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6382835232652724,
    "estimated_duration": 3599.8151368800013,
    "input_throughput": 1174.0100086536415,
    "output_throughput": 1063.4123849253674,
    "total_throughput": 2237.4223935790087,
    "itl": 21.232759139793373,
    "ttft": 4402.4642431142265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6384297511540353. Arrivals time: 0.05381166096776724 Scheduler time: 1.195122023113072 Scheduler overhead time: 0.1503355037420988 Adapter cache time: 0.03336739121004939 Engine time: 0.13695818092674017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6499650380574167,
    "estimated_duration": 3599.814061016999,
    "input_throughput": 1174.0103595256342,
    "output_throughput": 1063.4127027434606,
    "total_throughput": 2237.4230622690948,
    "itl": 21.23277219017733,
    "ttft": 4402.474568310038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6500592529773712. Arrivals time: 0.055556587409228086 Scheduler time: 1.2070989403873682 Scheduler overhead time: 0.14859611634165049 Adapter cache time: 0.03358675492927432 Engine time: 0.13608274841681123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6297254851087928,
    "estimated_duration": 3599.8230450999226,
    "input_throughput": 1174.007429546496,
    "output_throughput": 1063.4100487830344,
    "total_throughput": 2237.4174783295302,
    "itl": 21.23252294611323,
    "ttft": 4402.50572549821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.62981586297974. Arrivals time: 0.052097457461059093 Scheduler time: 1.1927278861403465 Scheduler overhead time: 0.14583436911925673 Adapter cache time: 0.03308458626270294 Engine time: 0.13787190755829215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6240024310536683,
    "estimated_duration": 3599.8162873569945,
    "input_throughput": 1174.0096334479651,
    "output_throughput": 1063.4120450659452,
    "total_throughput": 2237.4216785139106,
    "itl": 21.23276472450991,
    "ttft": 4402.442544234075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6240851269103587. Arrivals time: 0.05241656070575118 Scheduler time: 1.1883227000944316 Scheduler overhead time: 0.14684185944497585 Adapter cache time: 0.033540493343025446 Engine time: 0.13450349122285843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6390697970055044,
    "estimated_duration": 3599.8226577159444,
    "input_throughput": 1174.0075558837386,
    "output_throughput": 1063.410163218676,
    "total_throughput": 2237.4177191024146,
    "itl": 21.232774643877484,
    "ttft": 4402.454174091593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.639179591089487. Arrivals time: 0.05542195774614811 Scheduler time: 1.195772871375084 Scheduler overhead time: 0.15111713018268347 Adapter cache time: 0.03346615191549063 Engine time: 0.1346173007041216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 66, 66, 270, 66, 4320, 270, 66, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 4320, 4320, 66, 4320, 4320, 4320, 4320, 270, 66, 270, 270, 270, 270, 4320]
Prompts retrieved: 51150 . Total input tokens: 11347985 . Total output tokens: 10266873
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.630315009970218,
    "estimated_duration": 3599.817670645781,
    "input_throughput": 1174.009182315572,
    "output_throughput": 1063.4116364324832,
    "total_throughput": 2237.420818748055,
    "itl": 21.23294112914705,
    "ttft": 4402.46051583248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 17310,
    "finished_requests": 17289,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6304108882322907. Arrivals time: 0.05445902328938246 Scheduler time: 1.1930669792927802 Scheduler overhead time: 0.14673244440928102 Adapter cache time: 0.03351977653801441 Engine time: 0.13411289686337113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.624389807227999,
    "estimated_duration": 3599.8857655990837,
    "input_throughput": 1174.7603327896768,
    "output_throughput": 1035.0850673118227,
    "total_throughput": 2209.8454001014993,
    "itl": 21.073129343050315,
    "ttft": 5271.242466062534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6245380071923137. Arrivals time: 0.0552693922072649 Scheduler time: 1.1793347438797355 Scheduler overhead time: 0.14861593069508672 Adapter cache time: 0.033503380604088306 Engine time: 0.13852413464337587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6118192998692393,
    "estimated_duration": 3599.8868482438006,
    "input_throughput": 1174.7599794874423,
    "output_throughput": 1035.0847560160996,
    "total_throughput": 2209.844735503542,
    "itl": 21.073096835204638,
    "ttft": 5271.226850557774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.611930469982326. Arrivals time: 0.0526687023229897 Scheduler time: 1.171015595085919 Scheduler overhead time: 0.14753571432083845 Adapter cache time: 0.03336768690496683 Engine time: 0.138431494589895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.614801756106317,
    "estimated_duration": 3599.887966355086,
    "input_throughput": 1174.759614611534,
    "output_throughput": 1035.0844345227758,
    "total_throughput": 2209.84404913431,
    "itl": 21.073043330761784,
    "ttft": 5271.271266194266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6148840258829296. Arrivals time: 0.053773355670273304 Scheduler time: 1.170530968811363 Scheduler overhead time: 0.1483969260007143 Adapter cache time: 0.033600788563489914 Engine time: 0.13938121078535914 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6018375800922513,
    "estimated_duration": 3599.8854803457316,
    "input_throughput": 1174.760425877172,
    "output_throughput": 1035.085149331511,
    "total_throughput": 2209.8455752086834,
    "itl": 21.073085000819447,
    "ttft": 5271.197134020618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6019478552043438. Arrivals time: 0.05437791580334306 Scheduler time: 1.1620129756629467 Scheduler overhead time: 0.1479598470032215 Adapter cache time: 0.03326240414753556 Engine time: 0.13547131745144725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6070922170765698,
    "estimated_duration": 3599.8879071167453,
    "input_throughput": 1174.7596339429167,
    "output_throughput": 1035.0844515557187,
    "total_throughput": 2209.844085498635,
    "itl": 21.072996678880237,
    "ttft": 5271.288062260946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6071903049014509. Arrivals time: 0.05151133006438613 Scheduler time: 1.170675799716264 Scheduler overhead time: 0.14764136215671897 Adapter cache time: 0.033558431547135115 Engine time: 0.13499952713027596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6098217167891562,
    "estimated_duration": 3599.9065945425236,
    "input_throughput": 1174.7535356642836,
    "output_throughput": 1035.0790783430102,
    "total_throughput": 2209.8326140072936,
    "itl": 21.073124856879343,
    "ttft": 5271.207508870333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6099150269292295. Arrivals time: 0.05497475806623697 Scheduler time: 1.1662505338899791 Scheduler overhead time: 0.14783756900578737 Adapter cache time: 0.03334125783294439 Engine time: 0.13810551911592484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 270, 33, 33, 270, 33, 4320, 270, 33, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 4320, 4320, 33, 4320, 4320, 4320, 4320, 270, 33, 270, 270, 270, 270, 4320]
Prompts retrieved: 50820 . Total input tokens: 11277871 . Total output tokens: 10200214
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6221668813377619,
    "estimated_duration": 3599.8911159429917,
    "input_throughput": 1174.75858680026,
    "output_throughput": 1035.0835289149918,
    "total_throughput": 2209.842115715252,
    "itl": 21.073128920932213,
    "ttft": 5271.309155065203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 17187,
    "finished_requests": 17162,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6222523599863052. Arrivals time: 0.054116467013955116 Scheduler time: 1.173568082973361 Scheduler overhead time: 0.1546124629676342 Adapter cache time: 0.033820715732872486 Engine time: 0.13583171274513006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6019312050193548,
    "estimated_duration": 3599.554958151882,
    "input_throughput": 1131.9132635474218,
    "output_throughput": 1038.0130442343268,
    "total_throughput": 2169.9263077817486,
    "itl": 21.061780314361698,
    "ttft": 5172.050728606675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 2.0015664216633698e-05
}
#Debug simulation 
Total elapsed time: 1.602035601157695. Arrivals time: 0.05426050489768386 Scheduler time: 1.1610126537270844 Scheduler overhead time: 0.147993094753474 Adapter cache time: 0.03192501375451684 Engine time: 0.13785694260150194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5905254282988608,
    "estimated_duration": 3599.5646858134633,
    "input_throughput": 1131.9102046027638,
    "output_throughput": 1038.010239050786,
    "total_throughput": 2169.9204436535497,
    "itl": 21.061901248428853,
    "ttft": 5171.936031415229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.5845734171501677e-05
}
#Debug simulation 
Total elapsed time: 1.5906230313703418. Arrivals time: 0.0501437489874661 Scheduler time: 1.1575493696145713 Scheduler overhead time: 0.14727046713232994 Adapter cache time: 0.03162628272548318 Engine time: 0.1353704361245036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6015571700409055,
    "estimated_duration": 3599.564414002302,
    "input_throughput": 1131.9102900758353,
    "output_throughput": 1038.0103174332612,
    "total_throughput": 2169.9206075090965,
    "itl": 21.061898190950053,
    "ttft": 5171.939031772173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.5845734171501677e-05
}
#Debug simulation 
Total elapsed time: 1.6017049001529813. Arrivals time: 0.053375291638076305 Scheduler time: 1.164904147386551 Scheduler overhead time: 0.14744999166578054 Adapter cache time: 0.03174890112131834 Engine time: 0.13509526476264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.6163282236084342,
    "estimated_duration": 3599.558245634523,
    "input_throughput": 1131.9122297691215,
    "output_throughput": 1038.012096215256,
    "total_throughput": 2169.9243259843774,
    "itl": 21.061841804867903,
    "ttft": 5172.00024670141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971345,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.667972018052808e-05
}
#Debug simulation 
Total elapsed time: 1.616420769598335. Arrivals time: 0.05323718627914786 Scheduler time: 1.1754787787795067 Scheduler overhead time: 0.14798379829153419 Adapter cache time: 0.031964605674147606 Engine time: 0.1388320722617209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6021016389131546,
    "estimated_duration": 3599.5646846889695,
    "input_throughput": 1131.9102049563692,
    "output_throughput": 1038.0102393750574,
    "total_throughput": 2169.9204443314266,
    "itl": 21.061917712800884,
    "ttft": 5171.971052013964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.5845734171501677e-05
}
#Debug simulation 
Total elapsed time: 1.602215921971947. Arrivals time: 0.05118301510810852 Scheduler time: 1.1661518975161016 Scheduler overhead time: 0.1482238434255123 Adapter cache time: 0.03178896987810731 Engine time: 0.13586927903816104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.6060544908978045,
    "estimated_duration": 3599.5538919412666,
    "input_throughput": 1131.9135988272853,
    "output_throughput": 1038.0133517003517,
    "total_throughput": 2169.926950527637,
    "itl": 21.061635761509372,
    "ttft": 5172.115782186238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.9181678207607294e-05
}
#Debug simulation 
Total elapsed time: 1.6061478108167648. Arrivals time: 0.053381895180791616 Scheduler time: 1.1647905986756086 Scheduler overhead time: 0.14846112485975027 Adapter cache time: 0.032048008404672146 Engine time: 0.13840913213789463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 66, 66, 135, 66, 4320, 135, 66, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 4320, 4320, 66, 4320, 4320, 4320, 4320, 135, 66, 135, 135, 135, 135, 4320]
Prompts retrieved: 49665 . Total input tokens: 11014448 . Total output tokens: 9974437
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6147968317382038,
    "estimated_duration": 3599.5646948661406,
    "input_throughput": 1131.9102017560813,
    "output_throughput": 1038.0102364402558,
    "total_throughput": 2169.920438196337,
    "itl": 21.061813950568993,
    "ttft": 5171.973818961728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1075786313414573,
    "arrivals": 16818,
    "finished_requests": 16794,
    "scheduler_time": 1.5845734171501677e-05
}
#Debug simulation 
Total elapsed time: 1.6148915658704937. Arrivals time: 0.05293681425973773 Scheduler time: 1.1769269234500825 Scheduler overhead time: 0.1476648231036961 Adapter cache time: 0.03190282313153148 Engine time: 0.1367065808735788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5839452077634633,
    "estimated_duration": 3599.903254334189,
    "input_throughput": 1143.6704569888416,
    "output_throughput": 1011.2071749753933,
    "total_throughput": 2154.8776319642348,
    "itl": 20.890353614709632,
    "ttft": 6077.324578925543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5840521319769323. Arrivals time: 0.053391752764582634 Scheduler time: 1.141591447405517 Scheduler overhead time: 0.1493400912731886 Adapter cache time: 0.03146545961499214 Engine time: 0.13886689394712448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.573579482268542,
    "estimated_duration": 3599.887499979508,
    "input_throughput": 1143.6754620869226,
    "output_throughput": 1011.2116003682676,
    "total_throughput": 2154.88706245519,
    "itl": 20.890392890516797,
    "ttft": 6077.291390303879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5736814802512527. Arrivals time: 0.05012810742482543 Scheduler time: 1.138307101558894 Scheduler overhead time: 0.14859291026368737 Adapter cache time: 0.03140582796186209 Engine time: 0.13613760191947222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5847194232046604,
    "estimated_duration": 3599.887492761109,
    "input_throughput": 1143.67546438019,
    "output_throughput": 1011.2116023959222,
    "total_throughput": 2154.8870667761125,
    "itl": 20.890377970813113,
    "ttft": 6077.276040051365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5849947021342814. Arrivals time: 0.05007414007559419 Scheduler time: 1.1449124081991613 Scheduler overhead time: 0.1497214795090258 Adapter cache time: 0.0314421933144331 Engine time: 0.13919599261134863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5879227849654853,
    "estimated_duration": 3599.90363328501,
    "input_throughput": 1143.6703365981582,
    "output_throughput": 1011.2070685287135,
    "total_throughput": 2154.8774051268715,
    "itl": 20.89039814990766,
    "ttft": 6077.380776391489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5880169169977307. Arrivals time: 0.05292916297912598 Scheduler time: 1.1485126004554331 Scheduler overhead time: 0.14885894116014242 Adapter cache time: 0.031595306005328894 Engine time: 0.13635364966467023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5773552302271128,
    "estimated_duration": 3599.8917927565017,
    "input_throughput": 1143.6740982837878,
    "output_throughput": 1011.2103945248301,
    "total_throughput": 2154.884492808618,
    "itl": 20.890363209702127,
    "ttft": 6077.229928314699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.577505776192993. Arrivals time: 0.05180065054446459 Scheduler time: 1.139141721650958 Scheduler overhead time: 0.1491843811236322 Adapter cache time: 0.03136793011799455 Engine time: 0.1364892302080989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5850646519102156,
    "estimated_duration": 3599.9027432524244,
    "input_throughput": 1143.6706193568712,
    "output_throughput": 1011.2073185374793,
    "total_throughput": 2154.8779378943505,
    "itl": 20.890418819256972,
    "ttft": 6077.237097214405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5852051037363708. Arrivals time: 0.05342389177531004 Scheduler time: 1.1448788908310235 Scheduler overhead time: 0.14772021770477295 Adapter cache time: 0.03123923297971487 Engine time: 0.1387822860851884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 135, 33, 33, 135, 33, 4320, 135, 33, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 4320, 4320, 33, 4320, 4320, 4320, 4320, 135, 33, 135, 135, 135, 135, 4320]
Prompts retrieved: 49335 . Total input tokens: 10942046 . Total output tokens: 9914900
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5749912159517407,
    "estimated_duration": 3599.891661723551,
    "input_throughput": 1143.6741399125383,
    "output_throughput": 1011.2104313320161,
    "total_throughput": 2154.884571244554,
    "itl": 20.89036993494982,
    "ttft": 6077.255894750118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 16681,
    "finished_requests": 16653,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5750654190778732. Arrivals time: 0.05017730267718434 Scheduler time: 1.1375434952788055 Scheduler overhead time: 0.1490821409970522 Adapter cache time: 0.031634020153433084 Engine time: 0.1374195022508502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.5753005449660122,
    "estimated_duration": 3599.917954994914,
    "input_throughput": 1109.8350156720849,
    "output_throughput": 1013.0755882754979,
    "total_throughput": 2122.910603947583,
    "itl": 20.87248263880007,
    "ttft": 5069.03472011969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.575385516975075. Arrivals time: 0.05108793778344989 Scheduler time: 1.139443185646087 Scheduler overhead time: 0.14878274081274867 Adapter cache time: 0.030674928333610296 Engine time: 0.13616379722952843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5854760399088264,
    "estimated_duration": 3599.9325461118106,
    "input_throughput": 1109.8305173287847,
    "output_throughput": 1013.071482114023,
    "total_throughput": 2122.9019994428077,
    "itl": 20.87257916573438,
    "ttft": 5069.041451899005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5855842721648514. Arrivals time: 0.05299341259524226 Scheduler time: 1.1469411998987198 Scheduler overhead time: 0.1489110728725791 Adapter cache time: 0.030816963873803616 Engine time: 0.1366357682272792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5890233791433275,
    "estimated_duration": 3599.9316937857875,
    "input_throughput": 1109.830780094168,
    "output_throughput": 1013.0717219705705,
    "total_throughput": 2122.902502064738,
    "itl": 20.872547729519386,
    "ttft": 5069.066178604289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5891235689632595. Arrivals time: 0.053263583686202765 Scheduler time: 1.1465440141037107 Scheduler overhead time: 0.14907908765599132 Adapter cache time: 0.030853915493935347 Engine time: 0.1397014488466084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.5703868446871638,
    "estimated_duration": 3599.917925488406,
    "input_throughput": 1109.83502476878,
    "output_throughput": 1013.0755965791102,
    "total_throughput": 2122.9106213478904,
    "itl": 20.87238786787614,
    "ttft": 5069.025578796794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5704745878465474. Arrivals time: 0.04980090353637934 Scheduler time: 1.1357366964221 Scheduler overhead time: 0.14883450930938125 Adapter cache time: 0.03060950944200158 Engine time: 0.13616636209189892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5806364389136434,
    "estimated_duration": 3599.9325579065944,
    "input_throughput": 1109.830513692547,
    "output_throughput": 1013.0714787948054,
    "total_throughput": 2122.9019924873523,
    "itl": 20.87254832595178,
    "ttft": 5069.060657450347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5807268698699772. Arrivals time: 0.050803403835743666 Scheduler time: 1.1417676024138927 Scheduler overhead time: 0.1490137712098658 Adapter cache time: 0.03066343255341053 Engine time: 0.13915005419403315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.581075005698949,
    "estimated_duration": 3599.9385987690835,
    "input_throughput": 1109.8286513459163,
    "output_throughput": 1013.0697788142843,
    "total_throughput": 2122.898430160201,
    "itl": 20.872462655604505,
    "ttft": 5069.050471068494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.581173209939152. Arrivals time: 0.052909708116203547 Scheduler time: 1.13853292260319 Scheduler overhead time: 0.14863308100029826 Adapter cache time: 0.030842019245028496 Engine time: 0.14086202811449766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [10 11 11]
Adapter prompts. [4320, 66, 33, 33, 66, 33, 4320, 66, 33, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 4320, 4320, 33, 4320, 4320, 4320, 4320, 66, 33, 66, 66, 66, 66, 4320]
Prompts retrieved: 48576 . Total input tokens: 10775207 . Total output tokens: 9751665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.5801064670085907,
    "estimated_duration": 3599.932785242629,
    "input_throughput": 1109.830443606664,
    "output_throughput": 1013.0714148192629,
    "total_throughput": 2122.901858425927,
    "itl": 20.872535626244414,
    "ttft": 5069.089841394035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 16446,
    "finished_requests": 16423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5801922921091318. Arrivals time: 0.05057518603280187 Scheduler time: 1.1437335340306163 Scheduler overhead time: 0.1488344888202846 Adapter cache time: 0.03061744710430503 Engine time: 0.13697169022634625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 1.0207889936864376,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.33826529898983,
    "ttft": 7313.056404827149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0208716508932412. Arrivals time: 0.030600612983107567 Scheduler time: 0.5662729828618467 Scheduler overhead time: 0.154789247084409 Adapter cache time: 0.039998206309974194 Engine time: 0.1560678854584694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 1.0039671049453318,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.338327526207124,
    "ttft": 7312.991316509849,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0040460396558046. Arrivals time: 0.030642849393188953 Scheduler time: 0.559203970246017 Scheduler overhead time: 0.15371944615617394 Adapter cache time: 0.03996051987633109 Engine time: 0.1474790656939149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9994837357662618,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.338328639736407,
    "ttft": 7312.985902077448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9995960649102926. Arrivals time: 0.0306193046271801 Scheduler time: 0.5572799253277481 Scheduler overhead time: 0.15349422441795468 Adapter cache time: 0.03992799809202552 Engine time: 0.14550431165844202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0021868129260838,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.338260969679116,
    "ttft": 7313.033418738659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0022901599295437. Arrivals time: 0.031041269656270742 Scheduler time: 0.5599487079307437 Scheduler overhead time: 0.15341418515890837 Adapter cache time: 0.03959566215053201 Engine time: 0.14544217148795724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9905265369452536,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.338332700930458,
    "ttft": 7313.0137484530305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9905944378115237. Arrivals time: 0.029797511640936136 Scheduler time: 0.5515188775025308 Scheduler overhead time: 0.15284011559560895 Adapter cache time: 0.039364883210510015 Engine time: 0.14445566106587648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9959585648030043,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.33827879350186,
    "ttft": 7313.041226312866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9960489720106125. Arrivals time: 0.030304439831525087 Scheduler time: 0.5544530535116792 Scheduler overhead time: 0.1541819334961474 Adapter cache time: 0.039634456392377615 Engine time: 0.14471085648983717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 270, 270, 540, 270, 1080, 540, 270, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 1080, 1080, 270, 1080, 1080, 1080, 1080, 540, 270, 540, 540, 540, 540, 1080]
Prompts retrieved: 20520 . Total input tokens: 4532934 . Total output tokens: 4138207
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9987118700519204,
    "estimated_duration": 3599.5655183592257,
    "input_throughput": 468.50571031381367,
    "output_throughput": 423.1207883928852,
    "total_throughput": 891.6264987066988,
    "itl": 19.338348852511817,
    "ttft": 7313.015190418764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 6922,
    "finished_requests": 6908,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9987742123194039. Arrivals time: 0.030374804977327585 Scheduler time: 0.5549656543880701 Scheduler overhead time: 0.15511187259107828 Adapter cache time: 0.03954560915008187 Engine time: 0.14633206836879253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9828263190574944,
    "estimated_duration": 3599.6397962468604,
    "input_throughput": 436.97011063162756,
    "output_throughput": 401.2006983325838,
    "total_throughput": 838.1708089642113,
    "itl": 19.048496064913532,
    "ttft": 7286.3020511903305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9829192920587957. Arrivals time: 0.029730436857789755 Scheduler time: 0.5411922940984368 Scheduler overhead time: 0.1544780577532947 Adapter cache time: 0.03797749849036336 Engine time: 0.1464736768975854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9769279533065856,
    "estimated_duration": 3599.64370295379,
    "input_throughput": 436.9696363863133,
    "output_throughput": 401.200262907948,
    "total_throughput": 838.1698992942613,
    "itl": 19.15554105449531,
    "ttft": 7286.420608292231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.977021821308881. Arrivals time: 0.029799880925565958 Scheduler time: 0.5378967621363699 Scheduler overhead time: 0.1537406975403428 Adapter cache time: 0.037371969781816006 Engine time: 0.14542369917035103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9746496630832553,
    "estimated_duration": 3599.64370295379,
    "input_throughput": 436.9696363863133,
    "output_throughput": 401.200262907948,
    "total_throughput": 838.1698992942613,
    "itl": 19.155538574431088,
    "ttft": 7286.4113506565645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9747097073122859. Arrivals time: 0.029069120530039072 Scheduler time: 0.5356686878949404 Scheduler overhead time: 0.15388147300109267 Adapter cache time: 0.0373548730276525 Engine time: 0.1456747641786933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9736722256056964,
    "estimated_duration": 3599.6397962468604,
    "input_throughput": 436.97011063162756,
    "output_throughput": 401.2006983325838,
    "total_throughput": 838.1708089642113,
    "itl": 19.04847190586022,
    "ttft": 7286.170273905894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9737492967396975. Arrivals time: 0.02949949074536562 Scheduler time: 0.5332188885658979 Scheduler overhead time: 0.15395395271480083 Adapter cache time: 0.037811849266290665 Engine time: 0.1461198190227151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.976823722012341,
    "estimated_duration": 3599.64370295379,
    "input_throughput": 436.9696363863133,
    "output_throughput": 401.200262907948,
    "total_throughput": 838.1698992942613,
    "itl": 19.155633317610267,
    "ttft": 7286.382305438736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9769043126143515. Arrivals time: 0.029802949633449316 Scheduler time: 0.5371580016799271 Scheduler overhead time: 0.15292045567184687 Adapter cache time: 0.037500424310564995 Engine time: 0.1469678687863052 
