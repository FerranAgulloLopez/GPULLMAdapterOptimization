INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9871004670858383,
    "estimated_duration": 3599.6397962468604,
    "input_throughput": 436.97011063162756,
    "output_throughput": 401.2006983325838,
    "total_throughput": 838.1708089642113,
    "itl": 19.048717956066326,
    "ttft": 7286.2880502780445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9872111370787024. Arrivals time: 0.030217820778489113 Scheduler time: 0.5437607252970338 Scheduler overhead time: 0.14962641475722194 Adapter cache time: 0.03797026537358761 Engine time: 0.14864765852689743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 135, 135, 540, 135, 1080, 540, 135, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 1080, 1080, 135, 1080, 1080, 1080, 1080, 540, 135, 540, 540, 540, 540, 1080]
Prompts retrieved: 19170 . Total input tokens: 4225442 . Total output tokens: 3865622
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9691574643366039,
    "estimated_duration": 3599.64370295379,
    "input_throughput": 436.9696363863133,
    "output_throughput": 401.200262907948,
    "total_throughput": 838.1698992942613,
    "itl": 19.15563263547519,
    "ttft": 7286.4476081507255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 6451,
    "finished_requests": 6438,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9692716840654612. Arrivals time: 0.02934282785281539 Scheduler time: 0.5340627394616604 Scheduler overhead time: 0.14927962515503168 Adapter cache time: 0.037238295655697584 Engine time: 0.14534591091796756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9495533760637045,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.037163286020785,
    "ttft": 5796.9390985689815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9496529959142208. Arrivals time: 0.028143872506916523 Scheduler time: 0.5148643609136343 Scheduler overhead time: 0.14913798961788416 Adapter cache time: 0.03684484167024493 Engine time: 0.14632946997880936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9506704178638756,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.037135067428448,
    "ttft": 5796.839657261252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.950773443095386. Arrivals time: 0.02862987807020545 Scheduler time: 0.5144172180444002 Scheduler overhead time: 0.14912961749359965 Adapter cache time: 0.03765922738239169 Engine time: 0.1465999884530902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9523457773029804,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.03714184121351,
    "ttft": 5796.861546673812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9524784591048956. Arrivals time: 0.028600499965250492 Scheduler time: 0.5183139583095908 Scheduler overhead time: 0.14863373758271337 Adapter cache time: 0.036933401599526405 Engine time: 0.1454054112546146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9578251843340695,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.037313872646884,
    "ttft": 5796.922706237233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9580478579737246. Arrivals time: 0.029448459390550852 Scheduler time: 0.5172694227658212 Scheduler overhead time: 0.1493451506830752 Adapter cache time: 0.03715177020058036 Engine time: 0.15014027850702405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9553870786912739,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.037252629960207,
    "ttft": 5796.865874268033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9554742239415646. Arrivals time: 0.02909945184364915 Scheduler time: 0.5197195969521999 Scheduler overhead time: 0.14775050524622202 Adapter cache time: 0.037280276883393526 Engine time: 0.14765836717560887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9687998038716614,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.037223303208904,
    "ttft": 5796.966743492346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9689036030322313. Arrivals time: 0.029571307823061943 Scheduler time: 0.5302396831102669 Scheduler overhead time: 0.1483252001926303 Adapter cache time: 0.03690377343446016 Engine time: 0.14940306544303894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 66, 66, 540, 66, 1080, 540, 66, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 1080, 1080, 66, 1080, 1080, 1080, 1080, 540, 66, 540, 540, 540, 540, 1080]
Prompts retrieved: 18480 . Total input tokens: 4082172 . Total output tokens: 3725914
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9783627651631832,
    "estimated_duration": 3600.005480988318,
    "input_throughput": 427.70268215738764,
    "output_throughput": 380.0480324892149,
    "total_throughput": 807.7507146466025,
    "itl": 19.03734076506541,
    "ttft": 5796.8268499587075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 6244,
    "finished_requests": 6234,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9784491169266403. Arrivals time: 0.02940849307924509 Scheduler time: 0.5374836786650121 Scheduler overhead time: 0.14731626212596893 Adapter cache time: 0.03768199123442173 Engine time: 0.15134245017543435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9589037327095866,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.880975892098405,
    "ttft": 2965.178133367119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9589896588586271. Arrivals time: 0.028980887960642576 Scheduler time: 0.5177105385810137 Scheduler overhead time: 0.14908652193844318 Adapter cache time: 0.036851109471172094 Engine time: 0.1510937255807221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.946501845959574,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.881002494640523,
    "ttft": 2965.1998347198514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9465959356166422. Arrivals time: 0.0292735337279737 Scheduler time: 0.5092928502708673 Scheduler overhead time: 0.14955774508416653 Adapter cache time: 0.03664750326424837 Engine time: 0.14721782272681594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9538774923421443,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.881017860961666,
    "ttft": 2965.247927024299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9539576573297381. Arrivals time: 0.02976902946829796 Scheduler time: 0.5170930684544146 Scheduler overhead time: 0.14827765757218003 Adapter cache time: 0.03642181120812893 Engine time: 0.14780839253216982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9569916189648211,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.880976125852893,
    "ttft": 2965.1748344884077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9573346679098904. Arrivals time: 0.029814756009727716 Scheduler time: 0.5187881621532142 Scheduler overhead time: 0.14942966680973768 Adapter cache time: 0.036351575050503016 Engine time: 0.1480357451364398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.958726828917861,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.881008352868886,
    "ttft": 2965.2565923786924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.958828607108444. Arrivals time: 0.0300908163189888 Scheduler time: 0.5157883823849261 Scheduler overhead time: 0.1497596325352788 Adapter cache time: 0.03705195989459753 Engine time: 0.15064104087650776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9558804770931602,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.880943611339223,
    "ttft": 2965.24169209937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9559626402333379. Arrivals time: 0.02942914143204689 Scheduler time: 0.5155531791970134 Scheduler overhead time: 0.1489092600531876 Adapter cache time: 0.03726545488461852 Engine time: 0.15010601002722979 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 540, 33, 33, 540, 33, 1080, 540, 33, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 1080, 1080, 33, 1080, 1080, 1080, 1080, 540, 33, 540, 540, 540, 540, 1080]
Prompts retrieved: 18150 . Total input tokens: 4011940 . Total output tokens: 3661809
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9520171480253339,
    "estimated_duration": 3599.7412621678523,
    "input_throughput": 422.4861981008358,
    "output_throughput": 373.79908776823,
    "total_throughput": 796.2852858690658,
    "itl": 18.88101367196758,
    "ttft": 2965.2617083383566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 6135,
    "finished_requests": 6130,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.952103273011744. Arrivals time: 0.03023054590448737 Scheduler time: 0.5132017130963504 Scheduler overhead time: 0.14933929033577442 Adapter cache time: 0.037272900342941284 Engine time: 0.14679304417222738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9119731183163822,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.71664581133023,
    "ttft": 4009.722465846983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9120709882117808. Arrivals time: 0.028261355590075254 Scheduler time: 0.476104783359915 Scheduler overhead time: 0.14924902003258467 Adapter cache time: 0.03580819210037589 Engine time: 0.14759560814127326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.917192897759378,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.716673744312562,
    "ttft": 4009.7354020637476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.917287249583751. Arrivals time: 0.02796871028840542 Scheduler time: 0.4768187333829701 Scheduler overhead time: 0.15048576286062598 Adapter cache time: 0.03564572287723422 Engine time: 0.15115415584295988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9142974680289626,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.716673149107017,
    "ttft": 4009.7327110542196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9144564806483686. Arrivals time: 0.027767960913479328 Scheduler time: 0.47473944211378694 Scheduler overhead time: 0.14978153491392732 Adapter cache time: 0.03643116494640708 Engine time: 0.15050713438540697 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9165895152837038,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.71669238185851,
    "ttft": 4009.6970968359215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9166821739636362. Arrivals time: 0.02800149144604802 Scheduler time: 0.4767580209299922 Scheduler overhead time: 0.14952404284849763 Adapter cache time: 0.03596173832193017 Engine time: 0.15140660433098674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9288305332884192,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.71666909577749,
    "ttft": 4009.7091120514197,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9293966009281576. Arrivals time: 0.02720298059284687 Scheduler time: 0.4867115207016468 Scheduler overhead time: 0.15137207508087158 Adapter cache time: 0.03620366891846061 Engine time: 0.1522288857959211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.9138696887530386,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.71662629753367,
    "ttft": 4009.7234736699575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9139689020812511. Arrivals time: 0.02846432151272893 Scheduler time: 0.4770836173556745 Scheduler overhead time: 0.1500366060063243 Adapter cache time: 0.03572662826627493 Engine time: 0.1473181825131178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 135, 135, 270, 135, 1080, 270, 135, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 1080, 1080, 135, 1080, 1080, 1080, 1080, 270, 135, 270, 270, 270, 270, 1080]
Prompts retrieved: 16200 . Total input tokens: 3580396 . Total output tokens: 3290234
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9216273720376194,
    "estimated_duration": 3598.9079390022,
    "input_throughput": 362.5774879814736,
    "output_throughput": 336.21560220722847,
    "total_throughput": 698.7930901887021,
    "itl": 18.716669708270622,
    "ttft": 4009.7239261242653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 5429,
    "finished_requests": 5423,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9217387023381889. Arrivals time: 0.02772709261626005 Scheduler time: 0.48311941092833877 Scheduler overhead time: 0.14939850568771362 Adapter cache time: 0.036030122078955173 Engine time: 0.1501948358491063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8976639206521213,
    "estimated_duration": 3599.694515130156,
    "input_throughput": 358.3845780739408,
    "output_throughput": 317.2133066293579,
    "total_throughput": 675.5978847032987,
    "itl": 18.785461031667452,
    "ttft": 6932.699748894968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8977643949910998. Arrivals time: 0.027335206512361765 Scheduler time: 0.4594540963880718 Scheduler overhead time: 0.1485226871445775 Adapter cache time: 0.03409066749736667 Engine time: 0.15317904157564044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9001900721341372,
    "estimated_duration": 3599.69000781578,
    "input_throughput": 358.38502682146003,
    "output_throughput": 317.2137038246981,
    "total_throughput": 675.5987306461581,
    "itl": 18.678412590882775,
    "ttft": 6932.58035631676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9002854619175196. Arrivals time: 0.028585467021912336 Scheduler time: 0.4615233466029167 Scheduler overhead time: 0.14991253288462758 Adapter cache time: 0.035047260113060474 Engine time: 0.14972752192988992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.893225812818855,
    "estimated_duration": 3599.69000781578,
    "input_throughput": 358.38502682146003,
    "output_throughput": 317.2137038246981,
    "total_throughput": 675.5987306461581,
    "itl": 18.678399044557302,
    "ttft": 6932.587474651725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8933014879003167. Arrivals time: 0.026749091688543558 Scheduler time: 0.4548143967986107 Scheduler overhead time: 0.14936161739751697 Adapter cache time: 0.03524236800149083 Engine time: 0.15131340734660625 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8868359569460154,
    "estimated_duration": 3599.694515130156,
    "input_throughput": 358.3845780739408,
    "output_throughput": 317.2133066293579,
    "total_throughput": 675.5978847032987,
    "itl": 18.78546904237884,
    "ttft": 6932.700242612102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8872542600147426. Arrivals time: 0.027296191081404686 Scheduler time: 0.454338860232383 Scheduler overhead time: 0.14775593020021915 Adapter cache time: 0.03459881106391549 Engine time: 0.1479897042736411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9079962861724198,
    "estimated_duration": 3599.69000781578,
    "input_throughput": 358.38502682146003,
    "output_throughput": 317.2137038246981,
    "total_throughput": 675.5987306461581,
    "itl": 18.678408105309686,
    "ttft": 6932.569607270164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9083844581618905. Arrivals time: 0.027708332985639572 Scheduler time: 0.4641321818344295 Scheduler overhead time: 0.15162341063842177 Adapter cache time: 0.03499897290021181 Engine time: 0.1534951957874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8826769688166678,
    "estimated_duration": 3599.694515130156,
    "input_throughput": 358.3845780739408,
    "output_throughput": 317.2133066293579,
    "total_throughput": 675.5978847032987,
    "itl": 18.78546205802436,
    "ttft": 6932.687822681292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8827840737067163. Arrivals time: 0.027256914880126715 Scheduler time: 0.4508667215704918 Scheduler overhead time: 0.14847618667408824 Adapter cache time: 0.03412238322198391 Engine time: 0.14738986734300852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 66, 66, 270, 66, 1080, 270, 66, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 1080, 1080, 66, 1080, 1080, 1080, 1080, 270, 66, 270, 270, 270, 270, 1080]
Prompts retrieved: 15510 . Total input tokens: 3432200 . Total output tokens: 3141312
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8980097998864949,
    "estimated_duration": 3599.69000781578,
    "input_throughput": 358.38502682146003,
    "output_throughput": 317.2137038246981,
    "total_throughput": 675.5987306461581,
    "itl": 18.678412599392214,
    "ttft": 6932.568530420967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 5216,
    "finished_requests": 5206,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8980991169810295. Arrivals time: 0.02748667960986495 Scheduler time: 0.46165169728919864 Scheduler overhead time: 0.1496055070310831 Adapter cache time: 0.03468314465135336 Engine time: 0.1496586510911584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8879768559709191,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.681449397861286,
    "ttft": 5673.322054479656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.88806191412732. Arrivals time: 0.027210480999201536 Scheduler time: 0.4509554267860949 Scheduler overhead time: 0.14997985493391752 Adapter cache time: 0.03469772404059768 Engine time: 0.14973050029948354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8863106789067388,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.681522374309544,
    "ttft": 5673.395958248545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8863937007263303. Arrivals time: 0.02732244599610567 Scheduler time: 0.448199856095016 Scheduler overhead time: 0.15039069298654795 Adapter cache time: 0.034610042814165354 Engine time: 0.1503618936985731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.9061606852337718,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.68152602119743,
    "ttft": 5673.414934578926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9062444833107293. Arrivals time: 0.027491360437124968 Scheduler time: 0.4577089734375477 Scheduler overhead time: 0.15258955163881183 Adapter cache time: 0.03505769278854132 Engine time: 0.15722645493224263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8908176831901073,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.681475136825696,
    "ttft": 5673.3724116358835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8909121928736567. Arrivals time: 0.027127131819725037 Scheduler time: 0.4524903050623834 Scheduler overhead time: 0.1528364447876811 Adapter cache time: 0.034690429456532 Engine time: 0.14684383012354374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8824873957782984,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.681534810434204,
    "ttft": 5673.417420040037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8825568677857518. Arrivals time: 0.02707882644608617 Scheduler time: 0.44710941379889846 Scheduler overhead time: 0.14986927108839154 Adapter cache time: 0.034911214374005795 Engine time: 0.14825206715613604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8879953529685736,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.681455275401905,
    "ttft": 5673.38477871764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8880915651097894. Arrivals time: 0.02735739480704069 Scheduler time: 0.4501611599698663 Scheduler overhead time: 0.1493481956422329 Adapter cache time: 0.034677733201533556 Engine time: 0.15094288624823093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 270, 33, 33, 270, 33, 1080, 270, 33, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 1080, 1080, 33, 1080, 1080, 1080, 1080, 270, 33, 270, 270, 270, 270, 1080]
Prompts retrieved: 15180 . Total input tokens: 3353463 . Total output tokens: 3075895
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8944915379397571,
    "estimated_duration": 3599.3894383513793,
    "input_throughput": 345.133812630454,
    "output_throughput": 313.4992807326904,
    "total_throughput": 658.6330933631444,
    "itl": 18.681537215246315,
    "ttft": 5673.400321791043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 5104,
    "finished_requests": 5096,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8945694328285754. Arrivals time: 0.027440428268164396 Scheduler time: 0.4550377829000354 Scheduler overhead time: 0.15019707242026925 Adapter cache time: 0.034568489994853735 Engine time: 0.1512751798145473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.860555131919682,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.523268464447543,
    "ttft": 5395.5857277340765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8606516420841217. Arrivals time: 0.026302307844161987 Scheduler time: 0.42529929243028164 Scheduler overhead time: 0.14966067159548402 Adapter cache time: 0.033959080930799246 Engine time: 0.14973911456763744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8713082349859178,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.52328476352574,
    "ttft": 5395.599614425381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.871397006791085. Arrivals time: 0.02640010928735137 Scheduler time: 0.4302733759395778 Scheduler overhead time: 0.1518081952817738 Adapter cache time: 0.0337823573499918 Engine time: 0.15152818569913507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.863852703012526,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.523286775183585,
    "ttft": 5395.602151848276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8639844250865281. Arrivals time: 0.02658541826531291 Scheduler time: 0.42765892669558525 Scheduler overhead time: 0.14974858565256 Adapter cache time: 0.034067973494529724 Engine time: 0.14962324360385537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8618288319557905,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.523261722077592,
    "ttft": 5395.588788159785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8619043952785432. Arrivals time: 0.026404778007417917 Scheduler time: 0.42650099704042077 Scheduler overhead time: 0.1502536446787417 Adapter cache time: 0.03363589150831103 Engine time: 0.14980738516896963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8709394577890635,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.523295501911132,
    "ttft": 5395.590862179844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8710548267699778. Arrivals time: 0.02652977779507637 Scheduler time: 0.43126299045979977 Scheduler overhead time: 0.15005538845434785 Adapter cache time: 0.0337407854385674 Engine time: 0.1536108641885221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.863293313421309,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.522904205480376,
    "ttft": 5395.590344939834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8633641172200441. Arrivals time: 0.025570157449692488 Scheduler time: 0.4283674084581435 Scheduler overhead time: 0.15000645769760013 Adapter cache time: 0.03371285693719983 Engine time: 0.1502117607742548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 66, 66, 135, 66, 1080, 135, 66, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 1080, 1080, 66, 1080, 1080, 1080, 1080, 135, 66, 135, 135, 135, 135, 1080]
Prompts retrieved: 14025 . Total input tokens: 3078675 . Total output tokens: 2855195
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8601833609864116,
    "estimated_duration": 3598.8655370638576,
    "input_throughput": 305.4284714668116,
    "output_throughput": 288.6465163262274,
    "total_throughput": 594.074987793039,
    "itl": 18.523300522760817,
    "ttft": 5395.593768690806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 4697,
    "finished_requests": 4690,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8602855182252824. Arrivals time: 0.02606124011799693 Scheduler time: 0.42411606991663575 Scheduler overhead time: 0.15002522431313992 Adapter cache time: 0.034377967938780785 Engine time: 0.14991665678098798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8534841961227357,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.52111479291686,
    "ttft": 7909.752088534721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8535607270896435. Arrivals time: 0.02554583875462413 Scheduler time: 0.41973989410325885 Scheduler overhead time: 0.1488604862242937 Adapter cache time: 0.03338800882920623 Engine time: 0.15022377017885447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8596263350918889,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.521148301799833,
    "ttft": 7909.779009031552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8597391140647233. Arrivals time: 0.02569854585453868 Scheduler time: 0.42167412023991346 Scheduler overhead time: 0.15083692036569118 Adapter cache time: 0.0329191773198545 Engine time: 0.1526724100112915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8508854559622705,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.5211449719841,
    "ttft": 7909.774167014539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8509905873797834. Arrivals time: 0.02505706762894988 Scheduler time: 0.4182097758166492 Scheduler overhead time: 0.14980521984398365 Adapter cache time: 0.033284665551036596 Engine time: 0.1495502796024084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8465880840085447,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.52115535572641,
    "ttft": 7909.78233932787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.846709230914712. Arrivals time: 0.025088684633374214 Scheduler time: 0.4170776875689626 Scheduler overhead time: 0.14848205028101802 Adapter cache time: 0.03294150531291962 Engine time: 0.1479367115534842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8558290959335864,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.521153660194145,
    "ttft": 7909.79003475269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8559099161066115. Arrivals time: 0.026205196511000395 Scheduler time: 0.4201067900285125 Scheduler overhead time: 0.14977329643443227 Adapter cache time: 0.033252238761633635 Engine time: 0.15063242428004742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8548604631796479,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.521079413179812,
    "ttft": 7909.772620817087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8549560951068997. Arrivals time: 0.025732132606208324 Scheduler time: 0.41852549044415355 Scheduler overhead time: 0.14993360452353954 Adapter cache time: 0.03356410749256611 Engine time: 0.15052141062915325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 135, 33, 33, 135, 33, 1080, 135, 33, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 1080, 1080, 33, 1080, 1080, 1080, 1080, 135, 33, 135, 135, 135, 135, 1080]
Prompts retrieved: 13695 . Total input tokens: 3008761 . Total output tokens: 2795833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8622405831702054,
    "estimated_duration": 3598.265612769078,
    "input_throughput": 302.4070808276466,
    "output_throughput": 283.1769829286896,
    "total_throughput": 585.5840637563363,
    "itl": 18.521172802645825,
    "ttft": 7909.787075717601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 4569,
    "finished_requests": 4559,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8623061021789908. Arrivals time: 0.02547234809026122 Scheduler time: 0.42434907192364335 Scheduler overhead time: 0.1501798639073968 Adapter cache time: 0.03319642832502723 Engine time: 0.1532704415731132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8322514840401709,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.51431698768171,
    "ttft": 5072.409848716761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8323539150878787. Arrivals time: 0.024599912576377392 Scheduler time: 0.39892558148130774 Scheduler overhead time: 0.15013462584465742 Adapter cache time: 0.03207659116014838 Engine time: 0.15102970600128174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8300907681696117,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.514359747637943,
    "ttft": 5072.469735981654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8301676572300494. Arrivals time: 0.02518243808299303 Scheduler time: 0.39909073058515787 Scheduler overhead time: 0.14913485012948513 Adapter cache time: 0.03225608076900244 Engine time: 0.14930659951642156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8346558632329106,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.51436013644055,
    "ttft": 5072.467897297081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8347561131231487. Arrivals time: 0.02506623649969697 Scheduler time: 0.40011595003306866 Scheduler overhead time: 0.1497605349868536 Adapter cache time: 0.032800239976495504 Engine time: 0.15132380137220025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8300188360735774,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.51424005410393,
    "ttft": 5072.4520907518345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.830177394207567. Arrivals time: 0.025666116271167994 Scheduler time: 0.39962257957085967 Scheduler overhead time: 0.14903785707429051 Adapter cache time: 0.03204375132918358 Engine time: 0.1485871197655797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.8286806773394346,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.514385382276696,
    "ttft": 5072.46422819936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089386,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8287818380631506. Arrivals time: 0.024369956459850073 Scheduler time: 0.39661506237462163 Scheduler overhead time: 0.14936968171969056 Adapter cache time: 0.032396362628787756 Engine time: 0.15016721934080124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.8376936013810337,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.514369020949392,
    "ttft": 5072.432643213483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8377793249674141. Arrivals time: 0.02637334307655692 Scheduler time: 0.3997867042198777 Scheduler overhead time: 0.15072405524551868 Adapter cache time: 0.03219913085922599 Engine time: 0.15278219291940331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [10 11 11]
Adapter prompts. [1080, 66, 33, 33, 66, 33, 1080, 66, 33, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 1080, 1080, 33, 1080, 1080, 1080, 1080, 66, 33, 66, 66, 66, 66, 1080]
Prompts retrieved: 12936 . Total input tokens: 2845854 . Total output tokens: 2643421
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.829803017899394,
    "estimated_duration": 3599.045407215499,
    "input_throughput": 291.4920156041209,
    "output_throughput": 262.41875084613207,
    "total_throughput": 553.910766450253,
    "itl": 18.514418431294423,
    "ttft": 5072.459514404918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145731,
    "arrivals": 4284,
    "finished_requests": 4278,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.829936530906707. Arrivals time: 0.02492767618969083 Scheduler time: 0.3996957056224346 Scheduler overhead time: 0.1490047164261341 Adapter cache time: 0.032157077454030514 Engine time: 0.1488964124582708 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7585919848643243,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.167731401320523,
    "ttft": 3295.714944620441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7586566121317446. Arrivals time: 0.02232854813337326 Scheduler time: 0.33150348579511046 Scheduler overhead time: 0.14764880063012242 Adapter cache time: 0.03245328273624182 Engine time: 0.14957373589277267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7601323430426419,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.16776498182122,
    "ttft": 3295.7378695843345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7602133019827306. Arrivals time: 0.022166135255247355 Scheduler time: 0.33453396521508694 Scheduler overhead time: 0.14879978215321898 Adapter cache time: 0.03187438705936074 Engine time: 0.14770661853253841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7661507190205157,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.167765004581153,
    "ttft": 3295.740768975961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7662238818593323. Arrivals time: 0.022520095109939575 Scheduler time: 0.336435504257679 Scheduler overhead time: 0.14997995737940073 Adapter cache time: 0.032464440446347 Engine time: 0.14956603618338704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7600659574382007,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.16774454631705,
    "ttft": 3295.7235341016108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7602305533364415. Arrivals time: 0.02280415501445532 Scheduler time: 0.33176294853910804 Scheduler overhead time: 0.14903489872813225 Adapter cache time: 0.032115297857671976 Engine time: 0.14947497937828302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7628588611260056,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.167778337666757,
    "ttft": 3295.7387278009046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089388,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7629344328306615. Arrivals time: 0.022846124600619078 Scheduler time: 0.3353187832981348 Scheduler overhead time: 0.1481431215070188 Adapter cache time: 0.0324266217648983 Engine time: 0.14863249752670527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.763120946008712,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.167724800248124,
    "ttft": 3295.729568118795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.763250641990453. Arrivals time: 0.022437183186411858 Scheduler time: 0.33466074569150805 Scheduler overhead time: 0.1488317851908505 Adapter cache time: 0.03214065497741103 Engine time: 0.1495490618981421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 135, 135, 270, 135, 540, 270, 135, 135, 135, 540, 540, 135, 135, 270, 270, 270, 540, 540, 135, 540, 540, 540, 540, 270, 135, 270, 270, 270, 270, 540]
Prompts retrieved: 10260 . Total input tokens: 2249893 . Total output tokens: 2083953
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7617174596525729,
    "estimated_duration": 3599.4099182190334,
    "input_throughput": 224.0770065997578,
    "output_throughput": 200.20587162146845,
    "total_throughput": 424.2828782212262,
    "itl": 18.16778541096176,
    "ttft": 3295.753177888246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145734,
    "arrivals": 3307,
    "finished_requests": 3304,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.76178914681077. Arrivals time: 0.02228144323453307 Scheduler time: 0.33619068330153823 Scheduler overhead time: 0.14882277324795723 Adapter cache time: 0.031961564905941486 Engine time: 0.14760234905406833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7461090940050781,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.11116794541368,
    "ttft": 4664.430529432089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7462271824479103. Arrivals time: 0.022199065424501896 Scheduler time: 0.3217695285566151 Scheduler overhead time: 0.14712475705891848 Adapter cache time: 0.031889631412923336 Engine time: 0.1482192580588162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7418238129466772,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.11123801591662,
    "ttft": 4664.443396259603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.741893732920289. Arrivals time: 0.021967379841953516 Scheduler time: 0.3180977781303227 Scheduler overhead time: 0.14667192986235023 Adapter cache time: 0.03151632798835635 Engine time: 0.14901921851560473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7426135954447091,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.11123844423842,
    "ttft": 4664.445764008308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7426781980320811. Arrivals time: 0.022134519182145596 Scheduler time: 0.31916572293266654 Scheduler overhead time: 0.14644080586731434 Adapter cache time: 0.03153715003281832 Engine time: 0.14872139412909746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7451826841570437,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.111177876485232,
    "ttft": 4664.436657305633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7453130921348929. Arrivals time: 0.021718993317335844 Scheduler time: 0.32061433698982 Scheduler overhead time: 0.14729331387206912 Adapter cache time: 0.031167567241936922 Engine time: 0.1496031922288239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7456956459209323,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.111242479185318,
    "ttft": 4664.44088756987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7457604818046093. Arrivals time: 0.021978987846523523 Scheduler time: 0.31839124485850334 Scheduler overhead time: 0.14685259014368057 Adapter cache time: 0.03127915831282735 Engine time: 0.1528704189695418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7418727041222155,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.111157203673386,
    "ttft": 4664.430799065138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7419548551551998. Arrivals time: 0.0217917007394135 Scheduler time: 0.31872122595086694 Scheduler overhead time: 0.14666220545768738 Adapter cache time: 0.03205699706450105 Engine time: 0.1480823061428964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 66, 66, 270, 66, 540, 270, 66, 66, 66, 540, 540, 66, 66, 270, 270, 270, 540, 540, 66, 540, 540, 540, 540, 270, 66, 270, 270, 270, 270, 540]
Prompts retrieved: 9570 . Total input tokens: 2097154 . Total output tokens: 1941080
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7402143781073391,
    "estimated_duration": 3592.3756987681636,
    "input_throughput": 208.3028231865044,
    "output_throughput": 187.692506725064,
    "total_throughput": 395.9953299115684,
    "itl": 18.111246143411826,
    "ttft": 4664.434494687595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 3107,
    "finished_requests": 3103,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7402992700226605. Arrivals time: 0.021772414445877075 Scheduler time: 0.3175670546479523 Scheduler overhead time: 0.14657210418954492 Adapter cache time: 0.031441037543118 Engine time: 0.14812541706487536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7506670909933746,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.115841559554344,
    "ttft": 7251.353189753478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7507418231107295. Arrivals time: 0.023022384848445654 Scheduler time: 0.3222581557929516 Scheduler overhead time: 0.1485899994149804 Adapter cache time: 0.03142726141959429 Engine time: 0.14992406498640776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7458423329517245,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.115873600837325,
    "ttft": 7251.364718704024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7459380771033466. Arrivals time: 0.022063663229346275 Scheduler time: 0.31936855940148234 Scheduler overhead time: 0.1487431596033275 Adapter cache time: 0.031106206122785807 Engine time: 0.14984443550929427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7434485168196261,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.115874876506904,
    "ttft": 7251.360998880693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7435250896960497. Arrivals time: 0.02164981560781598 Scheduler time: 0.3185484246350825 Scheduler overhead time: 0.14920433703809977 Adapter cache time: 0.030988007318228483 Engine time: 0.14824224589392543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7408697856590152,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.11585239926669,
    "ttft": 7251.366124335137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7410137178376317. Arrivals time: 0.02211083984002471 Scheduler time: 0.31728091975674033 Scheduler overhead time: 0.14791474724188447 Adapter cache time: 0.031213387846946716 Engine time: 0.14742978708818555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.742324888240546,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.11588372488478,
    "ttft": 7251.361325085195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7424032539129257. Arrivals time: 0.02174191828817129 Scheduler time: 0.31564614456146955 Scheduler overhead time: 0.1481283870525658 Adapter cache time: 0.03163080383092165 Engine time: 0.1500269789248705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7439695801585913,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.11582600142774,
    "ttft": 7251.34261554913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7440363680943847. Arrivals time: 0.02161051332950592 Scheduler time: 0.3169254111126065 Scheduler overhead time: 0.14904009504243731 Adapter cache time: 0.03097812458872795 Engine time: 0.15022563748061657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 270, 33, 33, 270, 33, 540, 270, 33, 33, 33, 540, 540, 33, 33, 270, 270, 270, 540, 540, 33, 540, 540, 540, 540, 270, 33, 270, 270, 270, 270, 540]
Prompts retrieved: 9240 . Total input tokens: 2030489 . Total output tokens: 1873157
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7408840251155198,
    "estimated_duration": 3597.3303957245257,
    "input_throughput": 197.79473157252008,
    "output_throughput": 184.18297101302386,
    "total_throughput": 381.97770258554397,
    "itl": 18.115897091692222,
    "ttft": 7251.349345207118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 2991,
    "finished_requests": 2985,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.740993089042604. Arrivals time: 0.02196541614830494 Scheduler time: 0.3157265945337713 Scheduler overhead time: 0.14897878421470523 Adapter cache time: 0.03141038632020354 Engine time: 0.14783196663483977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6914259092882276,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.95973451282424,
    "ttft": 6923.064223219304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6915037082508206. Arrivals time: 0.02019317727535963 Scheduler time: 0.28138415329158306 Scheduler overhead time: 0.143096046987921 Adapter cache time: 0.029258640948683023 Engine time: 0.1448997249826789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.693806063849479,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.959762198738407,
    "ttft": 6923.040716360761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6938861268572509. Arrivals time: 0.02025718055665493 Scheduler time: 0.2818191144615412 Scheduler overhead time: 0.14351098518818617 Adapter cache time: 0.029753465205430984 Engine time: 0.14505249867215753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6979301730170846,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.95976232610615,
    "ttft": 6923.041352304076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6980074089951813. Arrivals time: 0.020460938569158316 Scheduler time: 0.2838945025578141 Scheduler overhead time: 0.1440438237041235 Adapter cache time: 0.029249108396470547 Engine time: 0.14693602174520493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7000811346806586,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.959739550053413,
    "ttft": 6923.064683099431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7001527766697109. Arrivals time: 0.020002684090286493 Scheduler time: 0.28355079237371683 Scheduler overhead time: 0.14411534601822495 Adapter cache time: 0.029225553385913372 Engine time: 0.15022309496998787 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7042696350254118,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.95976816599582,
    "ttft": 6923.029084165014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7043647756800056. Arrivals time: 0.020544263068586588 Scheduler time: 0.29114888329058886 Scheduler overhead time: 0.14373381901532412 Adapter cache time: 0.029261774849146605 Engine time: 0.14643846964463592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6952942321076989,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.959732077675657,
    "ttft": 6923.056830359755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6953747379593551. Arrivals time: 0.020636003464460373 Scheduler time: 0.28321464732289314 Scheduler overhead time: 0.14392235921695828 Adapter cache time: 0.029323100112378597 Engine time: 0.14475634275004268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 66, 66, 135, 66, 540, 135, 66, 66, 66, 540, 540, 66, 66, 135, 135, 135, 540, 540, 66, 540, 540, 540, 540, 135, 66, 135, 135, 135, 135, 540]
Prompts retrieved: 8085 . Total input tokens: 1770628 . Total output tokens: 1632704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6946614631451666,
    "estimated_duration": 3599.377110950381,
    "input_throughput": 178.15971492653082,
    "output_throughput": 154.39532532151532,
    "total_throughput": 332.55504024804617,
    "itl": 17.959769292139672,
    "ttft": 6923.033525631369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 2611,
    "finished_requests": 2606,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6947456002235413. Arrivals time: 0.02091968059539795 Scheduler time: 0.28147738287225366 Scheduler overhead time: 0.14386267447844148 Adapter cache time: 0.029564957600086927 Engine time: 0.1456573074683547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.7032964248210192,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.076759191884214,
    "ttft": 4287.93352718119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7033944698050618. Arrivals time: 0.020164250396192074 Scheduler time: 0.2894775024615228 Scheduler overhead time: 0.14338696841150522 Adapter cache time: 0.029009755700826645 Engine time: 0.14823115663602948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7133741928264499,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.076909624069277,
    "ttft": 4287.847824846017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7134519536048174. Arrivals time: 0.020290025509893894 Scheduler time: 0.2954532182775438 Scheduler overhead time: 0.1476553655229509 Adapter cache time: 0.029007359873503447 Engine time: 0.1479096277616918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.698534308001399,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.076906608580956,
    "ttft": 4287.85154221624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6986406240612268. Arrivals time: 0.020308038219809532 Scheduler time: 0.2863361076451838 Scheduler overhead time: 0.14334698533639312 Adapter cache time: 0.02919256640598178 Engine time: 0.14636856177821755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6955296117812395,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.076830890556188,
    "ttft": 4287.875110108843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6955900588072836. Arrivals time: 0.020210084039717913 Scheduler time: 0.2841309942305088 Scheduler overhead time: 0.1435206918977201 Adapter cache time: 0.02899325732141733 Engine time: 0.14559969073161483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6976622943766415,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.076917447086206,
    "ttft": 4287.83431866891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6977531393058598. Arrivals time: 0.020538369193673134 Scheduler time: 0.28625113470479846 Scheduler overhead time: 0.14306198991835117 Adapter cache time: 0.029173394199460745 Engine time: 0.14533804776147008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6956858821213245,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.076786108632223,
    "ttft": 4287.932401982683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6957887122407556. Arrivals time: 0.020222004503011703 Scheduler time: 0.28556035179644823 Scheduler overhead time: 0.14376270631328225 Adapter cache time: 0.02896488131955266 Engine time: 0.1443958138115704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 135, 33, 33, 135, 33, 540, 135, 33, 33, 33, 540, 540, 33, 33, 135, 135, 135, 540, 540, 33, 540, 540, 540, 540, 135, 33, 135, 135, 135, 135, 540]
Prompts retrieved: 7755 . Total input tokens: 1696596 . Total output tokens: 1570506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.7002704781480134,
    "estimated_duration": 3599.270546018147,
    "input_throughput": 170.5598376535335,
    "output_throughput": 157.5613704914142,
    "total_throughput": 328.12120814494773,
    "itl": 18.07694504145604,
    "ttft": 4287.840825534041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1075786313414573,
    "arrivals": 2536,
    "finished_requests": 2533,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7003525448963046. Arrivals time: 0.020239513833075762 Scheduler time: 0.2886302899569273 Scheduler overhead time: 0.14326222706586123 Adapter cache time: 0.029370023403316736 Engine time: 0.14611253375187516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6668367902748287,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.9944290459889,
    "ttft": 4807.612018605727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6668996280059218. Arrivals time: 0.01937956502661109 Scheduler time: 0.26579644344747066 Scheduler overhead time: 0.14046298759058118 Adapter cache time: 0.02764329267665744 Engine time: 0.14229752402752638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6644273139536381,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.994469449971998,
    "ttft": 4807.58977304836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6645879778079689. Arrivals time: 0.019220948684960604 Scheduler time: 0.2651826166547835 Scheduler overhead time: 0.13974136067554355 Adapter cache time: 0.028022459242492914 Engine time: 0.14114348031580448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6708243251778185,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.994468055893122,
    "ttft": 4807.596843052432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6709081460721791. Arrivals time: 0.019671348854899406 Scheduler time: 0.2678773542866111 Scheduler overhead time: 0.1400646730326116 Adapter cache time: 0.02814837032929063 Engine time: 0.14362922916188836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.6680744872428477,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.994452128210032,
    "ttft": 4807.596583543148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6681400663219392. Arrivals time: 0.01957919867709279 Scheduler time: 0.2670474830083549 Scheduler overhead time: 0.14045391650870442 Adapter cache time: 0.02772313356399536 Engine time: 0.14169295504689217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6649646828882396,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.994474683783054,
    "ttft": 4807.593861511382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1061953396908939,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6650524251163006. Arrivals time: 0.01905956119298935 Scheduler time: 0.2653266745619476 Scheduler overhead time: 0.14040661929175258 Adapter cache time: 0.027882162015885115 Engine time: 0.1406928743235767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.6693574427627027,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.9944211829129,
    "ttft": 4807.616280905641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6694691167213023. Arrivals time: 0.019300549756735563 Scheduler time: 0.26480648946017027 Scheduler overhead time: 0.14312406536191702 Adapter cache time: 0.027873612474650145 Engine time: 0.14273838605731726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [10 11 11]
Adapter prompts. [540, 66, 33, 33, 66, 33, 540, 66, 33, 33, 33, 540, 540, 33, 33, 66, 66, 66, 540, 540, 33, 540, 540, 540, 540, 66, 33, 66, 66, 66, 66, 540]
Prompts retrieved: 6996 . Total input tokens: 1535539 . Total output tokens: 1407267
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.6735023879446089,
    "estimated_duration": 3598.9114557435046,
    "input_throughput": 151.18904888077893,
    "output_throughput": 141.74758292146146,
    "total_throughput": 292.9366318022404,
    "itl": 17.994484119208064,
    "ttft": 4807.591583515792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 2260,
    "finished_requests": 2257,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6735668168403208. Arrivals time: 0.019540066830813885 Scheduler time: 0.269788873847574 Scheduler overhead time: 0.1407629088498652 Adapter cache time: 0.027695888187736273 Engine time: 0.1446206229738891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.567740582395345,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.778935432228774,
    "ttft": 8771.306397029504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5678384532220662. Arrivals time: 0.016387077048420906 Scheduler time: 0.20616500172764063 Scheduler overhead time: 0.12646379647776484 Adapter cache time: 0.025177669711411 Engine time: 0.1290928334929049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.577219586353749,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.77895683365768,
    "ttft": 8771.278846590501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255726,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5772894751280546. Arrivals time: 0.016845539212226868 Scheduler time: 0.2111026756465435 Scheduler overhead time: 0.1305743008852005 Adapter cache time: 0.024466268252581358 Engine time: 0.1290407064370811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5708831851370633,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.778965050817547,
    "ttft": 8771.280629513196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1048120480403304,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5709462519735098. Arrivals time: 0.016705847345292568 Scheduler time: 0.20701971417292953 Scheduler overhead time: 0.12768282322213054 Adapter cache time: 0.02470608614385128 Engine time: 0.13023546617478132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5765317920595407,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.77893766040295,
    "ttft": 8771.288811772769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5765968537889421. Arrivals time: 0.016619817819446325 Scheduler time: 0.21072401385754347 Scheduler overhead time: 0.13039411418139935 Adapter cache time: 0.024986480362713337 Engine time: 0.1289303544908762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.572666013147682,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.77896501503521,
    "ttft": 8771.265592960852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089384,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5727509032003582. Arrivals time: 0.01656588399782777 Scheduler time: 0.20873292069882154 Scheduler overhead time: 0.12826976086944342 Adapter cache time: 0.024552206974476576 Engine time: 0.12910410994663835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5691453623585403,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.77892019105156,
    "ttft": 8771.317161650426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5692124259658158. Arrivals time: 0.01650147559121251 Scheduler time: 0.20773960975930095 Scheduler overhead time: 0.1277174148708582 Adapter cache time: 0.024510175455361605 Engine time: 0.12751539470627904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 66, 66, 135, 66, 270, 135, 66, 66, 66, 270, 270, 66, 66, 135, 135, 135, 270, 270, 66, 270, 270, 270, 270, 135, 66, 135, 135, 135, 135, 270]
Prompts retrieved: 5115 . Total input tokens: 1122780 . Total output tokens: 1024077
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.567064056172967,
    "estimated_duration": 3595.9825634140693,
    "input_throughput": 110.39152526454846,
    "output_throughput": 95.99295711608606,
    "total_throughput": 206.38448238063452,
    "itl": 17.778970967769297,
    "ttft": 8771.247886393863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1075786313414573,
    "arrivals": 1647,
    "finished_requests": 1643,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5671204361133277. Arrivals time: 0.01661740057170391 Scheduler time: 0.20662336563691497 Scheduler overhead time: 0.12669454189017415 Adapter cache time: 0.025388747453689575 Engine time: 0.12732020067051053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5676320842467248,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694175268048628,
    "ttft": 9420.954722049672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5676875254139304. Arrivals time: 0.01613025227561593 Scheduler time: 0.20381271559745073 Scheduler overhead time: 0.12816023267805576 Adapter cache time: 0.02485198015347123 Engine time: 0.1293374360539019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5631793197244406,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694200855318513,
    "ttft": 9420.97214089378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5632379008457065. Arrivals time: 0.016248017083853483 Scheduler time: 0.2025410388596356 Scheduler overhead time: 0.12757697934284806 Adapter cache time: 0.02432808233425021 Engine time: 0.12748513603582978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5630831778980792,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694201632028463,
    "ttft": 9420.971635633949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5631586140953004. Arrivals time: 0.016433801967650652 Scheduler time: 0.20086344564333558 Scheduler overhead time: 0.12696767272427678 Adapter cache time: 0.024769154377281666 Engine time: 0.12907943688333035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5659932559356093,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694179842843205,
    "ttft": 9420.953483573305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5660804263316095. Arrivals time: 0.016331930179148912 Scheduler time: 0.20310341054573655 Scheduler overhead time: 0.1286728112027049 Adapter cache time: 0.02446600003167987 Engine time: 0.12835026858374476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.562047510407865,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694210499156796,
    "ttft": 9420.941342891136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.562107291072607. Arrivals time: 0.01631061267107725 Scheduler time: 0.20158459711819887 Scheduler overhead time: 0.12765924166887999 Adapter cache time: 0.02442405093461275 Engine time: 0.12701584538444877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5610424177721143,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694171048643906,
    "ttft": 9420.958922892081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5611065877601504. Arrivals time: 0.016086006071418524 Scheduler time: 0.20040327310562134 Scheduler overhead time: 0.1267422423698008 Adapter cache time: 0.024922179989516735 Engine time: 0.12831210438162088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 135, 33, 33, 135, 33, 270, 135, 33, 33, 33, 270, 270, 33, 33, 135, 135, 135, 270, 270, 33, 270, 270, 270, 270, 135, 33, 135, 135, 135, 135, 270]
Prompts retrieved: 4785 . Total input tokens: 1048094 . Total output tokens: 961085
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5666763731278479,
    "estimated_duration": 3590.0024230354093,
    "input_throughput": 104.3088432467909,
    "output_throughput": 91.45314161721437,
    "total_throughput": 195.76198486400526,
    "itl": 17.694214668876693,
    "ttft": 9420.947495229022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 1533,
    "finished_requests": 1529,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5667378520593047. Arrivals time: 0.016405891161412 Scheduler time: 0.20368805760517716 Scheduler overhead time: 0.12742819264531136 Adapter cache time: 0.024582847021520138 Engine time: 0.12925955280661583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5005976217798889,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.594009047395996,
    "ttft": 2807.040609479644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5007173968479037. Arrivals time: 0.014435358345508575 Scheduler time: 0.17716487450525165 Scheduler overhead time: 0.11529697431251407 Adapter cache time: 0.02189801074564457 Engine time: 0.11382465530186892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5032169497571886,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.594033186866916,
    "ttft": 2807.0662763881905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255727,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5032850378192961. Arrivals time: 0.014280847273766994 Scheduler time: 0.17709466768428683 Scheduler overhead time: 0.11490876041352749 Adapter cache time: 0.022069218568503857 Engine time: 0.11671629641205072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5001896270550787,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.59403707814582,
    "ttft": 2807.0518695656992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033041,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5002586538903415. Arrivals time: 0.014464910607784986 Scheduler time: 0.17625655513256788 Scheduler overhead time: 0.1144537809304893 Adapter cache time: 0.02165477955713868 Engine time: 0.11557927308604121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5040103038772941,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.594005807783237,
    "ttft": 2807.05979822989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971348,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5040798587724566. Arrivals time: 0.014084327034652233 Scheduler time: 0.1781990798190236 Scheduler overhead time: 0.11436381097882986 Adapter cache time: 0.022051203064620495 Engine time: 0.11729583563283086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.5028179618529975,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.59404584480925,
    "ttft": 2807.044329269995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10619533969089387,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5028900019824505. Arrivals time: 0.014339722227305174 Scheduler time: 0.1767678325995803 Scheduler overhead time: 0.1150120161473751 Adapter cache time: 0.02170586632564664 Engine time: 0.11673277383670211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.5015797298401594,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.59399692042493,
    "ttft": 2807.046862007453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5016652559861541. Arrivals time: 0.014129952527582645 Scheduler time: 0.17684910632669926 Scheduler overhead time: 0.11469687754288316 Adapter cache time: 0.0215614284388721 Engine time: 0.11610757419839501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [10 11 11]
Adapter prompts. [270, 66, 33, 33, 66, 33, 270, 66, 33, 33, 33, 270, 270, 33, 33, 66, 66, 66, 270, 270, 33, 270, 270, 270, 270, 66, 33, 66, 66, 66, 66, 270]
Prompts retrieved: 4026 . Total input tokens: 878074 . Total output tokens: 796133
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4994440139271319,
    "estimated_duration": 3599.8418209378756,
    "input_throughput": 88.07775890480488,
    "output_throughput": 76.96754851517726,
    "total_throughput": 165.04530741998215,
    "itl": 17.59404858008034,
    "ttft": 2807.048310664005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145733,
    "arrivals": 1295,
    "finished_requests": 1294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.49950395012274384. Arrivals time: 0.014513202477246523 Scheduler time: 0.17600407358258963 Scheduler overhead time: 0.1142112067900598 Adapter cache time: 0.02190972026437521 Engine time: 0.11491669621318579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [8]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.4079121919348836,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.544874764878067,
    "ttft": 4221.680895690555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09793560780584809,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4079831806011498. Arrivals time: 0.011634157970547676 Scheduler time: 0.13540603406727314 Scheduler overhead time: 0.09620584920048714 Adapter cache time: 0.017860207241028547 Engine time: 0.09768966538831592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4142127800732851,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.54489151383252,
    "ttft": 4221.677436776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10467070644255728,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4142812080681324. Arrivals time: 0.01171093713492155 Scheduler time: 0.137936741579324 Scheduler overhead time: 0.09735644096508622 Adapter cache time: 0.01811592560261488 Engine time: 0.09946874948218465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4087256817147136,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.544892677000888,
    "ttft": 4221.677931766464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10481204804033042,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40880858805030584. Arrivals time: 0.011523549910634756 Scheduler time: 0.1369180204346776 Scheduler overhead time: 0.09689198574051261 Adapter cache time: 0.017849062103778124 Engine time: 0.09687668038532138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11 21]
---Simulation End---
#Simulation results
{
    "duration": 0.4072589408606291,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.544886987426235,
    "ttft": 4221.665055099684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10017615793971346,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4073649412021041. Arrivals time: 0.011785252951085567 Scheduler time: 0.13552034739404917 Scheduler overhead time: 0.09621961088851094 Adapter cache time: 0.018065876327455044 Engine time: 0.09659429918974638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [11 11 10]
---Simulation End---
#Simulation results
{
    "duration": 0.41508294083178043,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.54489825058385,
    "ttft": 4221.659967008715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1061953396908939,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.41516819689422846. Arrivals time: 0.011870008893311024 Scheduler time: 0.13900374015793204 Scheduler overhead time: 0.09741764282807708 Adapter cache time: 0.018026307690888643 Engine time: 0.09889949671924114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [16]. Counts: [32]
---Simulation End---
#Simulation results
{
    "duration": 0.4091075900942087,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.544867770868986,
    "ttft": 4221.696935205753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09568160943686965,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.40920893009752035. Arrivals time: 0.011593585833907127 Scheduler time: 0.13698580209165812 Scheduler overhead time: 0.09677808964625001 Adapter cache time: 0.017640357371419668 Engine time: 0.09707852965220809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 32,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_32_slots_32_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [10 11 11]
Adapter prompts. [135, 66, 33, 33, 66, 33, 135, 66, 33, 33, 33, 135, 135, 33, 33, 66, 66, 66, 135, 135, 33, 135, 135, 135, 135, 66, 33, 66, 66, 66, 66, 135]
Prompts retrieved: 2541 . Total input tokens: 554808 . Total output tokens: 519874
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [22 10]
---Simulation End---
#Simulation results
{
    "duration": 0.4109158106148243,
    "estimated_duration": 3598.008070038666,
    "input_throughput": 55.96735640391044,
    "output_throughput": 53.83006269853047,
    "total_throughput": 109.79741910244091,
    "itl": 17.544904164882734,
    "ttft": 4221.664070861885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 32,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10757863134145736,
    "arrivals": 858,
    "finished_requests": 857,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.4110401766374707. Arrivals time: 0.011692308355122805 Scheduler time: 0.1358415214344859 Scheduler overhead time: 0.09741568472236395 Adapter cache time: 0.018088883720338345 Engine time: 0.09888836368918419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 184.69341514678672,
    "estimated_duration": 3600.0410164796513,
    "input_throughput": 8402.802318508247,
    "output_throughput": 7434.63223821058,
    "total_throughput": 15837.434556718827,
    "itl": 110.25389236602341,
    "ttft": 1679528.2611809575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.36725852927193003,
    "arrivals": 435333,
    "finished_requests": 121512,
    "scheduler_time": 223.93684768178713
}
#Debug simulation 
Total elapsed time: 184.6936172330752. Arrivals time: 0.9308123695664108 Scheduler time: 183.42241964070126 Scheduler overhead time: 0.13919213274493814 Adapter cache time: 0.02478606952354312 Engine time: 0.13776119519025087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 175.94596852222458,
    "estimated_duration": 3600.041231217108,
    "input_throughput": 8421.550769225514,
    "output_throughput": 7483.160683382558,
    "total_throughput": 15904.711452608071,
    "itl": 110.82242779114928,
    "ttft": 1672011.2253534934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4242543310415931,
    "arrivals": 435333,
    "finished_requests": 121848,
    "scheduler_time": 223.5748630512625
}
#Debug simulation 
Total elapsed time: 175.94629356404766. Arrivals time: 0.9509117910638452 Scheduler time: 174.6511995717883 Scheduler overhead time: 0.13979059550911188 Adapter cache time: 0.025757369585335255 Engine time: 0.13981521734967828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 170.44693495891988,
    "estimated_duration": 3600.041717000763,
    "input_throughput": 8421.549632835427,
    "output_throughput": 7483.159673617273,
    "total_throughput": 15904.709306452702,
    "itl": 110.82236935839342,
    "ttft": 1672011.3120046011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42499798236414904,
    "arrivals": 435333,
    "finished_requests": 121848,
    "scheduler_time": 223.57490529933185
}
#Debug simulation 
Total elapsed time: 170.44711968209594. Arrivals time: 0.9621951831504703 Scheduler time: 169.15331157809123 Scheduler overhead time: 0.1353550786152482 Adapter cache time: 0.024140747729688883 Engine time: 0.1330664148554206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 169.91448122588918,
    "estimated_duration": 3600.0230700643106,
    "input_throughput": 8421.593253695011,
    "output_throughput": 7483.198433925245,
    "total_throughput": 15904.791687620256,
    "itl": 110.82200678773651,
    "ttft": 1672003.4656733642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4066847323486584,
    "arrivals": 435333,
    "finished_requests": 121848,
    "scheduler_time": 223.57426244595402
}
#Debug simulation 
Total elapsed time: 169.91465769102797. Arrivals time: 0.9448968502692878 Scheduler time: 168.63578401552513 Scheduler overhead time: 0.1374135995283723 Adapter cache time: 0.02404237212613225 Engine time: 0.13404619321227074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 171.74135584197938,
    "estimated_duration": 3600.047310992185,
    "input_throughput": 8421.536546875068,
    "output_throughput": 7483.148045789247,
    "total_throughput": 15904.684592664315,
    "itl": 110.82246498361413,
    "ttft": 1672013.859025926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4304053951799874,
    "arrivals": 435333,
    "finished_requests": 121848,
    "scheduler_time": 223.5749918393615
}
#Debug simulation 
Total elapsed time: 171.7415269818157. Arrivals time: 0.9673706088215113 Scheduler time: 170.4354760288261 Scheduler overhead time: 0.13670867448672652 Adapter cache time: 0.024821550119668245 Engine time: 0.13694558572024107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 185.90879481332377,
    "estimated_duration": 3600.0315418601285,
    "input_throughput": 8402.82443313529,
    "output_throughput": 7434.651804792408,
    "total_throughput": 15837.476237927698,
    "itl": 110.25378464328375,
    "ttft": 1679523.5202910877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3588060353882615,
    "arrivals": 435333,
    "finished_requests": 121512,
    "scheduler_time": 223.93662586477612
}
#Debug simulation 
Total elapsed time: 185.9089869549498. Arrivals time: 0.9616954140365124 Scheduler time: 184.59815701423213 Scheduler overhead time: 0.1423800210468471 Adapter cache time: 0.02659371681511402 Engine time: 0.14019935205578804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [8640, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 17280]
Prompts retrieved: 1304640 . Total input tokens: 290666445 . Total output tokens: 261325878
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 171.60079892491922,
    "estimated_duration": 3600.0534064207786,
    "input_throughput": 8421.522287954747,
    "output_throughput": 7483.135375700939,
    "total_throughput": 15904.657663655687,
    "itl": 110.82257866345485,
    "ttft": 1672016.8744631533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 130,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43593856178224055,
    "arrivals": 435333,
    "finished_requests": 121848,
    "scheduler_time": 223.57515394703427
}
#Debug simulation 
Total elapsed time: 171.60097514325753. Arrivals time: 0.931137353181839 Scheduler time: 170.33625449379906 Scheduler overhead time: 0.13553497567772865 Adapter cache time: 0.024345381651073694 Engine time: 0.1349297189153731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 155.09861495578662,
    "estimated_duration": 3600.0252933516967,
    "input_throughput": 8430.352435591922,
    "output_throughput": 7453.995684296003,
    "total_throughput": 15884.348119887925,
    "itl": 110.25650569964945,
    "ttft": 1649600.0994291366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4223473086627195,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.87839063474752
}
#Debug simulation 
Total elapsed time: 155.09888626588508. Arrivals time: 0.9116738326847553 Scheduler time: 153.8722745566629 Scheduler overhead time: 0.12691129045560956 Adapter cache time: 0.02258738735690713 Engine time: 0.12803445756435394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 157.31614601891488,
    "estimated_duration": 3600.05461103548,
    "input_throughput": 8430.283781520362,
    "output_throughput": 7453.934981358963,
    "total_throughput": 15884.218762879325,
    "itl": 110.25716828994173,
    "ttft": 1649613.4378171347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4498091146745719,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.8790493161566
}
#Debug simulation 
Total elapsed time: 157.3163245706819. Arrivals time: 0.9253422287292778 Scheduler time: 156.06901210872456 Scheduler overhead time: 0.13080838695168495 Adapter cache time: 0.0236048330552876 Engine time: 0.12965309200808406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 157.0161454640329,
    "estimated_duration": 3600.0555101791033,
    "input_throughput": 8430.281675987299,
    "output_throughput": 7453.9331196770845,
    "total_throughput": 15884.214795664382,
    "itl": 110.25718269956658,
    "ttft": 1649613.8487587268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4506951231323195,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.8790624513181
}
#Debug simulation 
Total elapsed time: 157.01632794598117. Arrivals time: 0.9069391214288771 Scheduler time: 155.78385599469766 Scheduler overhead time: 0.13254261715337634 Adapter cache time: 0.02402946585789323 Engine time: 0.1311919200234115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 157.17321363603696,
    "estimated_duration": 3600.036070343126,
    "input_throughput": 8430.327198668134,
    "output_throughput": 7453.973370173024,
    "total_throughput": 15884.300568841156,
    "itl": 110.25670816265556,
    "ttft": 1649605.2953791006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43183092066319684,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.8785802551521
}
#Debug simulation 
Total elapsed time: 157.17340088589117. Arrivals time: 0.9224823974072933 Scheduler time: 155.92691186629236 Scheduler overhead time: 0.1300332830287516 Adapter cache time: 0.02357114525511861 Engine time: 0.13241237169131637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 157.08017288101837,
    "estimated_duration": 3600.061841085033,
    "input_throughput": 8430.266850875229,
    "output_throughput": 7453.920011527427,
    "total_throughput": 15884.186862402656,
    "itl": 110.25738382114339,
    "ttft": 1649616.686768187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.45622828973457275,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.8794034844048
}
#Debug simulation 
Total elapsed time: 157.0803504679352. Arrivals time: 0.911080087069422 Scheduler time: 155.84642532933503 Scheduler overhead time: 0.13187676621600986 Adapter cache time: 0.024109236430376768 Engine time: 0.12850235495716333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 157.20570205990225,
    "estimated_duration": 3600.0156729105606,
    "input_throughput": 8430.374964301998,
    "output_throughput": 7454.01560385559,
    "total_throughput": 15884.390568157587,
    "itl": 110.256136514038,
    "ttft": 1649596.2486199713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41262694069650074,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.87788869676885
}
#Debug simulation 
Total elapsed time: 157.20598533190787. Arrivals time: 0.9031660701148212 Scheduler time: 155.9843543744646 Scheduler overhead time: 0.1294650654308498 Adapter cache time: 0.023363220505416393 Engine time: 0.12732504028826952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [4320, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 17280]
Prompts retrieved: 1213920 . Total input tokens: 270411658 . Total output tokens: 243281069
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 157.97894272999838,
    "estimated_duration": 3600.067175905848,
    "input_throughput": 8430.254358340819,
    "output_throughput": 7453.908965809198,
    "total_throughput": 15884.163324150017,
    "itl": 110.25757464764939,
    "ttft": 1649618.7257003488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4621387176960704,
    "arrivals": 404972,
    "finished_requests": 122300,
    "scheduler_time": 222.87952814732452
}
#Debug simulation 
Total elapsed time: 157.97927322331816. Arrivals time: 0.9376599392853677 Scheduler time: 156.71753574395552 Scheduler overhead time: 0.13106685038655996 Adapter cache time: 0.023760646115988493 Engine time: 0.13122899737209082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 175.48876275122166,
    "estimated_duration": 3600.102131523148,
    "input_throughput": 8443.39073990089,
    "output_throughput": 7474.056850886035,
    "total_throughput": 15917.447590786924,
    "itl": 110.86532245500247,
    "ttft": 1618529.2757637943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3152302376250733,
    "arrivals": 382341,
    "finished_requests": 122888,
    "scheduler_time": 221.54375146587296
}
#Debug simulation 
Total elapsed time: 175.48896202119067. Arrivals time: 0.9394629937596619 Scheduler time: 174.21193682728335 Scheduler overhead time: 0.13889130018651485 Adapter cache time: 0.023932042066007853 Engine time: 0.13608917873352766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 158.78552958229557,
    "estimated_duration": 3600.0950314799743,
    "input_throughput": 8437.585045501588,
    "output_throughput": 7477.596775808818,
    "total_throughput": 15915.181821310405,
    "itl": 111.28626338333754,
    "ttft": 1613654.396829432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33793252168688925,
    "arrivals": 382341,
    "finished_requests": 122889,
    "scheduler_time": 221.28870707730758
}
#Debug simulation 
Total elapsed time: 158.7857237290591. Arrivals time: 0.895458769518882 Scheduler time: 157.57192370248958 Scheduler overhead time: 0.12923972634598613 Adapter cache time: 0.022358359768986702 Engine time: 0.12839567102491856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 159.65040080295876,
    "estimated_duration": 3600.0959221379435,
    "input_throughput": 8437.582958056551,
    "output_throughput": 7477.594925863344,
    "total_throughput": 15915.177883919896,
    "itl": 111.28625938792696,
    "ttft": 1613654.8654832204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3387842949107294,
    "arrivals": 382341,
    "finished_requests": 122889,
    "scheduler_time": 221.28874596205176
}
#Debug simulation 
Total elapsed time: 159.65057593304664. Arrivals time: 0.9038119395263493 Scheduler time: 158.42647319845855 Scheduler overhead time: 0.13118774304166436 Adapter cache time: 0.022356214001774788 Engine time: 0.12991786282509565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 155.11802991107106,
    "estimated_duration": 3600.0796456269795,
    "input_throughput": 8437.62110566023,
    "output_throughput": 7477.628733214228,
    "total_throughput": 15915.249838874457,
    "itl": 111.2861205565983,
    "ttft": 1613646.3070433496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32444887617835794,
    "arrivals": 382341,
    "finished_requests": 122889,
    "scheduler_time": 221.28840548710284
}
#Debug simulation 
Total elapsed time: 155.11819567671046. Arrivals time: 0.7563959322869778 Scheduler time: 154.07599967578426 Scheduler overhead time: 0.11511734034866095 Adapter cache time: 0.020298989489674568 Engine time: 0.11547309113666415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 156.25405799224973,
    "estimated_duration": 3600.100878886841,
    "input_throughput": 8437.571340887636,
    "output_throughput": 7477.584630440617,
    "total_throughput": 15915.155971328253,
    "itl": 111.28694205277907,
    "ttft": 1613658.4544506862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3429341698624195,
    "arrivals": 382341,
    "finished_requests": 122889,
    "scheduler_time": 221.28885256593682
}
#Debug simulation 
Total elapsed time: 156.25424344604835. Arrivals time: 0.7492194399237633 Scheduler time: 155.20660832244903 Scheduler overhead time: 0.12065631616860628 Adapter cache time: 0.02155496971681714 Engine time: 0.12034540204331279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 165.08929314790294,
    "estimated_duration": 3600.014292960565,
    "input_throughput": 8463.436397899255,
    "output_throughput": 7490.703037688022,
    "total_throughput": 15954.139435587278,
    "itl": 111.38203889162693,
    "ttft": 1617360.248851738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.33488563302904406,
    "arrivals": 382341,
    "finished_requests": 123208,
    "scheduler_time": 220.72414306666948
}
#Debug simulation 
Total elapsed time: 165.08956874674186. Arrivals time: 0.7832395918667316 Scheduler time: 164.00077404733747 Scheduler overhead time: 0.12425725627690554 Adapter cache time: 0.022089958656579256 Engine time: 0.12272524973377585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [21 21 22]
Adapter prompts. [1080, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 17280]
Prompts retrieved: 1145880 . Total input tokens: 255426271 . Total output tokens: 229483873
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 158.09112079115584,
    "estimated_duration": 3600.1033661875153,
    "input_throughput": 8437.56551139477,
    "output_throughput": 7477.579464199706,
    "total_throughput": 15915.144975594478,
    "itl": 111.28691847554346,
    "ttft": 1613659.3687199065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34708404481410965,
    "arrivals": 382341,
    "finished_requests": 122889,
    "scheduler_time": 221.28889064752607
}
#Debug simulation 
Total elapsed time: 158.0913434973918. Arrivals time: 0.7724393880926073 Scheduler time: 157.02241073548794 Scheduler overhead time: 0.11975179566070437 Adapter cache time: 0.021641621366143227 Engine time: 0.1192358797416091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 161.27514990977943,
    "estimated_duration": 3600.0177626689665,
    "input_throughput": 8478.080112963746,
    "output_throughput": 7488.751105498094,
    "total_throughput": 15966.831218461839,
    "itl": 111.22288281348416,
    "ttft": 1608152.1803515735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4009238944551903,
    "arrivals": 378554,
    "finished_requests": 123098,
    "scheduler_time": 220.8621725467937
}
#Debug simulation 
Total elapsed time: 161.27531370380893. Arrivals time: 0.8587799281813204 Scheduler time: 160.0967815904878 Scheduler overhead time: 0.12988034263253212 Adapter cache time: 0.02409597858786583 Engine time: 0.1287441048771143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 154.47461940301582,
    "estimated_duration": 3600.01889204707,
    "input_throughput": 8480.228830866045,
    "output_throughput": 7491.695129595271,
    "total_throughput": 15971.923960461316,
    "itl": 111.24738919705761,
    "ttft": 1606669.6597046098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4272443813364953,
    "arrivals": 378554,
    "finished_requests": 123174,
    "scheduler_time": 220.7555010603035
}
#Debug simulation 
Total elapsed time: 154.47480147564784. Arrivals time: 0.7979903500527143 Scheduler time: 153.38465969497338 Scheduler overhead time: 0.11812507966533303 Adapter cache time: 0.020892774686217308 Engine time: 0.11704451963305473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 155.8854960608296,
    "estimated_duration": 3600.0196901280588,
    "input_throughput": 8480.226950901491,
    "output_throughput": 7491.693468776729,
    "total_throughput": 15971.92041967822,
    "itl": 111.24741419563591,
    "ttft": 1606669.9680443811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4280415012128662,
    "arrivals": 378554,
    "finished_requests": 123174,
    "scheduler_time": 220.75550202141287
}
#Debug simulation 
Total elapsed time: 155.88566744793206. Arrivals time: 0.7975039267912507 Scheduler time: 154.7882650126703 Scheduler overhead time: 0.1219758098013699 Adapter cache time: 0.021629846654832363 Engine time: 0.1204456202685833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 160.96149383112788,
    "estimated_duration": 3600.0919475117807,
    "input_throughput": 8441.95493979131,
    "output_throughput": 7444.222089528257,
    "total_throughput": 15886.177029319568,
    "itl": 110.7117006302,
    "ttft": 1613165.035149557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.35000365981133674,
    "arrivals": 378554,
    "finished_requests": 122492,
    "scheduler_time": 223.06129308466566
}
#Debug simulation 
Total elapsed time: 160.96165807312354. Arrivals time: 0.8065286632627249 Scheduler time: 159.85539484675974 Scheduler overhead time: 0.12110853614285588 Adapter cache time: 0.022310341708362103 Engine time: 0.12036639079451561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 153.8076646500267,
    "estimated_duration": 3600.0242840179976,
    "input_throughput": 8480.216129521914,
    "output_throughput": 7491.683908836979,
    "total_throughput": 15971.900038358892,
    "itl": 111.24741363065115,
    "ttft": 1606671.6832065694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.43357466781511944,
    "arrivals": 378554,
    "finished_requests": 123174,
    "scheduler_time": 220.7555631305568
}
#Debug simulation 
Total elapsed time: 153.8078321670182. Arrivals time: 0.7853804146870971 Scheduler time: 152.7301051625982 Scheduler overhead time: 0.11862378194928169 Adapter cache time: 0.02131293062120676 Engine time: 0.11759372381493449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 152.61662577930838,
    "estimated_duration": 3600.006154426986,
    "input_throughput": 8478.1074505852,
    "output_throughput": 7488.7752530220805,
    "total_throughput": 15966.88270360728,
    "itl": 111.22275835308882,
    "ttft": 1608146.2921007383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3916965886321855,
    "arrivals": 378554,
    "finished_requests": 123098,
    "scheduler_time": 220.86189242080744
}
#Debug simulation 
Total elapsed time: 152.61680100718513. Arrivals time: 0.7986065298318863 Scheduler time: 151.52682196861133 Scheduler overhead time: 0.1178348921239376 Adapter cache time: 0.021162460558116436 Engine time: 0.11740648280829191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [21 21 22]
Adapter prompts. [540, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 34560, 17280, 34560, 540, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 540, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 540, 17280, 17280, 540, 17280, 540, 540, 540, 34560, 17280]
Prompts retrieved: 1134540 . Total input tokens: 252921097 . Total output tokens: 227201613
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 155.5137352910824,
    "estimated_duration": 3600.030931765092,
    "input_throughput": 8480.200470119757,
    "output_throughput": 7491.670074839193,
    "total_throughput": 15971.87054495895,
    "itl": 111.24785839601256,
    "ttft": 1606674.8360298618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4389820806309579,
    "arrivals": 378554,
    "finished_requests": 123174,
    "scheduler_time": 220.75610319477116
}
#Debug simulation 
Total elapsed time: 155.51390766724944. Arrivals time: 0.7773297973908484 Scheduler time: 154.44304863596335 Scheduler overhead time: 0.12000872613862157 Adapter cache time: 0.021694539580494165 Engine time: 0.11599086411297321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 167.03927318099886,
    "estimated_duration": 3600.014376195692,
    "input_throughput": 8338.537812096842,
    "output_throughput": 7446.159153488571,
    "total_throughput": 15784.696965585412,
    "itl": 111.65368130614863,
    "ttft": 1608036.5837910946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34889560280833354,
    "arrivals": 376669,
    "finished_requests": 121694,
    "scheduler_time": 222.34925991962166
}
#Debug simulation 
Total elapsed time: 167.03952895477414. Arrivals time: 0.8039929238148034 Scheduler time: 165.92584249889478 Scheduler overhead time: 0.12328235059976578 Adapter cache time: 0.022994085680693388 Engine time: 0.1250241338275373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 163.81063416600227,
    "estimated_duration": 3600.110483950399,
    "input_throughput": 8385.9145808415,
    "output_throughput": 7486.627735497948,
    "total_throughput": 15872.542316339448,
    "itl": 111.826233700957,
    "ttft": 1604134.1606030003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42044709010981024,
    "arrivals": 376669,
    "finished_requests": 122436,
    "scheduler_time": 220.50811658914924
}
#Debug simulation 
Total elapsed time: 163.81080541806296. Arrivals time: 0.7878382443450391 Scheduler time: 162.71710521448404 Scheduler overhead time: 0.12498731119558215 Adapter cache time: 0.02327369712293148 Engine time: 0.12159565789625049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 164.52424712618813,
    "estimated_duration": 3600.111326279727,
    "input_throughput": 8385.912618762788,
    "output_throughput": 7486.625983828198,
    "total_throughput": 15872.538602590987,
    "itl": 111.82623693333643,
    "ttft": 1604134.5440207422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42127996852621546,
    "arrivals": 376669,
    "finished_requests": 122436,
    "scheduler_time": 220.5081260400581
}
#Debug simulation 
Total elapsed time: 164.52441681688651. Arrivals time: 0.7961379820480943 Scheduler time: 163.42629791004583 Scheduler overhead time: 0.12285059178248048 Adapter cache time: 0.022824337240308523 Engine time: 0.12061206623911858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 169.74049992812797,
    "estimated_duration": 3600.0189371169845,
    "input_throughput": 8338.527247870563,
    "output_throughput": 7446.14971983102,
    "total_throughput": 15784.676967701584,
    "itl": 111.65364690256914,
    "ttft": 1608038.7457156752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.353532188490499,
    "arrivals": 376669,
    "finished_requests": 121694,
    "scheduler_time": 222.34936303138522
}
#Debug simulation 
Total elapsed time: 169.7406624313444. Arrivals time: 0.8080400470644236 Scheduler time: 168.624948205892 Scheduler overhead time: 0.12449515471234918 Adapter cache time: 0.022775225806981325 Engine time: 0.12377595249563456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 160.9003026871942,
    "estimated_duration": 3600.1161007846426,
    "input_throughput": 8385.901497293396,
    "output_throughput": 7486.6160550004715,
    "total_throughput": 15872.517552293868,
    "itl": 111.82626899481406,
    "ttft": 1604136.4834616582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42681313512846875,
    "arrivals": 376669,
    "finished_requests": 122436,
    "scheduler_time": 220.50816768701588
}
#Debug simulation 
Total elapsed time: 160.90047181397676. Arrivals time: 0.858019900508225 Scheduler time: 159.74190962547436 Scheduler overhead time: 0.12042978964745998 Adapter cache time: 0.021718885749578476 Engine time: 0.12118540145456791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 167.6860005389899,
    "estimated_duration": 3600.0045792350625,
    "input_throughput": 8338.560504380936,
    "output_throughput": 7446.179417276147,
    "total_throughput": 15784.739921657083,
    "itl": 111.6536494393098,
    "ttft": 1608031.7086294226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3408657336188484,
    "arrivals": 376669,
    "finished_requests": 121694,
    "scheduler_time": 222.34897210587567
}
#Debug simulation 
Total elapsed time: 167.6862293141894. Arrivals time: 0.8116448535583913 Scheduler time: 166.5638295598328 Scheduler overhead time: 0.1278720018453896 Adapter cache time: 0.023677665274590254 Engine time: 0.12266415543854237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [21 21 22]
Adapter prompts. [270, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 34560, 17280, 34560, 270, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 270, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 270, 17280, 17280, 270, 17280, 270, 270, 270, 34560, 17280]
Prompts retrieved: 1128870 . Total input tokens: 251650939 . Total output tokens: 226081943
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 163.3595417398028,
    "estimated_duration": 3600.122383022316,
    "input_throughput": 8385.886863839112,
    "output_throughput": 7486.602990805307,
    "total_throughput": 15872.489854644418,
    "itl": 111.82638182315053,
    "ttft": 1604139.4600768187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4319690403714774,
    "arrivals": 376669,
    "finished_requests": 122436,
    "scheduler_time": 220.50829363364534
}
#Debug simulation 
Total elapsed time: 163.3596924538724. Arrivals time: 0.8135086204856634 Scheduler time: 162.22301622712985 Scheduler overhead time: 0.13819734985008836 Adapter cache time: 0.02303162869066 Engine time: 0.1250217822380364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 161.96883298968896,
    "estimated_duration": 3600.0642328844224,
    "input_throughput": 8431.290398305087,
    "output_throughput": 7500.182567122228,
    "total_throughput": 15931.472965427314,
    "itl": 111.82195162691792,
    "ttft": 1599917.9068799687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3641980415279973,
    "arrivals": 375735,
    "finished_requests": 122980,
    "scheduler_time": 219.82143708464528
}
#Debug simulation 
Total elapsed time: 161.96901057986543. Arrivals time: 0.8052551290020347 Scheduler time: 160.86131169693545 Scheduler overhead time: 0.12343794107437134 Adapter cache time: 0.021801305003464222 Engine time: 0.12085775984451175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 172.83097845083103,
    "estimated_duration": 3600.0123315305086,
    "input_throughput": 8428.25668519321,
    "output_throughput": 7498.752924694315,
    "total_throughput": 15927.009609887524,
    "itl": 111.51088497572856,
    "ttft": 1595930.6610263092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3978823567717336,
    "arrivals": 375735,
    "finished_requests": 122862,
    "scheduler_time": 220.2352063441714
}
#Debug simulation 
Total elapsed time: 172.83115526475012. Arrivals time: 0.8338552280329168 Scheduler time: 171.6850522076711 Scheduler overhead time: 0.12667656410485506 Adapter cache time: 0.022687883116304874 Engine time: 0.12581947958096862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 174.4234909019433,
    "estimated_duration": 3600.0138600085943,
    "input_throughput": 8428.253106760974,
    "output_throughput": 7498.749740906706,
    "total_throughput": 15927.00284766768,
    "itl": 111.5108753638081,
    "ttft": 1595931.7231201706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3986263466067621,
    "arrivals": 375735,
    "finished_requests": 122862,
    "scheduler_time": 220.2352905623565
}
#Debug simulation 
Total elapsed time: 174.42363940691575. Arrivals time: 0.8402489898726344 Scheduler time: 173.26713139517233 Scheduler overhead time: 0.12876240583136678 Adapter cache time: 0.023265629541128874 Engine time: 0.12716484908014536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 172.8725217669271,
    "estimated_duration": 3600.127826631161,
    "input_throughput": 8428.154627051978,
    "output_throughput": 7498.620410170725,
    "total_throughput": 15926.775037222704,
    "itl": 111.51038649786008,
    "ttft": 1595946.6116365655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38235573467100054,
    "arrivals": 375735,
    "finished_requests": 122865,
    "scheduler_time": 220.24288918017993
}
#Debug simulation 
Total elapsed time: 172.87273560510948. Arrivals time: 0.8345387643203139 Scheduler time: 171.72280363785103 Scheduler overhead time: 0.12667442997917533 Adapter cache time: 0.02300235303118825 Engine time: 0.12749196263030171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 175.25089812697843,
    "estimated_duration": 3600.018498404096,
    "input_throughput": 8428.242247491413,
    "output_throughput": 7498.740079243278,
    "total_throughput": 15926.982326734691,
    "itl": 111.51094806392494,
    "ttft": 1595933.8105023452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4034049904905263,
    "arrivals": 375735,
    "finished_requests": 122862,
    "scheduler_time": 220.23535039113648
}
#Debug simulation 
Total elapsed time: 175.25107676815242. Arrivals time: 0.8225920158438385 Scheduler time: 174.11458187690005 Scheduler overhead time: 0.12742478167638183 Adapter cache time: 0.02372715948149562 Engine time: 0.12612923048436642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 162.83877208596095,
    "estimated_duration": 3600.055264418278,
    "input_throughput": 8431.311402355563,
    "output_throughput": 7500.2012515946835,
    "total_throughput": 15931.512653950247,
    "itl": 111.82183409244597,
    "ttft": 1599913.5309561156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 119,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3558159850933593,
    "arrivals": 375735,
    "finished_requests": 122980,
    "scheduler_time": 219.8212508292388
}
#Debug simulation 
Total elapsed time: 162.83893900411204. Arrivals time: 0.8064900836907327 Scheduler time: 161.7280733017251 Scheduler overhead time: 0.12328865472227335 Adapter cache time: 0.023399571888148785 Engine time: 0.12204254930838943 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [21 21 22]
Adapter prompts. [135, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 34560, 17280, 34560, 135, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 135, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 135, 17280, 17280, 135, 17280, 135, 135, 135, 34560, 17280]
Prompts retrieved: 1126035 . Total input tokens: 251026360 . Total output tokens: 225507485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 173.484013450332,
    "estimated_duration": 3600.023941818325,
    "input_throughput": 8428.22950357234,
    "output_throughput": 7498.72874077745,
    "total_throughput": 15926.95824434979,
    "itl": 111.51101855852605,
    "ttft": 1595935.9254845127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4088124033063647,
    "arrivals": 375735,
    "finished_requests": 122862,
    "scheduler_time": 220.23538639255253
}
#Debug simulation 
Total elapsed time: 173.48430351307616. Arrivals time: 0.8296319302171469 Scheduler time: 172.33627325389534 Scheduler overhead time: 0.12875405605882406 Adapter cache time: 0.022988880518823862 Engine time: 0.1298223715275526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 171.32980253500864,
    "estimated_duration": 3600.0387615275126,
    "input_throughput": 8436.891659219953,
    "output_throughput": 7496.462896013113,
    "total_throughput": 15933.354555233067,
    "itl": 111.55939063174506,
    "ttft": 1599596.784871288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4070448699430558,
    "arrivals": 375251,
    "finished_requests": 123235,
    "scheduler_time": 220.37517717721246
}
#Debug simulation 
Total elapsed time: 171.32997696800157. Arrivals time: 0.8194985841400921 Scheduler time: 170.19554448872805 Scheduler overhead time: 0.1293270206078887 Adapter cache time: 0.023276721592992544 Engine time: 0.124420793261379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 169.57903354614973,
    "estimated_duration": 3600.0361763371197,
    "input_throughput": 8465.39854246902,
    "output_throughput": 7539.683678294855,
    "total_throughput": 16005.082220763876,
    "itl": 112.05816013794762,
    "ttft": 1583517.280855868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3923108515003696,
    "arrivals": 375251,
    "finished_requests": 123619,
    "scheduler_time": 219.07851361500155
}
#Debug simulation 
Total elapsed time: 169.57920347107574. Arrivals time: 0.8096585697494447 Scheduler time: 168.46225808234885 Scheduler overhead time: 0.12388657545670867 Adapter cache time: 0.022347829770296812 Engine time: 0.12295630015432835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 169.6739502530545,
    "estimated_duration": 3600.0371607783536,
    "input_throughput": 8465.396227579753,
    "output_throughput": 7539.681616545164,
    "total_throughput": 16005.077844124917,
    "itl": 112.05819389995399,
    "ttft": 1583517.9013287723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3928765564039359,
    "arrivals": 375251,
    "finished_requests": 123619,
    "scheduler_time": 219.07853219700718
}
#Debug simulation 
Total elapsed time: 169.6741344393231. Arrivals time: 0.8139192024245858 Scheduler time: 168.55031142011285 Scheduler overhead time: 0.12596008507534862 Adapter cache time: 0.02407019678503275 Engine time: 0.12353882472962141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 169.56238198280334,
    "estimated_duration": 3600.0508246577365,
    "input_throughput": 8436.863388696083,
    "output_throughput": 7496.437776698821,
    "total_throughput": 15933.301165394905,
    "itl": 111.55963869722879,
    "ttft": 1599601.0007311392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4181064551440069,
    "arrivals": 375251,
    "finished_requests": 123235,
    "scheduler_time": 220.37527837499658
}
#Debug simulation 
Total elapsed time: 169.5625337981619. Arrivals time: 0.8381677903234959 Scheduler time: 168.40588406240568 Scheduler overhead time: 0.12987627694383264 Adapter cache time: 0.02344238292425871 Engine time: 0.125976559240371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 167.9621117739007,
    "estimated_duration": 3600.041151934382,
    "input_throughput": 8465.386842487816,
    "output_throughput": 7539.673257739121,
    "total_throughput": 16005.060100226938,
    "itl": 112.05820892258858,
    "ttft": 1583519.6168797412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39790670786052973,
    "arrivals": 375251,
    "finished_requests": 123619,
    "scheduler_time": 219.0785936259632
}
#Debug simulation 
Total elapsed time: 167.9623436331749. Arrivals time: 0.8362439069896936 Scheduler time: 166.8108452311717 Scheduler overhead time: 0.128535573836416 Adapter cache time: 0.023112063761800528 Engine time: 0.12566454941406846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 169.16914503322914,
    "estimated_duration": 3600.0302157258507,
    "input_throughput": 8436.9116868304,
    "output_throughput": 7496.48069122072,
    "total_throughput": 15933.392378051121,
    "itl": 111.55926077086126,
    "ttft": 1599593.7385273287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 133,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39767668922198984,
    "arrivals": 375251,
    "finished_requests": 123235,
    "scheduler_time": 220.3750992090265
}
#Debug simulation 
Total elapsed time: 169.16930775903165. Arrivals time: 0.8165696132928133 Scheduler time: 168.04157040221617 Scheduler overhead time: 0.12481072219088674 Adapter cache time: 0.02351758861914277 Engine time: 0.12627938436344266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [21 21 22]
Adapter prompts. [66, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 34560, 17280, 34560, 66, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 66, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 66, 17280, 17280, 66, 17280, 66, 66, 66, 34560, 17280]
Prompts retrieved: 1124586 . Total input tokens: 250714822 . Total output tokens: 225227815
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 166.75135424220935,
    "estimated_duration": 3600.047222566833,
    "input_throughput": 8465.372567605044,
    "output_throughput": 7539.660543854464,
    "total_throughput": 16005.033111459508,
    "itl": 112.05832982688369,
    "ttft": 1583522.5695022899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40318836688995324,
    "arrivals": 375251,
    "finished_requests": 123619,
    "scheduler_time": 219.0786823293254
}
#Debug simulation 
Total elapsed time: 166.75151175213978. Arrivals time: 0.8252113158814609 Scheduler time: 165.61977601330727 Scheduler overhead time: 0.12326632160693407 Adapter cache time: 0.023404988925904036 Engine time: 0.12353589152917266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 148.11534846993163,
    "estimated_duration": 3600.1151739728475,
    "input_throughput": 8488.3284348587,
    "output_throughput": 7542.34258845542,
    "total_throughput": 16030.67102331412,
    "itl": 111.72829211293806,
    "ttft": 1600479.4528986928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4131658454309213,
    "arrivals": 375015,
    "finished_requests": 123901,
    "scheduler_time": 219.86110045755385
}
#Debug simulation 
Total elapsed time: 148.1155250929296. Arrivals time: 0.8090612427331507 Scheduler time: 147.01309230551124 Scheduler overhead time: 0.11909598158672452 Adapter cache time: 0.021037224680185318 Engine time: 0.11738258833065629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 148.27993129007518,
    "estimated_duration": 3600.0150768169274,
    "input_throughput": 8488.235284564049,
    "output_throughput": 7542.323134937469,
    "total_throughput": 16030.558419501518,
    "itl": 111.72909570371888,
    "ttft": 1600435.5873551806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.440430368471425,
    "arrivals": 375015,
    "finished_requests": 123895,
    "scheduler_time": 219.85398552053437
}
#Debug simulation 
Total elapsed time: 148.2800813531503. Arrivals time: 0.8247291222214699 Scheduler time: 147.15387741290033 Scheduler overhead time: 0.12206395249813795 Adapter cache time: 0.021790347527712584 Engine time: 0.12054183706641197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 152.07392400503159,
    "estimated_duration": 3600.01684591891,
    "input_throughput": 8488.231113318605,
    "output_throughput": 7542.319428527365,
    "total_throughput": 16030.55054184597,
    "itl": 111.72912160718447,
    "ttft": 1600436.5908292872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4412273190915597,
    "arrivals": 375015,
    "finished_requests": 123895,
    "scheduler_time": 219.85405732466882
}
#Debug simulation 
Total elapsed time: 152.07411549892277. Arrivals time: 0.8145590289495885 Scheduler time: 150.96191465016454 Scheduler overhead time: 0.12071369215846062 Adapter cache time: 0.021678295452147722 Engine time: 0.12015940714627504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 148.7067269347608,
    "estimated_duration": 3600.126215307732,
    "input_throughput": 8488.302401750067,
    "output_throughput": 7542.319456619103,
    "total_throughput": 16030.62185836917,
    "itl": 111.72855259095084,
    "ttft": 1600483.8581346015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42326936509693064,
    "arrivals": 375015,
    "finished_requests": 123901,
    "scheduler_time": 219.86163811843733
}
#Debug simulation 
Total elapsed time: 148.70689215278253. Arrivals time: 0.8154879454523325 Scheduler time: 147.59410396171734 Scheduler overhead time: 0.12102703750133514 Adapter cache time: 0.021651596296578646 Engine time: 0.11967365629971027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 148.18385484302416,
    "estimated_duration": 3600.0215003835756,
    "input_throughput": 8488.220138891984,
    "output_throughput": 7542.309677069138,
    "total_throughput": 16030.529815961121,
    "itl": 111.72917544703112,
    "ttft": 1600438.600412902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.44650897812098334,
    "arrivals": 375015,
    "finished_requests": 123895,
    "scheduler_time": 219.85413040037022
}
#Debug simulation 
Total elapsed time: 148.18400798505172. Arrivals time: 0.7957338537089527 Scheduler time: 147.09270036639646 Scheduler overhead time: 0.11880731768906116 Adapter cache time: 0.0208273702301085 Engine time: 0.11953162727877498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 148.41720713721588,
    "estimated_duration": 3600.1064931350734,
    "input_throughput": 8488.348902531603,
    "output_throughput": 7542.3607750986685,
    "total_throughput": 16030.709677630271,
    "itl": 111.72818159478156,
    "ttft": 1600475.9217876773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4036567898117942,
    "arrivals": 375015,
    "finished_requests": 123901,
    "scheduler_time": 219.861028328156
}
#Debug simulation 
Total elapsed time: 148.41738827945665. Arrivals time: 0.8021586928516626 Scheduler time: 147.3223693515174 Scheduler overhead time: 0.11941513884812593 Adapter cache time: 0.021605700720101595 Engine time: 0.11603948008269072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 64,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_64_slots_16_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [21 21 22]
Adapter prompts. [33, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 34560, 17280, 34560, 33, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 33, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 33, 17280, 17280, 33, 17280, 33, 33, 33, 34560, 17280]
Prompts retrieved: 1123893 . Total input tokens: 250557472 . Total output tokens: 225084752
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 147.89327955478802,
    "estimated_duration": 3600.029003660828,
    "input_throughput": 8488.202447515325,
    "output_throughput": 7542.2939571845,
    "total_throughput": 16030.496404699827,
    "itl": 111.72931865548671,
    "ttft": 1600442.332001669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4525451598688959,
    "arrivals": 375015,
    "finished_requests": 123895,
    "scheduler_time": 219.8542969943353
}
#Debug simulation 
Total elapsed time: 147.89344089385122. Arrivals time: 0.8111188537441194 Scheduler time: 146.78935817163438 Scheduler overhead time: 0.11841307301074266 Adapter cache time: 0.02104354929178953 Engine time: 0.11840273626148701 
