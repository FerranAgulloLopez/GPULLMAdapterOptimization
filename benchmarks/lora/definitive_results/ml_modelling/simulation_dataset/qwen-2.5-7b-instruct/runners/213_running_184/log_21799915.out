INFO 06-01 00:47:20 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.0263733258470893,
    "estimated_duration": 3599.75148066685,
    "input_throughput": 2204.9444364780516,
    "output_throughput": 1935.3027667091737,
    "total_throughput": 4140.247203187226,
    "itl": 38.53583759701082,
    "ttft": 15426.307439847604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.212044439935184,
    "arrivals": 31815,
    "finished_requests": 31720,
    "scheduler_time": 12.20134987375461
}
#Debug simulation 
Total elapsed time: 3.026474970858544. Arrivals time: 0.08668099297210574 Scheduler time: 2.5309614753350616 Scheduler overhead time: 0.09455520007759333 Adapter cache time: 0.17529740324243903 Engine time: 0.09346830891445279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.031485340092331,
    "estimated_duration": 3599.7619006623568,
    "input_throughput": 2204.9380539694985,
    "output_throughput": 1935.2971647147392,
    "total_throughput": 4140.235218684238,
    "itl": 38.538135756965346,
    "ttft": 15427.707056255565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.31511443478868,
    "arrivals": 31815,
    "finished_requests": 31720,
    "scheduler_time": 12.202059537068205
}
#Debug simulation 
Total elapsed time: 3.03158428799361. Arrivals time: 0.08711061766371131 Scheduler time: 2.5391002418473363 Scheduler overhead time: 0.09420125745236874 Adapter cache time: 0.17454277956858277 Engine time: 0.09154941560700536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 3.056271940935403,
    "estimated_duration": 3599.77058268231,
    "input_throughput": 2205.0569106227194,
    "output_throughput": 1935.4408399016772,
    "total_throughput": 4140.497750524397,
    "itl": 38.50008568573136,
    "ttft": 15156.2019793568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.886165578624336,
    "arrivals": 31815,
    "finished_requests": 31722,
    "scheduler_time": 12.181070848702452
}
#Debug simulation 
Total elapsed time: 3.0563599201850593. Arrivals time: 0.0901321186684072 Scheduler time: 2.5599988820031285 Scheduler overhead time: 0.0940517084673047 Adapter cache time: 0.17407898604869843 Engine time: 0.09269735869020224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 3.0049560191109776,
    "estimated_duration": 3599.7682586093115,
    "input_throughput": 2204.9341595857,
    "output_throughput": 1935.2937465733949,
    "total_throughput": 4140.227906159094,
    "itl": 38.5485254864983,
    "ttft": 15439.800426369393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.02336705451097,
    "arrivals": 31815,
    "finished_requests": 31720,
    "scheduler_time": 12.208118411895692
}
#Debug simulation 
Total elapsed time: 3.005045648198575. Arrivals time: 0.08859279612079263 Scheduler time: 2.512703686952591 Scheduler overhead time: 0.09462879737839103 Adapter cache time: 0.17276819655671716 Engine time: 0.09097225358709693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 3.0362072670832276,
    "estimated_duration": 3599.7618915753987,
    "input_throughput": 2204.8444422323973,
    "output_throughput": 1935.2752237040795,
    "total_throughput": 4140.119665936477,
    "itl": 38.44696549248281,
    "ttft": 16080.80519885014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.98702492326719,
    "arrivals": 31815,
    "finished_requests": 31718,
    "scheduler_time": 12.218383480408077
}
#Debug simulation 
Total elapsed time: 3.036293878685683. Arrivals time: 0.0867460398003459 Scheduler time: 2.549742785282433 Scheduler overhead time: 0.09294014051556587 Adapter cache time: 0.17054348113015294 Engine time: 0.09148793714120984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 540, 135, 66, 540, 540, 66, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 66, 540, 66, 540, 135, 135, 135, 66, 66, 135, 66, 540, 66, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 540, 540, 540, 66, 135, 135, 135, 540, 135, 66, 135, 66, 540, 135, 540, 540, 135, 540, 540, 66, 66, 540, 135, 135, 66, 66, 66, 135, 66, 135, 66, 540, 66, 135, 540, 66, 540, 135, 66, 540, 540, 540, 540, 135, 66, 135, 540, 540, 135, 66, 66, 540, 135, 135, 66, 66, 540, 135, 540, 135, 540, 540, 135, 540, 540, 66, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 66, 66, 135, 135, 540, 66, 66, 540, 66, 540, 135, 66, 540, 135, 135, 66, 540, 540, 540, 66, 135, 540, 66, 540, 135, 135, 540, 540, 66, 135, 540, 66, 135, 135, 66, 135, 66, 135, 540, 540, 135, 66, 540, 66, 540, 135, 135, 135, 135, 135, 66, 66, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 66, 135, 135, 135, 135, 135, 135, 135, 135, 540, 66, 66, 66, 66, 66, 135, 66, 66, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66, 135, 540, 540, 135, 135, 66, 540, 135, 540, 66, 135, 135, 66, 66, 135, 66, 540, 540, 66, 540, 540, 66, 135, 540, 66, 66, 135, 135, 66, 66, 540, 540, 540, 540, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 66, 540, 540, 66, 540, 66, 66, 135, 66, 540, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 66, 540, 540, 135, 66, 540, 135, 135, 540, 540, 540, 66, 540, 66, 540, 540, 66, 66, 540, 66, 135, 540, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 540, 66, 66, 66, 135, 66, 135, 135, 66, 540, 135, 540, 66, 540, 66, 135, 135, 135, 135, 66, 135, 540, 540, 66, 540, 540, 66, 540, 135, 540, 135, 135, 135, 66, 135, 66, 66, 540, 66, 135, 66, 66, 135, 540, 135, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 94848 . Total input tokens: 21112697 . Total output tokens: 18991968
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 3.045870863366872,
    "estimated_duration": 3599.763976623363,
    "input_throughput": 2204.936782395737,
    "output_throughput": 1935.2960486411646,
    "total_throughput": 4140.232831036901,
    "itl": 38.55843157414451,
    "ttft": 15454.61307138879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.84829395302089,
    "arrivals": 31815,
    "finished_requests": 31720,
    "scheduler_time": 12.215332825435851
}
#Debug simulation 
Total elapsed time: 3.045962257310748. Arrivals time: 0.08781262394040823 Scheduler time: 2.5512999445199966 Scheduler overhead time: 0.09410682180896401 Adapter cache time: 0.17449090909212828 Engine time: 0.09321444761008024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.7621242739260197,
    "estimated_duration": 3599.952435341034,
    "input_throughput": 2098.877175660298,
    "output_throughput": 1836.2548168983724,
    "total_throughput": 3935.1319925586704,
    "itl": 37.28211887156852,
    "ttft": 7184.590665630748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19926,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.983278785583224,
    "arrivals": 30443,
    "finished_requests": 30394,
    "scheduler_time": 9.628155048158943
}
#Debug simulation 
Total elapsed time: 2.762207848019898. Arrivals time: 0.08412044448778033 Scheduler time: 2.2564337654039264 Scheduler overhead time: 0.09558572247624397 Adapter cache time: 0.18647591769695282 Engine time: 0.0933494558557868 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.7836863663978875,
    "estimated_duration": 3599.961698261722,
    "input_throughput": 2098.8292746693246,
    "output_throughput": 1836.0787013905217,
    "total_throughput": 3934.907976059846,
    "itl": 37.35639317923016,
    "ttft": 7335.974712944966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19904,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.0859754273223,
    "arrivals": 30443,
    "finished_requests": 30393,
    "scheduler_time": 9.668626057287344
}
#Debug simulation 
Total elapsed time: 2.783777059055865. Arrivals time: 0.08736270479857922 Scheduler time: 2.2725732307881117 Scheduler overhead time: 0.0960372812114656 Adapter cache time: 0.187313134316355 Engine time: 0.09411223698407412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.774786756373942,
    "estimated_duration": 3599.9473772577935,
    "input_throughput": 2098.837624053118,
    "output_throughput": 1836.0860055223716,
    "total_throughput": 3934.9236295754895,
    "itl": 37.35712010634331,
    "ttft": 7337.471184337886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19899,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.1600021696464,
    "arrivals": 30443,
    "finished_requests": 30393,
    "scheduler_time": 9.669478297667975
}
#Debug simulation 
Total elapsed time: 2.7748767700977623. Arrivals time: 0.08580838469788432 Scheduler time: 2.265089066233486 Scheduler overhead time: 0.0947574651800096 Adapter cache time: 0.18721601460129023 Engine time: 0.09599744901061058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.7819003351032734,
    "estimated_duration": 3599.9399770526943,
    "input_throughput": 2098.8844392305823,
    "output_throughput": 1836.2611716132064,
    "total_throughput": 3935.1456108437887,
    "itl": 37.30998328434906,
    "ttft": 7198.232352489579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.545345943601475,
    "arrivals": 30443,
    "finished_requests": 30394,
    "scheduler_time": 9.643871726637355
}
#Debug simulation 
Total elapsed time: 2.7819765089079738. Arrivals time: 0.08489329647272825 Scheduler time: 2.268528759945184 Scheduler overhead time: 0.09917694656178355 Adapter cache time: 0.18726401310414076 Engine time: 0.09545755200088024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.766616777982563,
    "estimated_duration": 3599.94935429021,
    "input_throughput": 2098.836471406341,
    "output_throughput": 1836.0849971744212,
    "total_throughput": 3934.9214685807624,
    "itl": 37.36985162502412,
    "ttft": 7343.873344163322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.94529316584956,
    "arrivals": 30443,
    "finished_requests": 30393,
    "scheduler_time": 9.677231900371293
}
#Debug simulation 
Total elapsed time: 2.7667056820355356. Arrivals time: 0.08586296206340194 Scheduler time: 2.260406575165689 Scheduler overhead time: 0.09431280707940459 Adapter cache time: 0.18621521582826972 Engine time: 0.0939514716155827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.7828969336114824,
    "estimated_duration": 3599.938928808747,
    "input_throughput": 2098.943662497178,
    "output_throughput": 1836.4247646244507,
    "total_throughput": 3935.368427121629,
    "itl": 37.25820643642521,
    "ttft": 7055.987294345094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.62758298095934,
    "arrivals": 30443,
    "finished_requests": 30395,
    "scheduler_time": 9.614976607226295
}
#Debug simulation 
Total elapsed time: 2.7829765640199184. Arrivals time: 0.08531612204387784 Scheduler time: 2.2735295239835978 Scheduler overhead time: 0.09482271131128073 Adapter cache time: 0.18840153515338898 Engine time: 0.09483389789238572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 135, 33, 540, 540, 33, 135, 540, 540, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 33, 540, 33, 540, 135, 135, 135, 33, 33, 135, 33, 540, 33, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 540, 540, 540, 33, 135, 135, 135, 540, 135, 33, 135, 33, 540, 135, 540, 540, 135, 540, 540, 33, 33, 540, 135, 135, 33, 33, 33, 135, 33, 135, 33, 540, 33, 135, 540, 33, 540, 135, 33, 540, 540, 540, 540, 135, 33, 135, 540, 540, 135, 33, 33, 540, 135, 135, 33, 33, 540, 135, 540, 135, 540, 540, 135, 540, 540, 33, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 33, 33, 135, 135, 540, 33, 33, 540, 33, 540, 135, 33, 540, 135, 135, 33, 540, 540, 540, 33, 135, 540, 33, 540, 135, 135, 540, 540, 33, 135, 540, 33, 135, 135, 33, 135, 33, 135, 540, 540, 135, 33, 540, 33, 540, 135, 135, 135, 135, 135, 33, 33, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 33, 135, 135, 135, 135, 135, 135, 135, 135, 540, 33, 33, 33, 33, 33, 135, 33, 33, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33, 135, 540, 540, 135, 135, 33, 540, 135, 540, 33, 135, 135, 33, 33, 135, 33, 540, 540, 33, 540, 540, 33, 135, 540, 33, 33, 135, 135, 33, 33, 540, 540, 540, 540, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 33, 540, 540, 33, 540, 33, 33, 135, 33, 540, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 33, 540, 540, 135, 33, 540, 135, 135, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 135, 540, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 540, 33, 33, 33, 135, 33, 135, 135, 33, 540, 135, 540, 33, 540, 33, 135, 135, 135, 135, 33, 135, 540, 540, 33, 540, 540, 33, 540, 135, 540, 135, 135, 135, 33, 135, 33, 33, 540, 33, 135, 33, 33, 135, 540, 135, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90624 . Total input tokens: 20179995 . Total output tokens: 18105372
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.786680256947875,
    "estimated_duration": 3599.9461017288277,
    "input_throughput": 2098.8383677109696,
    "output_throughput": 1836.086656082357,
    "total_throughput": 3934.9250237933265,
    "itl": 37.38827890846404,
    "ttft": 7351.088516400382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.81870820157987,
    "arrivals": 30443,
    "finished_requests": 30393,
    "scheduler_time": 9.685921169805768
}
#Debug simulation 
Total elapsed time: 2.7867715572938323. Arrivals time: 0.08702729269862175 Scheduler time: 2.275784431491047 Scheduler overhead time: 0.0947625795379281 Adapter cache time: 0.18758325884118676 Engine time: 0.09572698175907135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.479887577239424,
    "estimated_duration": 3600.0064504879856,
    "input_throughput": 1870.188315659094,
    "output_throughput": 1691.052247746609,
    "total_throughput": 3561.240563405703,
    "itl": 34.005597798265825,
    "ttft": 5395.560216280548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.02066916814203,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.667876627413368
}
#Debug simulation 
Total elapsed time: 2.479973755311221. Arrivals time: 0.077466344460845 Scheduler time: 1.979228189215064 Scheduler overhead time: 0.10429348098114133 Adapter cache time: 0.17175125889480114 Engine time: 0.09782191272825003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.425064709968865,
    "estimated_duration": 3600.002986832223,
    "input_throughput": 1870.1901150155281,
    "output_throughput": 1691.05387475161,
    "total_throughput": 3561.243989767138,
    "itl": 34.076925239604265,
    "ttft": 5398.856191728655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.7957265102955,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.704117074903944
}
#Debug simulation 
Total elapsed time: 2.4251671778038144. Arrivals time: 0.07705154735594988 Scheduler time: 1.930940045043826 Scheduler overhead time: 0.09989704471081495 Adapter cache time: 0.16964348684996367 Engine time: 0.09889492997899652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.4896813496015966,
    "estimated_duration": 3600.013357586066,
    "input_throughput": 1870.1847274573734,
    "output_throughput": 1691.0490032409436,
    "total_throughput": 3561.2337306983172,
    "itl": 34.080109920229795,
    "ttft": 5398.816890748147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.857154472597514,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.7048094040018595
}
#Debug simulation 
Total elapsed time: 2.489768813829869. Arrivals time: 0.0790866338647902 Scheduler time: 1.9873828161507845 Scheduler overhead time: 0.10094373160973191 Adapter cache time: 0.17297790804877877 Engine time: 0.1001134030520916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 2.4203677028417587,
    "estimated_duration": 3600.003608473743,
    "input_throughput": 1870.189792074789,
    "output_throughput": 1691.0535827437634,
    "total_throughput": 3561.2433748185526,
    "itl": 34.033129673886876,
    "ttft": 5396.822652274572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.43582878017114,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.681375205380248
}
#Debug simulation 
Total elapsed time: 2.4204548648558557. Arrivals time: 0.0777886169962585 Scheduler time: 1.9228559690527618 Scheduler overhead time: 0.10247026430442929 Adapter cache time: 0.1698597758077085 Engine time: 0.09805554430931807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 2.4879489769227803,
    "estimated_duration": 3600.005765055593,
    "input_throughput": 1870.188671738427,
    "output_throughput": 1691.052569718868,
    "total_throughput": 3561.241241457295,
    "itl": 34.091011091075444,
    "ttft": 5399.405734540418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.573597253384534,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.711664956459789
}
#Debug simulation 
Total elapsed time: 2.4880412332713604. Arrivals time: 0.07886331854388118 Scheduler time: 1.9878208516165614 Scheduler overhead time: 0.0999587974511087 Adapter cache time: 0.1725291614420712 Engine time: 0.09909393033012748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 2.479503312148154,
    "estimated_duration": 3599.99902784307,
    "input_throughput": 1870.1921717000778,
    "output_throughput": 1691.055734436542,
    "total_throughput": 3561.24790613662,
    "itl": 33.98183527519957,
    "ttft": 5394.538448007736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.759437453563166,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.65589402235381
}
#Debug simulation 
Total elapsed time: 2.4796193689107895. Arrivals time: 0.07756728865206242 Scheduler time: 1.9828517031855881 Scheduler overhead time: 0.09930996038019657 Adapter cache time: 0.17201349418610334 Engine time: 0.09915266698226333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 540, 66, 33, 540, 540, 33, 66, 540, 540, 540, 540, 66, 66, 66, 66, 540, 540, 66, 66, 33, 540, 33, 540, 66, 66, 66, 33, 33, 66, 33, 540, 33, 540, 66, 540, 66, 33, 66, 540, 66, 540, 33, 540, 540, 540, 540, 33, 66, 66, 66, 540, 66, 33, 66, 33, 540, 66, 540, 540, 66, 540, 540, 33, 33, 540, 66, 66, 33, 33, 33, 66, 33, 66, 33, 540, 33, 66, 540, 33, 540, 66, 33, 540, 540, 540, 540, 66, 33, 66, 540, 540, 66, 33, 33, 540, 66, 66, 33, 33, 540, 66, 540, 66, 540, 540, 66, 540, 540, 33, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 33, 33, 66, 66, 540, 33, 33, 540, 33, 540, 66, 33, 540, 66, 66, 33, 540, 540, 540, 33, 66, 540, 33, 540, 66, 66, 540, 540, 33, 66, 540, 33, 66, 66, 33, 66, 33, 66, 540, 540, 66, 33, 540, 33, 540, 66, 66, 66, 66, 66, 33, 33, 540, 33, 540, 33, 66, 540, 66, 540, 66, 540, 66, 540, 33, 66, 66, 66, 66, 66, 66, 66, 66, 540, 33, 33, 33, 33, 33, 66, 33, 33, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33, 66, 540, 540, 66, 66, 33, 540, 66, 540, 33, 66, 66, 33, 33, 66, 33, 540, 540, 33, 540, 540, 33, 66, 540, 33, 33, 66, 66, 33, 33, 540, 540, 540, 540, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 33, 540, 540, 33, 540, 33, 33, 66, 33, 540, 540, 540, 66, 33, 540, 540, 66, 66, 540, 540, 33, 540, 540, 66, 33, 540, 66, 66, 540, 540, 540, 33, 540, 33, 540, 540, 33, 33, 540, 33, 66, 540, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 540, 33, 33, 33, 66, 33, 66, 66, 33, 540, 66, 540, 33, 540, 33, 66, 66, 66, 66, 33, 66, 540, 540, 33, 540, 540, 33, 540, 66, 540, 66, 66, 66, 33, 66, 33, 33, 540, 33, 66, 33, 33, 66, 540, 66, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 81792 . Total input tokens: 18226101 . Total output tokens: 16350805
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 2.458651550114155,
    "estimated_duration": 3600.020934972348,
    "input_throughput": 1870.180791060237,
    "output_throughput": 1691.0454438917757,
    "total_throughput": 3561.226234952013,
    "itl": 34.1080096090169,
    "ttft": 5400.040629167222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.39192286763682,
    "arrivals": 27512,
    "finished_requests": 27472,
    "scheduler_time": 5.719438362317886
}
#Debug simulation 
Total elapsed time: 2.458759617060423. Arrivals time: 0.07708556996658444 Scheduler time: 1.9656500071287155 Scheduler overhead time: 0.09980765543878078 Adapter cache time: 0.16994689824059606 Engine time: 0.0978743345476687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.9181102397851646,
    "estimated_duration": 3599.9342589565294,
    "input_throughput": 1401.5183714667176,
    "output_throughput": 1224.7740327563693,
    "total_throughput": 2626.2924042230866,
    "itl": 27.176153677625678,
    "ttft": 7859.65272076879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.62196878784916,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.11731669287238634
}
#Debug simulation 
Total elapsed time: 1.9181936010718346. Arrivals time: 0.06115841493010521 Scheduler time: 1.42006583372131 Scheduler overhead time: 0.11582174152135849 Adapter cache time: 0.14603890059515834 Engine time: 0.11724358703941107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9153785011731088,
    "estimated_duration": 3599.948681384451,
    "input_throughput": 1401.5127565817618,
    "output_throughput": 1224.7691259599753,
    "total_throughput": 2626.281882541737,
    "itl": 27.219034017153774,
    "ttft": 7859.858806753086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.91791238781335,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.11973728165712595
}
#Debug simulation 
Total elapsed time: 1.9154594410210848. Arrivals time: 0.061439819633960724 Scheduler time: 1.4179358738474548 Scheduler overhead time: 0.11630139453336596 Adapter cache time: 0.14463902032002807 Engine time: 0.11739623639732599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9253356498666108,
    "estimated_duration": 3599.943329327193,
    "input_throughput": 1401.5148402191512,
    "output_throughput": 1224.7709468315531,
    "total_throughput": 2626.285787050704,
    "itl": 27.218908029383357,
    "ttft": 7859.837173874131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.00516131206739,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.11975095893126367
}
#Debug simulation 
Total elapsed time: 1.9254487110301852. Arrivals time: 0.06142262229695916 Scheduler time: 1.4273366662673652 Scheduler overhead time: 0.11629800265654922 Adapter cache time: 0.1458039041608572 Engine time: 0.11620858870446682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.9236312150023878,
    "estimated_duration": 3599.949384645373,
    "input_throughput": 1401.5124827920363,
    "output_throughput": 1224.7688866976491,
    "total_throughput": 2626.2813694896854,
    "itl": 27.19111705669071,
    "ttft": 7859.8075498248,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15891,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.79035656469458,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.11814733811687074
}
#Debug simulation 
Total elapsed time: 1.9237030684016645. Arrivals time: 0.06216335482895374 Scheduler time: 1.4215743681415915 Scheduler overhead time: 0.11818670528009534 Adapter cache time: 0.1460010171867907 Engine time: 0.11722111655399203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9116780986078084,
    "estimated_duration": 3599.9319795189695,
    "input_throughput": 1401.5192588928232,
    "output_throughput": 1224.7748082698924,
    "total_throughput": 2626.2940671627157,
    "itl": 27.22738604371602,
    "ttft": 7859.933057879042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.64293169242174,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.12016557268950082
}
#Debug simulation 
Total elapsed time: 1.9117688457481563. Arrivals time: 0.06231353059411049 Scheduler time: 1.4112081844359636 Scheduler overhead time: 0.11699148500338197 Adapter cache time: 0.1465342789888382 Engine time: 0.11645760061219335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.9323073183186352,
    "estimated_duration": 3599.93533469448,
    "input_throughput": 1401.5179526629447,
    "output_throughput": 1224.7736667675986,
    "total_throughput": 2626.291619430543,
    "itl": 27.160718402761763,
    "ttft": 7859.6733528476625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.508909135710454,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.11663758187343556
}
#Debug simulation 
Total elapsed time: 1.9323859042488039. Arrivals time: 0.0617224951274693 Scheduler time: 1.4316435032524168 Scheduler overhead time: 0.11828072648495436 Adapter cache time: 0.1459886315278709 Engine time: 0.11614058585837483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 270, 135, 66, 270, 270, 66, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 66, 270, 66, 270, 135, 135, 135, 66, 66, 135, 66, 270, 66, 270, 135, 270, 135, 66, 135, 270, 135, 270, 66, 270, 270, 270, 270, 66, 135, 135, 135, 270, 135, 66, 135, 66, 270, 135, 270, 270, 135, 270, 270, 66, 66, 270, 135, 135, 66, 66, 66, 135, 66, 135, 66, 270, 66, 135, 270, 66, 270, 135, 66, 270, 270, 270, 270, 135, 66, 135, 270, 270, 135, 66, 66, 270, 135, 135, 66, 66, 270, 135, 270, 135, 270, 270, 135, 270, 270, 66, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 66, 66, 135, 135, 270, 66, 66, 270, 66, 270, 135, 66, 270, 135, 135, 66, 270, 270, 270, 66, 135, 270, 66, 270, 135, 135, 270, 270, 66, 135, 270, 66, 135, 135, 66, 135, 66, 135, 270, 270, 135, 66, 270, 66, 270, 135, 135, 135, 135, 135, 66, 66, 270, 66, 270, 66, 135, 270, 135, 270, 135, 270, 135, 270, 66, 135, 135, 135, 135, 135, 135, 135, 135, 270, 66, 66, 66, 66, 66, 135, 66, 66, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66, 135, 270, 270, 135, 135, 66, 270, 135, 270, 66, 135, 135, 66, 66, 135, 66, 270, 270, 66, 270, 270, 66, 135, 270, 66, 66, 135, 135, 66, 66, 270, 270, 270, 270, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 66, 270, 270, 66, 270, 66, 66, 135, 66, 270, 270, 270, 135, 66, 270, 270, 135, 135, 270, 270, 66, 270, 270, 135, 66, 270, 135, 135, 270, 270, 270, 66, 270, 66, 270, 270, 66, 66, 270, 66, 135, 270, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 270, 66, 66, 66, 135, 66, 135, 135, 66, 270, 135, 270, 66, 270, 66, 135, 135, 135, 135, 66, 135, 270, 270, 66, 270, 270, 66, 270, 135, 270, 135, 135, 135, 66, 135, 66, 66, 270, 66, 135, 66, 66, 135, 270, 135, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 60288 . Total input tokens: 13366582 . Total output tokens: 12077996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9426356186158955,
    "estimated_duration": 3599.959282947426,
    "input_throughput": 1401.50862925015,
    "output_throughput": 1224.765519122787,
    "total_throughput": 2626.274148372937,
    "itl": 27.237602067412933,
    "ttft": 7860.100003730022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 15889,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.34638378773134,
    "arrivals": 20275,
    "finished_requests": 20231,
    "scheduler_time": 0.12068656080883126
}
#Debug simulation 
Total elapsed time: 1.9427264258265495. Arrivals time: 0.06227103108540177 Scheduler time: 1.439582555089146 Scheduler overhead time: 0.1160029536113143 Adapter cache time: 0.14719338109716773 Engine time: 0.11964882258325815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.8339215409941971,
    "estimated_duration": 3598.952789433252,
    "input_throughput": 1267.8382482251302,
    "output_throughput": 1156.662852655963,
    "total_throughput": 2424.501100881093,
    "itl": 26.22658041440092,
    "ttft": 10331.159382347734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.88127327250129,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.02527830963691711
}
#Debug simulation 
Total elapsed time: 1.8340518018230796. Arrivals time: 0.05890347249805927 Scheduler time: 1.3434758810326457 Scheduler overhead time: 0.11876750038936734 Adapter cache time: 0.1347707132808864 Engine time: 0.11884209280833602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.851550613064319,
    "estimated_duration": 3598.950722218564,
    "input_throughput": 1267.838976463456,
    "output_throughput": 1156.66351703584,
    "total_throughput": 2424.5024934992957,
    "itl": 26.259799556457516,
    "ttft": 10331.386677310009,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.84987163620904,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.025791708628180424
}
#Debug simulation 
Total elapsed time: 1.8516290271654725. Arrivals time: 0.05838507926091552 Scheduler time: 1.3600314720533788 Scheduler overhead time: 0.11886560311540961 Adapter cache time: 0.13602257193997502 Engine time: 0.11877011368051171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8381917546503246,
    "estimated_duration": 3598.947035991272,
    "input_throughput": 1267.8402750495675,
    "output_throughput": 1156.664701750308,
    "total_throughput": 2424.5049767998757,
    "itl": 26.261763056488046,
    "ttft": 10331.35678021623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.92137340343605,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.02581918829846014
}
#Debug simulation 
Total elapsed time: 1.838316007051617. Arrivals time: 0.058810824528336525 Scheduler time: 1.3440028061158955 Scheduler overhead time: 0.1197216734290123 Adapter cache time: 0.1354312994517386 Engine time: 0.12058583134785295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.8495533065870404,
    "estimated_duration": 3598.967194238119,
    "input_throughput": 1267.833173724146,
    "output_throughput": 1156.6582231326051,
    "total_throughput": 2424.491396856751,
    "itl": 26.23939379093175,
    "ttft": 10331.264895044731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.93816507817146,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.025447149212650913
}
#Debug simulation 
Total elapsed time: 1.8496455219574273. Arrivals time: 0.05889891926199198 Scheduler time: 1.3531655883416533 Scheduler overhead time: 0.12101130094379187 Adapter cache time: 0.13615312753245234 Engine time: 0.12031672056764364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8150641061365604,
    "estimated_duration": 3598.964379688202,
    "input_throughput": 1267.8341652259721,
    "output_throughput": 1156.6591276906843,
    "total_throughput": 2424.493292916656,
    "itl": 26.266805948306253,
    "ttft": 10331.375500357855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.50269117577569,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.02592376956553132
}
#Debug simulation 
Total elapsed time: 1.8151474390178919. Arrivals time: 0.05777336144819856 Scheduler time: 1.328021049965173 Scheduler overhead time: 0.1187167251482606 Adapter cache time: 0.1344514535740018 Engine time: 0.1169614065438509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.8336403886787593,
    "estimated_duration": 3598.948406191552,
    "input_throughput": 1267.8397923543735,
    "output_throughput": 1156.6642613821452,
    "total_throughput": 2424.5040537365185,
    "itl": 26.214514341515436,
    "ttft": 10331.080967444355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14335,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.8623709774285,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.02512281383732772
}
#Debug simulation 
Total elapsed time: 1.833727355580777. Arrivals time: 0.058443968649953604 Scheduler time: 1.3408687398768961 Scheduler overhead time: 0.11854979582130909 Adapter cache time: 0.1372282444499433 Engine time: 0.11923817964270711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 135, 33, 270, 270, 33, 135, 270, 270, 270, 270, 135, 135, 135, 135, 270, 270, 135, 135, 33, 270, 33, 270, 135, 135, 135, 33, 33, 135, 33, 270, 33, 270, 135, 270, 135, 33, 135, 270, 135, 270, 33, 270, 270, 270, 270, 33, 135, 135, 135, 270, 135, 33, 135, 33, 270, 135, 270, 270, 135, 270, 270, 33, 33, 270, 135, 135, 33, 33, 33, 135, 33, 135, 33, 270, 33, 135, 270, 33, 270, 135, 33, 270, 270, 270, 270, 135, 33, 135, 270, 270, 135, 33, 33, 270, 135, 135, 33, 33, 270, 135, 270, 135, 270, 270, 135, 270, 270, 33, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 33, 33, 135, 135, 270, 33, 33, 270, 33, 270, 135, 33, 270, 135, 135, 33, 270, 270, 270, 33, 135, 270, 33, 270, 135, 135, 270, 270, 33, 135, 270, 33, 135, 135, 33, 135, 33, 135, 270, 270, 135, 33, 270, 33, 270, 135, 135, 135, 135, 135, 33, 33, 270, 33, 270, 33, 135, 270, 135, 270, 135, 270, 135, 270, 33, 135, 135, 135, 135, 135, 135, 135, 135, 270, 33, 33, 33, 33, 33, 135, 33, 33, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33, 135, 270, 270, 135, 135, 33, 270, 135, 270, 33, 135, 135, 33, 33, 135, 33, 270, 270, 33, 270, 270, 33, 135, 270, 33, 33, 135, 135, 33, 33, 270, 270, 270, 270, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 33, 270, 270, 33, 270, 33, 33, 135, 33, 270, 270, 270, 135, 33, 270, 270, 135, 135, 270, 270, 33, 270, 270, 135, 33, 270, 135, 135, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 135, 270, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 270, 33, 33, 33, 135, 33, 135, 135, 33, 270, 135, 270, 33, 270, 33, 135, 135, 135, 135, 33, 135, 270, 270, 33, 270, 270, 33, 270, 135, 270, 135, 135, 135, 33, 135, 33, 33, 270, 33, 135, 33, 33, 135, 270, 135, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 56064 . Total input tokens: 12441396 . Total output tokens: 11225519
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.8415931398048997,
    "estimated_duration": 3598.9682314834345,
    "input_throughput": 1267.832808326639,
    "output_throughput": 1156.657889776419,
    "total_throughput": 2424.490698103058,
    "itl": 26.276229856267094,
    "ttft": 10331.483401367243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.15137118835122,
    "arrivals": 18900,
    "finished_requests": 18846,
    "scheduler_time": 0.026046198036785616
}
#Debug simulation 
Total elapsed time: 1.841679162811488. Arrivals time: 0.05904472526162863 Scheduler time: 1.347654485143721 Scheduler overhead time: 0.1193685233592987 Adapter cache time: 0.13581250002607703 Engine time: 0.12006539106369019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.6685504256747663,
    "estimated_duration": 3599.942723787878,
    "input_throughput": 1096.933563388739,
    "output_throughput": 1001.5376011889149,
    "total_throughput": 2098.471164577654,
    "itl": 24.376775012108283,
    "ttft": 5630.799362478421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.40372222181465,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.6686464147642255. Arrivals time: 0.05246037058532238 Scheduler time: 1.18363520456478 Scheduler overhead time: 0.12613712809979916 Adapter cache time: 0.11569949705153704 Engine time: 0.12774383835494518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.662243662867695,
    "estimated_duration": 3599.9367714853947,
    "input_throughput": 1096.9353771095869,
    "output_throughput": 1001.5392571776529,
    "total_throughput": 2098.4746342872395,
    "itl": 24.402078090524665,
    "ttft": 5631.093284909433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.81819838836967,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.6623434447683394. Arrivals time: 0.052127613220363855 Scheduler time: 1.1763024721294641 Scheduler overhead time: 0.12854127772152424 Adapter cache time: 0.11537362728267908 Engine time: 0.12644406594336033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.646843554917723,
    "estimated_duration": 3599.9373424496866,
    "input_throughput": 1096.9352031313,
    "output_throughput": 1001.5390983295679,
    "total_throughput": 2098.474301460868,
    "itl": 24.403577519194453,
    "ttft": 5631.034692656088,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.87299707375958,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.6469347570091486. Arrivals time: 0.05212476663291454 Scheduler time: 1.165167632047087 Scheduler overhead time: 0.12690124427899718 Adapter cache time: 0.11533528193831444 Engine time: 0.12438868219032884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.6604897151701152,
    "estimated_duration": 3599.9518207803644,
    "input_throughput": 1096.9307914637575,
    "output_throughput": 1001.5350703272572,
    "total_throughput": 2098.4658617910145,
    "itl": 24.386513848845617,
    "ttft": 5630.991696009757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.28474015826277,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.660577901173383. Arrivals time: 0.05161583796143532 Scheduler time: 1.1756759705021977 Scheduler overhead time: 0.12950320076197386 Adapter cache time: 0.11545836692675948 Engine time: 0.12530974997207522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.6493234508670866,
    "estimated_duration": 3599.946915897369,
    "input_throughput": 1096.9322860183474,
    "output_throughput": 1001.5364349063609,
    "total_throughput": 2098.468720924708,
    "itl": 24.407121625680613,
    "ttft": 5631.077076742733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11563,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.341907515323086,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 3.3359440361056163e-06
}
#Debug simulation 
Total elapsed time: 1.6494123367592692. Arrivals time: 0.051720787305384874 Scheduler time: 1.164854824077338 Scheduler overhead time: 0.12600165652111173 Adapter cache time: 0.11477775871753693 Engine time: 0.1291867457330227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.66220797970891,
    "estimated_duration": 3599.939920944504,
    "input_throughput": 1096.934417439928,
    "output_throughput": 1001.5383809666587,
    "total_throughput": 2098.4727984065867,
    "itl": 24.369942641126492,
    "ttft": 5630.914602669065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.579931660542385,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.662302715703845. Arrivals time: 0.05227300198748708 Scheduler time: 1.1765355812385678 Scheduler overhead time: 0.12819024547934532 Adapter cache time: 0.11521666822955012 Engine time: 0.127011698205024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 270, 66, 33, 270, 270, 33, 66, 270, 270, 270, 270, 66, 66, 66, 66, 270, 270, 66, 66, 33, 270, 33, 270, 66, 66, 66, 33, 33, 66, 33, 270, 33, 270, 66, 270, 66, 33, 66, 270, 66, 270, 33, 270, 270, 270, 270, 33, 66, 66, 66, 270, 66, 33, 66, 33, 270, 66, 270, 270, 66, 270, 270, 33, 33, 270, 66, 66, 33, 33, 33, 66, 33, 66, 33, 270, 33, 66, 270, 33, 270, 66, 33, 270, 270, 270, 270, 66, 33, 66, 270, 270, 66, 33, 33, 270, 66, 66, 33, 33, 270, 66, 270, 66, 270, 270, 66, 270, 270, 33, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 33, 33, 66, 66, 270, 33, 33, 270, 33, 270, 66, 33, 270, 66, 66, 33, 270, 270, 270, 33, 66, 270, 33, 270, 66, 66, 270, 270, 33, 66, 270, 33, 66, 66, 33, 66, 33, 66, 270, 270, 66, 33, 270, 33, 270, 66, 66, 66, 66, 66, 33, 33, 270, 33, 270, 33, 66, 270, 66, 270, 66, 270, 66, 270, 33, 66, 66, 66, 66, 66, 66, 66, 66, 270, 33, 33, 33, 33, 33, 66, 33, 33, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33, 66, 270, 270, 66, 66, 33, 270, 66, 270, 33, 66, 66, 33, 33, 66, 33, 270, 270, 33, 270, 270, 33, 66, 270, 33, 33, 66, 66, 33, 33, 270, 270, 270, 270, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 33, 270, 270, 33, 270, 33, 33, 66, 33, 270, 270, 270, 66, 33, 270, 270, 66, 66, 270, 270, 33, 270, 270, 66, 33, 270, 66, 66, 270, 270, 270, 33, 270, 33, 270, 270, 33, 33, 270, 33, 66, 270, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 270, 33, 33, 33, 66, 33, 66, 66, 33, 270, 66, 270, 33, 270, 33, 66, 66, 66, 66, 33, 66, 270, 270, 33, 270, 270, 33, 270, 66, 270, 66, 66, 66, 33, 66, 33, 33, 270, 33, 66, 33, 33, 66, 270, 66, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 47232 . Total input tokens: 10467415 . Total output tokens: 9475189
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.6584925069473684,
    "estimated_duration": 3599.930686098487,
    "input_throughput": 1096.937231388673,
    "output_throughput": 1001.5409501974398,
    "total_throughput": 2098.4781815861124,
    "itl": 24.41107816311068,
    "ttft": 5631.169661040693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.87545165929836,
    "arrivals": 16104,
    "finished_requests": 16079,
    "scheduler_time": 4.16993004513202e-06
}
#Debug simulation 
Total elapsed time: 1.6586208920925856. Arrivals time: 0.05186366708949208 Scheduler time: 1.1747133852913976 Scheduler overhead time: 0.1281292913481593 Adapter cache time: 0.11513283383101225 Engine time: 0.1254961509257555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.2402251716703176,
    "estimated_duration": 3599.89875179773,
    "input_throughput": 679.4668874446822,
    "output_throughput": 621.0660782844215,
    "total_throughput": 1300.5329657291036,
    "itl": 20.998323961536805,
    "ttft": 5695.767787732527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.49614390243872,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2403083466924727. Arrivals time: 0.03839207021519542 Scheduler time: 0.7720452267676592 Scheduler overhead time: 0.13959400169551373 Adapter cache time: 0.08216069731861353 Engine time: 0.13814582210034132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.241062665823847,
    "estimated_duration": 3599.9044787608777,
    "input_throughput": 679.465806504383,
    "output_throughput": 621.0650902519435,
    "total_throughput": 1300.5308967563265,
    "itl": 21.009777349394973,
    "ttft": 5696.021026101301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.13210987181144,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2411377551034093. Arrivals time: 0.03858694573864341 Scheduler time: 0.7717559710144997 Scheduler overhead time: 0.13926393631845713 Adapter cache time: 0.08209363743662834 Engine time: 0.13946071825921535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2437340077012777,
    "estimated_duration": 3599.9102511046417,
    "input_throughput": 679.4647170021627,
    "output_throughput": 621.0640943934496,
    "total_throughput": 1300.5288113956124,
    "itl": 21.010077003822172,
    "ttft": 5696.022551236544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.175382589717028,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2438201629556715. Arrivals time: 0.03848082013428211 Scheduler time: 0.7732233651913702 Scheduler overhead time: 0.13948110677301884 Adapter cache time: 0.08305941941216588 Engine time: 0.13970037503167987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 1.25719685992226,
    "estimated_duration": 3599.904137172307,
    "input_throughput": 679.465870977698,
    "output_throughput": 621.0651491837173,
    "total_throughput": 1300.5310201614154,
    "itl": 21.001336340603384,
    "ttft": 5695.9311913835145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8004,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.062128615882862,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.257269037887454. Arrivals time: 0.03900619689375162 Scheduler time: 0.7830505166202784 Scheduler overhead time: 0.1397220673970878 Adapter cache time: 0.08246376132592559 Engine time: 0.14152563782408834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2451610751450062,
    "estimated_duration": 3599.900798532516,
    "input_throughput": 679.4665011316717,
    "output_throughput": 621.0657251753726,
    "total_throughput": 1300.5322263070443,
    "itl": 21.01224822914476,
    "ttft": 5695.937750374033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.505612032841135,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2452245489694178. Arrivals time: 0.038589166942983866 Scheduler time: 0.7751976037397981 Scheduler overhead time: 0.13924423418939114 Adapter cache time: 0.0822632503695786 Engine time: 0.13994660647585988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 1.2528304760344326,
    "estimated_duration": 3599.9164747733685,
    "input_throughput": 679.4635423184334,
    "output_throughput": 621.0630206748762,
    "total_throughput": 1300.5265629933097,
    "itl": 20.992988768493245,
    "ttft": 5695.740933807064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.929372510101317,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2529007839038968. Arrivals time: 0.03856946574524045 Scheduler time: 0.7782718339003623 Scheduler overhead time: 0.14220758900046349 Adapter cache time: 0.08265700051560998 Engine time: 0.14016775228083134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 384,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_384_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 135, 66, 33, 135, 135, 33, 66, 135, 135, 135, 135, 66, 66, 66, 66, 135, 135, 66, 66, 33, 135, 33, 135, 66, 66, 66, 33, 33, 66, 33, 135, 33, 135, 66, 135, 66, 33, 66, 135, 66, 135, 33, 135, 135, 135, 135, 33, 66, 66, 66, 135, 66, 33, 66, 33, 135, 66, 135, 135, 66, 135, 135, 33, 33, 135, 66, 66, 33, 33, 33, 66, 33, 66, 33, 135, 33, 66, 135, 33, 135, 66, 33, 135, 135, 135, 135, 66, 33, 66, 135, 135, 66, 33, 33, 135, 66, 66, 33, 33, 135, 66, 135, 66, 135, 135, 66, 135, 135, 33, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 33, 33, 66, 66, 135, 33, 33, 135, 33, 135, 66, 33, 135, 66, 66, 33, 135, 135, 135, 33, 66, 135, 33, 135, 66, 66, 135, 135, 33, 66, 135, 33, 66, 66, 33, 66, 33, 66, 135, 135, 66, 33, 135, 33, 135, 66, 66, 66, 66, 66, 33, 33, 135, 33, 135, 33, 66, 135, 66, 135, 66, 135, 66, 135, 33, 66, 66, 66, 66, 66, 66, 66, 66, 135, 33, 33, 33, 33, 33, 66, 33, 33, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33, 66, 135, 135, 66, 66, 33, 135, 66, 135, 33, 66, 66, 33, 33, 66, 33, 135, 135, 33, 135, 135, 33, 66, 135, 33, 33, 66, 66, 33, 33, 135, 135, 135, 135, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 33, 135, 135, 33, 135, 33, 33, 66, 33, 135, 135, 135, 66, 33, 135, 135, 66, 66, 135, 135, 33, 135, 135, 66, 33, 135, 66, 66, 135, 135, 135, 33, 135, 33, 135, 135, 33, 33, 135, 33, 66, 135, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 135, 33, 33, 33, 66, 33, 66, 66, 33, 135, 66, 135, 33, 135, 33, 66, 66, 66, 66, 33, 66, 135, 135, 33, 135, 135, 33, 135, 66, 135, 66, 66, 66, 33, 66, 33, 33, 135, 33, 66, 33, 33, 66, 135, 66, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 29952 . Total input tokens: 6581748 . Total output tokens: 6022685
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2426604637876153,
    "estimated_duration": 3599.908919002457,
    "input_throughput": 679.4649684297556,
    "output_throughput": 621.0643242106077,
    "total_throughput": 1300.5292926403633,
    "itl": 21.012805183951055,
    "ttft": 5696.151388009199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8002,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.850277733428076,
    "arrivals": 10179,
    "finished_requests": 10163,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2427341239526868. Arrivals time: 0.03863622061908245 Scheduler time: 0.7692312402650714 Scheduler overhead time: 0.13980993255972862 Adapter cache time: 0.0816214894875884 Engine time: 0.14345977129414678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.7986079188995,
    "estimated_duration": 3600.1148727428545,
    "input_throughput": 5277.233274927507,
    "output_throughput": 4687.948189592528,
    "total_throughput": 9965.181464520036,
    "itl": 182.45069939512462,
    "ttft": 2187725.2503921976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.010740447763853,
    "arrivals": 2579962,
    "finished_requests": 77097,
    "scheduler_time": 137.95581346238765
}
#Debug simulation 
Total elapsed time: 69.79878177214414. Arrivals time: 0.9297750275582075 Scheduler time: 68.73041396494955 Scheduler overhead time: 0.05046506365761161 Adapter cache time: 0.01891800155863166 Engine time: 0.05042029405012727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 55.88390999287367,
    "estimated_duration": 3600.1486436728414,
    "input_throughput": 5282.476609243085,
    "output_throughput": 4698.4501680862095,
    "total_throughput": 9980.926777329294,
    "itl": 182.01631773144368,
    "ttft": 2191549.459701523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.497944947662768,
    "arrivals": 2579962,
    "finished_requests": 77242,
    "scheduler_time": 138.29508863428936
}
#Debug simulation 
Total elapsed time: 55.88407159084454. Arrivals time: 0.4192478130571544 Scheduler time: 55.33026027306914 Scheduler overhead time: 0.04860258102416992 Adapter cache time: 0.02014587027952075 Engine time: 0.0477097793482244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 55.16308973822743,
    "estimated_duration": 3600.0467938374527,
    "input_throughput": 5261.919104059099,
    "output_throughput": 4678.262246154693,
    "total_throughput": 9940.18135021379,
    "itl": 180.91090320413636,
    "ttft": 2189017.210983486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4901458424888485,
    "arrivals": 2579962,
    "finished_requests": 76910,
    "scheduler_time": 138.2837611478718
}
#Debug simulation 
Total elapsed time: 55.16326162125915. Arrivals time: 0.4297872227616608 Scheduler time: 54.59866079641506 Scheduler overhead time: 0.048998402431607246 Adapter cache time: 0.0200049364939332 Engine time: 0.04778745677322149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 56.080514144618064,
    "estimated_duration": 3600.0435484602026,
    "input_throughput": 5282.630819322778,
    "output_throughput": 4698.587328821306,
    "total_throughput": 9981.218148144084,
    "itl": 182.01157801395937,
    "ttft": 2191506.121336895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3933445461420138,
    "arrivals": 2579962,
    "finished_requests": 77242,
    "scheduler_time": 138.2945938231445
}
#Debug simulation 
Total elapsed time: 56.08066971087828. Arrivals time: 0.41902002692222595 Scheduler time: 55.52682522125542 Scheduler overhead time: 0.048591995146125555 Adapter cache time: 0.020203453488647938 Engine time: 0.047764800023287535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 54.983976969029754,
    "estimated_duration": 3600.0790188350943,
    "input_throughput": 5261.872003612183,
    "output_throughput": 4678.220370132232,
    "total_throughput": 9940.092373744415,
    "itl": 180.91233804230956,
    "ttft": 2189030.8197632316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5222130580246467,
    "arrivals": 2579962,
    "finished_requests": 76910,
    "scheduler_time": 138.28391892999468
}
#Debug simulation 
Total elapsed time: 54.98414619686082. Arrivals time: 0.4331484637223184 Scheduler time: 54.416440242901444 Scheduler overhead time: 0.048835360910743475 Adapter cache time: 0.020012855995446444 Engine time: 0.04792313650250435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.93958839681,
    "estimated_duration": 3600.0683412856683,
    "input_throughput": 5277.301484008812,
    "output_throughput": 4688.008782070169,
    "total_throughput": 9965.310266078981,
    "itl": 182.44864083767683,
    "ttft": 2187703.854507063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9644630437506965,
    "arrivals": 2579962,
    "finished_requests": 77097,
    "scheduler_time": 137.95555940914204
}
#Debug simulation 
Total elapsed time: 69.93975487072021. Arrivals time: 0.43762590596452355 Scheduler time: 69.36466783611104 Scheduler overhead time: 0.05011912249028683 Adapter cache time: 0.01871542911976576 Engine time: 0.050192061346024275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [8640, 8640, 34560, 17280, 8640, 34560, 34560, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 17280, 8640, 17280, 8640, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 17280, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 8640, 34560, 17280, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 34560, 8640, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 8640, 8640, 8640, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 34560, 8640, 17280, 34560, 8640, 8640, 17280, 17280, 8640, 8640, 34560, 34560, 34560, 34560, 17280, 8640, 17280, 17280, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 34560, 8640, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 34560, 34560, 17280, 8640, 34560, 34560, 17280, 17280, 34560, 34560, 8640, 34560, 34560, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 34560, 8640, 17280, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 8640, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 8640, 17280, 8640, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 34560, 17280, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 7741440 . Total input tokens: 1724144384 . Total output tokens: 1548076799
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 54.98005279805511,
    "estimated_duration": 3600.1108571204627,
    "input_throughput": 5261.825469216696,
    "output_throughput": 4678.178997374262,
    "total_throughput": 9940.004466590957,
    "itl": 180.9137735460446,
    "ttft": 2189043.9901329945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.553903012201205,
    "arrivals": 2579962,
    "finished_requests": 76910,
    "scheduler_time": 138.28406726120872
}
#Debug simulation 
Total elapsed time: 54.980216229334474. Arrivals time: 0.4255588152445853 Scheduler time: 54.41974230064079 Scheduler overhead time: 0.048575956374406815 Adapter cache time: 0.020103948656469584 Engine time: 0.04805781552568078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.8477831678465,
    "estimated_duration": 3600.069285000331,
    "input_throughput": 5285.024118639497,
    "output_throughput": 4672.815901096874,
    "total_throughput": 9957.840019736372,
    "itl": 181.93310816993576,
    "ttft": 2184193.421901912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6771472836751713,
    "arrivals": 2395765,
    "finished_requests": 77207,
    "scheduler_time": 137.9881310529126
}
#Debug simulation 
Total elapsed time: 69.8479497646913. Arrivals time: 0.44767240062355995 Scheduler time: 69.26373743917793 Scheduler overhead time: 0.0505023249424994 Adapter cache time: 0.017183358781039715 Engine time: 0.050107869785279036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.49127057939768,
    "estimated_duration": 3600.019663990097,
    "input_throughput": 5290.078882205902,
    "output_throughput": 4678.812221078561,
    "total_throughput": 9968.891103284463,
    "itl": 182.25289004745397,
    "ttft": 2184706.659490488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7838776119053414,
    "arrivals": 2395765,
    "finished_requests": 77282,
    "scheduler_time": 137.8551293895012
}
#Debug simulation 
Total elapsed time: 68.49144302122295. Arrivals time: 0.6065308349207044 Scheduler time: 67.7487663202919 Scheduler overhead time: 0.05043125990778208 Adapter cache time: 0.017324346117675304 Engine time: 0.04987019253894687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.18118033790961,
    "estimated_duration": 3600.1371667057965,
    "input_throughput": 5287.561034075349,
    "output_throughput": 4670.2895532685725,
    "total_throughput": 9957.850587343923,
    "itl": 180.70416070412168,
    "ttft": 2185721.859863092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.814271781537693,
    "arrivals": 2395765,
    "finished_requests": 77205,
    "scheduler_time": 138.24489527946275
}
#Debug simulation 
Total elapsed time: 67.18135778605938. Arrivals time: 0.44706301344558597 Scheduler time: 66.59950526012108 Scheduler overhead time: 0.04984402330592275 Adapter cache time: 0.017065769992768764 Engine time: 0.04951494373381138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 68.41396682988852,
    "estimated_duration": 3600.152950740802,
    "input_throughput": 5290.294123776307,
    "output_throughput": 4679.1281455232875,
    "total_throughput": 9969.422269299595,
    "itl": 182.25153500585455,
    "ttft": 2184701.806035354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7099218592676244,
    "arrivals": 2395765,
    "finished_requests": 77290,
    "scheduler_time": 137.86261827788246
}
#Debug simulation 
Total elapsed time: 68.41413928102702. Arrivals time: 0.4350576871074736 Scheduler time: 67.84372903546318 Scheduler overhead time: 0.04999640630558133 Adapter cache time: 0.017193754203617573 Engine time: 0.04973449697718024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 66.51319083943963,
    "estimated_duration": 3600.1604337105814,
    "input_throughput": 5287.52686179049,
    "output_throughput": 4670.259370266625,
    "total_throughput": 9957.786232057115,
    "itl": 180.7051723942994,
    "ttft": 2185731.732267431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8374104782380198,
    "arrivals": 2395765,
    "finished_requests": 77205,
    "scheduler_time": 138.24502358756476
}
#Debug simulation 
Total elapsed time: 66.51336504612118. Arrivals time: 0.43506507854908705 Scheduler time: 65.9434202555567 Scheduler overhead time: 0.04991955775767565 Adapter cache time: 0.01689076889306307 Engine time: 0.04956840071827173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 69.51032308815047,
    "estimated_duration": 3600.030461019468,
    "input_throughput": 5285.081114178136,
    "output_throughput": 4672.866294369121,
    "total_throughput": 9957.947408547258,
    "itl": 181.93143701821828,
    "ttft": 2184176.6032914417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 548,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.638547561606371,
    "arrivals": 2395765,
    "finished_requests": 77207,
    "scheduler_time": 137.9879067940577
}
#Debug simulation 
Total elapsed time: 69.51049037929624. Arrivals time: 0.44277091743424535 Scheduler time: 68.9312245324254 Scheduler overhead time: 0.050795760471373796 Adapter cache time: 0.017130174208432436 Engine time: 0.049819692969322205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 17280, 4320, 34560, 34560, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 17280, 4320, 17280, 4320, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 17280, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 4320, 34560, 17280, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 34560, 4320, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 4320, 4320, 4320, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 17280, 34560, 4320, 4320, 17280, 17280, 4320, 4320, 34560, 34560, 34560, 34560, 17280, 4320, 17280, 17280, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 34560, 4320, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 34560, 34560, 17280, 4320, 34560, 34560, 17280, 17280, 34560, 34560, 4320, 34560, 34560, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 17280, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 4320, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 4320, 17280, 4320, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 34560, 17280, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 7188480 . Total input tokens: 1601032366 . Total output tokens: 1437456396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 67.36606414522976,
    "estimated_duration": 3600.184081821161,
    "input_throughput": 5287.492130227582,
    "output_throughput": 4670.2286932769175,
    "total_throughput": 9957.7208235045,
    "itl": 180.70619347003245,
    "ttft": 2185742.058918996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8609264362975921,
    "arrivals": 2395765,
    "finished_requests": 77205,
    "scheduler_time": 138.24515574010425
}
#Debug simulation 
Total elapsed time: 67.3662266721949. Arrivals time: 0.6170323924161494 Scheduler time: 66.6140667470172 Scheduler overhead time: 0.049760022666305304 Adapter cache time: 0.01727101020514965 Engine time: 0.04923268361017108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 62.690678948070854,
    "estimated_duration": 3600.1840914490313,
    "input_throughput": 5295.370046570825,
    "output_throughput": 4685.423737098587,
    "total_throughput": 9980.793783669411,
    "itl": 183.25006460933847,
    "ttft": 2184303.320416593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9403492296533973,
    "arrivals": 2257312,
    "finished_requests": 76851,
    "scheduler_time": 137.51596572879802
}
#Debug simulation 
Total elapsed time: 62.6908302763477. Arrivals time: 0.4212345080450177 Scheduler time: 62.13517943909392 Scheduler overhead time: 0.04911705898120999 Adapter cache time: 0.018503245431929827 Engine time: 0.048481132835149765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 61.16488199215382,
    "estimated_duration": 3600.1138277044015,
    "input_throughput": 5289.89440651755,
    "output_throughput": 4681.566974438416,
    "total_throughput": 9971.461380955967,
    "itl": 182.77107971626387,
    "ttft": 2184195.614174354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1260259698424537,
    "arrivals": 2257312,
    "finished_requests": 76812,
    "scheduler_time": 137.70739287938957
}
#Debug simulation 
Total elapsed time: 61.16503742430359. Arrivals time: 0.41657041059806943 Scheduler time: 60.61408809758723 Scheduler overhead time: 0.04909113235771656 Adapter cache time: 0.01843039132654667 Engine time: 0.04845819855108857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 66.13692787988111,
    "estimated_duration": 3600.0599044240566,
    "input_throughput": 5276.567197300292,
    "output_throughput": 4665.47347708289,
    "total_throughput": 9942.04067438318,
    "itl": 180.32894959382057,
    "ttft": 2184737.8361669127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.428280305825172,
    "arrivals": 2257312,
    "finished_requests": 76696,
    "scheduler_time": 138.34271567025982
}
#Debug simulation 
Total elapsed time: 66.13708772696555. Arrivals time: 0.431671024300158 Scheduler time: 65.56573811173439 Scheduler overhead time: 0.05093420762568712 Adapter cache time: 0.0203291573561728 Engine time: 0.049900834914296865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 61.656151940114796,
    "estimated_duration": 3600.0648164371046,
    "input_throughput": 5297.600452337077,
    "output_throughput": 4688.070871097011,
    "total_throughput": 9985.671323434088,
    "itl": 183.29213140174085,
    "ttft": 2184218.866548343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 702,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1913578489888272,
    "arrivals": 2257312,
    "finished_requests": 76867,
    "scheduler_time": 137.510243850513
}
#Debug simulation 
Total elapsed time: 61.6563184899278. Arrivals time: 0.588511522859335 Scheduler time: 60.93253057729453 Scheduler overhead time: 0.04921930795535445 Adapter cache time: 0.019460884854197502 Engine time: 0.04860684834420681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 66.01962366281077,
    "estimated_duration": 3600.0919969401166,
    "input_throughput": 5276.52016008078,
    "output_throughput": 4665.431887372789,
    "total_throughput": 9941.95204745357,
    "itl": 180.33029286369012,
    "ttft": 2184748.742398048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.460221767574555,
    "arrivals": 2257312,
    "finished_requests": 76696,
    "scheduler_time": 138.3428667246171
}
#Debug simulation 
Total elapsed time: 66.01978507684544. Arrivals time: 0.4336156430654228 Scheduler time: 65.44819452986121 Scheduler overhead time: 0.049931447952985764 Adapter cache time: 0.020181996282190084 Engine time: 0.04937443044036627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 62.771228407975286,
    "estimated_duration": 3600.139219458673,
    "input_throughput": 5295.436047849995,
    "output_throughput": 4685.4821360315,
    "total_throughput": 9980.918183881495,
    "itl": 183.2480745573534,
    "ttft": 2184286.693830807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8956918869679489,
    "arrivals": 2257312,
    "finished_requests": 76851,
    "scheduler_time": 137.5157510810369
}
#Debug simulation 
Total elapsed time: 62.77139672776684. Arrivals time: 0.4221906065940857 Scheduler time: 62.214139147661626 Scheduler overhead time: 0.04921953147277236 Adapter cache time: 0.018634795676916838 Engine time: 0.048843519762158394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 17280, 1080, 34560, 34560, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 17280, 1080, 17280, 1080, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 17280, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 1080, 34560, 17280, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 34560, 1080, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 1080, 1080, 1080, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 17280, 34560, 1080, 1080, 17280, 17280, 1080, 1080, 34560, 34560, 34560, 34560, 17280, 1080, 17280, 17280, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 34560, 1080, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 34560, 34560, 17280, 1080, 34560, 34560, 17280, 17280, 34560, 34560, 1080, 34560, 34560, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 17280, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 1080, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 1080, 17280, 1080, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 34560, 17280, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 6773760 . Total input tokens: 1508644042 . Total output tokens: 1354491072
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 66.13275875290856,
    "estimated_duration": 3600.121318868263,
    "input_throughput": 5276.47718437766,
    "output_throughput": 4665.393888803725,
    "total_throughput": 9941.871073181384,
    "itl": 180.33153037652278,
    "ttft": 2184759.828557333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 744,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.489396646022807,
    "arrivals": 2257312,
    "finished_requests": 76696,
    "scheduler_time": 138.34301377435196
}
#Debug simulation 
Total elapsed time: 66.13292218698189. Arrivals time: 0.4339768048375845 Scheduler time: 65.56051920633763 Scheduler overhead time: 0.05011470103636384 Adapter cache time: 0.020256276708096266 Engine time: 0.049741138238459826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 63.93655167706311,
    "estimated_duration": 3600.089408542743,
    "input_throughput": 5292.732717911267,
    "output_throughput": 4686.163893587561,
    "total_throughput": 9978.896611498829,
    "itl": 183.4737605634537,
    "ttft": 2186351.588212607,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.231095565327019,
    "arrivals": 2233996,
    "finished_requests": 77182,
    "scheduler_time": 137.3596060781574
}
#Debug simulation 
Total elapsed time: 63.93672601599246. Arrivals time: 0.4264943730086088 Scheduler time: 63.37453602068126 Scheduler overhead time: 0.049632801208645105 Adapter cache time: 0.01912470581009984 Engine time: 0.048817326314747334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 62.915434151887894,
    "estimated_duration": 3600.0237155761874,
    "input_throughput": 5289.9801514090805,
    "output_throughput": 4685.305523688859,
    "total_throughput": 9975.285675097939,
    "itl": 183.5027395104836,
    "ttft": 2186469.068952305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4124403289449443,
    "arrivals": 2233996,
    "finished_requests": 77149,
    "scheduler_time": 137.34566884767804
}
#Debug simulation 
Total elapsed time: 62.91561344685033. Arrivals time: 0.41588661866262555 Scheduler time: 62.363797831814736 Scheduler overhead time: 0.049640477169305086 Adapter cache time: 0.019281089305877686 Engine time: 0.048868014477193356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 61.974890967831016,
    "estimated_duration": 3600.05044184776,
    "input_throughput": 5275.02331057701,
    "output_throughput": 4675.7864290813295,
    "total_throughput": 9950.80973965834,
    "itl": 181.6098628928362,
    "ttft": 2187682.1532087405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.420498739257452,
    "arrivals": 2233996,
    "finished_requests": 76944,
    "scheduler_time": 137.9073872385552
}
#Debug simulation 
Total elapsed time: 61.97505762800574. Arrivals time: 0.4303256366401911 Scheduler time: 61.40976749127731 Scheduler overhead time: 0.049055411480367184 Adapter cache time: 0.019481864292174578 Engine time: 0.048342169262468815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 63.010406681802124,
    "estimated_duration": 3600.130975860515,
    "input_throughput": 5290.072535610407,
    "output_throughput": 4685.444533297321,
    "total_throughput": 9975.517068907728,
    "itl": 183.49816380830313,
    "ttft": 2186495.520396604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 740,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3160118337929996,
    "arrivals": 2233996,
    "finished_requests": 77154,
    "scheduler_time": 137.35307679971285
}
#Debug simulation 
Total elapsed time: 63.01058198697865. Arrivals time: 0.4230430996976793 Scheduler time: 62.45191307319328 Scheduler overhead time: 0.04937771800905466 Adapter cache time: 0.019133723340928555 Engine time: 0.04866841156035662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 61.692987399641424,
    "estimated_duration": 3600.080371400423,
    "input_throughput": 5274.979456253861,
    "output_throughput": 4675.747556561349,
    "total_throughput": 9950.72701281521,
    "itl": 181.61123197986853,
    "ttft": 2187692.5797361336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4503023866377798,
    "arrivals": 2233996,
    "finished_requests": 76944,
    "scheduler_time": 137.90751314388373
}
#Debug simulation 
Total elapsed time: 61.693157594650984. Arrivals time: 0.6137959631159902 Scheduler time: 60.9426868702285 Scheduler overhead time: 0.04907087003812194 Adapter cache time: 0.0195572879165411 Engine time: 0.04998022550716996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 63.71847020089626,
    "estimated_duration": 3600.037827214221,
    "input_throughput": 5292.808552165851,
    "output_throughput": 4686.231036926299,
    "total_throughput": 9979.03958909215,
    "itl": 183.47140653744964,
    "ttft": 2186333.4680051473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 729,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1797466649836457,
    "arrivals": 2233996,
    "finished_requests": 77182,
    "scheduler_time": 137.3593736498728
}
#Debug simulation 
Total elapsed time: 63.71864709397778. Arrivals time: 0.45431293500587344 Scheduler time: 63.128293950576335 Scheduler overhead time: 0.04899090249091387 Adapter cache time: 0.0198117489926517 Engine time: 0.04902359889820218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 17280, 540, 34560, 34560, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 17280, 540, 540, 540, 17280, 540, 17280, 540, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 17280, 17280, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 17280, 540, 34560, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 34560, 540, 34560, 17280, 17280, 34560, 34560, 540, 17280, 34560, 540, 17280, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 34560, 540, 34560, 17280, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 34560, 540, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 540, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 540, 540, 540, 540, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 34560, 540, 540, 540, 17280, 540, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 34560, 540, 17280, 17280, 540, 540, 17280, 540, 34560, 34560, 540, 34560, 34560, 540, 17280, 34560, 540, 540, 17280, 17280, 540, 540, 34560, 34560, 34560, 34560, 17280, 540, 17280, 17280, 540, 540, 540, 540, 540, 540, 540, 540, 17280, 34560, 17280, 17280, 17280, 34560, 540, 17280, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 17280, 540, 34560, 34560, 34560, 17280, 540, 34560, 34560, 17280, 17280, 34560, 34560, 540, 34560, 34560, 17280, 540, 34560, 17280, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 17280, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 34560, 540, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 34560, 34560, 540, 34560, 34560, 540, 34560, 17280, 34560, 17280, 17280, 17280, 540, 17280, 540, 540, 34560, 540, 17280, 540, 540, 17280, 34560, 17280, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 6704640 . Total input tokens: 1493274357 . Total output tokens: 1340660428
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 61.45997463259846,
    "estimated_duration": 3600.1123625108,
    "input_throughput": 5274.932582036328,
    "output_throughput": 4675.706007203686,
    "total_throughput": 9950.638589240014,
    "itl": 181.61264474408668,
    "ttft": 2187703.9700210234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.482118094600748,
    "arrivals": 2233996,
    "finished_requests": 76944,
    "scheduler_time": 137.90768854634524
}
#Debug simulation 
Total elapsed time: 61.46014855662361. Arrivals time: 0.4358795485459268 Scheduler time: 60.888148300815374 Scheduler overhead time: 0.049402079079300165 Adapter cache time: 0.01959868334233761 Engine time: 0.04867416387423873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.90258919168264,
    "estimated_duration": 3600.0805173850813,
    "input_throughput": 5317.923281867578,
    "output_throughput": 4690.296485997692,
    "total_throughput": 10008.21976786527,
    "itl": 181.84812951164406,
    "ttft": 2177706.1770015955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.79344581794462,
    "arrivals": 2222461,
    "finished_requests": 77508,
    "scheduler_time": 138.04373810499385
}
#Debug simulation 
Total elapsed time: 73.90275160269812. Arrivals time: 0.45725032733753324 Scheduler time: 73.30823381664231 Scheduler overhead time: 0.05098349740728736 Adapter cache time: 0.01752205239608884 Engine time: 0.05006210831925273 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 66.33420622395352,
    "estimated_duration": 3600.113474113694,
    "input_throughput": 5321.293936357463,
    "output_throughput": 4683.620147320807,
    "total_throughput": 10004.91408367827,
    "itl": 181.8132899939062,
    "ttft": 2179411.147368635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 682,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.225533766332087,
    "arrivals": 2222461,
    "finished_requests": 77351,
    "scheduler_time": 138.01182798501998
}
#Debug simulation 
Total elapsed time: 66.33436275972053. Arrivals time: 0.4377250727266073 Scheduler time: 65.76184094557539 Scheduler overhead time: 0.049158398527652025 Adapter cache time: 0.0185224455781281 Engine time: 0.04874483589082956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.2393867210485,
    "estimated_duration": 3600.1297900107497,
    "input_throughput": 5294.812718388989,
    "output_throughput": 4676.068359177055,
    "total_throughput": 9970.881077566044,
    "itl": 180.36086455881542,
    "ttft": 2178319.591433117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.785876660812657,
    "arrivals": 2222461,
    "finished_requests": 77168,
    "scheduler_time": 138.38830318784778
}
#Debug simulation 
Total elapsed time: 72.23955706786364. Arrivals time: 0.42339356848970056 Scheduler time: 71.68092461954802 Scheduler overhead time: 0.050683291628956795 Adapter cache time: 0.01613589935004711 Engine time: 0.0501580242998898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 66.4574507069774,
    "estimated_duration": 3600.1660755874627,
    "input_throughput": 5331.316277365913,
    "output_throughput": 4693.382651033067,
    "total_throughput": 10024.69892839898,
    "itl": 181.55064538491047,
    "ttft": 2180832.5059412518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1170151869347156,
    "arrivals": 2222461,
    "finished_requests": 77539,
    "scheduler_time": 138.2818649061008
}
#Debug simulation 
Total elapsed time: 66.45760531304404. Arrivals time: 0.6052382313646376 Scheduler time: 65.71750255161896 Scheduler overhead time: 0.04955894686281681 Adapter cache time: 0.018138120882213116 Engine time: 0.04842276591807604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.48915355280042,
    "estimated_duration": 3600.152319312224,
    "input_throughput": 5294.779584115381,
    "output_throughput": 4676.039096928007,
    "total_throughput": 9970.818681043387,
    "itl": 180.36182549297664,
    "ttft": 2178328.7606866253,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8082608347944957,
    "arrivals": 2222461,
    "finished_requests": 77168,
    "scheduler_time": 138.3884483153639
}
#Debug simulation 
Total elapsed time: 72.48932033870369. Arrivals time: 0.4538991982117295 Scheduler time: 71.9012015806511 Scheduler overhead time: 0.05117368092760444 Adapter cache time: 0.015799783635884523 Engine time: 0.048902745358645916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.0169018888846,
    "estimated_duration": 3600.0390153395224,
    "input_throughput": 5317.984588062701,
    "output_throughput": 4690.350556772374,
    "total_throughput": 10008.335144835075,
    "itl": 181.8463986319881,
    "ttft": 2177691.0939254216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7521694728126496,
    "arrivals": 2222461,
    "finished_requests": 77508,
    "scheduler_time": 138.04351240447488
}
#Debug simulation 
Total elapsed time: 74.01705559995025. Arrivals time: 0.44217533711344004 Scheduler time: 73.43870402360335 Scheduler overhead time: 0.05069080740213394 Adapter cache time: 0.01708876108750701 Engine time: 0.049851992167532444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.09595199115574,
    "estimated_duration": 3600.17522443339,
    "input_throughput": 5294.74589754171,
    "output_throughput": 4676.0093469199055,
    "total_throughput": 9970.755244461616,
    "itl": 180.36278519998922,
    "ttft": 2178338.228102039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 547,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8310222701355787,
    "arrivals": 2222461,
    "finished_requests": 77168,
    "scheduler_time": 138.38859200121593
}
#Debug simulation 
Total elapsed time: 72.09611280495301. Arrivals time: 0.46337320003658533 Scheduler time: 71.49900784669444 Scheduler overhead time: 0.05056807631626725 Adapter cache time: 0.015563416294753551 Engine time: 0.049084202852100134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 64.33513263100758,
    "estimated_duration": 3600.143076204909,
    "input_throughput": 5361.422196683106,
    "output_throughput": 4703.595840932681,
    "total_throughput": 10065.018037615788,
    "itl": 180.65537225891586,
    "ttft": 2182673.2330601895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6373609430040441,
    "arrivals": 2216625,
    "finished_requests": 77674,
    "scheduler_time": 138.67280743581912
}
#Debug simulation 
Total elapsed time: 64.33529632817954. Arrivals time: 0.41046015871688724 Scheduler time: 63.79436206072569 Scheduler overhead time: 0.04896643152460456 Adapter cache time: 0.015327219851315022 Engine time: 0.0479330625385046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 64.08796819392592,
    "estimated_duration": 3600.0496593866983,
    "input_throughput": 5361.273267349339,
    "output_throughput": 4703.458174764355,
    "total_throughput": 10064.731442113694,
    "itl": 180.65874897821595,
    "ttft": 2182678.0106256274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7475884130480757,
    "arrivals": 2216625,
    "finished_requests": 77669,
    "scheduler_time": 138.6657747166252
}
#Debug simulation 
Total elapsed time: 64.08812312362716. Arrivals time: 0.3880703882314265 Scheduler time: 63.57331059500575 Scheduler overhead time: 0.04722568951547146 Adapter cache time: 0.015382330399006605 Engine time: 0.0466185649856925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.641962341964245,
    "estimated_duration": 3600.021301953803,
    "input_throughput": 5339.574793506784,
    "output_throughput": 4692.083069295339,
    "total_throughput": 10031.657862802123,
    "itl": 178.5541184017822,
    "ttft": 2187617.8649536753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.993460689131183,
    "arrivals": 2216625,
    "finished_requests": 77480,
    "scheduler_time": 139.31790811422852
}
#Debug simulation 
Total elapsed time: 60.64211616804823. Arrivals time: 0.38871137565001845 Scheduler time: 60.12437397846952 Scheduler overhead time: 0.047294709365814924 Adapter cache time: 0.01613959949463606 Engine time: 0.04621828580275178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 64.14901294605806,
    "estimated_duration": 3600.1821049668642,
    "input_throughput": 5361.364074714674,
    "output_throughput": 4703.5448503113585,
    "total_throughput": 10064.908925026033,
    "itl": 180.6569659761992,
    "ttft": 2182690.346222537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6760842323210023,
    "arrivals": 2216625,
    "finished_requests": 77674,
    "scheduler_time": 138.67311290841647
}
#Debug simulation 
Total elapsed time: 64.14916249504313. Arrivals time: 0.4071368365548551 Scheduler time: 63.61476325755939 Scheduler overhead time: 0.04693391686305404 Adapter cache time: 0.015341707970947027 Engine time: 0.047280322294682264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 60.64039110392332,
    "estimated_duration": 3600.047736991169,
    "input_throughput": 5339.535585176923,
    "output_throughput": 4692.048615476855,
    "total_throughput": 10031.584200653779,
    "itl": 178.55525036974933,
    "ttft": 2187628.234549307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0197432304918803,
    "arrivals": 2216625,
    "finished_requests": 77480,
    "scheduler_time": 139.31806061024983
}
#Debug simulation 
Total elapsed time: 60.64054139703512. Arrivals time: 0.39829652290791273 Scheduler time: 60.1142971906811 Scheduler overhead time: 0.047200869768857956 Adapter cache time: 0.016243457328528166 Engine time: 0.046879042871296406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 64.26581597188488,
    "estimated_duration": 3600.1051494896174,
    "input_throughput": 5361.478678681484,
    "output_throughput": 4703.645392802113,
    "total_throughput": 10065.124071483597,
    "itl": 180.65375598402704,
    "ttft": 2182656.185758223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.599676907772644,
    "arrivals": 2216625,
    "finished_requests": 77674,
    "scheduler_time": 138.67256475570113
}
#Debug simulation 
Total elapsed time: 64.26596410386264. Arrivals time: 0.4001530515961349 Scheduler time: 63.73855808470398 Scheduler overhead time: 0.0471855322830379 Adapter cache time: 0.015660977456718683 Engine time: 0.04673701198771596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.64970695786178,
    "estimated_duration": 3600.0738104652946,
    "input_throughput": 5339.496913680101,
    "output_throughput": 4692.014633393539,
    "total_throughput": 10031.51154707364,
    "itl": 178.55635111833445,
    "ttft": 2187638.498917618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.045648510493334,
    "arrivals": 2216625,
    "finished_requests": 77480,
    "scheduler_time": 139.31822880439103
}
#Debug simulation 
Total elapsed time: 60.649850107729435. Arrivals time: 0.3979158722795546 Scheduler time: 60.12453808123246 Scheduler overhead time: 0.04714812058955431 Adapter cache time: 0.016062805894762278 Engine time: 0.0464742723852396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.16355467494577,
    "estimated_duration": 3600.0849090652296,
    "input_throughput": 5336.863847744286,
    "output_throughput": 4731.836173392694,
    "total_throughput": 10068.70002113698,
    "itl": 180.13037284547028,
    "ttft": 2183651.605432571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.181348269158048,
    "arrivals": 2213766,
    "finished_requests": 77978,
    "scheduler_time": 139.5236400562914
}
#Debug simulation 
Total elapsed time: 76.16370405489579. Arrivals time: 0.4106964119710028 Scheduler time: 75.6246021585539 Scheduler overhead time: 0.0492228539660573 Adapter cache time: 0.012930578086525202 Engine time: 0.04843163536861539 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.75274666817859,
    "estimated_duration": 3600.026847476238,
    "input_throughput": 5330.7533007576185,
    "output_throughput": 4726.764471750878,
    "total_throughput": 10057.517772508498,
    "itl": 180.1616727578272,
    "ttft": 2183249.0913345213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3278096843883442,
    "arrivals": 2213766,
    "finished_requests": 77854,
    "scheduler_time": 139.41926896306506
}
#Debug simulation 
Total elapsed time: 75.75289677036926. Arrivals time: 0.40074810246005654 Scheduler time: 75.22464751312509 Scheduler overhead time: 0.047975484281778336 Adapter cache time: 0.013412115629762411 Engine time: 0.04805199196562171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.67800776613876,
    "estimated_duration": 3600.016948887465,
    "input_throughput": 5302.121704148864,
    "output_throughput": 4709.628660287177,
    "total_throughput": 10011.75036443604,
    "itl": 177.81107987124517,
    "ttft": 2183458.1172552886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.484626334570357,
    "arrivals": 2213766,
    "finished_requests": 77509,
    "scheduler_time": 140.28029264435557
}
#Debug simulation 
Total elapsed time: 73.67813389003277. Arrivals time: 0.8632077905349433 Scheduler time: 72.68650569394231 Scheduler overhead time: 0.04851211979985237 Adapter cache time: 0.01412351569160819 Engine time: 0.04786842130124569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 76.11602312512696,
    "estimated_duration": 3600.173633969997,
    "input_throughput": 5330.715946285367,
    "output_throughput": 4726.721744594004,
    "total_throughput": 10057.437690879371,
    "itl": 180.15905725390496,
    "ttft": 2183260.4214139627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2742836976726526,
    "arrivals": 2213766,
    "finished_requests": 77858,
    "scheduler_time": 139.42660803280629
}
#Debug simulation 
Total elapsed time: 76.1161505212076. Arrivals time: 0.4154978464357555 Scheduler time: 75.57259364565834 Scheduler overhead time: 0.048692069016397 Adapter cache time: 0.01366895018145442 Engine time: 0.04775854293256998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.15626715682447,
    "estimated_duration": 3600.0349257434214,
    "input_throughput": 5302.095227884021,
    "output_throughput": 4709.60514264977,
    "total_throughput": 10011.70037053379,
    "itl": 177.8117987522273,
    "ttft": 2183465.777377229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5024833722412638,
    "arrivals": 2213766,
    "finished_requests": 77509,
    "scheduler_time": 140.28041246265806
}
#Debug simulation 
Total elapsed time: 73.15639518480748. Arrivals time: 0.4119146093726158 Scheduler time: 72.61603741394356 Scheduler overhead time: 0.04846315970644355 Adapter cache time: 0.01413098257035017 Engine time: 0.04737423500046134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 76.66359560284764,
    "estimated_duration": 3600.057495951075,
    "input_throughput": 5336.904486000217,
    "output_throughput": 4731.872204585342,
    "total_throughput": 10068.776690585559,
    "itl": 180.12931703499112,
    "ttft": 2183638.1574523775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 386,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1541594138322357,
    "arrivals": 2213766,
    "finished_requests": 77978,
    "scheduler_time": 139.52341579743648
}
#Debug simulation 
Total elapsed time: 76.66373019199818. Arrivals time: 0.8868667078204453 Scheduler time: 75.64866483816877 Scheduler overhead time: 0.0487383627332747 Adapter cache time: 0.012693371623754501 Engine time: 0.048820188734680414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.67488616006449,
    "estimated_duration": 3600.054431027185,
    "input_throughput": 5302.066500853933,
    "output_throughput": 4709.579625762045,
    "total_throughput": 10011.646126615977,
    "itl": 177.81252996309905,
    "ttft": 2183473.810160799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5218494553491482,
    "arrivals": 2213766,
    "finished_requests": 77509,
    "scheduler_time": 140.280551663333
}
#Debug simulation 
Total elapsed time: 73.67501347698271. Arrivals time: 0.4025376373901963 Scheduler time: 73.14405344752595 Scheduler overhead time: 0.04885608656331897 Adapter cache time: 0.014036021195352077 Engine time: 0.047863433603197336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 67.70347917405888,
    "estimated_duration": 3600.0053482378485,
    "input_throughput": 5382.761725475003,
    "output_throughput": 4778.830678243582,
    "total_throughput": 10161.592403718585,
    "itl": 179.1055536032031,
    "ttft": 2186220.748505653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3496750950743552,
    "arrivals": 2212338,
    "finished_requests": 79123,
    "scheduler_time": 140.44847361082623
}
#Debug simulation 
Total elapsed time: 67.70360699482262. Arrivals time: 0.42750647384673357 Scheduler time: 67.14989180956036 Scheduler overhead time: 0.047769148368388414 Adapter cache time: 0.013616705313324928 Engine time: 0.04687535762786865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 66.76462639635429,
    "estimated_duration": 3600.158015472416,
    "input_throughput": 5379.722200181965,
    "output_throughput": 4777.619183957673,
    "total_throughput": 10157.341384139638,
    "itl": 179.11249728317043,
    "ttft": 2186460.504105431,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4765329007385357,
    "arrivals": 2212338,
    "finished_requests": 79071,
    "scheduler_time": 140.4611222420459
}
#Debug simulation 
Total elapsed time: 66.76475942507386. Arrivals time: 0.4196255411952734 Scheduler time: 66.21816649613902 Scheduler overhead time: 0.048211101442575455 Adapter cache time: 0.01354040065780282 Engine time: 0.04735509492456913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.06945805530995,
    "estimated_duration": 3600.0579815531355,
    "input_throughput": 5369.552962494331,
    "output_throughput": 4770.590942702158,
    "total_throughput": 10140.143905196488,
    "itl": 177.76961026125247,
    "ttft": 2185087.210523939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6259440260008076,
    "arrivals": 2212338,
    "finished_requests": 78926,
    "scheduler_time": 140.70974175959125
}
#Debug simulation 
Total elapsed time: 63.06959392223507. Arrivals time: 0.4123482732102275 Scheduler time: 62.53046679776162 Scheduler overhead time: 0.04789569368585944 Adapter cache time: 0.014242293313145638 Engine time: 0.04662877228111029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 67.49821456801146,
    "estimated_duration": 3600.0391363613426,
    "input_throughput": 5382.711205630349,
    "output_throughput": 4778.78582658642,
    "total_throughput": 10161.497032216768,
    "itl": 179.1068472480113,
    "ttft": 2186235.2766989693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3831702403654327,
    "arrivals": 2212338,
    "finished_requests": 79123,
    "scheduler_time": 140.44876658900168
}
#Debug simulation 
Total elapsed time: 67.49835055693984. Arrivals time: 0.39137357845902443 Scheduler time: 66.9808778851293 Scheduler overhead time: 0.04776739049702883 Adapter cache time: 0.013711031526327133 Engine time: 0.046886355616152287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 62.7449168539606,
    "estimated_duration": 3600.077738184286,
    "input_throughput": 5369.523495275833,
    "output_throughput": 4770.564762488151,
    "total_throughput": 10140.088257763984,
    "itl": 177.7703887043671,
    "ttft": 2185095.243191548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6455616166815215,
    "arrivals": 2212338,
    "finished_requests": 78926,
    "scheduler_time": 140.7098808000813
}
#Debug simulation 
Total elapsed time: 62.74505096999928. Arrivals time: 0.39250105805695057 Scheduler time: 62.226271705236286 Scheduler overhead time: 0.048106894828379154 Adapter cache time: 0.013875269331037998 Engine time: 0.04667524993419647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 67.8694969220087,
    "estimated_duration": 3600.160045376639,
    "input_throughput": 5382.79014147901,
    "output_throughput": 4778.863934700462,
    "total_throughput": 10161.654076179473,
    "itl": 179.10419909293412,
    "ttft": 2186228.3837189307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 443,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3245922806416537,
    "arrivals": 2212338,
    "finished_requests": 79127,
    "scheduler_time": 140.4561204415153
}
#Debug simulation 
Total elapsed time: 67.86962502030656. Arrivals time: 0.39635543059557676 Scheduler time: 67.34798665111884 Scheduler overhead time: 0.047242256347090006 Adapter cache time: 0.013328476343303919 Engine time: 0.04670424899086356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_384_slots_96_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 62.93240508809686,
    "estimated_duration": 3600.1005310072032,
    "input_throughput": 5369.489499947889,
    "output_throughput": 4770.534559265517,
    "total_throughput": 10140.024059213407,
    "itl": 177.77131603551723,
    "ttft": 2185104.4069583705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6681972982361895,
    "arrivals": 2212338,
    "finished_requests": 78926,
    "scheduler_time": 140.7100379414646
}
#Debug simulation 
Total elapsed time: 62.93254198599607. Arrivals time: 0.41499703424051404 Scheduler time: 62.391022643540055 Scheduler overhead time: 0.04826635355129838 Adapter cache time: 0.014222386293113232 Engine time: 0.04628449073061347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 50.27640356402844,
    "estimated_duration": 3600.0606173629517,
    "input_throughput": 5276.02060598444,
    "output_throughput": 4684.6766742371465,
    "total_throughput": 9960.697280221588,
    "itl": 183.27326897859257,
    "ttft": 2176913.6055696104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0597082516667786,
    "arrivals": 2026382,
    "finished_requests": 77032,
    "scheduler_time": 137.41801516527568
}
#Debug simulation 
Total elapsed time: 50.27653848938644. Arrivals time: 0.39884624956175685 Scheduler time: 49.75186938326806 Scheduler overhead time: 0.04599705385044217 Adapter cache time: 0.018424497451633215 Engine time: 0.044461546931415796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 52.09432716993615,
    "estimated_duration": 3600.018082952647,
    "input_throughput": 5273.879897966539,
    "output_throughput": 4684.238137539881,
    "total_throughput": 9958.118035506419,
    "itl": 183.1874017291313,
    "ttft": 2176823.268447871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.084982456350705,
    "arrivals": 2026382,
    "finished_requests": 77074,
    "scheduler_time": 137.44357623576335
}
#Debug simulation 
Total elapsed time: 52.094458892941475. Arrivals time: 0.40997296245768666 Scheduler time: 51.5572505723685 Scheduler overhead time: 0.046552968211472034 Adapter cache time: 0.018137100152671337 Engine time: 0.04557063244283199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 59.90619706502184,
    "estimated_duration": 3600.0096140394235,
    "input_throughput": 5262.153724846288,
    "output_throughput": 4677.312786702909,
    "total_throughput": 9939.466511549197,
    "itl": 181.100399111073,
    "ttft": 2177708.847766263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.316015647314489,
    "arrivals": 2026382,
    "finished_requests": 76932,
    "scheduler_time": 138.06008705997522
}
#Debug simulation 
Total elapsed time: 59.90632851794362. Arrivals time: 0.4053987772203982 Scheduler time: 59.36870042420924 Scheduler overhead time: 0.047719286754727364 Adapter cache time: 0.01935221068561077 Engine time: 0.04695796221494675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 52.14659184589982,
    "estimated_duration": 3600.1363714253184,
    "input_throughput": 5273.82438918088,
    "output_throughput": 4684.181725406015,
    "total_throughput": 9958.006114586895,
    "itl": 183.18371196487925,
    "ttft": 2176808.203358596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 638,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9971344628860104,
    "arrivals": 2026382,
    "finished_requests": 77076,
    "scheduler_time": 137.4509513119393
}
#Debug simulation 
Total elapsed time: 52.14672007597983. Arrivals time: 0.3974772850051522 Scheduler time: 51.6210627052933 Scheduler overhead time: 0.046938905492424965 Adapter cache time: 0.018000819254666567 Engine time: 0.04584639333188534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 60.01367351599038,
    "estimated_duration": 3600.0396967374977,
    "input_throughput": 5262.109753169568,
    "output_throughput": 4677.2737020815675,
    "total_throughput": 9939.383455251136,
    "itl": 181.10170736709915,
    "ttft": 2177719.3363743145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.345945048481228,
    "arrivals": 2026382,
    "finished_requests": 76932,
    "scheduler_time": 138.06024035692104
}
#Debug simulation 
Total elapsed time: 60.01380876079202. Arrivals time: 0.39949158905074 Scheduler time: 59.483039506245404 Scheduler overhead time: 0.047452245373278856 Adapter cache time: 0.019275672268122435 Engine time: 0.04675787501037121 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 50.26001515612006,
    "estimated_duration": 3600.012970760292,
    "input_throughput": 5276.090434748803,
    "output_throughput": 4684.738676493777,
    "total_throughput": 9960.829111242581,
    "itl": 183.27114021570478,
    "ttft": 2176893.329708291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.01230384846913,
    "arrivals": 2026382,
    "finished_requests": 77032,
    "scheduler_time": 137.41777296571237
}
#Debug simulation 
Total elapsed time: 50.260154956020415. Arrivals time: 0.404709302354604 Scheduler time: 49.73004735307768 Scheduler overhead time: 0.04518474545329809 Adapter cache time: 0.018069420009851456 Engine time: 0.04472957085818052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.0743016009219,
    "estimated_duration": 3600.070026457968,
    "input_throughput": 5262.065421165822,
    "output_throughput": 4677.2342971803,
    "total_throughput": 9939.299718346123,
    "itl": 181.1030388882023,
    "ttft": 2177730.0124129173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 708,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.376125957220801,
    "arrivals": 2026382,
    "finished_requests": 76932,
    "scheduler_time": 138.06038916868974
}
#Debug simulation 
Total elapsed time: 60.07443005684763. Arrivals time: 0.41329804714769125 Scheduler time: 59.529745574109256 Scheduler overhead time: 0.04762673191726208 Adapter cache time: 0.01932853553444147 Engine time: 0.04675658419728279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.44828556803986,
    "estimated_duration": 3600.0629130976463,
    "input_throughput": 5301.128469329715,
    "output_throughput": 4683.185379528034,
    "total_throughput": 9984.31384885775,
    "itl": 181.83836949102079,
    "ttft": 2173678.1042659227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8271111831278815,
    "arrivals": 1888011,
    "finished_requests": 77110,
    "scheduler_time": 138.0200403574439
}
#Debug simulation 
Total elapsed time: 74.44841868802905. Arrivals time: 0.4099676492623985 Scheduler time: 73.90599657781422 Scheduler overhead time: 0.047961242496967316 Adapter cache time: 0.018296136055141687 Engine time: 0.04806833388283849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 75.59065463813022,
    "estimated_duration": 3600.041211341998,
    "input_throughput": 5301.479866361148,
    "output_throughput": 4682.899169844658,
    "total_throughput": 9984.379036205806,
    "itl": 182.24849807089336,
    "ttft": 2173975.455621388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.906767332369933,
    "arrivals": 1888011,
    "finished_requests": 77131,
    "scheduler_time": 137.817216354356
}
#Debug simulation 
Total elapsed time: 75.59078320115805. Arrivals time: 0.4065328110009432 Scheduler time: 75.05090534174815 Scheduler overhead time: 0.04913140553981066 Adapter cache time: 0.01796799385920167 Engine time: 0.04849628126248717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.3904471937567,
    "estimated_duration": 3600.0149916838272,
    "input_throughput": 5288.039923160391,
    "output_throughput": 4670.243329219059,
    "total_throughput": 9958.28325237945,
    "itl": 180.58867132009112,
    "ttft": 2174218.082417222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2335199736990057,
    "arrivals": 1888011,
    "finished_requests": 76847,
    "scheduler_time": 138.23217409775629
}
#Debug simulation 
Total elapsed time: 73.39057358400896. Arrivals time: 0.39703853614628315 Scheduler time: 72.86163942050189 Scheduler overhead time: 0.04772911826148629 Adapter cache time: 0.018754759803414345 Engine time: 0.04760696878656745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 74.50439219502732,
    "estimated_duration": 3600.1016019031204,
    "input_throughput": 5301.071500290832,
    "output_throughput": 4683.135051268395,
    "total_throughput": 9984.206551559226,
    "itl": 181.84005225435317,
    "ttft": 2173690.872652083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8655533037893353,
    "arrivals": 1888011,
    "finished_requests": 77110,
    "scheduler_time": 138.0202870421843
}
#Debug simulation 
Total elapsed time: 74.50451890705153. Arrivals time: 0.41064556781202555 Scheduler time: 73.96148403082043 Scheduler overhead time: 0.048662540037184954 Adapter cache time: 0.017710252199321985 Engine time: 0.048014281783252954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.3698153491132,
    "estimated_duration": 3600.044182411894,
    "input_throughput": 5287.9970454267905,
    "output_throughput": 4670.205460849639,
    "total_throughput": 9958.20250627643,
    "itl": 180.5899576082678,
    "ttft": 2174226.235990119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2625690983608373,
    "arrivals": 1888011,
    "finished_requests": 76847,
    "scheduler_time": 138.23231570120467
}
#Debug simulation 
Total elapsed time: 73.36993981711566. Arrivals time: 0.4071723027154803 Scheduler time: 72.82963782874867 Scheduler overhead time: 0.04854535823687911 Adapter cache time: 0.01889153104275465 Engine time: 0.0475794542580843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.54372913902625,
    "estimated_duration": 3600.020631915159,
    "input_throughput": 5301.190729522952,
    "output_throughput": 4683.240382161602,
    "total_throughput": 9984.431111684555,
    "itl": 181.83653674534676,
    "ttft": 2173665.1059080856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7850600260565723,
    "arrivals": 1888011,
    "finished_requests": 77110,
    "scheduler_time": 138.01981033193272
}
#Debug simulation 
Total elapsed time: 74.54385615605861. Arrivals time: 0.4108528420329094 Scheduler time: 74.00155261950567 Scheduler overhead time: 0.04819941706955433 Adapter cache time: 0.01761398557573557 Engine time: 0.047658275812864304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.33078073710203,
    "estimated_duration": 3600.073003887846,
    "input_throughput": 5287.954710763156,
    "output_throughput": 4670.168072103845,
    "total_throughput": 9958.122782867002,
    "itl": 180.59120976356263,
    "ttft": 2174234.3900153246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.29124096166343,
    "arrivals": 1888011,
    "finished_requests": 76847,
    "scheduler_time": 138.23246531389788
}
#Debug simulation 
Total elapsed time: 73.33090127399191. Arrivals time: 0.41231295047327876 Scheduler time: 72.78629197366536 Scheduler overhead time: 0.04799507139250636 Adapter cache time: 0.01914815977215767 Engine time: 0.047315546311438084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 74.3441218319349,
    "estimated_duration": 3600.0605059629866,
    "input_throughput": 5307.887733650347,
    "output_throughput": 4678.228316469623,
    "total_throughput": 9986.11605011997,
    "itl": 182.02652741516445,
    "ttft": 2172586.839918505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7108126488584328,
    "arrivals": 1864865,
    "finished_requests": 77312,
    "scheduler_time": 137.77287089072178
}
#Debug simulation 
Total elapsed time: 74.34425584366545. Arrivals time: 0.42285848082974553 Scheduler time: 73.79078704258427 Scheduler overhead time: 0.048407492227852345 Adapter cache time: 0.016434766817837954 Engine time: 0.04783125361427665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.84682939900085,
    "estimated_duration": 3600.0393997241636,
    "input_throughput": 5307.086083964495,
    "output_throughput": 4679.31573229191,
    "total_throughput": 9986.401816256404,
    "itl": 182.01879499674564,
    "ttft": 2172607.696161814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8544319791486543,
    "arrivals": 1864865,
    "finished_requests": 77305,
    "scheduler_time": 137.77240412853857
}
#Debug simulation 
Total elapsed time: 74.84696355974302. Arrivals time: 0.5705995438620448 Scheduler time: 74.14457393903285 Scheduler overhead time: 0.048970047384500504 Adapter cache time: 0.016760705038905144 Engine time: 0.04800777230411768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.12924257200211,
    "estimated_duration": 3600.024217791094,
    "input_throughput": 5298.449356461212,
    "output_throughput": 4671.038021604722,
    "total_throughput": 9969.487378065935,
    "itl": 180.06580901249234,
    "ttft": 2174286.5413182466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8785146334581193,
    "arrivals": 1864865,
    "finished_requests": 77201,
    "scheduler_time": 138.38599282788778
}
#Debug simulation 
Total elapsed time: 74.12937076296657. Arrivals time: 0.4249391392804682 Scheduler time: 73.5729545801878 Scheduler overhead time: 0.048500909470021725 Adapter cache time: 0.01675498904660344 Engine time: 0.048423934262245893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 73.59568703593686,
    "estimated_duration": 3600.0805676979717,
    "input_throughput": 5303.426031992566,
    "output_throughput": 4674.865932448193,
    "total_throughput": 9978.29196444076,
    "itl": 182.06332133820518,
    "ttft": 2172638.4265072993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9498321365518372,
    "arrivals": 1864865,
    "finished_requests": 77291,
    "scheduler_time": 137.73876269041705
}
#Debug simulation 
Total elapsed time: 73.59581794310361. Arrivals time: 0.4146629157476127 Scheduler time: 73.0495614958927 Scheduler overhead time: 0.04846801329404116 Adapter cache time: 0.017224942333996296 Engine time: 0.047820141073316336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.61928589362651,
    "estimated_duration": 3600.0480108776387,
    "input_throughput": 5298.4143384659765,
    "output_throughput": 4671.00715023535,
    "total_throughput": 9969.421488701328,
    "itl": 180.06679699777928,
    "ttft": 2174293.795304902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9021563453041053,
    "arrivals": 1864865,
    "finished_requests": 77201,
    "scheduler_time": 138.38614420261484
}
#Debug simulation 
Total elapsed time: 74.6194153255783. Arrivals time: 0.4237495078705251 Scheduler time: 74.06399726308882 Scheduler overhead time: 0.04857396241277456 Adapter cache time: 0.016641799360513687 Engine time: 0.048184080980718136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.76577489404008,
    "estimated_duration": 3600.0208752934104,
    "input_throughput": 5307.94616529622,
    "output_throughput": 4678.279816537826,
    "total_throughput": 9986.225981834046,
    "itl": 182.02481783256522,
    "ttft": 2172574.4641433842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 559,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6714381148502937,
    "arrivals": 1864865,
    "finished_requests": 77312,
    "scheduler_time": 137.77261475507248
}
#Debug simulation 
Total elapsed time: 73.7659001541324. Arrivals time: 0.40536485286429524 Scheduler time: 73.22886798065156 Scheduler overhead time: 0.04890817031264305 Adapter cache time: 0.016297596972435713 Engine time: 0.04804116813465953 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 74.3274846333079,
    "estimated_duration": 3600.0724335340396,
    "input_throughput": 5298.378394368949,
    "output_throughput": 4670.975462427735,
    "total_throughput": 9969.353856796684,
    "itl": 180.0678304960905,
    "ttft": 2174301.737977127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9264268260821662,
    "arrivals": 1864865,
    "finished_requests": 77201,
    "scheduler_time": 138.38629637826637
}
#Debug simulation 
Total elapsed time: 74.32761700125411. Arrivals time: 0.5557089555077255 Scheduler time: 73.64047878002748 Scheduler overhead time: 0.048442728351801634 Adapter cache time: 0.016542699187994003 Engine time: 0.04795647971332073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.05175636615604,
    "estimated_duration": 3600.0134586525455,
    "input_throughput": 5347.501397176864,
    "output_throughput": 4699.958540247508,
    "total_throughput": 10047.459937424372,
    "itl": 181.29665631959455,
    "ttft": 2175399.390612719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7750828914810228,
    "arrivals": 1853406,
    "finished_requests": 77765,
    "scheduler_time": 138.3999966053354
}
#Debug simulation 
Total elapsed time: 72.05188041599467. Arrivals time: 0.40930946450680494 Scheduler time: 71.51043661823496 Scheduler overhead time: 0.048593385610729456 Adapter cache time: 0.016901530791074038 Engine time: 0.048570625949651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.2250233576633,
    "estimated_duration": 3600.1277110409665,
    "input_throughput": 5347.331690750939,
    "output_throughput": 4699.809384014229,
    "total_throughput": 10047.141074765168,
    "itl": 181.30154988669383,
    "ttft": 2175434.1835242985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8886782014137182,
    "arrivals": 1853406,
    "finished_requests": 77765,
    "scheduler_time": 138.40065368378026
}
#Debug simulation 
Total elapsed time: 72.22515207203105. Arrivals time: 0.4111576736904681 Scheduler time: 71.68158413562924 Scheduler overhead time: 0.048774899914860725 Adapter cache time: 0.016832136549055576 Engine time: 0.04850028734654188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.68247651914135,
    "estimated_duration": 3600.058179264852,
    "input_throughput": 5340.600913268056,
    "output_throughput": 4695.229398612577,
    "total_throughput": 10035.830311880633,
    "itl": 179.26056796301106,
    "ttft": 2177330.5098355147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9109815983101843,
    "arrivals": 1853406,
    "finished_requests": 77689,
    "scheduler_time": 139.10727501970172
}
#Debug simulation 
Total elapsed time: 72.68260074127465. Arrivals time: 0.4321425170637667 Scheduler time: 72.11661736248061 Scheduler overhead time: 0.04910574108362198 Adapter cache time: 0.017541274894028902 Engine time: 0.04856962012127042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.18558739637956,
    "estimated_duration": 3600.0533359242904,
    "input_throughput": 5347.442163674892,
    "output_throughput": 4699.9064794844,
    "total_throughput": 10047.348643159292,
    "itl": 181.2983782152712,
    "ttft": 2175411.5443884456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8147224487760003,
    "arrivals": 1853406,
    "finished_requests": 77765,
    "scheduler_time": 138.4002343197216
}
#Debug simulation 
Total elapsed time: 72.18571816710755. Arrivals time: 0.42686135740950704 Scheduler time: 71.6268484853208 Scheduler overhead time: 0.04884748253971338 Adapter cache time: 0.017028114292770624 Engine time: 0.04826659383252263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 73.01477534789592,
    "estimated_duration": 3600.0815785909786,
    "input_throughput": 5340.566201148412,
    "output_throughput": 4695.198881191919,
    "total_throughput": 10035.765082340331,
    "itl": 179.26157166190703,
    "ttft": 2177337.5251528625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9342460487969262,
    "arrivals": 1853406,
    "finished_requests": 77689,
    "scheduler_time": 139.10740989538445
}
#Debug simulation 
Total elapsed time: 73.01490405481309. Arrivals time: 0.419694185256958 Scheduler time: 72.46275859000161 Scheduler overhead time: 0.048657387495040894 Adapter cache time: 0.01732076331973076 Engine time: 0.048116945661604404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.1013863091357,
    "estimated_duration": 3600.171561506755,
    "input_throughput": 5347.373221275827,
    "output_throughput": 4699.98518429446,
    "total_throughput": 10047.358405570287,
    "itl": 181.29550244770112,
    "ttft": 2175436.063933034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 580,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7342291710432371,
    "arrivals": 1853406,
    "finished_requests": 77768,
    "scheduler_time": 138.40746810668497
}
#Debug simulation 
Total elapsed time: 72.10151091916487. Arrivals time: 0.4056822466664016 Scheduler time: 71.56460725935176 Scheduler overhead time: 0.048420948442071676 Adapter cache time: 0.01709063397720456 Engine time: 0.04774107225239277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.673194848001,
    "estimated_duration": 3600.1059901946055,
    "input_throughput": 5340.529987829804,
    "output_throughput": 4695.167043980918,
    "total_throughput": 10035.697031810721,
    "itl": 179.2626450746511,
    "ttft": 2177345.0556000886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9585165295749862,
    "arrivals": 1853406,
    "finished_requests": 77689,
    "scheduler_time": 139.10755101827814
}
#Debug simulation 
Total elapsed time: 72.67332678288221. Arrivals time: 0.4112462247721851 Scheduler time: 72.12875418690965 Scheduler overhead time: 0.048999379854649305 Adapter cache time: 0.017433485481888056 Engine time: 0.04814688581973314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 46.85694726323709,
    "estimated_duration": 3600.030148429242,
    "input_throughput": 5351.6960152142665,
    "output_throughput": 4681.8030141647505,
    "total_throughput": 10033.499029379016,
    "itl": 182.44256582414266,
    "ttft": 2167702.776367987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5883931391011183,
    "arrivals": 1847695,
    "finished_requests": 77577,
    "scheduler_time": 137.5089171075054
}
#Debug simulation 
Total elapsed time: 46.85708192596212. Arrivals time: 0.53221974382177 Scheduler time: 46.202810113783926 Scheduler overhead time: 0.04495162749662995 Adapter cache time: 0.015541124623268843 Engine time: 0.04454261437058449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 47.01500621624291,
    "estimated_duration": 3600.071022626979,
    "input_throughput": 5357.0707018794,
    "output_throughput": 4680.472105715431,
    "total_throughput": 10037.542807594831,
    "itl": 182.33539419208788,
    "ttft": 2168318.9420385533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.696070250463678,
    "arrivals": 1847695,
    "finished_requests": 77642,
    "scheduler_time": 137.52567495697826
}
#Debug simulation 
Total elapsed time: 47.015149699058384. Arrivals time: 0.39554125629365444 Scheduler time: 46.49708225438371 Scheduler overhead time: 0.04539602808654308 Adapter cache time: 0.015317826066166162 Engine time: 0.04456037050113082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 43.85211572330445,
    "estimated_duration": 3600.0250033877783,
    "input_throughput": 5339.261250105698,
    "output_throughput": 4673.28670888895,
    "total_throughput": 10012.547958994648,
    "itl": 180.7428491290662,
    "ttft": 2170449.204020245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.872082056868833,
    "arrivals": 1847695,
    "finished_requests": 77457,
    "scheduler_time": 137.99949055199357
}
#Debug simulation 
Total elapsed time: 43.85225184215233. Arrivals time: 0.39407764794304967 Scheduler time: 43.33464426547289 Scheduler overhead time: 0.04477633163332939 Adapter cache time: 0.01718663005158305 Engine time: 0.044209702871739864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 46.682907816022635,
    "estimated_duration": 3600.0640914839028,
    "input_throughput": 5351.645556970814,
    "output_throughput": 4681.758871979617,
    "total_throughput": 10033.40442895043,
    "itl": 182.44401239002192,
    "ttft": 2167719.5682767876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6221144978259616,
    "arrivals": 1847695,
    "finished_requests": 77577,
    "scheduler_time": 137.50913880340195
}
#Debug simulation 
Total elapsed time: 46.6830444871448. Arrivals time: 0.4060852867551148 Scheduler time: 46.154281275346875 Scheduler overhead time: 0.04488196177408099 Adapter cache time: 0.01566912978887558 Engine time: 0.044583629816770554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 43.73595763137564,
    "estimated_duration": 3600.0356526747255,
    "input_throughput": 5336.987145037029,
    "output_throughput": 4672.254283788274,
    "total_throughput": 10009.241428825302,
    "itl": 180.69084443857759,
    "ttft": 2170595.2181815985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9147794183902482,
    "arrivals": 1847695,
    "finished_requests": 77454,
    "scheduler_time": 138.00841396305415
}
#Debug simulation 
Total elapsed time: 43.736092136241496. Arrivals time: 0.39419143134728074 Scheduler time: 43.21929755574092 Scheduler overhead time: 0.044472492299973965 Adapter cache time: 0.01692889304831624 Engine time: 0.04386671585962176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 46.651922904420644,
    "estimated_duration": 3600.19475117209,
    "input_throughput": 5351.667432359698,
    "output_throughput": 4681.865611440167,
    "total_throughput": 10033.533043799865,
    "itl": 182.43993765003762,
    "ttft": 2167756.1208335375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.551836103054211,
    "arrivals": 1847695,
    "finished_requests": 77583,
    "scheduler_time": 137.516441992284
}
#Debug simulation 
Total elapsed time: 46.652060811407864. Arrivals time: 0.391720911487937 Scheduler time: 46.13767127413303 Scheduler overhead time: 0.045017065946012735 Adapter cache time: 0.01614970015361905 Engine time: 0.04438965627923608 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 43.729701770003885,
    "estimated_duration": 3600.059813892101,
    "input_throughput": 5336.951326713665,
    "output_throughput": 4672.222926711664,
    "total_throughput": 10009.17425342533,
    "itl": 180.691892905729,
    "ttft": 2170606.4472328946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9387983915954785,
    "arrivals": 1847695,
    "finished_requests": 77454,
    "scheduler_time": 138.00855620724212
}
#Debug simulation 
Total elapsed time: 43.72983577894047. Arrivals time: 0.38018393563106656 Scheduler time: 43.226168585475534 Scheduler overhead time: 0.04490029253065586 Adapter cache time: 0.017185401171445847 Engine time: 0.04423114564269781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 62.78106489498168,
    "estimated_duration": 3600.1830828209736,
    "input_throughput": 5368.602250320924,
    "output_throughput": 4723.696436758593,
    "total_throughput": 10092.298687079518,
    "itl": 181.01207257906862,
    "ttft": 2179724.9105749754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8209902076400157,
    "arrivals": 1844823,
    "finished_requests": 77885,
    "scheduler_time": 138.73795925307286
}
#Debug simulation 
Total elapsed time: 62.78119641682133. Arrivals time: 0.40308867348358035 Scheduler time: 62.25087263295427 Scheduler overhead time: 0.046341797802597284 Adapter cache time: 0.016461899504065514 Engine time: 0.04685148550197482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 63.298984149005264,
    "estimated_duration": 3600.1047189984984,
    "input_throughput": 5368.61800102767,
    "output_throughput": 4723.765092236222,
    "total_throughput": 10092.383093263892,
    "itl": 181.01711425585398,
    "ttft": 2179709.4785801047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9433352434798203,
    "arrivals": 1844823,
    "finished_requests": 77884,
    "scheduler_time": 138.73088528877753
}
#Debug simulation 
Total elapsed time: 63.29911746876314. Arrivals time: 0.833301892504096 Scheduler time: 62.33845182415098 Scheduler overhead time: 0.046623277477920055 Adapter cache time: 0.016556669026613235 Engine time: 0.04668279364705086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.57600176893175,
    "estimated_duration": 3600.197244342826,
    "input_throughput": 5350.118255400187,
    "output_throughput": 4706.914329937848,
    "total_throughput": 10057.032585338035,
    "itl": 179.14532432201628,
    "ttft": 2179632.767853921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9779141387902324,
    "arrivals": 1844823,
    "finished_requests": 77610,
    "scheduler_time": 139.22210591937989
}
#Debug simulation 
Total elapsed time: 60.5761325689964. Arrivals time: 0.4154339930973947 Scheduler time: 60.03359701856971 Scheduler overhead time: 0.046616589184850454 Adapter cache time: 0.016931739170104265 Engine time: 0.045966488774865866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 62.896015892736614,
    "estimated_duration": 3600.023850888131,
    "input_throughput": 5368.738597448974,
    "output_throughput": 4723.871203187885,
    "total_throughput": 10092.60980063686,
    "itl": 181.0135281511099,
    "ttft": 2179686.1205059146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8628419657470552,
    "arrivals": 1844823,
    "finished_requests": 77884,
    "scheduler_time": 138.73051045612004
}
#Debug simulation 
Total elapsed time: 62.89615003298968. Arrivals time: 0.42249215254560113 Scheduler time: 62.345895318780094 Scheduler overhead time: 0.04716711724177003 Adapter cache time: 0.016600971575826406 Engine time: 0.046433602925390005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 60.44326564669609,
    "estimated_duration": 3600.018517005022,
    "input_throughput": 5349.983037315897,
    "output_throughput": 4706.699401673206,
    "total_throughput": 10056.682438989103,
    "itl": 179.1447081213887,
    "ttft": 2179611.4699029927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.002813388500366,
    "arrivals": 1844823,
    "finished_requests": 77604,
    "scheduler_time": 139.21442941764516
}
#Debug simulation 
Total elapsed time: 60.443394667934626. Arrivals time: 0.41891149478033185 Scheduler time: 59.89639187557623 Scheduler overhead time: 0.0469060386531055 Adapter cache time: 0.017114970833063126 Engine time: 0.0462516350671649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 63.298791914246976,
    "estimated_duration": 3600.1409610948235,
    "input_throughput": 5368.665063081935,
    "output_throughput": 4723.75170410781,
    "total_throughput": 10092.416767189745,
    "itl": 181.0102330688843,
    "ttft": 2179712.5731579172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7790799254667682,
    "arrivals": 1844823,
    "finished_requests": 77885,
    "scheduler_time": 138.73774780900968
}
#Debug simulation 
Total elapsed time: 63.29892257042229. Arrivals time: 0.8460032972507179 Scheduler time: 62.324677443131804 Scheduler overhead time: 0.04768156399950385 Adapter cache time: 0.01673727435991168 Engine time: 0.04608264146372676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 60.533477902878076,
    "estimated_duration": 3600.0446992533216,
    "input_throughput": 5349.944128192266,
    "output_throughput": 4706.665170994784,
    "total_throughput": 10056.60929918705,
    "itl": 179.1458111497424,
    "ttft": 2179619.7631659587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 605,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0288444222882345,
    "arrivals": 1844823,
    "finished_requests": 77604,
    "scheduler_time": 139.21458063218734
}
#Debug simulation 
Total elapsed time: 60.533612202852964. Arrivals time: 0.4108402072452009 Scheduler time: 59.995823262725025 Scheduler overhead time: 0.04670687858015299 Adapter cache time: 0.016896109096705914 Engine time: 0.04553320771083236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 45.41450854111463,
    "estimated_duration": 3600.1879255993977,
    "input_throughput": 5305.400272076063,
    "output_throughput": 4689.999896932832,
    "total_throughput": 9995.400169008893,
    "itl": 183.05682155742122,
    "ttft": 2175134.7292594076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4261872886726767,
    "arrivals": 1843393,
    "finished_requests": 77427,
    "scheduler_time": 137.38841331917163
}
#Debug simulation 
Total elapsed time: 45.41464358009398. Arrivals time: 0.39705578377470374 Scheduler time: 44.898390201851726 Scheduler overhead time: 0.04403519490733743 Adapter cache time: 0.01472891354933381 Engine time: 0.043377057649195194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 44.8824588698335,
    "estimated_duration": 3600.0861016548465,
    "input_throughput": 5305.0283967433425,
    "output_throughput": 4689.8692206941905,
    "total_throughput": 9994.897617437533,
    "itl": 183.06120343431496,
    "ttft": 2175115.238593845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.523705344006891,
    "arrivals": 1843393,
    "finished_requests": 77421,
    "scheduler_time": 137.38138324665314
}
#Debug simulation 
Total elapsed time: 44.882586683146656. Arrivals time: 0.38462461112067103 Scheduler time: 44.379683221224695 Scheduler overhead time: 0.04373604152351618 Adapter cache time: 0.014530640095472336 Engine time: 0.04312419705092907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 49.61813141871244,
    "estimated_duration": 3600.119963980259,
    "input_throughput": 5288.144614756619,
    "output_throughput": 4678.307436560843,
    "total_throughput": 9966.452051317463,
    "itl": 181.51203388678726,
    "ttft": 2173126.217389263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4917168233543723,
    "arrivals": 1843393,
    "finished_requests": 77229,
    "scheduler_time": 137.8269241233914
}
#Debug simulation 
Total elapsed time: 49.61826101364568. Arrivals time: 0.3939629360102117 Scheduler time: 49.102621951606125 Scheduler overhead time: 0.0451741898432374 Adapter cache time: 0.014257121831178665 Engine time: 0.04498406266793609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 45.33206109935418,
    "estimated_duration": 3600.0214975851286,
    "input_throughput": 5305.1235979593985,
    "output_throughput": 4689.953382591086,
    "total_throughput": 9995.076980550484,
    "itl": 183.0585198297337,
    "ttft": 2175082.296340538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4595558790117464,
    "arrivals": 1843393,
    "finished_requests": 77421,
    "scheduler_time": 137.38092864191728
}
#Debug simulation 
Total elapsed time: 45.33219008799642. Arrivals time: 0.3952314630150795 Scheduler time: 44.81792222522199 Scheduler overhead time: 0.04402649449184537 Adapter cache time: 0.014273542445152998 Engine time: 0.0438961386680603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 49.5268098320812,
    "estimated_duration": 3600.138847062693,
    "input_throughput": 5288.116877917868,
    "output_throughput": 4678.282898378087,
    "total_throughput": 9966.399776295955,
    "itl": 181.51280452871873,
    "ttft": 2173136.5088662338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5104541375301823,
    "arrivals": 1843393,
    "finished_requests": 77229,
    "scheduler_time": 137.82706989164706
}
#Debug simulation 
Total elapsed time: 49.526933511253446. Arrivals time: 0.3914059503003955 Scheduler time: 49.01326490100473 Scheduler overhead time: 0.045267116744071245 Adapter cache time: 0.014353703707456589 Engine time: 0.04535667598247528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 45.12060616211966,
    "estimated_duration": 3600.1548883819114,
    "input_throughput": 5305.448957665454,
    "output_throughput": 4690.042935232963,
    "total_throughput": 9995.491892898417,
    "itl": 183.0554279676698,
    "ttft": 2175117.749732987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 466,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3933634374244013,
    "arrivals": 1843393,
    "finished_requests": 77427,
    "scheduler_time": 137.3881999528897
}
#Debug simulation 
Total elapsed time: 45.120749338995665. Arrivals time: 0.3918594615533948 Scheduler time: 44.60919719003141 Scheduler overhead time: 0.04413227643817663 Adapter cache time: 0.014364229515194893 Engine time: 0.043926309794187546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_384_slots_96_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 49.469495011959225,
    "estimated_duration": 3600.158980314484,
    "input_throughput": 5288.0873050603395,
    "output_throughput": 4678.256735909135,
    "total_throughput": 9966.344040969476,
    "itl": 181.51362461180764,
    "ttft": 2173147.4815719556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5304489895701407,
    "arrivals": 1843393,
    "finished_requests": 77229,
    "scheduler_time": 137.8272082913975
}
#Debug simulation 
Total elapsed time: 49.46963185118511. Arrivals time: 0.38845298858359456 Scheduler time: 48.959125683642924 Scheduler overhead time: 0.04544339934363961 Adapter cache time: 0.01428217114880681 Engine time: 0.04488402884453535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 77.17342902114615,
    "estimated_duration": 3600.1027458030057,
    "input_throughput": 5318.706257015187,
    "output_throughput": 4682.666909896704,
    "total_throughput": 10001.37316691189,
    "itl": 182.51450284626046,
    "ttft": 2171576.2707161736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.72917557532203,
    "arrivals": 1703822,
    "finished_requests": 77169,
    "scheduler_time": 137.5514384056122
}
#Debug simulation 
Total elapsed time: 77.17356938123703. Arrivals time: 0.41910996194928885 Scheduler time: 76.62122759781778 Scheduler overhead time: 0.049539659172296524 Adapter cache time: 0.017477855551987886 Engine time: 0.04796310281381011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 77.29245353396982,
    "estimated_duration": 3600.0146648921896,
    "input_throughput": 5318.657778460301,
    "output_throughput": 4682.49509214286,
    "total_throughput": 10001.152870603162,
    "itl": 182.51852189976148,
    "ttft": 2171535.3854756504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8430102563533055,
    "arrivals": 1703822,
    "finished_requests": 77165,
    "scheduler_time": 137.54431530362405
}
#Debug simulation 
Total elapsed time: 77.29259499395266. Arrivals time: 0.4273350783623755 Scheduler time: 76.7328369077295 Scheduler overhead time: 0.049112978391349316 Adapter cache time: 0.016734345350414515 Engine time: 0.04822911974042654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.58131194673479,
    "estimated_duration": 3600.1614468331386,
    "input_throughput": 5300.630341671583,
    "output_throughput": 4671.266621888098,
    "total_throughput": 9971.89696355968,
    "itl": 180.46702075024973,
    "ttft": 2170645.415007082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8653288155794259,
    "arrivals": 1703822,
    "finished_requests": 76914,
    "scheduler_time": 138.17049669925933
}
#Debug simulation 
Total elapsed time: 76.58144193189219. Arrivals time: 0.3999320180155337 Scheduler time: 76.04882017476484 Scheduler overhead time: 0.04918891144916415 Adapter cache time: 0.017329596914350986 Engine time: 0.047910511028021574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 77.2176850377582,
    "estimated_duration": 3600.138716583518,
    "input_throughput": 5318.653115169707,
    "output_throughput": 4682.6201230373945,
    "total_throughput": 10001.2732382071,
    "itl": 182.51609565062168,
    "ttft": 2171585.866748015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7649685505311836,
    "arrivals": 1703822,
    "finished_requests": 77169,
    "scheduler_time": 137.55161621084716
}
#Debug simulation 
Total elapsed time: 77.21782545372844. Arrivals time: 0.41248072776943445 Scheduler time: 76.67187110008672 Scheduler overhead time: 0.04931364115327597 Adapter cache time: 0.017519733402878046 Engine time: 0.048468871507793665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 76.16283842269331,
    "estimated_duration": 3600.011942264939,
    "input_throughput": 5300.583249730695,
    "output_throughput": 4671.229781926765,
    "total_throughput": 9971.813031657459,
    "itl": 180.46738084043756,
    "ttft": 2170659.8428089954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8890962812118268,
    "arrivals": 1703822,
    "finished_requests": 76911,
    "scheduler_time": 138.16357337181515
}
#Debug simulation 
Total elapsed time: 76.16297175874934. Arrivals time: 0.42200431367382407 Scheduler time: 75.60875098127872 Scheduler overhead time: 0.04884639102965593 Adapter cache time: 0.016729893628507853 Engine time: 0.048181462567299604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 78.02697788365185,
    "estimated_duration": 3600.0627274290528,
    "input_throughput": 5318.765379867218,
    "output_throughput": 4682.718962521807,
    "total_throughput": 10001.484342389025,
    "itl": 182.51275616436095,
    "ttft": 2171564.833975762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6893784166197061,
    "arrivals": 1703822,
    "finished_requests": 77169,
    "scheduler_time": 137.55121719027034
}
#Debug simulation 
Total elapsed time: 78.02711708191782. Arrivals time: 0.4242370296269655 Scheduler time: 77.46966197481379 Scheduler overhead time: 0.049442294519394636 Adapter cache time: 0.01695583574473858 Engine time: 0.04826520662754774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 76.53678484726697,
    "estimated_duration": 3600.035837077515,
    "input_throughput": 5300.548067735562,
    "output_throughput": 4671.198777190926,
    "total_throughput": 9971.746844926487,
    "itl": 180.4684014043835,
    "ttft": 2170666.361035412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9128637468442284,
    "arrivals": 1703822,
    "finished_requests": 76911,
    "scheduler_time": 138.16370071880775
}
#Debug simulation 
Total elapsed time: 76.53691427828744. Arrivals time: 0.4267102563753724 Scheduler time: 75.97756431018934 Scheduler overhead time: 0.04846976883709431 Adapter cache time: 0.017259853426367044 Engine time: 0.04866118170320988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.3852149778977,
    "estimated_duration": 3600.024429676125,
    "input_throughput": 5300.592641177363,
    "output_throughput": 4681.624897061119,
    "total_throughput": 9982.217538238481,
    "itl": 182.8072280065567,
    "ttft": 2166822.9925364736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7567199650174257,
    "arrivals": 1680953,
    "finished_requests": 76975,
    "scheduler_time": 137.52853378512356
}
#Debug simulation 
Total elapsed time: 72.38534883083776. Arrivals time: 0.4216636046767235 Scheduler time: 71.83485283982009 Scheduler overhead time: 0.047651803120970726 Adapter cache time: 0.016644629649817944 Engine time: 0.04686444811522961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.09404769120738,
    "estimated_duration": 3600.0671743090807,
    "input_throughput": 5302.64466625229,
    "output_throughput": 4682.582902980216,
    "total_throughput": 9985.227569232507,
    "itl": 182.75326553591466,
    "ttft": 2167492.1010987107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8493989522615495,
    "arrivals": 1680953,
    "finished_requests": 77028,
    "scheduler_time": 137.5397555097206
}
#Debug simulation 
Total elapsed time: 73.09417285397649. Arrivals time: 0.4045047676190734 Scheduler time: 72.55924440547824 Scheduler overhead time: 0.04804611625149846 Adapter cache time: 0.016362260561436415 Engine time: 0.04812081530690193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.52752985898405,
    "estimated_duration": 3600.1052450226794,
    "input_throughput": 5285.497979901454,
    "output_throughput": 4666.530797461219,
    "total_throughput": 9952.028777362673,
    "itl": 180.2780886809952,
    "ttft": 2168993.1306822426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8335446371138209,
    "arrivals": 1680953,
    "finished_requests": 76776,
    "scheduler_time": 138.26106859716995
}
#Debug simulation 
Total elapsed time: 71.52765852119774. Arrivals time: 0.407955857925117 Scheduler time: 70.98955196887255 Scheduler overhead time: 0.04828724777325988 Adapter cache time: 0.016665938775986433 Engine time: 0.04726141644641757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.60919919237494,
    "estimated_duration": 3600.0614825951716,
    "input_throughput": 5300.538085878521,
    "output_throughput": 4681.576712365064,
    "total_throughput": 9982.114798243585,
    "itl": 182.80863861870677,
    "ttft": 2166834.4967307425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7935133844590638,
    "arrivals": 1680953,
    "finished_requests": 76975,
    "scheduler_time": 137.52879328465568
}
#Debug simulation 
Total elapsed time: 72.6093344273977. Arrivals time: 0.39420402655377984 Scheduler time: 72.08514304505661 Scheduler overhead time: 0.0471646673977375 Adapter cache time: 0.01711383881047368 Engine time: 0.047557034995406866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 71.6725995359011,
    "estimated_duration": 3600.1291515287544,
    "input_throughput": 5285.462881774623,
    "output_throughput": 4666.499809559907,
    "total_throughput": 9951.96269133453,
    "itl": 180.27912762885563,
    "ttft": 2168999.7877376373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8573121027462223,
    "arrivals": 1680953,
    "finished_requests": 76776,
    "scheduler_time": 138.26120763766
}
#Debug simulation 
Total elapsed time: 71.67273717187345. Arrivals time: 0.393214023206383 Scheduler time: 71.14904313767329 Scheduler overhead time: 0.048000405076891184 Adapter cache time: 0.016311406157910824 Engine time: 0.04739858815446496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.59513517003506,
    "estimated_duration": 3600.1883716500574,
    "input_throughput": 5301.05900854653,
    "output_throughput": 4681.945292844363,
    "total_throughput": 9983.004301390893,
    "itl": 182.8062675303541,
    "ttft": 2166849.6653150385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7162888692738247,
    "arrivals": 1680953,
    "finished_requests": 76983,
    "scheduler_time": 137.53612991478357
}
#Debug simulation 
Total elapsed time: 72.59526826813817. Arrivals time: 0.4117637719027698 Scheduler time: 72.05271520698443 Scheduler overhead time: 0.04807014297693968 Adapter cache time: 0.017172394786030054 Engine time: 0.04744890099391341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 71.58392718527466,
    "estimated_duration": 3600.152568635402,
    "input_throughput": 5285.428502607178,
    "output_throughput": 4666.469456423025,
    "total_throughput": 9951.897959030202,
    "itl": 180.28007901714656,
    "ttft": 2169006.621451561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 561,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8805765532329641,
    "arrivals": 1680953,
    "finished_requests": 76776,
    "scheduler_time": 138.2613602938662
}
#Debug simulation 
Total elapsed time: 71.5840606810525. Arrivals time: 0.4014527122490108 Scheduler time: 71.05121838999912 Scheduler overhead time: 0.048267456237226725 Adapter cache time: 0.016942369285970926 Engine time: 0.04792824713513255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.17078858800232,
    "estimated_duration": 3600.0165683118703,
    "input_throughput": 5308.320013916251,
    "output_throughput": 4685.367880934367,
    "total_throughput": 9993.687894850618,
    "itl": 182.85208810313057,
    "ttft": 2165842.2146201003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6924497223948356,
    "arrivals": 1669342,
    "finished_requests": 77126,
    "scheduler_time": 137.45526814531155
}
#Debug simulation 
Total elapsed time: 73.17091927630827. Arrivals time: 0.42398548498749733 Scheduler time: 72.61908594332635 Scheduler overhead time: 0.046509770676493645 Adapter cache time: 0.016457506455481052 Engine time: 0.04634523997083306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.8295862749219,
    "estimated_duration": 3600.0903113074182,
    "input_throughput": 5307.5268528641,
    "output_throughput": 4684.354708278302,
    "total_throughput": 9991.881561142402,
    "itl": 182.86956682262587,
    "ttft": 2165953.6690835413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8052165592880967,
    "arrivals": 1669342,
    "finished_requests": 77110,
    "scheduler_time": 137.45486083980308
}
#Debug simulation 
Total elapsed time: 72.82971735764295. Arrivals time: 0.40685674315318465 Scheduler time: 72.29458739701658 Scheduler overhead time: 0.04759254585951567 Adapter cache time: 0.016536906827241182 Engine time: 0.046663966961205006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.54871042538434,
    "estimated_duration": 3600.136811887661,
    "input_throughput": 5288.717344610216,
    "output_throughput": 4671.243866196928,
    "total_throughput": 9959.961210807143,
    "itl": 180.76152175661042,
    "ttft": 2167006.722397003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8349019184894972,
    "arrivals": 1669342,
    "finished_requests": 76881,
    "scheduler_time": 138.11946996826924
}
#Debug simulation 
Total elapsed time: 72.54884847719222. Arrivals time: 0.4188299593515694 Scheduler time: 72.00073047960177 Scheduler overhead time: 0.04750425601378083 Adapter cache time: 0.017046367283910513 Engine time: 0.04683450795710087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.79165958520025,
    "estimated_duration": 3600.016426480361,
    "input_throughput": 5307.6357817291855,
    "output_throughput": 4684.450847488931,
    "total_throughput": 9992.086629218116,
    "itl": 182.86633979811984,
    "ttft": 2165934.717475933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 554,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7316694019688201,
    "arrivals": 1669342,
    "finished_requests": 77110,
    "scheduler_time": 137.45452317004154
}
#Debug simulation 
Total elapsed time: 72.79179016919807. Arrivals time: 0.41023161076009274 Scheduler time: 72.25313169090077 Scheduler overhead time: 0.04688987601548433 Adapter cache time: 0.01677617710083723 Engine time: 0.04688400588929653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 74.66122057288885,
    "estimated_duration": 3600.1596743996242,
    "input_throughput": 5288.683759054436,
    "output_throughput": 4671.214201854667,
    "total_throughput": 9959.897960909104,
    "itl": 180.7625030235154,
    "ttft": 2167012.67607557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.85766335383058,
    "arrivals": 1669342,
    "finished_requests": 76881,
    "scheduler_time": 138.11957104493885
}
#Debug simulation 
Total elapsed time: 74.6613520309329. Arrivals time: 0.5297606186941266 Scheduler time: 74.00336294807494 Scheduler overhead time: 0.04646993149071932 Adapter cache time: 0.01659968262538314 Engine time: 0.04696998372673988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.87533495295793,
    "estimated_duration": 3600.187974538551,
    "input_throughput": 5308.28921577338,
    "output_throughput": 4685.307578186117,
    "total_throughput": 9993.596793959498,
    "itl": 182.8498815628716,
    "ttft": 2165894.736982738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 555,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6594779136706854,
    "arrivals": 1669342,
    "finished_requests": 77129,
    "scheduler_time": 137.46286924070336
}
#Debug simulation 
Total elapsed time: 72.87546518212184. Arrivals time: 0.41349825030192733 Scheduler time: 72.33323514088988 Scheduler overhead time: 0.047061117365956306 Adapter cache time: 0.0168187296949327 Engine time: 0.0467813634313643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.00824778107926,
    "estimated_duration": 3600.1834623602344,
    "input_throughput": 5288.6488144461255,
    "output_throughput": 4671.1833371333005,
    "total_throughput": 9959.832151579425,
    "itl": 180.7634980016882,
    "ttft": 2167019.105641113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8813050656765666,
    "arrivals": 1669342,
    "finished_requests": 76881,
    "scheduler_time": 138.1197172937492
}
#Debug simulation 
Total elapsed time: 72.00837341928855. Arrivals time: 0.40065800910815597 Scheduler time: 71.47885261895135 Scheduler overhead time: 0.0472904397174716 Adapter cache time: 0.01658114278689027 Engine time: 0.04705663165077567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.38235550699756,
    "estimated_duration": 3600.161470458026,
    "input_throughput": 5302.7235463333855,
    "output_throughput": 4687.451420853361,
    "total_throughput": 9990.174967186747,
    "itl": 182.86924484982126,
    "ttft": 2164883.119723442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5026994822709983,
    "arrivals": 1663594,
    "finished_requests": 77457,
    "scheduler_time": 137.37026378682302
}
#Debug simulation 
Total elapsed time: 73.38248856086284. Arrivals time: 0.40886355051770806 Scheduler time: 72.84542728634551 Scheduler overhead time: 0.04774853168055415 Adapter cache time: 0.015556553844362497 Engine time: 0.04683590168133378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 73.08181842183694,
    "estimated_duration": 3600.161037610262,
    "input_throughput": 5301.871722013325,
    "output_throughput": 4685.517070980013,
    "total_throughput": 9987.388792993339,
    "itl": 182.88002292450875,
    "ttft": 2164822.5666002394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.651479262171784,
    "arrivals": 1663594,
    "finished_requests": 77435,
    "scheduler_time": 137.36158766191983
}
#Debug simulation 
Total elapsed time: 73.08194584725425. Arrivals time: 0.5211655264720321 Scheduler time: 72.43287882069126 Scheduler overhead time: 0.047504646703600883 Adapter cache time: 0.015193196013569832 Engine time: 0.0471477834507823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.0094127622433,
    "estimated_duration": 3600.145017817753,
    "input_throughput": 5289.919685386427,
    "output_throughput": 4673.67645378883,
    "total_throughput": 9963.596139175257,
    "itl": 181.31349365777558,
    "ttft": 2165452.9250087035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6628034996800225,
    "arrivals": 1663594,
    "finished_requests": 77257,
    "scheduler_time": 137.81936558733355
}
#Debug simulation 
Total elapsed time: 72.00953620439395. Arrivals time: 0.40550327813252807 Scheduler time: 71.47661115974188 Scheduler overhead time: 0.04728752700611949 Adapter cache time: 0.015317210461944342 Engine time: 0.04672308498993516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 72.97274364717305,
    "estimated_duration": 3600.0020453120924,
    "input_throughput": 5301.045043807908,
    "output_throughput": 4685.312893631356,
    "total_throughput": 9986.357937439265,
    "itl": 182.88732261655863,
    "ttft": 2164945.237977825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5768551480839887,
    "arrivals": 1663594,
    "finished_requests": 77430,
    "scheduler_time": 137.35326135510638
}
#Debug simulation 
Total elapsed time: 72.97287419205531. Arrivals time: 0.40670422185212374 Scheduler time: 72.43730267789215 Scheduler overhead time: 0.04865637607872486 Adapter cache time: 0.015302693471312523 Engine time: 0.04710683226585388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 72.1209097490646,
    "estimated_duration": 3600.165778717139,
    "input_throughput": 5289.88918026608,
    "output_throughput": 4673.649502328097,
    "total_throughput": 9963.538682594177,
    "itl": 181.31438723857377,
    "ttft": 2165459.2026098133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6834271206520535,
    "arrivals": 1663594,
    "finished_requests": 77257,
    "scheduler_time": 137.81950286578973
}
#Debug simulation 
Total elapsed time: 72.1210375376977. Arrivals time: 0.4041996211744845 Scheduler time: 71.58789563458413 Scheduler overhead time: 0.04806166933849454 Adapter cache time: 0.01608096295967698 Engine time: 0.04691932676360011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 73.58959638467059,
    "estimated_duration": 3600.1266702219414,
    "input_throughput": 5302.7748045385015,
    "output_throughput": 4687.49673159685,
    "total_throughput": 9990.271536135351,
    "itl": 182.86773049817194,
    "ttft": 2164872.526007226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.468114694796953,
    "arrivals": 1663594,
    "finished_requests": 77457,
    "scheduler_time": 137.37004833813742
}
#Debug simulation 
Total elapsed time: 73.58972505293787. Arrivals time: 0.41809363663196564 Scheduler time: 73.04310190118849 Scheduler overhead time: 0.04738750122487545 Adapter cache time: 0.015147052705287933 Engine time: 0.04768218845129013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_96_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 72.03024030802771,
    "estimated_duration": 3600.1877116070127,
    "input_throughput": 5289.856953458444,
    "output_throughput": 4673.621029746094,
    "total_throughput": 9963.477983204539,
    "itl": 181.31528720026634,
    "ttft": 2165466.4877084475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.705182525701819,
    "arrivals": 1663594,
    "finished_requests": 77257,
    "scheduler_time": 137.8196803506549
}
#Debug simulation 
Total elapsed time: 72.03036626894027. Arrivals time: 0.39879267243668437 Scheduler time: 71.50084023131058 Scheduler overhead time: 0.05030658841133118 Adapter cache time: 0.015687033534049988 Engine time: 0.04689467092975974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_96_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 72.01493049319834,
    "estimated_duration": 3600.042618319819,
    "input_throughput": 5308.63354304385,
    "output_throughput": 4684.340933683318,
    "total_throughput": 9992.974476727168,
    "itl": 182.80682396182993,
    "ttft": 2169077.166285666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 492,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5057599700149311,
    "arrivals": 1660646,
    "finished_requests": 77292,
    "scheduler_time": 137.41238182326268
}
#Debug simulation 
Total elapsed time: 72.01506334217265. Arrivals time: 0.40999750699847937 Scheduler time: 71.47826571436599 Scheduler overhead time: 0.04723039036616683 Adapter cache time: 0.015320323873311281 Engine time: 0.046275828033685684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_96_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 69.90011660661548,
    "estimated_duration": 3600.044221090935,
    "input_throughput": 5302.8601393721,
    "output_throughput": 4681.293052253956,
    "total_throughput": 9984.153191626057,
    "itl": 182.5903620924971,
    "ttft": 2168735.049374226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6106955148116737,
    "arrivals": 1660646,
    "finished_requests": 77260,
    "scheduler_time": 137.54497707136449
}
#Debug simulation 
Total elapsed time: 69.9002504949458. Arrivals time: 0.39129450218752027 Scheduler time: 69.38138758111745 Scheduler overhead time: 0.047117387410253286 Adapter cache time: 0.01596834883093834 Engine time: 0.04645784664899111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_96_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 68.59179918887094,
    "estimated_duration": 3600.0210410629056,
    "input_throughput": 5289.525750765538,
    "output_throughput": 4669.68631801012,
    "total_throughput": 9959.212068775658,
    "itl": 180.75361416461678,
    "ttft": 2170032.255584679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6557047194987635,
    "arrivals": 1660646,
    "finished_requests": 77054,
    "scheduler_time": 138.07258281701945
}
#Debug simulation 
Total elapsed time: 68.59192829858512. Arrivals time: 0.4042396708391607 Scheduler time: 68.06087782699615 Scheduler overhead time: 0.04652715381234884 Adapter cache time: 0.015844897367060184 Engine time: 0.04645984619855881 
