INFO 06-01 00:47:19 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 12.790632290765643,
    "estimated_duration": 3600.104837194989,
    "input_throughput": 4456.728546966752,
    "output_throughput": 3926.6100958921475,
    "total_throughput": 8383.3386428589,
    "itl": 178.1921031788812,
    "ttft": 2250912.9872707515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.096532327234697,
    "arrivals": 2222461,
    "finished_requests": 64780,
    "scheduler_time": 117.89874600212013
}
#Debug simulation 
Total elapsed time: 12.790752707980573. Arrivals time: 0.3008036841638386 Scheduler time: 12.367759951855987 Scheduler overhead time: 0.03626334061846137 Adapter cache time: 0.034974838607013226 Engine time: 0.035527986008673906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.47882555006072,
    "estimated_duration": 3600.1813149901013,
    "input_throughput": 4638.196118199095,
    "output_throughput": 4074.239799791953,
    "total_throughput": 8712.435917991048,
    "itl": 209.6735914086855,
    "ttft": 2233918.9183308184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8196174280926884,
    "arrivals": 2222461,
    "finished_requests": 67404,
    "scheduler_time": 111.02392498116362
}
#Debug simulation 
Total elapsed time: 25.478959061205387. Arrivals time: 0.33486721105873585 Scheduler time: 25.028818061109632 Scheduler overhead time: 0.03865717351436615 Adapter cache time: 0.023887216113507748 Engine time: 0.03792581148445606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 17280, 270, 34560, 34560, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 17280, 270, 270, 270, 17280, 270, 17280, 270, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 17280, 17280, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 17280, 270, 34560, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 34560, 270, 34560, 17280, 17280, 34560, 34560, 270, 17280, 34560, 270, 17280, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 34560, 270, 34560, 17280, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 34560, 270, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 270, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 270, 270, 270, 270, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 34560, 270, 270, 270, 17280, 270, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 34560, 270, 17280, 17280, 270, 270, 17280, 270, 34560, 34560, 270, 34560, 34560, 270, 17280, 34560, 270, 270, 17280, 17280, 270, 270, 34560, 34560, 34560, 34560, 17280, 270, 17280, 17280, 270, 270, 270, 270, 270, 270, 270, 270, 17280, 34560, 17280, 17280, 17280, 34560, 270, 17280, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 17280, 270, 34560, 34560, 34560, 17280, 270, 34560, 34560, 17280, 17280, 34560, 34560, 270, 34560, 34560, 17280, 270, 34560, 17280, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 17280, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 34560, 270, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 34560, 34560, 270, 34560, 34560, 270, 34560, 17280, 34560, 17280, 17280, 17280, 270, 17280, 270, 270, 34560, 270, 17280, 270, 270, 17280, 34560, 17280, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 6670080 . Total input tokens: 1485588020 . Total output tokens: 1333718023
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.920210822951049,
    "estimated_duration": 3600.171643556608,
    "input_throughput": 4456.645845960127,
    "output_throughput": 3926.537231995652,
    "total_throughput": 8383.183077955779,
    "itl": 178.19522063512395,
    "ttft": 2250938.7633359795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.163181834034568,
    "arrivals": 2222461,
    "finished_requests": 64780,
    "scheduler_time": 117.89890285699123
}
#Debug simulation 
Total elapsed time: 12.920279361773282. Arrivals time: 0.44747521402314305 Scheduler time: 12.350583120249212 Scheduler overhead time: 0.03603250067681074 Adapter cache time: 0.03486796794459224 Engine time: 0.03601543139666319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 30.12796683004126,
    "estimated_duration": 3600.139483722598,
    "input_throughput": 4684.878482141497,
    "output_throughput": 4103.883493070355,
    "total_throughput": 8788.761975211853,
    "itl": 208.10277393473297,
    "ttft": 2240594.60970066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3014867834374746,
    "arrivals": 2216625,
    "finished_requests": 67913,
    "scheduler_time": 111.85459800894496
}
#Debug simulation 
Total elapsed time: 30.12810563482344. Arrivals time: 0.8484194581396878 Scheduler time: 29.164614303503186 Scheduler overhead time: 0.0396233438514173 Adapter cache time: 0.0215917881578207 Engine time: 0.03897835547104478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 29.894549978896976,
    "estimated_duration": 3600.077886183558,
    "input_throughput": 4684.756422833702,
    "output_throughput": 4103.673716809897,
    "total_throughput": 8788.4301396436,
    "itl": 208.11017253649177,
    "ttft": 2240619.7147518233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.456084243534139,
    "arrivals": 2216625,
    "finished_requests": 67909,
    "scheduler_time": 111.84816962012697
}
#Debug simulation 
Total elapsed time: 29.894655565731227. Arrivals time: 0.5121672358363867 Scheduler time: 29.26641353685409 Scheduler overhead time: 0.03967319009825587 Adapter cache time: 0.021892009302973747 Engine time: 0.039621695410460234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.590741725172848,
    "estimated_duration": 3600.025105130035,
    "input_throughput": 4400.871809872485,
    "output_throughput": 3860.824464861046,
    "total_throughput": 8261.696274733531,
    "itl": 170.6220440667234,
    "ttft": 2262442.669256095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.231710419151868,
    "arrivals": 2216625,
    "finished_requests": 63755,
    "scheduler_time": 119.58346768090628
}
#Debug simulation 
Total elapsed time: 12.590838975273073. Arrivals time: 0.45271582528948784 Scheduler time: 12.017193121369928 Scheduler overhead time: 0.03728831512853503 Adapter cache time: 0.03075207443907857 Engine time: 0.03700257372111082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 30.167000245768577,
    "estimated_duration": 3600.191368225374,
    "input_throughput": 4684.810965566474,
    "output_throughput": 4103.824349560272,
    "total_throughput": 8788.635315126747,
    "itl": 208.10533128699143,
    "ttft": 2240614.480766011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.353118223287147,
    "arrivals": 2216625,
    "finished_requests": 67913,
    "scheduler_time": 111.85485107181256
}
#Debug simulation 
Total elapsed time: 30.167145703919232. Arrivals time: 0.8619453618302941 Scheduler time: 29.190149520523846 Scheduler overhead time: 0.039859453681856394 Adapter cache time: 0.020937197841703892 Engine time: 0.03932546777650714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 12.568110824096948,
    "estimated_duration": 3600.080968155578,
    "input_throughput": 4400.803520848849,
    "output_throughput": 3860.7645558374425,
    "total_throughput": 8261.568076686292,
    "itl": 170.62451364617704,
    "ttft": 2262464.6029962855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.287419346533701,
    "arrivals": 2216625,
    "finished_requests": 63755,
    "scheduler_time": 119.58362177910126
}
#Debug simulation 
Total elapsed time: 12.568218009080738. Arrivals time: 0.4594332189299166 Scheduler time: 11.987623821012676 Scheduler overhead time: 0.03715189918875694 Adapter cache time: 0.030971219297498465 Engine time: 0.03706676559522748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 29.8460224987939,
    "estimated_duration": 3600.086279754371,
    "input_throughput": 4684.947717739354,
    "output_throughput": 4103.9441424187335,
    "total_throughput": 8788.891860158086,
    "itl": 208.10012874613065,
    "ttft": 2240573.4087559185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 752,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2485178217663933,
    "arrivals": 2216625,
    "finished_requests": 67913,
    "scheduler_time": 111.85436300230594
}
#Debug simulation 
Total elapsed time: 29.846183977089822. Arrivals time: 0.3510921336710453 Scheduler time: 29.377088213339448 Scheduler overhead time: 0.03995214682072401 Adapter cache time: 0.022025854792445898 Engine time: 0.04105511773377657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 17280, 135, 34560, 34560, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 17280, 135, 135, 135, 17280, 135, 17280, 135, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 17280, 17280, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 17280, 135, 34560, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 34560, 135, 34560, 17280, 17280, 34560, 34560, 135, 17280, 34560, 135, 17280, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 34560, 135, 34560, 17280, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 34560, 135, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 135, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 135, 135, 135, 135, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 34560, 135, 135, 135, 17280, 135, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 34560, 135, 17280, 17280, 135, 135, 17280, 135, 34560, 34560, 135, 34560, 34560, 135, 17280, 34560, 135, 135, 17280, 17280, 135, 135, 34560, 34560, 34560, 34560, 17280, 135, 17280, 17280, 135, 135, 135, 135, 135, 135, 135, 135, 17280, 34560, 17280, 17280, 17280, 34560, 135, 17280, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 17280, 135, 34560, 34560, 34560, 17280, 135, 34560, 34560, 17280, 17280, 34560, 34560, 135, 34560, 34560, 17280, 135, 34560, 17280, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 17280, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 34560, 135, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 34560, 34560, 135, 34560, 34560, 135, 34560, 17280, 34560, 17280, 17280, 17280, 135, 17280, 135, 135, 34560, 135, 17280, 135, 135, 17280, 34560, 17280, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 6652800 . Total input tokens: 1481717448 . Total output tokens: 1330287339
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.984944705851376,
    "estimated_duration": 3600.135952558624,
    "input_throughput": 4400.736307955307,
    "output_throughput": 3860.705590888007,
    "total_throughput": 8261.441898843314,
    "itl": 170.62692951401993,
    "ttft": 2262485.807244195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.342247997410623,
    "arrivals": 2216625,
    "finished_requests": 63755,
    "scheduler_time": 119.5837775313019
}
#Debug simulation 
Total elapsed time: 12.98505165381357. Arrivals time: 0.830203652381897 Scheduler time: 12.033100173342973 Scheduler overhead time: 0.03701544366776943 Adapter cache time: 0.03115531988441944 Engine time: 0.03761211270466447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.36916617816314,
    "estimated_duration": 3600.0155443986105,
    "input_throughput": 4660.5068208956245,
    "output_throughput": 4126.738570091862,
    "total_throughput": 8787.245390987488,
    "itl": 208.40328551914294,
    "ttft": 2232759.659364001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.224974589839153,
    "arrivals": 2213766,
    "finished_requests": 67925,
    "scheduler_time": 112.1957326473897
}
#Debug simulation 
Total elapsed time: 25.369319557212293. Arrivals time: 0.3599025006406009 Scheduler time: 24.896458209957927 Scheduler overhead time: 0.03922888729721308 Adapter cache time: 0.02054066676646471 Engine time: 0.03841298073530197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 25.776871828828007,
    "estimated_duration": 3600.008474665939,
    "input_throughput": 4663.9423540684975,
    "output_throughput": 4132.83804877171,
    "total_throughput": 8796.780402840208,
    "itl": 208.19612400821998,
    "ttft": 2234455.362202478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3379488377040305,
    "arrivals": 2213766,
    "finished_requests": 68034,
    "scheduler_time": 112.30080671657977
}
#Debug simulation 
Total elapsed time: 25.777009192854166. Arrivals time: 0.3581500081345439 Scheduler time: 25.304428377654403 Scheduler overhead time: 0.03927280008792877 Adapter cache time: 0.02165289269760251 Engine time: 0.038500606548041105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.448395241051912,
    "estimated_duration": 3600.1442412356905,
    "input_throughput": 4460.900709491491,
    "output_throughput": 3953.9962974133737,
    "total_throughput": 8414.897006904865,
    "itl": 177.44747466621823,
    "ttft": 2253537.627798275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.398404586650375,
    "arrivals": 2213766,
    "finished_requests": 65120,
    "scheduler_time": 118.60692667390182
}
#Debug simulation 
Total elapsed time: 13.448537490796298. Arrivals time: 0.8120487285777926 Scheduler time: 12.513804204761982 Scheduler overhead time: 0.03654839051887393 Adapter cache time: 0.0336017687804997 Engine time: 0.036925353575497866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 25.896296264138073,
    "estimated_duration": 3600.1347497011684,
    "input_throughput": 4663.889039540455,
    "output_throughput": 4132.773641662997,
    "total_throughput": 8796.662681203452,
    "itl": 208.19171564554557,
    "ttft": 2234526.0682375296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2398859612783237,
    "arrivals": 2213766,
    "finished_requests": 68036,
    "scheduler_time": 112.30742150146659
}
#Debug simulation 
Total elapsed time: 25.89643932506442. Arrivals time: 0.36854691430926323 Scheduler time: 25.413059981074184 Scheduler overhead time: 0.03919674176722765 Adapter cache time: 0.021879246924072504 Engine time: 0.03865639492869377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 12.905215251725167,
    "estimated_duration": 3600.1995740928196,
    "input_throughput": 4460.832148186335,
    "output_throughput": 3953.935526917819,
    "total_throughput": 8414.767675104154,
    "itl": 177.45000328755503,
    "ttft": 2253558.596641132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.453610498886534,
    "arrivals": 2213766,
    "finished_requests": 65120,
    "scheduler_time": 118.60705361883704
}
#Debug simulation 
Total elapsed time: 12.905288255773485. Arrivals time: 0.32132662925869226 Scheduler time: 12.461556505411863 Scheduler overhead time: 0.03645331459119916 Adapter cache time: 0.033852833323180676 Engine time: 0.036549792625010014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.92235421668738,
    "estimated_duration": 3600.1962909295366,
    "input_throughput": 4660.461720454673,
    "output_throughput": 4126.840816272257,
    "total_throughput": 8787.30253672693,
    "itl": 208.40199755602436,
    "ttft": 2232758.77333077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 727,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1737665643938415,
    "arrivals": 2213766,
    "finished_requests": 67929,
    "scheduler_time": 112.20268693495241
}
#Debug simulation 
Total elapsed time: 25.92245036875829. Arrivals time: 0.8572028554044664 Scheduler time: 24.952041329350322 Scheduler overhead time: 0.038883053697645664 Adapter cache time: 0.021034068893641233 Engine time: 0.03818275686353445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 17280, 66, 34560, 34560, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 17280, 66, 66, 66, 17280, 66, 17280, 66, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 17280, 17280, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 17280, 66, 34560, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 34560, 66, 34560, 17280, 17280, 34560, 34560, 66, 17280, 34560, 66, 17280, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 34560, 66, 34560, 17280, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 34560, 66, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 66, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 66, 66, 66, 66, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 34560, 66, 66, 66, 17280, 66, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 34560, 66, 17280, 17280, 66, 66, 17280, 66, 34560, 34560, 66, 34560, 34560, 66, 17280, 34560, 66, 66, 17280, 17280, 66, 66, 34560, 34560, 34560, 34560, 17280, 66, 17280, 17280, 66, 66, 66, 66, 66, 66, 66, 66, 17280, 34560, 17280, 17280, 17280, 34560, 66, 17280, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 17280, 66, 34560, 34560, 34560, 17280, 66, 34560, 34560, 17280, 17280, 34560, 34560, 66, 34560, 34560, 17280, 66, 34560, 17280, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 17280, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 34560, 66, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 34560, 34560, 66, 34560, 34560, 66, 34560, 17280, 34560, 17280, 17280, 17280, 66, 17280, 66, 66, 34560, 66, 17280, 66, 66, 17280, 34560, 17280, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 6643968 . Total input tokens: 1479776568 . Total output tokens: 1328527229
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.89705127896741,
    "estimated_duration": 3600.0553218859627,
    "input_throughput": 4460.441177772727,
    "output_throughput": 3953.647299104162,
    "total_throughput": 8414.08847687689,
    "itl": 177.45317469748147,
    "ttft": 2253474.781394657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.512086009569478,
    "arrivals": 2213766,
    "finished_requests": 65112,
    "scheduler_time": 118.60060060961901
}
#Debug simulation 
Total elapsed time: 12.897138108033687. Arrivals time: 0.30348349129781127 Scheduler time: 12.472135883755982 Scheduler overhead time: 0.036147310864180326 Adapter cache time: 0.03357726288959384 Engine time: 0.03633881779387593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.811149314045906,
    "estimated_duration": 3600.1021104162623,
    "input_throughput": 4700.28529219785,
    "output_throughput": 4165.816840752311,
    "total_throughput": 8866.102132950162,
    "itl": 206.1022573591505,
    "ttft": 2226082.1546337255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.09337361685004,
    "arrivals": 2212338,
    "finished_requests": 69099,
    "scheduler_time": 113.26469629740444
}
#Debug simulation 
Total elapsed time: 25.81124770687893. Arrivals time: 0.3461728501133621 Scheduler time: 25.351049466524273 Scheduler overhead time: 0.03877328848466277 Adapter cache time: 0.02105185855180025 Engine time: 0.039250573609024286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 25.830251683015376,
    "estimated_duration": 3600.089040547876,
    "input_throughput": 4713.0170417723475,
    "output_throughput": 4176.71363975811,
    "total_throughput": 8889.730681530458,
    "itl": 205.67923953027693,
    "ttft": 2226551.601233835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.242526994398801,
    "arrivals": 2212338,
    "finished_requests": 69269,
    "scheduler_time": 113.50541484731141
}
#Debug simulation 
Total elapsed time: 25.830353730823845. Arrivals time: 0.3494154796935618 Scheduler time: 25.36641803244129 Scheduler overhead time: 0.03969346405938268 Adapter cache time: 0.020809313748031855 Engine time: 0.03899048501625657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.02951195370406,
    "estimated_duration": 3600.2030136450285,
    "input_throughput": 4478.735209899978,
    "output_throughput": 3972.6054185815874,
    "total_throughput": 8451.340628481565,
    "itl": 177.332869349577,
    "ttft": 2248996.1529911226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.625952548328728,
    "arrivals": 2212338,
    "finished_requests": 65739,
    "scheduler_time": 118.83574405662415
}
#Debug simulation 
Total elapsed time: 12.029583845753223. Arrivals time: 0.30819217627868056 Scheduler time: 11.59994352888316 Scheduler overhead time: 0.036042011342942715 Adapter cache time: 0.03349834168329835 Engine time: 0.03645508037880063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 25.85021197097376,
    "estimated_duration": 3600.1518798952957,
    "input_throughput": 4700.220314175227,
    "output_throughput": 4165.759251366965,
    "total_throughput": 8865.979565542191,
    "itl": 206.10457759819428,
    "ttft": 2226103.5340975556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.142848682820316,
    "arrivals": 2212338,
    "finished_requests": 69099,
    "scheduler_time": 113.26499071041381
}
#Debug simulation 
Total elapsed time: 25.850363843608648. Arrivals time: 0.3507093111984432 Scheduler time: 25.38586866343394 Scheduler overhead time: 0.03937393380329013 Adapter cache time: 0.020250827074050903 Engine time: 0.03904991550371051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.97237349813804,
    "estimated_duration": 3600.0575544838202,
    "input_throughput": 4478.84172849339,
    "output_throughput": 3972.645376790538,
    "total_throughput": 8451.487105283928,
    "itl": 177.33498955510885,
    "ttft": 2248947.7411860568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.683422028720346,
    "arrivals": 2212338,
    "finished_requests": 65737,
    "scheduler_time": 118.82928162707967
}
#Debug simulation 
Total elapsed time: 11.97249315911904. Arrivals time: 0.3002815879881382 Scheduler time: 11.549746949225664 Scheduler overhead time: 0.0357594839297235 Adapter cache time: 0.034590286668390036 Engine time: 0.03663960285484791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.974982334300876,
    "estimated_duration": 3600.053683376018,
    "input_throughput": 4700.348519284174,
    "output_throughput": 4165.872878299953,
    "total_throughput": 8866.221397584126,
    "itl": 206.09992771675005,
    "ttft": 2226061.8715243223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0451944017130526,
    "arrivals": 2212338,
    "finished_requests": 69099,
    "scheduler_time": 113.26444847222147
}
#Debug simulation 
Total elapsed time: 25.975116924382746. Arrivals time: 0.36999102961272 Scheduler time: 25.491589822340757 Scheduler overhead time: 0.03906030999496579 Adapter cache time: 0.020816379226744175 Engine time: 0.03873930033296347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 17280, 33, 34560, 34560, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 34560, 34560, 17280, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 17280, 33, 33, 33, 17280, 33, 17280, 33, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 17280, 17280, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 17280, 33, 34560, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 34560, 33, 34560, 17280, 17280, 34560, 34560, 33, 17280, 34560, 33, 17280, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 34560, 33, 34560, 17280, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 34560, 33, 17280, 34560, 17280, 34560, 17280, 34560, 17280, 34560, 33, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 17280, 34560, 33, 33, 33, 33, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 34560, 33, 33, 33, 17280, 33, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 34560, 33, 17280, 17280, 33, 33, 17280, 33, 34560, 34560, 33, 34560, 34560, 33, 17280, 34560, 33, 33, 17280, 17280, 33, 33, 34560, 34560, 34560, 34560, 17280, 33, 17280, 17280, 33, 33, 33, 33, 33, 33, 33, 33, 17280, 34560, 17280, 17280, 17280, 34560, 33, 17280, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 17280, 33, 34560, 34560, 34560, 17280, 33, 34560, 34560, 17280, 17280, 34560, 34560, 33, 34560, 34560, 17280, 33, 34560, 17280, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 17280, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 34560, 33, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 34560, 34560, 33, 34560, 34560, 33, 34560, 17280, 34560, 17280, 17280, 17280, 33, 17280, 33, 33, 34560, 33, 17280, 33, 33, 17280, 34560, 17280, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 6639744 . Total input tokens: 1478838354 . Total output tokens: 1327688405
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.10208530491218,
    "estimated_duration": 3600.119335242501,
    "input_throughput": 4478.764868196763,
    "output_throughput": 3972.5772032044724,
    "total_throughput": 8451.342071401235,
    "itl": 177.33782495482907,
    "ttft": 2248971.255562185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.745041384063649,
    "arrivals": 2212338,
    "finished_requests": 65737,
    "scheduler_time": 118.82944303046635
}
#Debug simulation 
Total elapsed time: 12.102178384084255. Arrivals time: 0.32799310563132167 Scheduler time: 11.652338948100805 Scheduler overhead time: 0.03589670918881893 Adapter cache time: 0.034193444065749645 Engine time: 0.036291060503572226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 31.129078121855855,
    "estimated_duration": 3600.1476691314097,
    "input_throughput": 4597.2969780967815,
    "output_throughput": 4080.3892923492735,
    "total_throughput": 8677.686270446055,
    "itl": 210.68186813060086,
    "ttft": 2234413.678448696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.886039942528651,
    "arrivals": 2026382,
    "finished_requests": 67279,
    "scheduler_time": 110.93481464574968
}
#Debug simulation 
Total elapsed time: 31.12921990500763. Arrivals time: 0.3911096411757171 Scheduler time: 30.61291837086901 Scheduler overhead time: 0.04136249562725425 Adapter cache time: 0.0276067485101521 Engine time: 0.040673666168004274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 29.34233405208215,
    "estimated_duration": 3600.0874986339577,
    "input_throughput": 4593.7880693942325,
    "output_throughput": 4080.109443332586,
    "total_throughput": 8673.897512726819,
    "itl": 210.81658443853954,
    "ttft": 2234599.02457727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1006,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.284201031937269,
    "arrivals": 2026382,
    "finished_requests": 67315,
    "scheduler_time": 110.87135410894578
}
#Debug simulation 
Total elapsed time: 29.34247389389202. Arrivals time: 0.3891287622973323 Scheduler time: 28.824409754946828 Scheduler overhead time: 0.041892629116773605 Adapter cache time: 0.029832078143954277 Engine time: 0.041665418073534966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.336818878073245,
    "estimated_duration": 3600.1896086004162,
    "input_throughput": 4394.853527214908,
    "output_throughput": 3901.199249741753,
    "total_throughput": 8296.052776956662,
    "itl": 178.64950951311795,
    "ttft": 2258598.3184242793,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.436399350818194,
    "arrivals": 2026382,
    "finished_requests": 64296,
    "scheduler_time": 117.33494721717764
}
#Debug simulation 
Total elapsed time: 15.336917749140412. Arrivals time: 0.3334897025488317 Scheduler time: 14.869318640325218 Scheduler overhead time: 0.03850704664364457 Adapter cache time: 0.041421407368034124 Engine time: 0.03819127520546317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 29.377285281196237,
    "estimated_duration": 3600.1839500128417,
    "input_throughput": 4593.998870513548,
    "output_throughput": 4080.548439739475,
    "total_throughput": 8674.547310253023,
    "itl": 210.81068033374163,
    "ttft": 2234569.6710095345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1006,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1444614330306306,
    "arrivals": 2026382,
    "finished_requests": 67319,
    "scheduler_time": 110.8781402320313
}
#Debug simulation 
Total elapsed time: 29.377388208173215. Arrivals time: 0.3827525661326945 Scheduler time: 28.86749075865373 Scheduler overhead time: 0.04187261685729027 Adapter cache time: 0.028661475516855717 Engine time: 0.04131002863869071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 15.3696229592897,
    "estimated_duration": 3600.0624853160957,
    "input_throughput": 4394.847607377239,
    "output_throughput": 3901.194231290363,
    "total_throughput": 8296.041838667603,
    "itl": 178.6522978752873,
    "ttft": 2258552.27829787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.506695717424077,
    "arrivals": 2026382,
    "finished_requests": 64294,
    "scheduler_time": 117.32863167370692
}
#Debug simulation 
Total elapsed time: 15.369696171022952. Arrivals time: 0.3263660757802427 Scheduler time: 14.908307016361505 Scheduler overhead time: 0.038793365471065044 Adapter cache time: 0.04179815808311105 Engine time: 0.0384173858910799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 31.114050099626184,
    "estimated_duration": 3600.0810038917807,
    "input_throughput": 4597.382109488091,
    "output_throughput": 4080.4648517963137,
    "total_throughput": 8677.846961284406,
    "itl": 210.67839605666478,
    "ttft": 2234390.1483103326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8196174280926884,
    "arrivals": 2026382,
    "finished_requests": 67279,
    "scheduler_time": 110.93457192041753
}
#Debug simulation 
Total elapsed time: 31.11411948176101. Arrivals time: 0.37035520700737834 Scheduler time: 30.619282245170325 Scheduler overhead time: 0.041519413236528635 Adapter cache time: 0.027514036744832993 Engine time: 0.04037503572180867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 34560, 8640, 4320, 34560, 34560, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 8640, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 4320, 34560, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 34560, 4320, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 34560, 4320, 8640, 34560, 4320, 4320, 8640, 8640, 4320, 4320, 34560, 34560, 34560, 34560, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 34560, 4320, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 34560, 34560, 8640, 4320, 34560, 34560, 8640, 8640, 34560, 34560, 4320, 34560, 34560, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 34560, 4320, 8640, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 34560, 8640, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6082560 . Total input tokens: 1354711576 . Total output tokens: 1216423649
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.354391662869602,
    "estimated_duration": 3600.1310445120266,
    "input_throughput": 4394.763913974283,
    "output_throughput": 3901.11993878924,
    "total_throughput": 8295.883852763523,
    "itl": 178.655494110516,
    "ttft": 2258576.5713273836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.575105777233744,
    "arrivals": 2026382,
    "finished_requests": 64294,
    "scheduler_time": 117.32878080988489
}
#Debug simulation 
Total elapsed time: 15.354464432690293. Arrivals time: 0.3140824749134481 Scheduler time: 14.907012812793255 Scheduler overhead time: 0.038210388738662004 Adapter cache time: 0.04106806963682175 Engine time: 0.038139240350574255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 33.484233601018786,
    "estimated_duration": 3600.1825035735587,
    "input_throughput": 4632.482654266985,
    "output_throughput": 4088.9813184158816,
    "total_throughput": 8721.463972682866,
    "itl": 209.83730969442226,
    "ttft": 2228137.6609143824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7177131166123436,
    "arrivals": 1888011,
    "finished_requests": 67401,
    "scheduler_time": 111.20583510750255
}
#Debug simulation 
Total elapsed time: 33.484357841312885. Arrivals time: 0.3604678111150861 Scheduler time: 32.997847157064825 Scheduler overhead time: 0.04303696472197771 Adapter cache time: 0.025694500654935837 Engine time: 0.041709036100655794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 34.37466888176277,
    "estimated_duration": 3600.141512219938,
    "input_throughput": 4633.351478929573,
    "output_throughput": 4092.295247281921,
    "total_throughput": 8725.646726211495,
    "itl": 209.870294201931,
    "ttft": 2228360.7180627054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 874,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8511064330767897,
    "arrivals": 1888011,
    "finished_requests": 67455,
    "scheduler_time": 111.2110920451374
}
#Debug simulation 
Total elapsed time: 34.37478164304048. Arrivals time: 0.3833801723085344 Scheduler time: 33.86491586640477 Scheduler overhead time: 0.04261021455749869 Adapter cache time: 0.025971543043851852 Engine time: 0.041944201570004225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.27689343970269,
    "estimated_duration": 3600.0391111277695,
    "input_throughput": 4414.874535910539,
    "output_throughput": 3905.0228528200723,
    "total_throughput": 8319.897388730611,
    "itl": 178.48765823748874,
    "ttft": 2246608.958314043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.299811415709503,
    "arrivals": 1888011,
    "finished_requests": 64248,
    "scheduler_time": 117.44954598900358
}
#Debug simulation 
Total elapsed time: 14.276984320022166. Arrivals time: 0.30479211127385497 Scheduler time: 13.841293974779546 Scheduler overhead time: 0.0376893556676805 Adapter cache time: 0.03971063904464245 Engine time: 0.037886685226112604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 33.391835063230246,
    "estimated_duration": 3600.006561543892,
    "input_throughput": 4632.399612307394,
    "output_throughput": 4088.8083808623173,
    "total_throughput": 8721.207993169712,
    "itl": 209.83896926785462,
    "ttft": 2228120.6180133764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7752916854945666,
    "arrivals": 1888011,
    "finished_requests": 67397,
    "scheduler_time": 111.19884680746983
}
#Debug simulation 
Total elapsed time: 33.39196333801374. Arrivals time: 0.3681189129129052 Scheduler time: 32.897960010915995 Scheduler overhead time: 0.04267584718763828 Adapter cache time: 0.026026069186627865 Engine time: 0.04162309039384127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 14.292707497719675,
    "estimated_duration": 3600.108047585055,
    "input_throughput": 4414.789997945055,
    "output_throughput": 3904.948077719566,
    "total_throughput": 8319.738075664622,
    "itl": 178.49084072672431,
    "ttft": 2246631.3310731603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.36859873687842,
    "arrivals": 1888011,
    "finished_requests": 64248,
    "scheduler_time": 117.44969512518155
}
#Debug simulation 
Total elapsed time: 14.292803887743503. Arrivals time: 0.30964497569948435 Scheduler time: 13.851034103427082 Scheduler overhead time: 0.038054218515753746 Adapter cache time: 0.03988411510363221 Engine time: 0.03826454887166619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 33.41584934480488,
    "estimated_duration": 3600.1197241094974,
    "input_throughput": 4632.563436241085,
    "output_throughput": 4089.0526227266823,
    "total_throughput": 8721.616058967767,
    "itl": 209.83412241722556,
    "ttft": 2228118.3425241876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 888,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6551646618730746,
    "arrivals": 1888011,
    "finished_requests": 67401,
    "scheduler_time": 111.20560409804389
}
#Debug simulation 
Total elapsed time: 33.415999067015946. Arrivals time: 0.3676832257770002 Scheduler time: 32.9216791735962 Scheduler overhead time: 0.04321915842592716 Adapter cache time: 0.026243627071380615 Engine time: 0.04169161105528474 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 8640, 1080, 34560, 34560, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 8640, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 1080, 34560, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 34560, 1080, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 8640, 34560, 1080, 1080, 8640, 8640, 1080, 1080, 34560, 34560, 34560, 34560, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 34560, 1080, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 34560, 34560, 8640, 1080, 34560, 34560, 8640, 8640, 34560, 34560, 1080, 34560, 34560, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 8640, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 34560, 8640, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5667840 . Total input tokens: 1262484234 . Total output tokens: 1133400767
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.32154553104192,
    "estimated_duration": 3600.1737086548833,
    "input_throughput": 4414.709479654052,
    "output_throughput": 3904.876858081527,
    "total_throughput": 8319.58633773558,
    "itl": 178.4938366441292,
    "ttft": 2246653.2269525807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1623,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.434116459600547,
    "arrivals": 1888011,
    "finished_requests": 64248,
    "scheduler_time": 117.44983847233966
}
#Debug simulation 
Total elapsed time: 14.321666238829494. Arrivals time: 0.3071095924824476 Scheduler time: 13.882453547324985 Scheduler overhead time: 0.037864196579903364 Adapter cache time: 0.04024255974218249 Engine time: 0.0381836979649961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 30.803081824909896,
    "estimated_duration": 3600.135512766976,
    "input_throughput": 4636.345198898179,
    "output_throughput": 4091.191553142335,
    "total_throughput": 8727.536752040513,
    "itl": 209.48480184196592,
    "ttft": 2229327.7429856225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.757499457283471,
    "arrivals": 1864865,
    "finished_requests": 67673,
    "scheduler_time": 111.25067357049733
}
#Debug simulation 
Total elapsed time: 30.803250724915415. Arrivals time: 0.36449089320376515 Scheduler time: 30.31445531034842 Scheduler overhead time: 0.04249577037990093 Adapter cache time: 0.02468441240489483 Engine time: 0.04181453585624695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 30.60448423307389,
    "estimated_duration": 3600.107609787528,
    "input_throughput": 4632.593191008615,
    "output_throughput": 4085.9211985799902,
    "total_throughput": 8718.514389588605,
    "itl": 209.64104078505392,
    "ttft": 2228669.3702613967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9178535593883193,
    "arrivals": 1864865,
    "finished_requests": 67562,
    "scheduler_time": 111.15925950186248
}
#Debug simulation 
Total elapsed time: 30.604639968834817. Arrivals time: 0.49408059753477573 Scheduler time: 29.98667449457571 Scheduler overhead time: 0.0417015147395432 Adapter cache time: 0.025604397989809513 Engine time: 0.04088608920574188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.070443835575134,
    "estimated_duration": 3600.1298017051085,
    "input_throughput": 4423.296624598868,
    "output_throughput": 3908.2518617345427,
    "total_throughput": 8331.548486333411,
    "itl": 178.8710693121605,
    "ttft": 2248662.4597620973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.087801712974851,
    "arrivals": 1864865,
    "finished_requests": 64547,
    "scheduler_time": 117.32762210177839
}
#Debug simulation 
Total elapsed time: 13.070588210597634. Arrivals time: 0.30799609050154686 Scheduler time: 12.636029934044927 Scheduler overhead time: 0.0369435609318316 Adapter cache time: 0.0374954822473228 Engine time: 0.036535931285470724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 31.083771964069456,
    "estimated_duration": 3600.1266006920446,
    "input_throughput": 4636.214458900288,
    "output_throughput": 4090.8055836616913,
    "total_throughput": 8727.020042561979,
    "itl": 209.51801293435906,
    "ttft": 2229091.1755520324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7966306328773216,
    "arrivals": 1864865,
    "finished_requests": 67645,
    "scheduler_time": 111.23541241873872
}
#Debug simulation 
Total elapsed time: 31.083931155968457. Arrivals time: 0.38063564570620656 Scheduler time: 30.57923184428364 Scheduler overhead time: 0.04226643266156316 Adapter cache time: 0.02505239797756076 Engine time: 0.04135930258780718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 13.122728653717786,
    "estimated_duration": 3600.193953729504,
    "input_throughput": 4423.217805669495,
    "output_throughput": 3908.1822204118807,
    "total_throughput": 8331.400026081375,
    "itl": 178.87407228934487,
    "ttft": 2248684.7849822273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.151810390260019,
    "arrivals": 1864865,
    "finished_requests": 64547,
    "scheduler_time": 117.3277654489365
}
#Debug simulation 
Total elapsed time: 13.122843445744365. Arrivals time: 0.3285721754655242 Scheduler time: 12.668815560638905 Scheduler overhead time: 0.036846522241830826 Adapter cache time: 0.036194502376019955 Engine time: 0.03680279431864619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 30.989638531114906,
    "estimated_duration": 3600.071818856587,
    "input_throughput": 4636.427226971642,
    "output_throughput": 4091.2639361394754,
    "total_throughput": 8727.691163111116,
    "itl": 209.48152970391436,
    "ttft": 2229308.7310725837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6940353157068015,
    "arrivals": 1864865,
    "finished_requests": 67673,
    "scheduler_time": 111.25044380154291
}
#Debug simulation 
Total elapsed time: 30.989743434358388. Arrivals time: 0.3744375640526414 Scheduler time: 30.493078742641956 Scheduler overhead time: 0.04189602052792907 Adapter cache time: 0.024416678119450808 Engine time: 0.040902890264987946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 8640, 540, 34560, 34560, 540, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 540, 540, 8640, 540, 34560, 540, 34560, 8640, 34560, 8640, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 34560, 34560, 540, 8640, 8640, 8640, 34560, 8640, 540, 8640, 540, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 34560, 34560, 8640, 540, 540, 34560, 8640, 8640, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 540, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 8640, 540, 34560, 8640, 8640, 540, 34560, 34560, 34560, 540, 8640, 34560, 540, 34560, 8640, 8640, 34560, 34560, 540, 8640, 34560, 540, 8640, 8640, 540, 8640, 540, 8640, 34560, 34560, 8640, 540, 34560, 540, 34560, 8640, 8640, 8640, 8640, 8640, 540, 540, 34560, 540, 34560, 540, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 34560, 540, 540, 540, 8640, 540, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 34560, 540, 8640, 8640, 540, 540, 8640, 540, 34560, 34560, 540, 34560, 34560, 540, 8640, 34560, 540, 540, 8640, 8640, 540, 540, 34560, 34560, 34560, 34560, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 34560, 8640, 8640, 8640, 34560, 540, 8640, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 8640, 540, 34560, 34560, 34560, 8640, 540, 34560, 34560, 8640, 8640, 34560, 34560, 540, 34560, 34560, 8640, 540, 34560, 8640, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 8640, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 34560, 540, 540, 540, 8640, 540, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 540, 8640, 8640, 8640, 8640, 540, 8640, 34560, 34560, 540, 34560, 34560, 540, 34560, 8640, 34560, 8640, 8640, 8640, 540, 8640, 540, 540, 34560, 540, 8640, 540, 540, 8640, 34560, 8640, 34560, 540, 34560, 34560, 8640, 34560, 8640, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5598720 . Total input tokens: 1247095620 . Total output tokens: 1119518383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.261179592926055,
    "estimated_duration": 3600.0636023332263,
    "input_throughput": 4423.279074758426,
    "output_throughput": 3908.1942860346408,
    "total_throughput": 8331.473360793067,
    "itl": 178.87660076643365,
    "ttft": 2248697.09886718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1556,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.219088665991966,
    "arrivals": 1864865,
    "finished_requests": 64545,
    "scheduler_time": 117.32143138810814
}
#Debug simulation 
Total elapsed time: 13.261281622573733. Arrivals time: 0.45121521269902587 Scheduler time: 12.684011154808104 Scheduler overhead time: 0.03697044309228659 Adapter cache time: 0.037255920469760895 Engine time: 0.036301698070019484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.238292541354895,
    "estimated_duration": 3600.168397362379,
    "input_throughput": 4639.197436496705,
    "output_throughput": 4080.813556044667,
    "total_throughput": 8720.010992541373,
    "itl": 209.77467915980532,
    "ttft": 2226707.997322451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7360760430759408,
    "arrivals": 1853406,
    "finished_requests": 67474,
    "scheduler_time": 111.05940731044413
}
#Debug simulation 
Total elapsed time: 25.238388722296804. Arrivals time: 0.34574336651712656 Scheduler time: 24.773253447841853 Scheduler overhead time: 0.03984338790178299 Adapter cache time: 0.024709093384444714 Engine time: 0.03987026819959283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 25.159920691978186,
    "estimated_duration": 3600.1182309021033,
    "input_throughput": 4638.82181886435,
    "output_throughput": 4080.4390461140556,
    "total_throughput": 8719.260864978405,
    "itl": 209.78248984905147,
    "ttft": 2226716.1822503624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9137676062039146,
    "arrivals": 1853406,
    "finished_requests": 67470,
    "scheduler_time": 111.05291098470745
}
#Debug simulation 
Total elapsed time: 25.160041647963226. Arrivals time: 0.34241809183731675 Scheduler time: 24.69768493855372 Scheduler overhead time: 0.040579304564744234 Adapter cache time: 0.024164585396647453 Engine time: 0.039968912955373526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.904270004946738,
    "estimated_duration": 3600.008877193727,
    "input_throughput": 4440.589050008539,
    "output_throughput": 3909.635914834606,
    "total_throughput": 8350.224964843144,
    "itl": 178.27950504854692,
    "ttft": 2245894.470241305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.590795894917042,
    "arrivals": 1853406,
    "finished_requests": 64575,
    "scheduler_time": 117.53967503035689
}
#Debug simulation 
Total elapsed time: 12.904393773060292. Arrivals time: 0.30355897918343544 Scheduler time: 12.476683725137264 Scheduler overhead time: 0.03731273673474789 Adapter cache time: 0.034521390683948994 Engine time: 0.03667786344885826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 25.223699673078954,
    "estimated_duration": 3600.0034253219405,
    "input_throughput": 4638.969752787534,
    "output_throughput": 4080.569172982467,
    "total_throughput": 8719.538925770003,
    "itl": 209.7765674161287,
    "ttft": 2226679.343430314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.799360917040587,
    "arrivals": 1853406,
    "finished_requests": 67470,
    "scheduler_time": 111.05251209367324
}
#Debug simulation 
Total elapsed time: 25.223861273843795. Arrivals time: 0.34663762943819165 Scheduler time: 24.75660048937425 Scheduler overhead time: 0.04074306087568402 Adapter cache time: 0.024842760059982538 Engine time: 0.039774700067937374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 12.889025952201337,
    "estimated_duration": 3600.0644556315738,
    "input_throughput": 4440.520495401931,
    "output_throughput": 3909.5755571772993,
    "total_throughput": 8350.09605257923,
    "itl": 178.2820706054607,
    "ttft": 2245914.3049777783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.64625331472602,
    "arrivals": 1853406,
    "finished_requests": 64575,
    "scheduler_time": 117.53979604843846
}
#Debug simulation 
Total elapsed time: 12.889131620991975. Arrivals time: 0.3174965586513281 Scheduler time: 12.448138112667948 Scheduler overhead time: 0.03638879954814911 Adapter cache time: 0.034652549773454666 Engine time: 0.036879172548651695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 25.154656113125384,
    "estimated_duration": 3600.1051936196222,
    "input_throughput": 4639.278882628305,
    "output_throughput": 4080.8851991429556,
    "total_throughput": 8720.164081771261,
    "itl": 209.77140095421697,
    "ttft": 2226687.601132762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.673104963642487,
    "arrivals": 1853406,
    "finished_requests": 67474,
    "scheduler_time": 111.0591746469798
}
#Debug simulation 
Total elapsed time: 25.154792623128742. Arrivals time: 0.37379635497927666 Scheduler time: 24.66390046244487 Scheduler overhead time: 0.03912671934813261 Adapter cache time: 0.02436437737196684 Engine time: 0.038744340650737286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 8640, 270, 34560, 34560, 270, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 270, 270, 8640, 270, 34560, 270, 34560, 8640, 34560, 8640, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 34560, 34560, 270, 8640, 8640, 8640, 34560, 8640, 270, 8640, 270, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 34560, 34560, 8640, 270, 270, 34560, 8640, 8640, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 270, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 8640, 270, 34560, 8640, 8640, 270, 34560, 34560, 34560, 270, 8640, 34560, 270, 34560, 8640, 8640, 34560, 34560, 270, 8640, 34560, 270, 8640, 8640, 270, 8640, 270, 8640, 34560, 34560, 8640, 270, 34560, 270, 34560, 8640, 8640, 8640, 8640, 8640, 270, 270, 34560, 270, 34560, 270, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 34560, 270, 270, 270, 8640, 270, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 34560, 270, 8640, 8640, 270, 270, 8640, 270, 34560, 34560, 270, 34560, 34560, 270, 8640, 34560, 270, 270, 8640, 8640, 270, 270, 34560, 34560, 34560, 34560, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 34560, 8640, 8640, 8640, 34560, 270, 8640, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 8640, 270, 34560, 34560, 34560, 8640, 270, 34560, 34560, 8640, 8640, 34560, 34560, 270, 34560, 34560, 8640, 270, 34560, 8640, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 8640, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 34560, 270, 270, 270, 8640, 270, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 270, 8640, 8640, 8640, 8640, 270, 8640, 34560, 34560, 270, 34560, 34560, 270, 34560, 8640, 34560, 8640, 8640, 8640, 270, 8640, 270, 270, 34560, 270, 8640, 270, 270, 8640, 34560, 8640, 34560, 270, 34560, 34560, 8640, 34560, 8640, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5564160 . Total input tokens: 1239343507 . Total output tokens: 1112626833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.832869285717607,
    "estimated_duration": 3600.126465706588,
    "input_throughput": 4440.444010030752,
    "output_throughput": 3909.508217022478,
    "total_throughput": 8349.95222705323,
    "itl": 178.28501303426003,
    "ttft": 2245936.5014149323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1405,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7081241776421585,
    "arrivals": 1853406,
    "finished_requests": 64575,
    "scheduler_time": 117.5399352605824
}
#Debug simulation 
Total elapsed time: 12.832963058725. Arrivals time: 0.3122622650116682 Scheduler time: 12.39700206136331 Scheduler overhead time: 0.03697887388989329 Adapter cache time: 0.03428563196212053 Engine time: 0.03682288294658065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 20.123415099922568,
    "estimated_duration": 3600.0299954715006,
    "input_throughput": 4660.315892118743,
    "output_throughput": 4073.918278027888,
    "total_throughput": 8734.23417014663,
    "itl": 209.27919807486376,
    "ttft": 2225617.8541146107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0298828664934954,
    "arrivals": 1847695,
    "finished_requests": 67567,
    "scheduler_time": 111.0326903111868
}
#Debug simulation 
Total elapsed time: 20.12352761393413. Arrivals time: 0.48175794491544366 Scheduler time: 19.5278005823493 Scheduler overhead time: 0.03797834413126111 Adapter cache time: 0.025581715162843466 Engine time: 0.03615513537079096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 21.67379733780399,
    "estimated_duration": 3600.05105893907,
    "input_throughput": 4654.084546494642,
    "output_throughput": 4070.5947665971757,
    "total_throughput": 8724.679313091818,
    "itl": 209.53239362128426,
    "ttft": 2222712.797917863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 861,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8134615651983834,
    "arrivals": 1847695,
    "finished_requests": 67483,
    "scheduler_time": 110.93498899063398
}
#Debug simulation 
Total elapsed time: 21.673943486064672. Arrivals time: 0.3727224268950522 Scheduler time: 21.184744876809418 Scheduler overhead time: 0.039435004349797964 Adapter cache time: 0.023107069078832865 Engine time: 0.03901506820693612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.31354414485395,
    "estimated_duration": 3600.058077812126,
    "input_throughput": 4458.463628385283,
    "output_throughput": 3905.086166983127,
    "total_throughput": 8363.54979536841,
    "itl": 178.0237555070099,
    "ttft": 2243042.3738356973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.760845954567134,
    "arrivals": 1847695,
    "finished_requests": 64678,
    "scheduler_time": 117.5526060341889
}
#Debug simulation 
Total elapsed time: 11.313639268744737. Arrivals time: 0.3009428158402443 Scheduler time: 10.892742503900081 Scheduler overhead time: 0.03512160945683718 Adapter cache time: 0.034554265439510345 Engine time: 0.034986295737326145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 20.077694126870483,
    "estimated_duration": 3600.0969738912595,
    "input_throughput": 4660.229188733724,
    "output_throughput": 4073.842484344976,
    "total_throughput": 8734.0716730787,
    "itl": 209.28254408582072,
    "ttft": 2225640.5879045697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0966206283121984,
    "arrivals": 1847695,
    "finished_requests": 67567,
    "scheduler_time": 111.03293096901187
}
#Debug simulation 
Total elapsed time: 20.077826575841755. Arrivals time: 0.3444559979252517 Scheduler time: 19.615736197214574 Scheduler overhead time: 0.03828983148559928 Adapter cache time: 0.026645352598279715 Engine time: 0.03839136892929673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.625335945747793,
    "estimated_duration": 3600.104369667647,
    "input_throughput": 4463.329489940149,
    "output_throughput": 3906.7172936706856,
    "total_throughput": 8370.046783610835,
    "itl": 178.04373726247888,
    "ttft": 2244331.829738975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.049722332451441,
    "arrivals": 1847695,
    "finished_requests": 64713,
    "scheduler_time": 117.51218610368531
}
#Debug simulation 
Total elapsed time: 11.625427840743214. Arrivals time: 0.2977339061908424 Scheduler time: 11.205068062990904 Scheduler overhead time: 0.03575054323300719 Adapter cache time: 0.03630918823182583 Engine time: 0.035289517138153315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.93889666115865,
    "estimated_duration": 3600.1955481703517,
    "input_throughput": 4660.819051489483,
    "output_throughput": 4074.203138064086,
    "total_throughput": 8735.02218955357,
    "itl": 209.27647807535644,
    "ttft": 2225609.069161555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 990,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9601497919530857,
    "arrivals": 1847695,
    "finished_requests": 67574,
    "scheduler_time": 111.03972025217652
}
#Debug simulation 
Total elapsed time: 19.9390435279347. Arrivals time: 0.34014222864061594 Scheduler time: 19.48243378009647 Scheduler overhead time: 0.0376113997772336 Adapter cache time: 0.026652120985090733 Engine time: 0.03762839501723647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 8640, 135, 34560, 34560, 135, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 135, 135, 8640, 135, 34560, 135, 34560, 8640, 34560, 8640, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 34560, 34560, 135, 8640, 8640, 8640, 34560, 8640, 135, 8640, 135, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 34560, 34560, 8640, 135, 135, 34560, 8640, 8640, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 135, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 8640, 135, 34560, 8640, 8640, 135, 34560, 34560, 34560, 135, 8640, 34560, 135, 34560, 8640, 8640, 34560, 34560, 135, 8640, 34560, 135, 8640, 8640, 135, 8640, 135, 8640, 34560, 34560, 8640, 135, 34560, 135, 34560, 8640, 8640, 8640, 8640, 8640, 135, 135, 34560, 135, 34560, 135, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 34560, 135, 135, 135, 8640, 135, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 34560, 135, 8640, 8640, 135, 135, 8640, 135, 34560, 34560, 135, 34560, 34560, 135, 8640, 34560, 135, 135, 8640, 8640, 135, 135, 34560, 34560, 34560, 34560, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 34560, 8640, 8640, 8640, 34560, 135, 8640, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 8640, 135, 34560, 34560, 34560, 8640, 135, 34560, 34560, 8640, 8640, 34560, 34560, 135, 34560, 34560, 8640, 135, 34560, 8640, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 8640, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 34560, 135, 135, 135, 8640, 135, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 135, 8640, 8640, 8640, 8640, 135, 8640, 34560, 34560, 135, 34560, 34560, 135, 34560, 8640, 34560, 8640, 8640, 8640, 135, 8640, 135, 135, 34560, 135, 8640, 135, 135, 8640, 34560, 8640, 34560, 135, 34560, 34560, 8640, 34560, 8640, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5546880 . Total input tokens: 1235512233 . Total output tokens: 1109175816
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.604585173074156,
    "estimated_duration": 3600.1692766282504,
    "input_throughput": 4463.249021181848,
    "output_throughput": 3906.646859997715,
    "total_throughput": 8369.895881179564,
    "itl": 178.04668936533824,
    "ttft": 2244355.572774886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1523,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.114485532455099,
    "arrivals": 1847695,
    "finished_requests": 64713,
    "scheduler_time": 117.51232986434485
}
#Debug simulation 
Total elapsed time: 11.604686603415757. Arrivals time: 0.3030771603807807 Scheduler time: 11.178837485145777 Scheduler overhead time: 0.036161639261990786 Adapter cache time: 0.03579090954735875 Engine time: 0.03528376994654536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.488281320780516,
    "estimated_duration": 3600.1692460488457,
    "input_throughput": 4656.396367586924,
    "output_throughput": 4085.300994152332,
    "total_throughput": 8741.697361739256,
    "itl": 209.298098671139,
    "ttft": 2230847.3149668328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7850438469788665,
    "arrivals": 1844823,
    "finished_requests": 67516,
    "scheduler_time": 111.25659696317751
}
#Debug simulation 
Total elapsed time: 19.48842151183635. Arrivals time: 0.33558408077806234 Scheduler time: 19.039077326655388 Scheduler overhead time: 0.03758041327819228 Adapter cache time: 0.02391148079186678 Engine time: 0.03754232684150338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 20.010536732152104,
    "estimated_duration": 3600.1284342452795,
    "input_throughput": 4655.702513433734,
    "output_throughput": 4084.845101667301,
    "total_throughput": 8740.547615101035,
    "itl": 209.3069432789107,
    "ttft": 2230851.5959988604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9763178423862042,
    "arrivals": 1844823,
    "finished_requests": 67507,
    "scheduler_time": 111.2500859440853
}
#Debug simulation 
Total elapsed time: 20.010638935957104. Arrivals time: 0.8133003516122699 Scheduler time: 19.084921477362514 Scheduler overhead time: 0.03764370363205671 Adapter cache time: 0.023529175203293562 Engine time: 0.03669495228677988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.024305067025125,
    "estimated_duration": 3600.101211216352,
    "input_throughput": 4447.47496268037,
    "output_throughput": 3912.8144386920276,
    "total_throughput": 8360.289401372398,
    "itl": 178.4983412961283,
    "ttft": 2250907.8454893376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.835905600506757,
    "arrivals": 1844823,
    "finished_requests": 64539,
    "scheduler_time": 117.54570953422513
}
#Debug simulation 
Total elapsed time: 11.024394020438194. Arrivals time: 0.2887299498543143 Scheduler time: 10.615208181552589 Scheduler overhead time: 0.03506520017981529 Adapter cache time: 0.03576282039284706 Engine time: 0.03431734023615718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 19.535834135022014,
    "estimated_duration": 3600.0029868549427,
    "input_throughput": 4655.864748224268,
    "output_throughput": 4084.9874440930726,
    "total_throughput": 8740.852192317341,
    "itl": 209.30047512117204,
    "ttft": 2230803.4373233174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.851287674943424,
    "arrivals": 1844823,
    "finished_requests": 67507,
    "scheduler_time": 111.24966872115489
}
#Debug simulation 
Total elapsed time: 19.535946692340076. Arrivals time: 0.34790022019296885 Scheduler time: 19.075794852804393 Scheduler overhead time: 0.03768368856981397 Adapter cache time: 0.023714795242995024 Engine time: 0.036318072117865086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.03101429482922,
    "estimated_duration": 3600.1613298847105,
    "input_throughput": 4447.400694821845,
    "output_throughput": 3912.749099066374,
    "total_throughput": 8360.149793888218,
    "itl": 178.50112399351036,
    "ttft": 2250928.9521745373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.895890156626663,
    "arrivals": 1844823,
    "finished_requests": 64539,
    "scheduler_time": 117.54584364651825
}
#Debug simulation 
Total elapsed time: 11.031109742820263. Arrivals time: 0.28901658253744245 Scheduler time: 10.62160000577569 Scheduler overhead time: 0.0352722886018455 Adapter cache time: 0.03530764067545533 Engine time: 0.03466848563402891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.99002544907853,
    "estimated_duration": 3600.1049288146005,
    "input_throughput": 4656.479555866665,
    "output_throughput": 4085.3739795975334,
    "total_throughput": 8741.853535464197,
    "itl": 209.2947906755173,
    "ttft": 2230822.8296444896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.72094576836092,
    "arrivals": 1844823,
    "finished_requests": 67516,
    "scheduler_time": 111.25637780742616
}
#Debug simulation 
Total elapsed time: 19.990125773008913. Arrivals time: 0.81742910342291 Scheduler time: 19.060745745431632 Scheduler overhead time: 0.037084538489580154 Adapter cache time: 0.023649368900805712 Engine time: 0.037026172503829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 8640, 66, 34560, 34560, 66, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 66, 66, 8640, 66, 34560, 66, 34560, 8640, 34560, 8640, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 34560, 34560, 66, 8640, 8640, 8640, 34560, 8640, 66, 8640, 66, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 34560, 34560, 8640, 66, 66, 34560, 8640, 8640, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 66, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 8640, 66, 34560, 8640, 8640, 66, 34560, 34560, 34560, 66, 8640, 34560, 66, 34560, 8640, 8640, 34560, 34560, 66, 8640, 34560, 66, 8640, 8640, 66, 8640, 66, 8640, 34560, 34560, 8640, 66, 34560, 66, 34560, 8640, 8640, 8640, 8640, 8640, 66, 66, 34560, 66, 34560, 66, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 34560, 66, 66, 66, 8640, 66, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 34560, 66, 8640, 8640, 66, 66, 8640, 66, 34560, 34560, 66, 34560, 34560, 66, 8640, 34560, 66, 66, 8640, 8640, 66, 66, 34560, 34560, 34560, 34560, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 34560, 8640, 8640, 8640, 34560, 66, 8640, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 8640, 66, 34560, 34560, 34560, 8640, 66, 34560, 34560, 8640, 8640, 34560, 34560, 66, 34560, 34560, 8640, 66, 34560, 8640, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 8640, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 34560, 66, 66, 66, 8640, 66, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 66, 8640, 8640, 8640, 8640, 66, 8640, 34560, 34560, 66, 34560, 34560, 66, 34560, 8640, 34560, 8640, 8640, 8640, 66, 8640, 66, 66, 34560, 66, 8640, 66, 66, 8640, 34560, 8640, 34560, 66, 34560, 34560, 8640, 34560, 8640, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5538048 . Total input tokens: 1233587320 . Total output tokens: 1107392299
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.022164301015437,
    "estimated_duration": 3600.03332274849,
    "input_throughput": 4447.40994446583,
    "output_throughput": 3912.6104502961184,
    "total_throughput": 8360.020394761948,
    "itl": 178.50316171587906,
    "ttft": 2250959.4196184184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1478,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.961785140708057,
    "arrivals": 1844823,
    "finished_requests": 64535,
    "scheduler_time": 117.5395985664176
}
#Debug simulation 
Total elapsed time: 11.022233047988266. Arrivals time: 0.2906457562930882 Scheduler time: 10.612517475150526 Scheduler overhead time: 0.035220163874328136 Adapter cache time: 0.0339201963506639 Engine time: 0.03469605464488268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.009785722009838,
    "estimated_duration": 3600.233272558146,
    "input_throughput": 4635.978209306557,
    "output_throughput": 4097.0734070015105,
    "total_throughput": 8733.051616308068,
    "itl": 209.38849309254672,
    "ttft": 2229063.939017651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.818709212162128,
    "arrivals": 1843393,
    "finished_requests": 67595,
    "scheduler_time": 111.41283420324538
}
#Debug simulation 
Total elapsed time: 17.00992285599932. Arrivals time: 0.7923033302649856 Scheduler time: 16.110094013158232 Scheduler overhead time: 0.03511261101812124 Adapter cache time: 0.023200578521937132 Engine time: 0.035001701675355434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.169764171354473,
    "estimated_duration": 3600.0720770147695,
    "input_throughput": 4636.280230767036,
    "output_throughput": 4090.9964258861637,
    "total_throughput": 8727.276656653201,
    "itl": 209.4913365003103,
    "ttft": 2229343.939379032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0391088985791486,
    "arrivals": 1843393,
    "finished_requests": 67534,
    "scheduler_time": 111.27913216922018
}
#Debug simulation 
Total elapsed time: 17.169833207968622. Arrivals time: 0.32460913294926286 Scheduler time: 16.736995714250952 Scheduler overhead time: 0.03558280132710934 Adapter cache time: 0.02390589751303196 Engine time: 0.034789144061505795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.246353941969573,
    "estimated_duration": 3600.0026059402976,
    "input_throughput": 4421.640965963229,
    "output_throughput": 3913.5205004442287,
    "total_throughput": 8335.161466407457,
    "itl": 178.6229433392727,
    "ttft": 2249881.539345983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.147874046955197,
    "arrivals": 1843393,
    "finished_requests": 64423,
    "scheduler_time": 117.46290954424057
}
#Debug simulation 
Total elapsed time: 11.24649151507765. Arrivals time: 0.29197319643571973 Scheduler time: 10.838029086124152 Scheduler overhead time: 0.035008860286325216 Adapter cache time: 0.031249848660081625 Engine time: 0.034993949346244335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 17.191872221883386,
    "estimated_duration": 3600.1866992750147,
    "input_throughput": 4636.1523426996555,
    "output_throughput": 4090.9692275030884,
    "total_throughput": 8727.121570202744,
    "itl": 209.48577833227282,
    "ttft": 2229351.4138247077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9153045170916894,
    "arrivals": 1843393,
    "finished_requests": 67536,
    "scheduler_time": 111.28604741515096
}
#Debug simulation 
Total elapsed time: 17.1919690258801. Arrivals time: 0.32658834382891655 Scheduler time: 16.756221608724445 Scheduler overhead time: 0.03532619448378682 Adapter cache time: 0.02414966095238924 Engine time: 0.035691102501004934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.272957087028772,
    "estimated_duration": 3600.054161635322,
    "input_throughput": 4421.577644478909,
    "output_throughput": 3913.4644556570297,
    "total_throughput": 8335.04210013594,
    "itl": 178.6252829131763,
    "ttft": 2249901.1865466936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.199307345598923,
    "arrivals": 1843393,
    "finished_requests": 64423,
    "scheduler_time": 117.4630319406602
}
#Debug simulation 
Total elapsed time: 11.27310184109956. Arrivals time: 0.2985860086046159 Scheduler time: 10.85803023725748 Scheduler overhead time: 0.03516103280708194 Adapter cache time: 0.031593100633472204 Engine time: 0.034472120460122824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 16.57356315292418,
    "estimated_duration": 3600.1681858874936,
    "input_throughput": 4636.062022165091,
    "output_throughput": 4097.147477115381,
    "total_throughput": 8733.20949928047,
    "itl": 209.38509807376786,
    "ttft": 2229039.260163025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 921,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.753836321604843,
    "arrivals": 1843393,
    "finished_requests": 67595,
    "scheduler_time": 111.41262042301247
}
#Debug simulation 
Total elapsed time: 16.57365901907906. Arrivals time: 0.32764303823933005 Scheduler time: 16.13866258878261 Scheduler overhead time: 0.03452328545972705 Adapter cache time: 0.02311737835407257 Engine time: 0.0357565563172102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 8640, 33, 34560, 34560, 33, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 33, 33, 8640, 33, 34560, 33, 34560, 8640, 34560, 8640, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 34560, 34560, 33, 8640, 8640, 8640, 34560, 8640, 33, 8640, 33, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 34560, 34560, 8640, 33, 33, 34560, 8640, 8640, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 34560, 34560, 33, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 34560, 33, 33, 34560, 33, 34560, 8640, 33, 34560, 8640, 8640, 33, 34560, 34560, 34560, 33, 8640, 34560, 33, 34560, 8640, 8640, 34560, 34560, 33, 8640, 34560, 33, 8640, 8640, 33, 8640, 33, 8640, 34560, 34560, 8640, 33, 34560, 33, 34560, 8640, 8640, 8640, 8640, 8640, 33, 33, 34560, 33, 34560, 33, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 34560, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 34560, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 34560, 33, 33, 33, 8640, 33, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 34560, 33, 8640, 8640, 33, 33, 8640, 33, 34560, 34560, 33, 34560, 34560, 33, 8640, 34560, 33, 33, 8640, 8640, 33, 33, 34560, 34560, 34560, 34560, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 34560, 8640, 8640, 8640, 34560, 33, 8640, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 8640, 33, 34560, 34560, 34560, 8640, 33, 34560, 34560, 8640, 8640, 34560, 34560, 33, 34560, 34560, 8640, 33, 34560, 8640, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 8640, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 34560, 33, 33, 33, 8640, 33, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 33, 8640, 8640, 8640, 8640, 33, 8640, 34560, 34560, 33, 34560, 34560, 33, 34560, 8640, 34560, 8640, 8640, 8640, 33, 8640, 33, 33, 34560, 33, 8640, 33, 33, 8640, 34560, 8640, 34560, 33, 34560, 34560, 8640, 34560, 8640, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5533824 . Total input tokens: 1232656559 . Total output tokens: 1106535012
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.225319892633706,
    "estimated_duration": 3600.1093845895502,
    "input_throughput": 4421.509820823071,
    "output_throughput": 3913.404426073086,
    "total_throughput": 8334.914246896158,
    "itl": 178.62779533219015,
    "ttft": 2249922.059320128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.254387504048682,
    "arrivals": 1843393,
    "finished_requests": 64423,
    "scheduler_time": 117.4631747364831
}
#Debug simulation 
Total elapsed time: 11.225458320695907. Arrivals time: 0.29175256472080946 Scheduler time: 10.817642701789737 Scheduler overhead time: 0.03489918867126107 Adapter cache time: 0.0313039431348443 Engine time: 0.03457202576100826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 29.550548342987895,
    "estimated_duration": 3600.166586319395,
    "input_throughput": 4627.491145356129,
    "output_throughput": 4075.196702216824,
    "total_throughput": 8702.687847572954,
    "itl": 210.24355064746428,
    "ttft": 2228303.606077241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.494297511305245,
    "arrivals": 1703822,
    "finished_requests": 67238,
    "scheduler_time": 110.87201515070632
}
#Debug simulation 
Total elapsed time: 29.550646810326725. Arrivals time: 0.36413996294140816 Scheduler time: 29.068240833934397 Scheduler overhead time: 0.04093346977606416 Adapter cache time: 0.022787197958678007 Engine time: 0.0397205576300621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 29.681333559099585,
    "estimated_duration": 3600.101297771383,
    "input_throughput": 4627.463402297275,
    "output_throughput": 4075.1611653488676,
    "total_throughput": 8702.624567646142,
    "itl": 210.25149242102444,
    "ttft": 2228329.1474458617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.659166843576827,
    "arrivals": 1703822,
    "finished_requests": 67236,
    "scheduler_time": 110.86551701293334
}
#Debug simulation 
Total elapsed time: 29.681407089345157. Arrivals time: 0.35692862467840314 Scheduler time: 29.203689007554203 Scheduler overhead time: 0.04183548828586936 Adapter cache time: 0.02342781238257885 Engine time: 0.040136223658919334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.785472896881402,
    "estimated_duration": 3600.013876388273,
    "input_throughput": 4424.731833528632,
    "output_throughput": 3904.5693940775136,
    "total_throughput": 8329.301227606145,
    "itl": 178.85843720538526,
    "ttft": 2249500.398309408,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.135362724065717,
    "arrivals": 1703822,
    "finished_requests": 64280,
    "scheduler_time": 117.27138676076464
}
#Debug simulation 
Total elapsed time: 14.785599482711405. Arrivals time: 0.29985575238242745 Scheduler time: 14.361327711027116 Scheduler overhead time: 0.03877821518108249 Adapter cache time: 0.032019621692597866 Engine time: 0.03782003605738282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 29.62545007560402,
    "estimated_duration": 3600.2209737321464,
    "input_throughput": 4627.421239294039,
    "output_throughput": 4075.1351394942294,
    "total_throughput": 8702.556378788267,
    "itl": 210.2463937072951,
    "ttft": 2228321.7072891532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5484375122794645,
    "arrivals": 1703822,
    "finished_requests": 67238,
    "scheduler_time": 110.87226256238787
}
#Debug simulation 
Total elapsed time: 29.625592265743762. Arrivals time: 0.36986538395285606 Scheduler time: 29.136567015666515 Scheduler overhead time: 0.04070231970399618 Adapter cache time: 0.023197419941425323 Engine time: 0.03996666939929128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 14.774082073941827,
    "estimated_duration": 3600.067079563243,
    "input_throughput": 4424.666443140972,
    "output_throughput": 3904.5116908503055,
    "total_throughput": 8329.178133991278,
    "itl": 178.8608852403504,
    "ttft": 2249520.016925024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.188430821932841,
    "arrivals": 1703822,
    "finished_requests": 64280,
    "scheduler_time": 117.27152183789441
}
#Debug simulation 
Total elapsed time: 14.774151052348316. Arrivals time: 0.2974908510223031 Scheduler time: 14.354179200716317 Scheduler overhead time: 0.03802965488284826 Adapter cache time: 0.03093385836109519 Engine time: 0.0377621091902256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 29.570933992043138,
    "estimated_duration": 3600.108945481091,
    "input_throughput": 4627.565235466429,
    "output_throughput": 4075.2619496184243,
    "total_throughput": 8702.827185084852,
    "itl": 210.24060231338737,
    "ttft": 2228286.3558657244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4368909903452236,
    "arrivals": 1703822,
    "finished_requests": 67238,
    "scheduler_time": 110.87178083323631
}
#Debug simulation 
Total elapsed time: 29.571103679016232. Arrivals time: 0.3296666359528899 Scheduler time: 29.122241457924247 Scheduler overhead time: 0.041502769105136395 Adapter cache time: 0.02266056602820754 Engine time: 0.03984389640390873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 34560, 4320, 1080, 34560, 34560, 1080, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 1080, 34560, 4320, 34560, 4320, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 4320, 4320, 4320, 34560, 4320, 1080, 4320, 1080, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 4320, 4320, 34560, 1080, 1080, 34560, 1080, 34560, 4320, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 4320, 34560, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 1080, 34560, 1080, 34560, 4320, 4320, 4320, 4320, 4320, 1080, 1080, 34560, 1080, 34560, 1080, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 1080, 4320, 34560, 34560, 1080, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 34560, 34560, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 4320, 4320, 1080, 1080, 4320, 1080, 34560, 34560, 1080, 34560, 34560, 1080, 4320, 34560, 1080, 1080, 4320, 4320, 1080, 1080, 34560, 34560, 34560, 34560, 4320, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 34560, 1080, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 1080, 1080, 4320, 1080, 34560, 34560, 34560, 4320, 1080, 34560, 34560, 4320, 4320, 34560, 34560, 1080, 34560, 34560, 4320, 1080, 34560, 4320, 4320, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 34560, 1080, 4320, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 1080, 1080, 1080, 4320, 1080, 4320, 4320, 1080, 34560, 4320, 34560, 1080, 34560, 1080, 4320, 4320, 4320, 4320, 1080, 4320, 34560, 34560, 1080, 34560, 34560, 1080, 34560, 4320, 34560, 4320, 4320, 4320, 1080, 4320, 1080, 1080, 34560, 1080, 4320, 1080, 1080, 4320, 34560, 4320, 34560, 1080, 34560, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5114880 . Total input tokens: 1139568477 . Total output tokens: 1022716391
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.672445849981159,
    "estimated_duration": 3600.12054968317,
    "input_throughput": 4424.600726606737,
    "output_throughput": 3904.4536998176486,
    "total_throughput": 8329.054426424385,
    "itl": 178.8633662004637,
    "ttft": 2249540.208429271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1265,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.241750427372793,
    "arrivals": 1703822,
    "finished_requests": 64280,
    "scheduler_time": 117.27167235241043
}
#Debug simulation 
Total elapsed time: 14.672546334099025. Arrivals time: 0.32856725761666894 Scheduler time: 14.2215845012106 Scheduler overhead time: 0.03739632898941636 Adapter cache time: 0.031955770682543516 Engine time: 0.037445776630192995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 20.836962060071528,
    "estimated_duration": 3600.103478572026,
    "input_throughput": 4614.10987180536,
    "output_throughput": 4070.0049560275033,
    "total_throughput": 8684.114827832864,
    "itl": 210.59735678878712,
    "ttft": 2225209.9740244783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.907463356736181,
    "arrivals": 1680953,
    "finished_requests": 67050,
    "scheduler_time": 110.69883576232895
}
#Debug simulation 
Total elapsed time: 20.83703369507566. Arrivals time: 0.3321927930228412 Scheduler time: 20.391684762667865 Scheduler overhead time: 0.03697425406426191 Adapter cache time: 0.024333694018423557 Engine time: 0.037232200149446726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 21.1533115808852,
    "estimated_duration": 3600.06247758498,
    "input_throughput": 4613.119384289345,
    "output_throughput": 4069.4782635627676,
    "total_throughput": 8682.597647852113,
    "itl": 210.6059655197675,
    "ttft": 2225330.2132281084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 913,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9824278260418278,
    "arrivals": 1680953,
    "finished_requests": 67025,
    "scheduler_time": 110.69705075943985
}
#Debug simulation 
Total elapsed time: 21.153472061734647. Arrivals time: 0.3362317616119981 Scheduler time: 20.70434721466154 Scheduler overhead time: 0.037656139582395554 Adapter cache time: 0.02334578102454543 Engine time: 0.03751356899738312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.467234313953668,
    "estimated_duration": 3600.0813533478286,
    "input_throughput": 4418.990138988381,
    "output_throughput": 3903.5048435590866,
    "total_throughput": 8322.494982547467,
    "itl": 179.16424901911498,
    "ttft": 2247124.7230003006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.799071001019276,
    "arrivals": 1680953,
    "finished_requests": 64207,
    "scheduler_time": 117.17138864931943
}
#Debug simulation 
Total elapsed time: 11.467328002210706. Arrivals time: 0.2900924407877028 Scheduler time: 11.057541637681425 Scheduler overhead time: 0.03541085682809353 Adapter cache time: 0.033815617207437754 Engine time: 0.03515756316483021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 20.960516768041998,
    "estimated_duration": 3600.1659218415216,
    "input_throughput": 4614.029842131044,
    "output_throughput": 4069.934363609866,
    "total_throughput": 8683.96420574091,
    "itl": 210.60055107569846,
    "ttft": 2225228.8347691284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.969663900784187,
    "arrivals": 1680953,
    "finished_requests": 67050,
    "scheduler_time": 110.69907848766111
}
#Debug simulation 
Total elapsed time: 20.960675642825663. Arrivals time: 0.33154720813035965 Scheduler time: 20.51698766835034 Scheduler overhead time: 0.03638644376769662 Adapter cache time: 0.024083093274384737 Engine time: 0.03715860936790705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.465691342018545,
    "estimated_duration": 3600.1424740492994,
    "input_throughput": 4418.915116463846,
    "output_throughput": 3903.438572583437,
    "total_throughput": 8322.353689047282,
    "itl": 179.16710683954196,
    "ttft": 2247146.3555124095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.860061587430501,
    "arrivals": 1680953,
    "finished_requests": 64207,
    "scheduler_time": 117.17151876443218
}
#Debug simulation 
Total elapsed time: 11.465780806262046. Arrivals time: 0.29483582777902484 Scheduler time: 11.051648989319801 Scheduler overhead time: 0.03507759980857372 Adapter cache time: 0.03402418876066804 Engine time: 0.03497388632968068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 20.90717609692365,
    "estimated_duration": 3600.036341496675,
    "input_throughput": 4614.195920337306,
    "output_throughput": 4070.0808575472356,
    "total_throughput": 8684.276777884543,
    "itl": 210.59382025462185,
    "ttft": 2225189.347742644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.840547780157003,
    "arrivals": 1680953,
    "finished_requests": 67050,
    "scheduler_time": 110.6986142634029
}
#Debug simulation 
Total elapsed time: 20.907335116993636. Arrivals time: 0.33588190050795674 Scheduler time: 20.459096235688776 Scheduler overhead time: 0.03759242640808225 Adapter cache time: 0.023577038664370775 Engine time: 0.0367348357103765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.467236668802798,
    "estimated_duration": 3600.0111042466892,
    "input_throughput": 4418.797759049893,
    "output_throughput": 3903.3232379266274,
    "total_throughput": 8322.12099697652,
    "itl": 179.1691756391734,
    "ttft": 2247174.5061951466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.92142943520096,
    "arrivals": 1680953,
    "finished_requests": 64204,
    "scheduler_time": 117.16528913181618
}
#Debug simulation 
Total elapsed time: 11.467331476975232. Arrivals time: 0.2888853047043085 Scheduler time: 11.058887661900371 Scheduler overhead time: 0.035520386416465044 Adapter cache time: 0.033374182879924774 Engine time: 0.035404898691922426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.875421826262027,
    "estimated_duration": 3600.0309251021663,
    "input_throughput": 4608.059582024066,
    "output_throughput": 4072.4577941185134,
    "total_throughput": 8680.51737614258,
    "itl": 210.85635737845996,
    "ttft": 2224670.379775443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5861121436232306,
    "arrivals": 1669342,
    "finished_requests": 67022,
    "scheduler_time": 110.6673986479714
}
#Debug simulation 
Total elapsed time: 17.87558107590303. Arrivals time: 0.32301849918439984 Scheduler time: 17.446170643903315 Scheduler overhead time: 0.03535481868311763 Adapter cache time: 0.02113271877169609 Engine time: 0.03567522671073675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.647498454898596,
    "estimated_duration": 3600.129999453053,
    "input_throughput": 4609.117727004565,
    "output_throughput": 4070.7596676304715,
    "total_throughput": 8679.877394635036,
    "itl": 210.81250569709397,
    "ttft": 2224842.4850896657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7651932190405257,
    "arrivals": 1669342,
    "finished_requests": 67024,
    "scheduler_time": 110.67349652116718
}
#Debug simulation 
Total elapsed time: 17.647594159003347. Arrivals time: 0.3196239648386836 Scheduler time: 17.22285137278959 Scheduler overhead time: 0.03537066048011184 Adapter cache time: 0.021048898808658123 Engine time: 0.03465238073840737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.857050395105034,
    "estimated_duration": 3600.031288198322,
    "input_throughput": 4422.317398237834,
    "output_throughput": 3905.334391423069,
    "total_throughput": 8327.651789660902,
    "itl": 179.18935536837378,
    "ttft": 2246666.2244717055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.364605214614364,
    "arrivals": 1669342,
    "finished_requests": 64279,
    "scheduler_time": 117.16157007147864
}
#Debug simulation 
Total elapsed time: 10.857170525938272. Arrivals time: 0.29023452987894416 Scheduler time: 10.450154238380492 Scheduler overhead time: 0.03494848031550646 Adapter cache time: 0.03194855246692896 Engine time: 0.0346917430870235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 17.64647597586736,
    "estimated_duration": 3600.0188908031546,
    "input_throughput": 4609.259979826954,
    "output_throughput": 4070.8853049186223,
    "total_throughput": 8680.145284745575,
    "itl": 210.80663143805646,
    "ttft": 2224802.519898575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6544638877431623,
    "arrivals": 1669342,
    "finished_requests": 67024,
    "scheduler_time": 110.67311720253339
}
#Debug simulation 
Total elapsed time: 17.646572201047093. Arrivals time: 0.32315706461668015 Scheduler time: 17.217915473505855 Scheduler overhead time: 0.035912846215069294 Adapter cache time: 0.020730350632220507 Engine time: 0.034855859354138374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.034884873311967,
    "estimated_duration": 3600.085732233239,
    "input_throughput": 4422.2505196075035,
    "output_throughput": 3905.2753311179026,
    "total_throughput": 8327.525850725406,
    "itl": 179.19186404362864,
    "ttft": 2246685.073726157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.41893085034562,
    "arrivals": 1669342,
    "finished_requests": 64279,
    "scheduler_time": 117.16168847071789
}
#Debug simulation 
Total elapsed time: 11.035019853152335. Arrivals time: 0.4195076343603432 Scheduler time: 10.498485368676484 Scheduler overhead time: 0.03473370103165507 Adapter cache time: 0.03257483243942261 Engine time: 0.03452845849096775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.742684368044138,
    "estimated_duration": 3600.2086737319737,
    "input_throughput": 4608.332878327807,
    "output_throughput": 4072.403110123586,
    "total_throughput": 8680.735988451392,
    "itl": 210.85281118732308,
    "ttft": 2224682.1680372464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5265924991922857,
    "arrivals": 1669342,
    "finished_requests": 67028,
    "scheduler_time": 110.67449605246749
}
#Debug simulation 
Total elapsed time: 17.74277708400041. Arrivals time: 0.32122209994122386 Scheduler time: 17.315435007680207 Scheduler overhead time: 0.035398019943386316 Adapter cache time: 0.021114835049957037 Engine time: 0.03546680975705385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.873520591761917,
    "estimated_duration": 3600.142842872586,
    "input_throughput": 4422.180367514781,
    "output_throughput": 3905.213380028538,
    "total_throughput": 8327.39374754332,
    "itl": 179.19453783188408,
    "ttft": 2246704.5664265663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.475897315591588,
    "arrivals": 1669342,
    "finished_requests": 64279,
    "scheduler_time": 117.16183264487884
}
#Debug simulation 
Total elapsed time: 10.873658399097621. Arrivals time: 0.29385593393817544 Scheduler time: 10.461945930030197 Scheduler overhead time: 0.03507484449073672 Adapter cache time: 0.032206238247454166 Engine time: 0.03506982605904341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.497150420211256,
    "estimated_duration": 3600.1855229227153,
    "input_throughput": 4621.231293239982,
    "output_throughput": 4074.6816814292574,
    "total_throughput": 8695.91297466924,
    "itl": 210.27268275127489,
    "ttft": 2223131.5747058345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.402482878987259,
    "arrivals": 1663594,
    "finished_requests": 67526,
    "scheduler_time": 110.78598841232774
}
#Debug simulation 
Total elapsed time: 19.497242957353592. Arrivals time: 0.3207597341388464 Scheduler time: 19.069503631908447 Scheduler overhead time: 0.036537197418510914 Adapter cache time: 0.01982576074078679 Engine time: 0.03646740410476923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 19.81616820814088,
    "estimated_duration": 3600.1828692336517,
    "input_throughput": 4616.859088476836,
    "output_throughput": 4072.481741218034,
    "total_throughput": 8689.340829694871,
    "itl": 210.41955873483838,
    "ttft": 2222951.642375613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5568178259790946,
    "arrivals": 1663594,
    "finished_requests": 67474,
    "scheduler_time": 110.71817927318094
}
#Debug simulation 
Total elapsed time: 19.816320135258138. Arrivals time: 0.46736412635073066 Scheduler time: 19.23912546504289 Scheduler overhead time: 0.03749163867905736 Adapter cache time: 0.020141281187534332 Engine time: 0.037410225719213486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.189046198036522,
    "estimated_duration": 3600.06421879663,
    "input_throughput": 4418.555346025788,
    "output_throughput": 3908.9191594209606,
    "total_throughput": 8327.474505446748,
    "itl": 179.41477442532877,
    "ttft": 2241585.1577252783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2067043561674,
    "arrivals": 1663594,
    "finished_requests": 64632,
    "scheduler_time": 117.09558516640976
}
#Debug simulation 
Total elapsed time: 10.189143182244152. Arrivals time: 0.2869040369987488 Scheduler time: 9.787504244130105 Scheduler overhead time: 0.03496335260570049 Adapter cache time: 0.030436455737799406 Engine time: 0.03427490405738354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 19.754854855127633,
    "estimated_duration": 3600.082777691111,
    "input_throughput": 4618.844350758068,
    "output_throughput": 4073.6493868637112,
    "total_throughput": 8692.493737621779,
    "itl": 210.2795961970311,
    "ttft": 2223100.295124659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.451938712205717,
    "arrivals": 1663594,
    "finished_requests": 67509,
    "scheduler_time": 110.77808879100755
}
#Debug simulation 
Total elapsed time: 19.754987611901015. Arrivals time: 0.33802436338737607 Scheduler time: 19.30580002302304 Scheduler overhead time: 0.037945866119116545 Adapter cache time: 0.020477646496146917 Engine time: 0.0382101945579052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 10.174172285944223,
    "estimated_duration": 3600.117433549616,
    "input_throughput": 4418.490033619835,
    "output_throughput": 3908.8613801481033,
    "total_throughput": 8327.35141376794,
    "itl": 179.41725351647256,
    "ttft": 2241605.099269938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.259772454034524,
    "arrivals": 1663594,
    "finished_requests": 64632,
    "scheduler_time": 117.09573182157922
}
#Debug simulation 
Total elapsed time: 10.17426835373044. Arrivals time: 0.28198559349402785 Scheduler time: 9.77840605378151 Scheduler overhead time: 0.03433707915246487 Adapter cache time: 0.030401527881622314 Engine time: 0.034057374112308025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 19.577892385423183,
    "estimated_duration": 3600.129996586212,
    "input_throughput": 4621.30256845618,
    "output_throughput": 4074.7445269782793,
    "total_throughput": 8696.04709543446,
    "itl": 210.26981812745018,
    "ttft": 2223112.577167395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3471894814981615,
    "arrivals": 1663594,
    "finished_requests": 67526,
    "scheduler_time": 110.7857554731958
}
#Debug simulation 
Total elapsed time: 19.578025214374065. Arrivals time: 0.3462127782404423 Scheduler time: 19.12336299009621 Scheduler overhead time: 0.03696251753717661 Adapter cache time: 0.020079702138900757 Engine time: 0.03696485189720988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.207647535949945,
    "estimated_duration": 3600.172561211327,
    "input_throughput": 4418.422375467427,
    "output_throughput": 3908.8015256871918,
    "total_throughput": 8327.223901154619,
    "itl": 179.41981508529054,
    "ttft": 2241626.321868287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1287,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3147268586978615,
    "arrivals": 1663594,
    "finished_requests": 64632,
    "scheduler_time": 117.09590507867321
}
#Debug simulation 
Total elapsed time: 10.2077422356233. Arrivals time: 0.2855755789205432 Scheduler time: 9.807354702614248 Scheduler overhead time: 0.03459788765758276 Adapter cache time: 0.030350164510309696 Engine time: 0.03460496477782726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.50018987385556,
    "estimated_duration": 3600.0029387579357,
    "input_throughput": 4626.500112176689,
    "output_throughput": 4079.7547251634514,
    "total_throughput": 8706.25483734014,
    "itl": 210.1941642886152,
    "ttft": 2222193.2953901216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.267821418254213,
    "arrivals": 1660646,
    "finished_requests": 67339,
    "scheduler_time": 110.91163248886076
}
#Debug simulation 
Total elapsed time: 17.50032076286152. Arrivals time: 0.3480864576995373 Scheduler time: 17.047528327908367 Scheduler overhead time: 0.035498049575835466 Adapter cache time: 0.019177827052772045 Engine time: 0.03587763663381338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 19.782257398124784,
    "estimated_duration": 3600.224203664232,
    "input_throughput": 4626.506588963934,
    "output_throughput": 4074.9034421435776,
    "total_throughput": 8701.41003110751,
    "itl": 210.18905734096376,
    "ttft": 2223181.319006475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1408463382511456,
    "arrivals": 1660646,
    "finished_requests": 67331,
    "scheduler_time": 110.85893948721412
}
#Debug simulation 
Total elapsed time: 19.782349311746657. Arrivals time: 0.32772299321368337 Scheduler time: 19.347899129614234 Scheduler overhead time: 0.0369551507756114 Adapter cache time: 0.018136061262339354 Engine time: 0.036917137913405895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.70426400192082,
    "estimated_duration": 3600.1528031883645,
    "input_throughput": 4433.430154926927,
    "output_throughput": 3911.5825826971704,
    "total_throughput": 8345.012737624096,
    "itl": 178.94710371932183,
    "ttft": 2242912.0908581214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.412832429297227,
    "arrivals": 1660646,
    "finished_requests": 64533,
    "scheduler_time": 117.29120888066382
}
#Debug simulation 
Total elapsed time: 11.70439911680296. Arrivals time: 0.29255397990345955 Scheduler time: 11.299487739801407 Scheduler overhead time: 0.035168868489563465 Adapter cache time: 0.02670332882553339 Engine time: 0.03519221907481551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 17.33415883826092,
    "estimated_duration": 3600.060141138675,
    "input_throughput": 4626.42660039896,
    "output_throughput": 4079.6899007788684,
    "total_throughput": 8706.116501177828,
    "itl": 210.1970366943027,
    "ttft": 2222214.6722491877,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3247222185460674,
    "arrivals": 1660646,
    "finished_requests": 67339,
    "scheduler_time": 110.91193406922804
}
#Debug simulation 
Total elapsed time: 17.334260994102806. Arrivals time: 0.3147260411642492 Scheduler time: 16.91516784299165 Scheduler overhead time: 0.03538635093718767 Adapter cache time: 0.019797928165644407 Engine time: 0.034890242386609316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 11.69878095574677,
    "estimated_duration": 3600.195429813223,
    "input_throughput": 4433.377662730952,
    "output_throughput": 3911.536269221525,
    "total_throughput": 8344.913931952477,
    "itl": 178.94908104920654,
    "ttft": 2242928.0224790173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4553372091054917,
    "arrivals": 1660646,
    "finished_requests": 64533,
    "scheduler_time": 117.29133072574821
}
#Debug simulation 
Total elapsed time: 11.698888590093702. Arrivals time: 0.2960879229940474 Scheduler time: 11.289599368348718 Scheduler overhead time: 0.03581398958340287 Adapter cache time: 0.02669433830305934 Engine time: 0.03530129557475448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.431633055675775,
    "estimated_duration": 3600.185820222622,
    "input_throughput": 4626.605078670638,
    "output_throughput": 4079.9505174129354,
    "total_throughput": 8706.555596083574,
    "itl": 210.19069636217213,
    "ttft": 2222247.09694343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 741,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2156272685224705,
    "arrivals": 1660646,
    "finished_requests": 67346,
    "scheduler_time": 110.91864377465902
}
#Debug simulation 
Total elapsed time: 17.431726841721684. Arrivals time: 0.3288165582343936 Scheduler time: 16.998516978230327 Scheduler overhead time: 0.03586591640487313 Adapter cache time: 0.019248450640589 Engine time: 0.03507111594080925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.732315824832767,
    "estimated_duration": 3600.04093852658,
    "input_throughput": 4433.275141179944,
    "output_throughput": 3911.2452442729464,
    "total_throughput": 8344.52038545289,
    "itl": 178.95104538111934,
    "ttft": 2242870.1830441677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5006085722148863,
    "arrivals": 1660646,
    "finished_requests": 64526,
    "scheduler_time": 117.28497022825995
}
#Debug simulation 
Total elapsed time: 11.732456932775676. Arrivals time: 0.29064065124839544 Scheduler time: 11.328047000337392 Scheduler overhead time: 0.03596149617806077 Adapter cache time: 0.02693404583260417 Engine time: 0.03552991198375821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.20843995222822,
    "estimated_duration": 3600.2108847894433,
    "input_throughput": 4657.9799174682985,
    "output_throughput": 4074.5313175891692,
    "total_throughput": 8732.511235057467,
    "itl": 209.28428465458606,
    "ttft": 2220296.609305823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.228035077583086,
    "arrivals": 1659330,
    "finished_requests": 67703,
    "scheduler_time": 111.0423375993261
}
#Debug simulation 
Total elapsed time: 17.208531512878835. Arrivals time: 0.3237701337784529 Scheduler time: 16.78119195671752 Scheduler overhead time: 0.03536512516438961 Adapter cache time: 0.018816541880369186 Engine time: 0.035304450429975986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 17.394397592172027,
    "estimated_duration": 3600.1155426482806,
    "input_throughput": 4657.784118691057,
    "output_throughput": 4074.4631182613875,
    "total_throughput": 8732.247236952446,
    "itl": 209.29305188208707,
    "ttft": 2220287.931864351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3749253441323575,
    "arrivals": 1659330,
    "finished_requests": 67698,
    "scheduler_time": 111.03563816579089
}
#Debug simulation 
Total elapsed time: 17.394540806300938. Arrivals time: 0.3185104336589575 Scheduler time: 16.970375328790396 Scheduler overhead time: 0.036298482213169336 Adapter cache time: 0.018801190424710512 Engine time: 0.03656234871596098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.053833741229028,
    "estimated_duration": 3600.072263719946,
    "input_throughput": 4462.670419676272,
    "output_throughput": 3907.7118372794894,
    "total_throughput": 8370.382256955761,
    "itl": 179.18021481765493,
    "ttft": 2241989.643319895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8483099581859426,
    "arrivals": 1659330,
    "finished_requests": 64884,
    "scheduler_time": 117.13021342110879
}
#Debug simulation 
Total elapsed time: 10.053921043872833. Arrivals time: 0.2933768657967448 Scheduler time: 9.646940526552498 Scheduler overhead time: 0.03450439777225256 Adapter cache time: 0.029868238139897585 Engine time: 0.0341333975084126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 17.911250634118915,
    "estimated_duration": 3600.01336175934,
    "input_throughput": 4657.916322789742,
    "output_throughput": 4074.578765683089,
    "total_throughput": 8732.49508847283,
    "itl": 209.2879014850671,
    "ttft": 2220251.3135739365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2731851098406857,
    "arrivals": 1659330,
    "finished_requests": 67698,
    "scheduler_time": 111.03519751111348
}
#Debug simulation 
Total elapsed time: 17.911399939097464. Arrivals time: 0.3334093396551907 Scheduler time: 17.472151968628168 Scheduler overhead time: 0.03622354939579964 Adapter cache time: 0.019184024538844824 Engine time: 0.03581553045660257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 10.051674175076187,
    "estimated_duration": 3600.1223180882203,
    "input_throughput": 4462.608372854265,
    "output_throughput": 3907.657506334557,
    "total_throughput": 8370.265879188823,
    "itl": 179.1824316632182,
    "ttft": 2242007.4604162103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.898234211392702,
    "arrivals": 1659330,
    "finished_requests": 64884,
    "scheduler_time": 117.13034353622155
}
#Debug simulation 
Total elapsed time: 10.051741529721767. Arrivals time: 0.28515509655699134 Scheduler time: 9.652650160714984 Scheduler overhead time: 0.034613233990967274 Adapter cache time: 0.02968819160014391 Engine time: 0.034629967994987965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 17.28841477399692,
    "estimated_duration": 3600.1593688390053,
    "input_throughput": 4658.046570146134,
    "output_throughput": 4074.5896214951663,
    "total_throughput": 8732.6361916413,
    "itl": 209.2817094517206,
    "ttft": 2220277.823226488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 728,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1767566146887436,
    "arrivals": 1659330,
    "finished_requests": 67703,
    "scheduler_time": 111.04210011167856
}
#Debug simulation 
Total elapsed time: 17.28854944789782. Arrivals time: 0.3267211373895407 Scheduler time: 16.85839697252959 Scheduler overhead time: 0.03513633320108056 Adapter cache time: 0.018709616735577583 Engine time: 0.03547667386010289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.99807331012562,
    "estimated_duration": 3600.1717745623305,
    "input_throughput": 4462.547068869546,
    "output_throughput": 3907.6038258508484,
    "total_throughput": 8370.150894720395,
    "itl": 179.18461001883463,
    "ttft": 2242025.2728120084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9475296956673867,
    "arrivals": 1659330,
    "finished_requests": 64884,
    "scheduler_time": 117.13050452610682
}
#Debug simulation 
Total elapsed time: 9.998166002798826. Arrivals time: 0.28206390468403697 Scheduler time: 9.602734194602817 Scheduler overhead time: 0.034285989589989185 Adapter cache time: 0.029627549927681684 Engine time: 0.03433292778208852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 18.708386932034045,
    "estimated_duration": 3600.023617609086,
    "input_throughput": 4634.126820278973,
    "output_throughput": 4070.550239815464,
    "total_throughput": 8704.677060094436,
    "itl": 210.0755779872992,
    "ttft": 2216137.709270183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2586399550224145,
    "arrivals": 1542191,
    "finished_requests": 67524,
    "scheduler_time": 110.7427197321698
}
#Debug simulation 
Total elapsed time: 18.708518548868597. Arrivals time: 0.3417464215308428 Scheduler time: 18.261449871584773 Scheduler overhead time: 0.0363726238720119 Adapter cache time: 0.018963180482387543 Engine time: 0.03575789136812091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 18.84300380712375,
    "estimated_duration": 3600.2125215419032,
    "input_throughput": 4634.100320515153,
    "output_throughput": 4070.383043310972,
    "total_throughput": 8704.483363826124,
    "itl": 210.0865058129122,
    "ttft": 2216277.0525740217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4090416833316017,
    "arrivals": 1542191,
    "finished_requests": 67526,
    "scheduler_time": 110.74703460072054
}
#Debug simulation 
Total elapsed time: 18.843096170108765. Arrivals time: 0.3276406582444906 Scheduler time: 18.40810087090358 Scheduler overhead time: 0.037198870442807674 Adapter cache time: 0.018918681889772415 Engine time: 0.03660627221688628 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.153778733219951,
    "estimated_duration": 3600.1006563755245,
    "input_throughput": 4446.625671882376,
    "output_throughput": 3910.590659477238,
    "total_throughput": 8357.216331359614,
    "itl": 179.5758519061712,
    "ttft": 2235994.9763016393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3864607935398414,
    "arrivals": 1542191,
    "finished_requests": 64800,
    "scheduler_time": 117.01379087354037
}
#Debug simulation 
Total elapsed time: 9.153898358345032. Arrivals time: 0.27678675996139646 Scheduler time: 8.769382770173252 Scheduler overhead time: 0.03311001183465123 Adapter cache time: 0.025937556754797697 Engine time: 0.03369179554283619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 18.864450861234218,
    "estimated_duration": 3600.187579715126,
    "input_throughput": 4635.1504277231115,
    "output_throughput": 4070.7645575399865,
    "total_throughput": 8705.914985263098,
    "itl": 210.1130861733054,
    "ttft": 2216110.505977969,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3063543753372304,
    "arrivals": 1542191,
    "finished_requests": 67539,
    "scheduler_time": 110.740840300361
}
#Debug simulation 
Total elapsed time: 18.864544430281967. Arrivals time: 0.33549157390370965 Scheduler time: 18.422417858615518 Scheduler overhead time: 0.03680375264957547 Adapter cache time: 0.019362323451787233 Engine time: 0.03628470283001661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 9.193000389728695,
    "estimated_duration": 3600.1451642073225,
    "input_throughput": 4446.57069919143,
    "output_throughput": 3910.5423136735653,
    "total_throughput": 8357.113012864995,
    "itl": 179.5778606650368,
    "ttft": 2236011.305957263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.430851880144329,
    "arrivals": 1542191,
    "finished_requests": 64800,
    "scheduler_time": 117.01390761877396
}
#Debug simulation 
Total elapsed time: 9.193120426964015. Arrivals time: 0.27593428222462535 Scheduler time: 8.810206329915673 Scheduler overhead time: 0.03327117534354329 Adapter cache time: 0.02532285824418068 Engine time: 0.03343466017395258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 18.71771947806701,
    "estimated_duration": 3600.2059782256197,
    "input_throughput": 4634.234291289882,
    "output_throughput": 4070.6218168169453,
    "total_throughput": 8704.856108106827,
    "itl": 210.073117309602,
    "ttft": 2216186.9706974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 738,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2066571176377643,
    "arrivals": 1542191,
    "finished_requests": 67529,
    "scheduler_time": 110.74976487240743
}
#Debug simulation 
Total elapsed time: 18.717807508073747. Arrivals time: 0.3234013896435499 Scheduler time: 18.288608077913523 Scheduler overhead time: 0.03639937983825803 Adapter cache time: 0.019649234134703875 Engine time: 0.03538917051628232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.148270756937563,
    "estimated_duration": 3600.1879284396678,
    "input_throughput": 4446.51788134239,
    "output_throughput": 3910.495862948375,
    "total_throughput": 8357.013744290765,
    "itl": 179.579750290364,
    "ttft": 2236027.1123235547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.473482413739011,
    "arrivals": 1542191,
    "finished_requests": 64800,
    "scheduler_time": 117.01404131756566
}
#Debug simulation 
Total elapsed time: 9.148405990097672. Arrivals time: 0.27960120560601354 Scheduler time: 8.76154338894412 Scheduler overhead time: 0.0331306541338563 Adapter cache time: 0.025979917962104082 Engine time: 0.033285886980593204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 14.481006809975952,
    "estimated_duration": 3600.2005595756946,
    "input_throughput": 4633.111606972767,
    "output_throughput": 4073.463341089084,
    "total_throughput": 8706.57494806185,
    "itl": 210.12193669766444,
    "ttft": 2218651.4485875955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.442269219658386,
    "arrivals": 1530695,
    "finished_requests": 67408,
    "scheduler_time": 110.71268434172129
}
#Debug simulation 
Total elapsed time: 14.481101751327515. Arrivals time: 0.30587084079161286 Scheduler time: 14.074120352044702 Scheduler overhead time: 0.033929971512407064 Adapter cache time: 0.019792528823018074 Engine time: 0.03355324361473322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 14.46990551194176,
    "estimated_duration": 3600.1317445913196,
    "input_throughput": 4632.950453843293,
    "output_throughput": 4073.3301002196213,
    "total_throughput": 8706.280554062914,
    "itl": 210.12897951361688,
    "ttft": 2218662.2234372976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.604250035379087,
    "arrivals": 1530695,
    "finished_requests": 67405,
    "scheduler_time": 110.7061227953484
}
#Debug simulation 
Total elapsed time: 14.470036247279495. Arrivals time: 0.30961550725623965 Scheduler time: 14.0590102635324 Scheduler overhead time: 0.033784535713493824 Adapter cache time: 0.019983703270554543 Engine time: 0.03371687140315771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.156636447180063,
    "estimated_duration": 3600.060723272672,
    "input_throughput": 4445.509181703832,
    "output_throughput": 3910.2032110178375,
    "total_throughput": 8355.712392721669,
    "itl": 179.50862171761912,
    "ttft": 2239005.048569662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6620305618084488,
    "arrivals": 1530695,
    "finished_requests": 64618,
    "scheduler_time": 117.00147492398999
}
#Debug simulation 
Total elapsed time: 8.156731381081045. Arrivals time: 0.3812062186188996 Scheduler time: 7.668299595825374 Scheduler overhead time: 0.03256743401288986 Adapter cache time: 0.027119279839098454 Engine time: 0.03272233624011278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 14.461512899026275,
    "estimated_duration": 3600.0271825635464,
    "input_throughput": 4633.08501690892,
    "output_throughput": 4073.4484092304897,
    "total_throughput": 8706.53342613941,
    "itl": 210.12367627024392,
    "ttft": 2218632.0472557764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.500058229176772,
    "arrivals": 1530695,
    "finished_requests": 67405,
    "scheduler_time": 110.7057525737458
}
#Debug simulation 
Total elapsed time: 14.461652287747711. Arrivals time: 0.3087749653495848 Scheduler time: 14.051944066770375 Scheduler overhead time: 0.03359936270862818 Adapter cache time: 0.019984996877610683 Engine time: 0.033599997870624065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 8.014663383830339,
    "estimated_duration": 3600.10724826491,
    "input_throughput": 4445.451731393074,
    "output_throughput": 3910.152678586024,
    "total_throughput": 8355.604409979098,
    "itl": 179.5107498961472,
    "ttft": 2239022.479105315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7084337089955826,
    "arrivals": 1530695,
    "finished_requests": 64618,
    "scheduler_time": 117.0015967690744
}
#Debug simulation 
Total elapsed time: 8.014758363831788. Arrivals time: 0.2622633269056678 Scheduler time: 7.645427904557437 Scheduler overhead time: 0.03275886783376336 Adapter cache time: 0.02701240312308073 Engine time: 0.032584411557763815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 14.509689935017377,
    "estimated_duration": 3600.144149943302,
    "input_throughput": 4633.184201877775,
    "output_throughput": 4073.5271670249535,
    "total_throughput": 8706.711368902728,
    "itl": 210.11910300605265,
    "ttft": 2218635.0749437013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 798,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3860601353318884,
    "arrivals": 1530695,
    "finished_requests": 67408,
    "scheduler_time": 110.71248379353374
}
#Debug simulation 
Total elapsed time: 14.509796923957765. Arrivals time: 0.3287715930491686 Scheduler time: 14.079103701747954 Scheduler overhead time: 0.03383725509047508 Adapter cache time: 0.020151331555098295 Engine time: 0.03368875337764621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.132082195952535,
    "estimated_duration": 3600.153155377087,
    "input_throughput": 4445.39504551264,
    "output_throughput": 3910.102818535661,
    "total_throughput": 8355.4978640483,
    "itl": 179.5128430950709,
    "ttft": 2239040.3942714455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.754208087250642,
    "arrivals": 1530695,
    "finished_requests": 64618,
    "scheduler_time": 117.00172950302945
}
#Debug simulation 
Total elapsed time: 8.132174686994404. Arrivals time: 0.3785352441482246 Scheduler time: 7.646233079023659 Scheduler overhead time: 0.03293281840160489 Adapter cache time: 0.027000609319657087 Engine time: 0.032688642386347055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 13.137289602775127,
    "estimated_duration": 3600.1538634975773,
    "input_throughput": 4650.594845336467,
    "output_throughput": 4070.3535336580376,
    "total_throughput": 8720.948378994504,
    "itl": 209.76038303405255,
    "ttft": 2221329.6815874707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.90056288898227,
    "arrivals": 1525074,
    "finished_requests": 67086,
    "scheduler_time": 110.78449930594505
}
#Debug simulation 
Total elapsed time: 13.137380173895508. Arrivals time: 0.4261312335729599 Scheduler time: 12.61611133441329 Scheduler overhead time: 0.0325980051420629 Adapter cache time: 0.016623837873339653 Engine time: 0.03236148972064257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.959886839147657,
    "estimated_duration": 3600.048205819853,
    "input_throughput": 4650.489672036845,
    "output_throughput": 4070.1004992968187,
    "total_throughput": 8720.590171333663,
    "itl": 209.76489172554275,
    "ttft": 2221335.816895101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 620,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.022172454036777,
    "arrivals": 1525074,
    "finished_requests": 67082,
    "scheduler_time": 110.77801924964668
}
#Debug simulation 
Total elapsed time: 12.95998469600454. Arrivals time: 0.2986407969146967 Scheduler time: 12.566050436347723 Scheduler overhead time: 0.032830944750458 Adapter cache time: 0.016388293355703354 Engine time: 0.03240344952791929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.518124585971236,
    "estimated_duration": 3600.190720812641,
    "input_throughput": 4455.428682505836,
    "output_throughput": 3903.052390743405,
    "total_throughput": 8358.48107324924,
    "itl": 178.46855665388364,
    "ttft": 2243460.9629023587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.247166587077047,
    "arrivals": 1525074,
    "finished_requests": 64228,
    "scheduler_time": 117.25315191820205
}
#Debug simulation 
Total elapsed time: 7.518216431606561. Arrivals time: 0.2677553603425622 Scheduler time: 7.145968730095774 Scheduler overhead time: 0.03258317708969116 Adapter cache time: 0.023961457889527082 Engine time: 0.0331598361954093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 13.000309737864882,
    "estimated_duration": 3600.1271400910805,
    "input_throughput": 4647.516420649717,
    "output_throughput": 4070.515409527802,
    "total_throughput": 8718.031830177519,
    "itl": 209.77365680148446,
    "ttft": 2221362.452515911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8522374335885854,
    "arrivals": 1525074,
    "finished_requests": 67084,
    "scheduler_time": 110.78040661103378
}
#Debug simulation 
Total elapsed time: 13.000420190859586. Arrivals time: 0.2964568380266428 Scheduler time: 12.608223320916295 Scheduler overhead time: 0.03301750123500824 Adapter cache time: 0.01641888450831175 Engine time: 0.032635708805173635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 7.4965769299305975,
    "estimated_duration": 3600.0281556906457,
    "input_throughput": 4455.2243222450625,
    "output_throughput": 3902.9578082020416,
    "total_throughput": 8358.182130447105,
    "itl": 178.47019205840033,
    "ttft": 2243426.463548107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2875335525162526,
    "arrivals": 1525074,
    "finished_requests": 64223,
    "scheduler_time": 117.24668604281241
}
#Debug simulation 
Total elapsed time: 7.49666934274137. Arrivals time: 0.2629724983125925 Scheduler time: 7.129284360446036 Scheduler overhead time: 0.0325509044341743 Adapter cache time: 0.02440840331837535 Engine time: 0.03272458491846919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 12.961439765058458,
    "estimated_duration": 3600.1099206044664,
    "input_throughput": 4650.651610434394,
    "output_throughput": 4070.403216338344,
    "total_throughput": 8721.054826772737,
    "itl": 209.75827372350304,
    "ttft": 2221316.104387665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.856821233134222,
    "arrivals": 1525074,
    "finished_requests": 67086,
    "scheduler_time": 110.78429806858847
}
#Debug simulation 
Total elapsed time: 12.961571555119008. Arrivals time: 0.29913875414058566 Scheduler time: 12.566565208602697 Scheduler overhead time: 0.033084478229284286 Adapter cache time: 0.01695122430101037 Engine time: 0.03233643900603056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.486279871780425,
    "estimated_duration": 3600.0706856446454,
    "input_throughput": 4455.171689810306,
    "output_throughput": 3902.911700047358,
    "total_throughput": 8358.083389857664,
    "itl": 178.47208827456058,
    "ttft": 2243442.478865092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3299125785380994,
    "arrivals": 1525074,
    "finished_requests": 64223,
    "scheduler_time": 117.24683697082985
}
#Debug simulation 
Total elapsed time: 7.486372007988393. Arrivals time: 0.26288200356066227 Scheduler time: 7.119034524541348 Scheduler overhead time: 0.03258674778044224 Adapter cache time: 0.024097927380353212 Engine time: 0.03292967565357685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.409313292708248,
    "estimated_duration": 3600.030198271475,
    "input_throughput": 4629.455610678524,
    "output_throughput": 4068.498649548135,
    "total_throughput": 8697.95426022666,
    "itl": 210.3599495869446,
    "ttft": 2218161.6710138195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8056877689203514,
    "arrivals": 1522091,
    "finished_requests": 67217,
    "scheduler_time": 110.7106261724105
}
#Debug simulation 
Total elapsed time: 11.409457196947187. Arrivals time: 0.2944505740888417 Scheduler time: 11.02314177621156 Scheduler overhead time: 0.031303422059863806 Adapter cache time: 0.015608151443302631 Engine time: 0.03141952399164438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.529762555845082,
    "estimated_duration": 3600.1473826819365,
    "input_throughput": 4629.304922395843,
    "output_throughput": 4068.366220354262,
    "total_throughput": 8697.671142750105,
    "itl": 210.36570940645126,
    "ttft": 2218203.6985540437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9222560622287035,
    "arrivals": 1522091,
    "finished_requests": 67217,
    "scheduler_time": 110.71124228952279
}
#Debug simulation 
Total elapsed time: 11.529851827770472. Arrivals time: 0.4116944717243314 Scheduler time: 11.02511636260897 Scheduler overhead time: 0.032288636080920696 Adapter cache time: 0.015709539875388145 Engine time: 0.031612527556717396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.335686360951513,
    "estimated_duration": 3600.186678340024,
    "input_throughput": 4440.554734614821,
    "output_throughput": 3908.6192626234074,
    "total_throughput": 8349.17399723823,
    "itl": 179.3606647826303,
    "ttft": 2240103.6858730516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0564780990779106,
    "arrivals": 1522091,
    "finished_requests": 64483,
    "scheduler_time": 117.09077761665532
}
#Debug simulation 
Total elapsed time: 7.335796949919313. Arrivals time: 0.26287030847743154 Scheduler time: 6.970032440498471 Scheduler overhead time: 0.03252371121197939 Adapter cache time: 0.02327114064246416 Engine time: 0.03234755992889404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.41827576002106,
    "estimated_duration": 3600.068133991497,
    "input_throughput": 4629.406827787378,
    "output_throughput": 4068.4557777412874,
    "total_throughput": 8697.862605528666,
    "itl": 210.3618055143183,
    "ttft": 2218175.994154838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8433971657697,
    "arrivals": 1522091,
    "finished_requests": 67217,
    "scheduler_time": 110.71085249551976
}
#Debug simulation 
Total elapsed time: 11.418387947138399. Arrivals time: 0.29702929873019457 Scheduler time: 11.02896931907162 Scheduler overhead time: 0.03147823363542557 Adapter cache time: 0.01563806924968958 Engine time: 0.031769650522619486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 7.313027378171682,
    "estimated_duration": 3600.0216333739154,
    "input_throughput": 4440.4949825310205,
    "output_throughput": 3908.5812345001877,
    "total_throughput": 8349.076217031208,
    "itl": 179.36419809217213,
    "ttft": 2240022.1006287527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0949587577208884,
    "arrivals": 1522091,
    "finished_requests": 64479,
    "scheduler_time": 117.08429271515125
}
#Debug simulation 
Total elapsed time: 7.313122062012553. Arrivals time: 0.27027426892891526 Scheduler time: 6.939522195607424 Scheduler overhead time: 0.03261672146618366 Adapter cache time: 0.023461395408958197 Engine time: 0.03249495290219784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.479881916195154,
    "estimated_duration": 3600.226280388926,
    "input_throughput": 4629.583726664934,
    "output_throughput": 4068.664539168241,
    "total_throughput": 8698.248265833176,
    "itl": 210.3603498352003,
    "ttft": 2218191.4304072103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7641296739922578,
    "arrivals": 1522091,
    "finished_requests": 67223,
    "scheduler_time": 110.71771250762365
}
#Debug simulation 
Total elapsed time: 11.48002225579694. Arrivals time: 0.40422328002750874 Scheduler time: 10.983631955459714 Scheduler overhead time: 0.031406575348228216 Adapter cache time: 0.015823815017938614 Engine time: 0.03142816387116909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.317235702648759,
    "estimated_duration": 3600.0607519869664,
    "input_throughput": 4440.446731677232,
    "output_throughput": 3908.538763473329,
    "total_throughput": 8348.98549515056,
    "itl": 179.36595648142716,
    "ttft": 2240037.295341792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1339424315095292,
    "arrivals": 1522091,
    "finished_requests": 64479,
    "scheduler_time": 117.08442765444721
}
#Debug simulation 
Total elapsed time: 7.317324659787118. Arrivals time: 0.2675915998406708 Scheduler time: 6.9464698396623135 Scheduler overhead time: 0.03271832037717104 Adapter cache time: 0.023417445365339518 Engine time: 0.03240252751857042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.652005943935364,
    "estimated_duration": 3600.2176324250863,
    "input_throughput": 4617.36641981904,
    "output_throughput": 4071.9168941254393,
    "total_throughput": 8689.28331394448,
    "itl": 210.60938389296984,
    "ttft": 2216541.600456059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4812760680634682,
    "arrivals": 1520700,
    "finished_requests": 67357,
    "scheduler_time": 110.69511620500087
}
#Debug simulation 
Total elapsed time: 11.652136613614857. Arrivals time: 0.7111595133319497 Scheduler time: 10.851472256239504 Scheduler overhead time: 0.03148199385032058 Adapter cache time: 0.01375839626416564 Engine time: 0.03078344278037548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.316693301312625,
    "estimated_duration": 3600.0797832672047,
    "input_throughput": 4617.394613658819,
    "output_throughput": 4072.041977551899,
    "total_throughput": 8689.436591210719,
    "itl": 210.61377253852942,
    "ttft": 2216559.358086682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5791606305888903,
    "arrivals": 1520700,
    "finished_requests": 67356,
    "scheduler_time": 110.68840433175826
}
#Debug simulation 
Total elapsed time: 11.316757730208337. Arrivals time: 0.29722362803295255 Scheduler time: 10.929120819084346 Scheduler overhead time: 0.0319088869728148 Adapter cache time: 0.013808839488774538 Engine time: 0.03121100878342986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.165916968137026,
    "estimated_duration": 3600.1755442306253,
    "input_throughput": 4429.245408756242,
    "output_throughput": 3908.0047145330855,
    "total_throughput": 8337.250123289326,
    "itl": 179.3450441538389,
    "ttft": 2239183.7371440222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.936102917902149,
    "arrivals": 1520700,
    "finished_requests": 64636,
    "scheduler_time": 117.1123259895057
}
#Debug simulation 
Total elapsed time: 7.166023679077625. Arrivals time: 0.26201285142451525 Scheduler time: 6.801702312193811 Scheduler overhead time: 0.03238624148070812 Adapter cache time: 0.02297302708029747 Engine time: 0.03220579260960221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.410815769806504,
    "estimated_duration": 3600.014056953565,
    "input_throughput": 4617.478914531475,
    "output_throughput": 4072.1163217916537,
    "total_throughput": 8689.595236323128,
    "itl": 210.61066965382838,
    "ttft": 2216530.031929696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5137853796384237,
    "arrivals": 1520700,
    "finished_requests": 67356,
    "scheduler_time": 110.68805326905468
}
#Debug simulation 
Total elapsed time: 11.4109100070782. Arrivals time: 0.29664499079808593 Scheduler time: 11.022502104286104 Scheduler overhead time: 0.03184909000992775 Adapter cache time: 0.013814711943268776 Engine time: 0.03257604502141476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 7.138378200121224,
    "estimated_duration": 3600.0098814101684,
    "input_throughput": 4428.63812189173,
    "output_throughput": 3907.8898290382517,
    "total_throughput": 8336.527950929982,
    "itl": 179.3485220908736,
    "ttft": 2239109.6590169044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 897,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9710370425507464,
    "arrivals": 1520700,
    "finished_requests": 64628,
    "scheduler_time": 117.10589721160667
}
#Debug simulation 
Total elapsed time: 7.138468329794705. Arrivals time: 0.26484334794804454 Scheduler time: 6.771398939192295 Scheduler overhead time: 0.032479820773005486 Adapter cache time: 0.022769662085920572 Engine time: 0.03221758687868714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.189709932077676,
    "estimated_duration": 3600.1833393246216,
    "input_throughput": 4617.410401970945,
    "output_throughput": 4071.9556806654496,
    "total_throughput": 8689.366082636394,
    "itl": 210.60775334912563,
    "ttft": 2216526.265680499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4471843427326385,
    "arrivals": 1520700,
    "finished_requests": 67357,
    "scheduler_time": 110.69491482981049
}
#Debug simulation 
Total elapsed time: 11.189823904074728. Arrivals time: 0.2932795463129878 Scheduler time: 10.806954902596772 Scheduler overhead time: 0.0319513943977654 Adapter cache time: 0.01399726839736104 Engine time: 0.030377880204468966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.106149424798787,
    "estimated_duration": 3600.0477500662173,
    "input_throughput": 4428.591537350234,
    "output_throughput": 3907.84872221243,
    "total_throughput": 8336.440259562663,
    "itl": 179.35023050560207,
    "ttft": 2239125.121845417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 897,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.00876317847523,
    "arrivals": 1520700,
    "finished_requests": 64628,
    "scheduler_time": 117.10603973176195
}
#Debug simulation 
Total elapsed time: 7.106237126979977. Arrivals time: 0.26436903653666377 Scheduler time: 6.7390964245423675 Scheduler overhead time: 0.0324427867308259 Adapter cache time: 0.023215339984744787 Engine time: 0.03249054169282317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.870378719177097,
    "estimated_duration": 3600.1712618500055,
    "input_throughput": 4596.281342320603,
    "output_throughput": 4075.1383567405546,
    "total_throughput": 8671.419699061156,
    "itl": 211.31538623667223,
    "ttft": 2219202.4128138926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7536594772734928,
    "arrivals": 1507762,
    "finished_requests": 67030,
    "scheduler_time": 110.5690318979855
}
#Debug simulation 
Total elapsed time: 11.870476509910077. Arrivals time: 0.29018076695501804 Scheduler time: 11.488000178243965 Scheduler overhead time: 0.03209261875599623 Adapter cache time: 0.015660203527659178 Engine time: 0.030978285241872072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.380656783934683,
    "estimated_duration": 3600.049207483844,
    "input_throughput": 4596.209675579624,
    "output_throughput": 4074.97374466536,
    "total_throughput": 8671.183420244983,
    "itl": 211.3216600329623,
    "ttft": 2219185.1521455497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8701994212600457,
    "arrivals": 1507762,
    "finished_requests": 67027,
    "scheduler_time": 110.56233199103796
}
#Debug simulation 
Total elapsed time: 11.380792636889964. Arrivals time: 0.28810789715498686 Scheduler time: 11.001715062186122 Scheduler overhead time: 0.031149139627814293 Adapter cache time: 0.015480760484933853 Engine time: 0.030965270940214396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.67429986782372,
    "estimated_duration": 3600.145478954129,
    "input_throughput": 4408.607955645958,
    "output_throughput": 3911.033618588779,
    "total_throughput": 8319.641574234736,
    "itl": 180.10340552932553,
    "ttft": 2242697.5628576754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.386798041034451,
    "arrivals": 1507762,
    "finished_requests": 64321,
    "scheduler_time": 116.91917998752402
}
#Debug simulation 
Total elapsed time: 6.674390992615372. Arrivals time: 0.2527628084644675 Scheduler time: 6.318595345132053 Scheduler overhead time: 0.03198802703991532 Adapter cache time: 0.024194911122322083 Engine time: 0.03224118426442146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.600223830901086,
    "estimated_duration": 3600.2112379722125,
    "input_throughput": 4596.230306008427,
    "output_throughput": 4075.093107109855,
    "total_throughput": 8671.323413118282,
    "itl": 211.31723187754616,
    "ttft": 2219220.0042015575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7933835013932444,
    "arrivals": 1507762,
    "finished_requests": 67030,
    "scheduler_time": 110.56928399601645
}
#Debug simulation 
Total elapsed time: 11.600333746988326. Arrivals time: 0.3149224300868809 Scheduler time: 11.191455941647291 Scheduler overhead time: 0.03252856666222215 Adapter cache time: 0.015850738156586885 Engine time: 0.03193719079717994 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 7.098172251600772,
    "estimated_duration": 3600.1891190522942,
    "input_throughput": 4408.554516207752,
    "output_throughput": 3910.986210553979,
    "total_throughput": 8319.54072676173,
    "itl": 180.10543289637997,
    "ttft": 2242713.9119004016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4303088511340345,
    "arrivals": 1507762,
    "finished_requests": 64321,
    "scheduler_time": 116.91930927563394
}
#Debug simulation 
Total elapsed time: 7.0982488938607275. Arrivals time: 0.672212852165103 Scheduler time: 6.322326174471527 Scheduler overhead time: 0.03232582053169608 Adapter cache time: 0.02460122387856245 Engine time: 0.032170281279832125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.462797585874796,
    "estimated_duration": 3600.130696370751,
    "input_throughput": 4596.333132205794,
    "output_throughput": 4075.184274501439,
    "total_throughput": 8671.517406707233,
    "itl": 211.3134049345366,
    "ttft": 2219186.030229728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7132988189789227,
    "arrivals": 1507762,
    "finished_requests": 67030,
    "scheduler_time": 110.56882707694996
}
#Debug simulation 
Total elapsed time: 11.462868138682097. Arrivals time: 0.30408190190792084 Scheduler time: 11.067039118614048 Scheduler overhead time: 0.03127429448068142 Adapter cache time: 0.015781129244714975 Engine time: 0.03125242004171014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.683299534954131,
    "estimated_duration": 3600.022609321175,
    "input_throughput": 4408.513424028914,
    "output_throughput": 3911.0151596117043,
    "total_throughput": 8319.528583640618,
    "itl": 180.1090314289333,
    "ttft": 2242649.669808886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4739454150200317,
    "arrivals": 1507762,
    "finished_requests": 64317,
    "scheduler_time": 116.91271483091906
}
#Debug simulation 
Total elapsed time: 6.683418456930667. Arrivals time: 0.2569168866612017 Scheduler time: 6.323129674419761 Scheduler overhead time: 0.03220361704006791 Adapter cache time: 0.024723361246287823 Engine time: 0.03178049111738801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.709353773854673,
    "estimated_duration": 3600.0846494435623,
    "input_throughput": 4588.784044995546,
    "output_throughput": 4077.691618242638,
    "total_throughput": 8666.475663238183,
    "itl": 211.15604776958463,
    "ttft": 2216620.301418309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8508155928133044,
    "arrivals": 1502157,
    "finished_requests": 66956,
    "scheduler_time": 110.58443005352423
}
#Debug simulation 
Total elapsed time: 10.709449698682874. Arrivals time: 0.3945167548954487 Scheduler time: 10.22950449725613 Scheduler overhead time: 0.031241107266396284 Adapter cache time: 0.009254037402570248 Engine time: 0.03154466021806002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.678958729840815,
    "estimated_duration": 3600.139992199457,
    "input_throughput": 4588.713504417733,
    "output_throughput": 4077.6289343769186,
    "total_throughput": 8666.34243879465,
    "itl": 211.15804955822102,
    "ttft": 2216644.8750956017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9055983299389525,
    "arrivals": 1502157,
    "finished_requests": 66956,
    "scheduler_time": 110.58499007227753
}
#Debug simulation 
Total elapsed time: 10.679067132994533. Arrivals time: 0.2909858305938542 Scheduler time: 10.30212848028168 Scheduler overhead time: 0.031705503817647696 Adapter cache time: 0.009454852901399136 Engine time: 0.03148876689374447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.511776422150433,
    "estimated_duration": 3600.033170749264,
    "input_throughput": 4390.46482360894,
    "output_throughput": 3908.634263242469,
    "total_throughput": 8299.099086851409,
    "itl": 179.41290783879256,
    "ttft": 2238513.144352523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.816756062004696,
    "arrivals": 1502157,
    "finished_requests": 64105,
    "scheduler_time": 117.06386959742841
}
#Debug simulation 
Total elapsed time: 6.511889045126736. Arrivals time: 0.3686762312427163 Scheduler time: 6.043502080719918 Scheduler overhead time: 0.03205439541488886 Adapter cache time: 0.020870141219347715 Engine time: 0.032137646805495024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 10.767112728208303,
    "estimated_duration": 3600.1045063500565,
    "input_throughput": 4588.7587348814795,
    "output_throughput": 4077.669127134107,
    "total_throughput": 8666.427862015587,
    "itl": 211.15675945042625,
    "ttft": 2216629.6485041594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8704591325530808,
    "arrivals": 1502157,
    "finished_requests": 66956,
    "scheduler_time": 110.58464342025573
}
#Debug simulation 
Total elapsed time: 10.767212867271155. Arrivals time: 0.30219920398667455 Scheduler time: 10.37855327501893 Scheduler overhead time: 0.031717813573777676 Adapter cache time: 0.009572614915668964 Engine time: 0.03179805725812912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.466892888769507,
    "estimated_duration": 3600.0682448417474,
    "input_throughput": 4390.422048983906,
    "output_throughput": 3908.596182908901,
    "total_throughput": 8299.018231892807,
    "itl": 179.41451378288752,
    "ttft": 2238525.841638377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.85171561462805,
    "arrivals": 1502157,
    "finished_requests": 64105,
    "scheduler_time": 117.0639841373211
}
#Debug simulation 
Total elapsed time: 6.467014328110963. Arrivals time: 0.36463601188734174 Scheduler time: 6.0030911793001 Scheduler overhead time: 0.03180564194917679 Adapter cache time: 0.021157358773052692 Engine time: 0.03171858889982104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.62758602714166,
    "estimated_duration": 3600.064866871073,
    "input_throughput": 4588.809260639254,
    "output_throughput": 4077.7140254027895,
    "total_throughput": 8666.523286042044,
    "itl": 211.15527567020433,
    "ttft": 2216611.7334978865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.831233981982806,
    "arrivals": 1502157,
    "finished_requests": 66956,
    "scheduler_time": 110.58422909183525
}
#Debug simulation 
Total elapsed time: 10.62768154637888. Arrivals time: 0.28359629213809967 Scheduler time: 10.259534294251353 Scheduler overhead time: 0.031189063098281622 Adapter cache time: 0.00933670299127698 Engine time: 0.030769122298806906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.512706561945379,
    "estimated_duration": 3600.1054699806446,
    "input_throughput": 4390.376651960971,
    "output_throughput": 3908.55576797189,
    "total_throughput": 8298.93241993286,
    "itl": 179.41615814806414,
    "ttft": 2238539.939364052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 862,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.888812981620456,
    "arrivals": 1502157,
    "finished_requests": 64105,
    "scheduler_time": 117.06411190925914
}
#Debug simulation 
Total elapsed time: 6.512808884959668. Arrivals time: 0.36399153526872396 Scheduler time: 6.0488497340120375 Scheduler overhead time: 0.031985482666641474 Adapter cache time: 0.021222718991339207 Engine time: 0.032094813883304596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.97594293486327,
    "estimated_duration": 3600.011841323738,
    "input_throughput": 4596.987379328951,
    "output_throughput": 4075.0654849528723,
    "total_throughput": 8672.052864281823,
    "itl": 211.25981729503215,
    "ttft": 2220464.6942186933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.465973629343804,
    "arrivals": 1499241,
    "finished_requests": 67007,
    "scheduler_time": 110.59789548161703
}
#Debug simulation 
Total elapsed time: 8.97603276791051. Arrivals time: 0.2733741495758295 Scheduler time: 8.617076725233346 Scheduler overhead time: 0.02976200869306922 Adapter cache time: 0.01298183435574174 Engine time: 0.029749781358987093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 9.024374323897064,
    "estimated_duration": 3600.201200945054,
    "input_throughput": 4594.076018767604,
    "output_throughput": 4078.542053745651,
    "total_throughput": 8672.618072513254,
    "itl": 211.3667065095974,
    "ttft": 2220382.7179723545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5552402282296736,
    "arrivals": 1499241,
    "finished_requests": 67015,
    "scheduler_time": 110.58622508579143
}
#Debug simulation 
Total elapsed time: 9.024463342037052. Arrivals time: 0.2811698387376964 Scheduler time: 8.657268684357405 Scheduler overhead time: 0.02979570208117366 Adapter cache time: 0.013123465701937675 Engine time: 0.02989925444126129 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.164372453931719,
    "estimated_duration": 3600.0217924254475,
    "input_throughput": 4398.78031664108,
    "output_throughput": 3915.586852740397,
    "total_throughput": 8314.367169381478,
    "itl": 180.3799919437488,
    "ttft": 2239788.2954888735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9783583514950904,
    "arrivals": 1499241,
    "finished_requests": 64179,
    "scheduler_time": 116.91453149647187
}
#Debug simulation 
Total elapsed time: 6.164464958943427. Arrivals time: 0.2460127822123468 Scheduler time: 5.818164022639394 Scheduler overhead time: 0.03194948146119714 Adapter cache time: 0.02184730675071478 Engine time: 0.03191904490813613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 9.034378519281745,
    "estimated_duration": 3600.0453436678836,
    "input_throughput": 4596.944599353003,
    "output_throughput": 4075.0275620287807,
    "total_throughput": 8671.972161381784,
    "itl": 211.2613552716672,
    "ttft": 2220479.6418510852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.499243723482354,
    "arrivals": 1499241,
    "finished_requests": 67007,
    "scheduler_time": 110.59812773157994
}
#Debug simulation 
Total elapsed time: 9.034471380058676. Arrivals time: 0.2718727234750986 Scheduler time: 8.677119799423963 Scheduler overhead time: 0.029524659272283316 Adapter cache time: 0.01309484476223588 Engine time: 0.029761457350105047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.229314820840955,
    "estimated_duration": 3600.0602624214966,
    "input_throughput": 4398.7333115775355,
    "output_throughput": 3915.545011048932,
    "total_throughput": 8314.278322626467,
    "itl": 180.38177871513165,
    "ttft": 2239802.5995496185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0167132563516494,
    "arrivals": 1499241,
    "finished_requests": 64179,
    "scheduler_time": 116.91464658769978
}
#Debug simulation 
Total elapsed time: 6.229431957937777. Arrivals time: 0.24736554361879826 Scheduler time: 5.881004313006997 Scheduler overhead time: 0.03228037478402257 Adapter cache time: 0.022102465853095055 Engine time: 0.03200941253453493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 9.144790513906628,
    "estimated_duration": 3600.2120502830785,
    "input_throughput": 4596.974502848713,
    "output_throughput": 4074.850812981001,
    "total_throughput": 8671.825315829714,
    "itl": 211.2556356501128,
    "ttft": 2220488.87779075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4322340912581282,
    "arrivals": 1499241,
    "finished_requests": 67010,
    "scheduler_time": 110.604928672892
}
#Debug simulation 
Total elapsed time: 9.144879875238985. Arrivals time: 0.26868285005912185 Scheduler time: 8.790603928733617 Scheduler overhead time: 0.029669306240975857 Adapter cache time: 0.013012032955884933 Engine time: 0.029755104333162308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.280057293828577,
    "estimated_duration": 3600.0998872198634,
    "input_throughput": 4398.684896554063,
    "output_throughput": 3915.5019142776146,
    "total_throughput": 8314.186810831678,
    "itl": 180.38357420983138,
    "ttft": 2239817.709355102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0561999452859476,
    "arrivals": 1499241,
    "finished_requests": 64179,
    "scheduler_time": 116.91478469717326
}
#Debug simulation 
Total elapsed time: 6.280150864738971. Arrivals time: 0.261177446693182 Scheduler time: 5.917867038398981 Scheduler overhead time: 0.03207111405208707 Adapter cache time: 0.022218368016183376 Engine time: 0.03209936013445258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.673506366554648,
    "estimated_duration": 3600.013531824658,
    "input_throughput": 4602.93992050669,
    "output_throughput": 4076.0669009381672,
    "total_throughput": 8679.006821444857,
    "itl": 211.02859938946537,
    "ttft": 2218862.0720549305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3710985092818853,
    "arrivals": 1497804,
    "finished_requests": 66993,
    "scheduler_time": 110.62055936870121
}
#Debug simulation 
Total elapsed time: 8.673622868955135. Arrivals time: 0.26666690688580275 Scheduler time: 8.32332923496142 Scheduler overhead time: 0.02900790609419346 Adapter cache time: 0.0123494160361588 Engine time: 0.02928706305101514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 8.613575675990433,
    "estimated_duration": 3600.1039312665007,
    "input_throughput": 4602.824339621362,
    "output_throughput": 4075.964549956142,
    "total_throughput": 8678.788889577503,
    "itl": 211.03273527795102,
    "ttft": 2218898.1922109397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4608953416929629,
    "arrivals": 1497804,
    "finished_requests": 66993,
    "scheduler_time": 110.62116197810052
}
#Debug simulation 
Total elapsed time: 8.613662951160222. Arrivals time: 0.26499612675979733 Scheduler time: 8.264466483145952 Scheduler overhead time: 0.029178558848798275 Adapter cache time: 0.012428383808583021 Engine time: 0.029306401032954454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.119355195201933,
    "estimated_duration": 3600.070830584891,
    "input_throughput": 4403.002259104086,
    "output_throughput": 3906.420918311535,
    "total_throughput": 8309.423177415621,
    "itl": 179.44070665330398,
    "ttft": 2238909.8871564157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5777085199206966,
    "arrivals": 1497804,
    "finished_requests": 64071,
    "scheduler_time": 117.11627658320884
}
#Debug simulation 
Total elapsed time: 6.119443066883832. Arrivals time: 0.35138427652418613 Scheduler time: 5.669275036547333 Scheduler overhead time: 0.0321249277330935 Adapter cache time: 0.01991040864959359 Engine time: 0.03196109877899289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 8.610602675937116,
    "estimated_duration": 3600.043505251796,
    "input_throughput": 4602.901597113063,
    "output_throughput": 4076.03296421099,
    "total_throughput": 8678.934561324053,
    "itl": 211.02985100635064,
    "ttft": 2218875.1761515997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4008318298822229,
    "arrivals": 1497804,
    "finished_requests": 66993,
    "scheduler_time": 110.62079947519105
}
#Debug simulation 
Total elapsed time: 8.610705978702754. Arrivals time: 0.2607913906686008 Scheduler time: 8.265747158322483 Scheduler overhead time: 0.029114946722984314 Adapter cache time: 0.0126475696451962 Engine time: 0.029378187842667103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.01322759501636,
    "estimated_duration": 3600.103900335487,
    "input_throughput": 4402.961814108438,
    "output_throughput": 3906.385034801206,
    "total_throughput": 8309.346848909645,
    "itl": 179.44221222147883,
    "ttft": 2238922.282577964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6106560119614053,
    "arrivals": 1497804,
    "finished_requests": 64071,
    "scheduler_time": 117.11639884179466
}
#Debug simulation 
Total elapsed time: 6.0133134867064655. Arrivals time: 0.24172264011576772 Scheduler time: 5.672682758886367 Scheduler overhead time: 0.0321026504971087 Adapter cache time: 0.019797322805970907 Engine time: 0.032289739698171616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 8.730937687214464,
    "estimated_duration": 3600.219260386051,
    "input_throughput": 4602.868270368361,
    "output_throughput": 4076.0106367595104,
    "total_throughput": 8678.878907127872,
    "itl": 211.0280279349596,
    "ttft": 2218887.237981085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.339542532116164,
    "arrivals": 1497804,
    "finished_requests": 66996,
    "scheduler_time": 110.62767303758638
}
#Debug simulation 
Total elapsed time: 8.731035714037716. Arrivals time: 0.28206590050831437 Scheduler time: 8.364063849207014 Scheduler overhead time: 0.02954109711572528 Adapter cache time: 0.012552336324006319 Engine time: 0.029711492359638214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_384_slots_128_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.0097690569236875,
    "estimated_duration": 3600.137991829433,
    "input_throughput": 4402.920120277155,
    "output_throughput": 3906.348043301973,
    "total_throughput": 8309.268163579127,
    "itl": 179.44370677514192,
    "ttft": 2238936.2664508685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6446095342934304,
    "arrivals": 1497804,
    "finished_requests": 64071,
    "scheduler_time": 117.11653681343435
}
#Debug simulation 
Total elapsed time: 6.009856810793281. Arrivals time: 0.241613594815135 Scheduler time: 5.669476941227913 Scheduler overhead time: 0.03231362998485565 Adapter cache time: 0.019553341902792454 Engine time: 0.03215942671522498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.665685614105314,
    "estimated_duration": 3600.202762089495,
    "input_throughput": 4635.006165684728,
    "output_throughput": 4071.215419959629,
    "total_throughput": 8706.221585644358,
    "itl": 209.9013709140255,
    "ttft": 2215404.4966748543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.487397043551334,
    "arrivals": 1490652,
    "finished_requests": 67477,
    "scheduler_time": 110.73970971590346
}
#Debug simulation 
Total elapsed time: 7.665773890912533. Arrivals time: 0.2574192248284817 Scheduler time: 7.324102878104895 Scheduler overhead time: 0.028810746502131224 Adapter cache time: 0.013297234661877155 Engine time: 0.02926348987966776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.742172954138368,
    "estimated_duration": 3600.0863881915834,
    "input_throughput": 4634.813224129789,
    "output_throughput": 4071.1267507561934,
    "total_throughput": 8705.939974885981,
    "itl": 209.90667156267838,
    "ttft": 2215398.5755351125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5888180890446582,
    "arrivals": 1490652,
    "finished_requests": 67472,
    "scheduler_time": 110.73338172495784
}
#Debug simulation 
Total elapsed time: 7.742271333932877. Arrivals time: 0.2629804080352187 Scheduler time: 7.395019978750497 Scheduler overhead time: 0.028869959991425276 Adapter cache time: 0.013396112248301506 Engine time: 0.02894565463066101 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.7417514328844845,
    "estimated_duration": 3600.0877414906245,
    "input_throughput": 4442.850882678036,
    "output_throughput": 3908.9008408926434,
    "total_throughput": 8351.75172357068,
    "itl": 179.2114597125395,
    "ttft": 2235412.179875757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5807520387694156,
    "arrivals": 1490652,
    "finished_requests": 64659,
    "scheduler_time": 117.06083862116724
}
#Debug simulation 
Total elapsed time: 5.741838437039405. Arrivals time: 0.3508286918513477 Scheduler time: 5.292107243090868 Scheduler overhead time: 0.032127019949257374 Adapter cache time: 0.020067987963557243 Engine time: 0.03203834081068635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 7.744438171386719,
    "estimated_duration": 3600.020649886404,
    "input_throughput": 4634.897858301592,
    "output_throughput": 4071.201091711091,
    "total_throughput": 8706.098950012683,
    "itl": 209.90354663318786,
    "ttft": 2215370.4483457697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5234428380941913,
    "arrivals": 1490652,
    "finished_requests": 67472,
    "scheduler_time": 110.73301867071315
}
#Debug simulation 
Total elapsed time: 7.744523528963327. Arrivals time: 0.2643257090821862 Scheduler time: 7.396066798828542 Scheduler overhead time: 0.028738010209053755 Adapter cache time: 0.013362467754632235 Engine time: 0.029039282351732254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.581312912050635,
    "estimated_duration": 3600.1192899285766,
    "input_throughput": 4442.811949244416,
    "output_throughput": 3908.866586551132,
    "total_throughput": 8351.678535795547,
    "itl": 179.21286833173278,
    "ttft": 2235424.408905361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 789,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6121904853731386,
    "arrivals": 1490652,
    "finished_requests": 64659,
    "scheduler_time": 117.06094861254432
}
#Debug simulation 
Total elapsed time: 5.581429722253233. Arrivals time: 0.23975575901567936 Scheduler time: 5.243724638596177 Scheduler overhead time: 0.03181424317881465 Adapter cache time: 0.019597995560616255 Engine time: 0.03191318875178695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_128_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.749759349040687,
    "estimated_duration": 3600.1683410705114,
    "input_throughput": 4635.050480733388,
    "output_throughput": 4071.2543446348054,
    "total_throughput": 8706.304825368194,
    "itl": 209.89973054162522,
    "ttft": 2215389.5201809984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4531644433224427,
    "arrivals": 1490652,
    "finished_requests": 67477,
    "scheduler_time": 110.73952129709082
}
#Debug simulation 
Total elapsed time: 7.749846022110432. Arrivals time: 0.2639566804282367 Scheduler time: 7.40174415986985 Scheduler overhead time: 0.028831115923821926 Adapter cache time: 0.013353044167160988 Engine time: 0.02901775250211358 
